<!DOCTYPE html>
<html lang="es" xml:lang="es">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.1 Regresión lineal múltiple | Métodos predictivos de aprendizaje estadístico</title>
  <meta name="description" content="2.1 Regresión lineal múltiple | Métodos predictivos de aprendizaje estadístico con R." />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="2.1 Regresión lineal múltiple | Métodos predictivos de aprendizaje estadístico" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="2.1 Regresión lineal múltiple | Métodos predictivos de aprendizaje estadístico con R." />
  <meta name="github-repo" content="rubenfcasal/aprendizaje_estadistico" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.1 Regresión lineal múltiple | Métodos predictivos de aprendizaje estadístico" />
  
  <meta name="twitter:description" content="2.1 Regresión lineal múltiple | Métodos predictivos de aprendizaje estadístico con R." />
  

<meta name="author" content="Rubén Fernández Casal (ruben.fcasal@udc.es)" />
<meta name="author" content="Julián Costa Bouzas (julian.costa@udc.es)" />
<meta name="author" content="Manuel Oviedo de la Fuente (manuel.oviedo@udc.es)" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="clasicos.html"/>
<link rel="next" href="reg-glm.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.30/datatables.js"></script>
<link href="libs/dt-core-1.13.4/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.13.4/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.13.4/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Métodos predictivos de aprendizaje estadístico</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Bienvenida</a></li>
<li class="chapter" data-level="" data-path="prólogo.html"><a href="prólogo.html"><i class="fa fa-check"></i>Prólogo</a>
<ul>
<li class="chapter" data-level="" data-path="el-lenguaje-de-programación-r.html"><a href="el-lenguaje-de-programación-r.html"><i class="fa fa-check"></i>El lenguaje de programación R</a></li>
<li class="chapter" data-level="" data-path="organización.html"><a href="organización.html"><i class="fa fa-check"></i>Organización</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro-AE.html"><a href="intro-AE.html"><i class="fa fa-check"></i><b>1</b> Introducción al aprendizaje estadístico</a>
<ul>
<li class="chapter" data-level="1.1" data-path="aprendizaje-estadístico-vs.-aprendizaje-automático.html"><a href="aprendizaje-estadístico-vs.-aprendizaje-automático.html"><i class="fa fa-check"></i><b>1.1</b> Aprendizaje estadístico vs. aprendizaje automático</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="aprendizaje-estadístico-vs.-aprendizaje-automático.html"><a href="aprendizaje-estadístico-vs.-aprendizaje-automático.html#las-dos-culturas"><i class="fa fa-check"></i><b>1.1.1</b> Las dos culturas</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="métodos-de-aprendizaje-estadístico.html"><a href="métodos-de-aprendizaje-estadístico.html"><i class="fa fa-check"></i><b>1.2</b> Métodos de aprendizaje estadístico</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="métodos-de-aprendizaje-estadístico.html"><a href="métodos-de-aprendizaje-estadístico.html#notacion"><i class="fa fa-check"></i><b>1.2.1</b> Notación y terminología</a></li>
<li class="chapter" data-level="1.2.2" data-path="métodos-de-aprendizaje-estadístico.html"><a href="métodos-de-aprendizaje-estadístico.html#metodos-pkgs"><i class="fa fa-check"></i><b>1.2.2</b> Métodos (de aprendizaje supervisado) y paquetes de R</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="const-eval.html"><a href="const-eval.html"><i class="fa fa-check"></i><b>1.3</b> Construcción y evaluación de los modelos</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="const-eval.html"><a href="const-eval.html#bias-variance"><i class="fa fa-check"></i><b>1.3.1</b> Equilibrio entre sesgo y varianza: infraajuste y sobreajuste</a></li>
<li class="chapter" data-level="1.3.2" data-path="const-eval.html"><a href="const-eval.html#entrenamiento-test"><i class="fa fa-check"></i><b>1.3.2</b> Datos de entrenamiento y datos de test</a></li>
<li class="chapter" data-level="1.3.3" data-path="const-eval.html"><a href="const-eval.html#cv"><i class="fa fa-check"></i><b>1.3.3</b> Selección de hiperparámetros mediante validación cruzada</a></li>
<li class="chapter" data-level="1.3.4" data-path="const-eval.html"><a href="const-eval.html#eval-reg"><i class="fa fa-check"></i><b>1.3.4</b> Evaluación de un método de regresión</a></li>
<li class="chapter" data-level="1.3.5" data-path="const-eval.html"><a href="const-eval.html#eval-class"><i class="fa fa-check"></i><b>1.3.5</b> Evaluación de un método de clasificación</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="dimen-curse.html"><a href="dimen-curse.html"><i class="fa fa-check"></i><b>1.4</b> La maldición de la dimensionalidad</a></li>
<li class="chapter" data-level="1.5" data-path="analisis-modelos.html"><a href="analisis-modelos.html"><i class="fa fa-check"></i><b>1.5</b> Análisis e interpretación de los modelos</a></li>
<li class="chapter" data-level="1.6" data-path="caret.html"><a href="caret.html"><i class="fa fa-check"></i><b>1.6</b> Introducción al paquete <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="clasicos.html"><a href="clasicos.html"><i class="fa fa-check"></i><b>2</b> Métodos clásicos de estadística</a>
<ul>
<li class="chapter" data-level="2.1" data-path="rlm.html"><a href="rlm.html"><i class="fa fa-check"></i><b>2.1</b> Regresión lineal múltiple</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="rlm.html"><a href="rlm.html#colinealidad"><i class="fa fa-check"></i><b>2.1.1</b> El problema de la colinealidad</a></li>
<li class="chapter" data-level="2.1.2" data-path="rlm.html"><a href="rlm.html#seleccion-rlm"><i class="fa fa-check"></i><b>2.1.2</b> Selección de variables explicativas</a></li>
<li class="chapter" data-level="2.1.3" data-path="rlm.html"><a href="rlm.html#analisis-rlm"><i class="fa fa-check"></i><b>2.1.3</b> Análisis e interpretación del modelo</a></li>
<li class="chapter" data-level="2.1.4" data-path="rlm.html"><a href="rlm.html#eval-rlm"><i class="fa fa-check"></i><b>2.1.4</b> Evaluación de la precisión</a></li>
<li class="chapter" data-level="2.1.5" data-path="rlm.html"><a href="rlm.html#selec-ae-rlm"><i class="fa fa-check"></i><b>2.1.5</b> Selección del modelo mediante remuestreo</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="reg-glm.html"><a href="reg-glm.html"><i class="fa fa-check"></i><b>2.2</b> Modelos lineales generalizados</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="reg-glm.html"><a href="reg-glm.html#seleccion-glm"><i class="fa fa-check"></i><b>2.2.1</b> Selección de variables explicativas</a></li>
<li class="chapter" data-level="2.2.2" data-path="reg-glm.html"><a href="reg-glm.html#analisis-glm"><i class="fa fa-check"></i><b>2.2.2</b> Análisis e interpretación del modelo</a></li>
<li class="chapter" data-level="2.2.3" data-path="reg-glm.html"><a href="reg-glm.html#glm-bfan"><i class="fa fa-check"></i><b>2.2.3</b> Evaluación de la precisión</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="generadores.html"><a href="generadores.html"><i class="fa fa-check"></i><b>2.3</b> Otros métodos de clasificación</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="generadores.html"><a href="generadores.html#clas-lda"><i class="fa fa-check"></i><b>2.3.1</b> Análisis discriminante lineal</a></li>
<li class="chapter" data-level="2.3.2" data-path="generadores.html"><a href="generadores.html#clas-qda"><i class="fa fa-check"></i><b>2.3.2</b> Análisis discriminante cuadrático</a></li>
<li class="chapter" data-level="2.3.3" data-path="generadores.html"><a href="generadores.html#bayes"><i class="fa fa-check"></i><b>2.3.3</b> Bayes naíf</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="trees.html"><a href="trees.html"><i class="fa fa-check"></i><b>3</b> Árboles de decisión</a>
<ul>
<li class="chapter" data-level="3.1" data-path="árboles-de-regresión-cart.html"><a href="árboles-de-regresión-cart.html"><i class="fa fa-check"></i><b>3.1</b> Árboles de regresión CART</a></li>
<li class="chapter" data-level="3.2" data-path="árboles-de-clasificación-cart.html"><a href="árboles-de-clasificación-cart.html"><i class="fa fa-check"></i><b>3.2</b> Árboles de clasificación CART</a></li>
<li class="chapter" data-level="3.3" data-path="tree-rpart.html"><a href="tree-rpart.html"><i class="fa fa-check"></i><b>3.3</b> CART con el paquete <code>rpart</code></a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="tree-rpart.html"><a href="tree-rpart.html#reg-rpart"><i class="fa fa-check"></i><b>3.3.1</b> Ejemplo: regresión</a></li>
<li class="chapter" data-level="3.3.2" data-path="tree-rpart.html"><a href="tree-rpart.html#class-rpart"><i class="fa fa-check"></i><b>3.3.2</b> Ejemplo: modelo de clasificación</a></li>
<li class="chapter" data-level="3.3.3" data-path="tree-rpart.html"><a href="tree-rpart.html#interfaz-de-caret"><i class="fa fa-check"></i><b>3.3.3</b> Interfaz de <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="alternativas-a-los-árboles-cart.html"><a href="alternativas-a-los-árboles-cart.html"><i class="fa fa-check"></i><b>3.4</b> Alternativas a los árboles CART</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bagging-boosting.html"><a href="bagging-boosting.html"><i class="fa fa-check"></i><b>4</b> Bagging y boosting</a>
<ul>
<li class="chapter" data-level="4.1" data-path="bagging.html"><a href="bagging.html"><i class="fa fa-check"></i><b>4.1</b> Bagging</a></li>
<li class="chapter" data-level="4.2" data-path="rf.html"><a href="rf.html"><i class="fa fa-check"></i><b>4.2</b> Bosques aleatorios</a></li>
<li class="chapter" data-level="4.3" data-path="bagging-rf-r.html"><a href="bagging-rf-r.html"><i class="fa fa-check"></i><b>4.3</b> Bagging y bosques aleatorios en R</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="bagging-rf-r.html"><a href="bagging-rf-r.html#ejemplo-clasificación-con-bagging"><i class="fa fa-check"></i><b>4.3.1</b> Ejemplo: clasificación con bagging</a></li>
<li class="chapter" data-level="4.3.2" data-path="bagging-rf-r.html"><a href="bagging-rf-r.html#ejemplo-clasif-rf"><i class="fa fa-check"></i><b>4.3.2</b> Ejemplo: clasificación con bosques aleatorios</a></li>
<li class="chapter" data-level="4.3.3" data-path="bagging-rf-r.html"><a href="bagging-rf-r.html#ejemplo-bosques-aleatorios-con-caret"><i class="fa fa-check"></i><b>4.3.3</b> Ejemplo: bosques aleatorios con <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="boosting.html"><a href="boosting.html"><i class="fa fa-check"></i><b>4.4</b> Boosting</a></li>
<li class="chapter" data-level="4.5" data-path="boosting-r.html"><a href="boosting-r.html"><i class="fa fa-check"></i><b>4.5</b> Boosting en R</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="boosting-r.html"><a href="boosting-r.html#ejemplo-clasificación-con-el-paquete-ada"><i class="fa fa-check"></i><b>4.5.1</b> Ejemplo: clasificación con el paquete <code>ada</code></a></li>
<li class="chapter" data-level="4.5.2" data-path="boosting-r.html"><a href="boosting-r.html#ejemplo-regresión-con-el-paquete-gbm"><i class="fa fa-check"></i><b>4.5.2</b> Ejemplo: regresión con el paquete <code>gbm</code></a></li>
<li class="chapter" data-level="4.5.3" data-path="boosting-r.html"><a href="boosting-r.html#xgb-caret"><i class="fa fa-check"></i><b>4.5.3</b> Ejemplo: XGBoost con el paquete <code>caret</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="svm.html"><a href="svm.html"><i class="fa fa-check"></i><b>5</b> Máquinas de soporte vectorial</a>
<ul>
<li class="chapter" data-level="5.1" data-path="clasificadores-de-máximo-margen.html"><a href="clasificadores-de-máximo-margen.html"><i class="fa fa-check"></i><b>5.1</b> Clasificadores de máximo margen</a></li>
<li class="chapter" data-level="5.2" data-path="clasificadores-de-soporte-vectorial.html"><a href="clasificadores-de-soporte-vectorial.html"><i class="fa fa-check"></i><b>5.2</b> Clasificadores de soporte vectorial</a></li>
<li class="chapter" data-level="5.3" data-path="máquinas-de-soporte-vectorial.html"><a href="máquinas-de-soporte-vectorial.html"><i class="fa fa-check"></i><b>5.3</b> Máquinas de soporte vectorial</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="máquinas-de-soporte-vectorial.html"><a href="máquinas-de-soporte-vectorial.html#regresión-con-svm"><i class="fa fa-check"></i><b>5.3.1</b> Regresión con SVM</a></li>
<li class="chapter" data-level="5.3.2" data-path="máquinas-de-soporte-vectorial.html"><a href="máquinas-de-soporte-vectorial.html#ventajas-e-incovenientes"><i class="fa fa-check"></i><b>5.3.2</b> Ventajas e incovenientes</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="svm-kernlab.html"><a href="svm-kernlab.html"><i class="fa fa-check"></i><b>5.4</b> SVM en R</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ext-glm.html"><a href="ext-glm.html"><i class="fa fa-check"></i><b>6</b> Extensiones de los modelos lineales (generalizados)</a>
<ul>
<li class="chapter" data-level="6.1" data-path="shrinkage.html"><a href="shrinkage.html"><i class="fa fa-check"></i><b>6.1</b> Métodos de regularización</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="shrinkage.html"><a href="shrinkage.html#implementación-en-r"><i class="fa fa-check"></i><b>6.1.1</b> Implementación en R</a></li>
<li class="chapter" data-level="6.1.2" data-path="shrinkage.html"><a href="shrinkage.html#ejemplo-ridge-regression"><i class="fa fa-check"></i><b>6.1.2</b> Ejemplo: <em>ridge regression</em></a></li>
<li class="chapter" data-level="6.1.3" data-path="shrinkage.html"><a href="shrinkage.html#ejemplo-lasso"><i class="fa fa-check"></i><b>6.1.3</b> Ejemplo: LASSO</a></li>
<li class="chapter" data-level="6.1.4" data-path="shrinkage.html"><a href="shrinkage.html#ejemplo-elastic-net"><i class="fa fa-check"></i><b>6.1.4</b> Ejemplo: <em>elastic net</em></a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="pca-pls.html"><a href="pca-pls.html"><i class="fa fa-check"></i><b>6.2</b> Métodos de reducción de la dimensión</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="pca-pls.html"><a href="pca-pls.html#regresión-por-componentes-principales-pcr"><i class="fa fa-check"></i><b>6.2.1</b> Regresión por componentes principales (PCR)</a></li>
<li class="chapter" data-level="6.2.2" data-path="pca-pls.html"><a href="pca-pls.html#regresión-por-mínimos-cuadrados-parciales-plsr"><i class="fa fa-check"></i><b>6.2.2</b> Regresión por mínimos cuadrados parciales (PLSR)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="reg-np.html"><a href="reg-np.html"><i class="fa fa-check"></i><b>7</b> Regresión no paramétrica</a>
<ul>
<li class="chapter" data-level="7.1" data-path="reg-local.html"><a href="reg-local.html"><i class="fa fa-check"></i><b>7.1</b> Regresión local</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="reg-local.html"><a href="reg-local.html#reg-knn"><i class="fa fa-check"></i><b>7.1.1</b> Vecinos más próximos</a></li>
<li class="chapter" data-level="7.1.2" data-path="reg-local.html"><a href="reg-local.html#reg-locpol"><i class="fa fa-check"></i><b>7.1.2</b> Regresión polinómica local</a></li>
<li class="chapter" data-level="7.1.3" data-path="reg-local.html"><a href="reg-local.html#regresión-polinómica-local-robusta"><i class="fa fa-check"></i><b>7.1.3</b> Regresión polinómica local robusta</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>7.2</b> Splines</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="splines.html"><a href="splines.html#reg-splines"><i class="fa fa-check"></i><b>7.2.1</b> Splines de regresión</a></li>
<li class="chapter" data-level="7.2.2" data-path="splines.html"><a href="splines.html#splines-de-suavizado"><i class="fa fa-check"></i><b>7.2.2</b> Splines de suavizado</a></li>
<li class="chapter" data-level="7.2.3" data-path="splines.html"><a href="splines.html#splines-penalizados"><i class="fa fa-check"></i><b>7.2.3</b> Splines penalizados</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="reg-gam.html"><a href="reg-gam.html"><i class="fa fa-check"></i><b>7.3</b> Modelos aditivos</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="reg-gam.html"><a href="reg-gam.html#superficies-de-predicción"><i class="fa fa-check"></i><b>7.3.1</b> Superficies de predicción</a></li>
<li class="chapter" data-level="7.3.2" data-path="reg-gam.html"><a href="reg-gam.html#anova-gam"><i class="fa fa-check"></i><b>7.3.2</b> Comparación y selección de modelos</a></li>
<li class="chapter" data-level="7.3.3" data-path="reg-gam.html"><a href="reg-gam.html#mgcv-diagnosis"><i class="fa fa-check"></i><b>7.3.3</b> Diagnosis del modelo</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="mars.html"><a href="mars.html"><i class="fa fa-check"></i><b>7.4</b> Regresión spline adaptativa multivariante</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="mars.html"><a href="mars.html#mars-con-el-paquete-earth"><i class="fa fa-check"></i><b>7.4.1</b> MARS con el paquete <code>earth</code></a></li>
<li class="chapter" data-level="7.4.2" data-path="mars.html"><a href="mars.html#mars-con-el-paquete-caret"><i class="fa fa-check"></i><b>7.4.2</b> MARS con el paquete <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="pursuit.html"><a href="pursuit.html"><i class="fa fa-check"></i><b>7.5</b> Projection pursuit</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="pursuit.html"><a href="pursuit.html#ppr"><i class="fa fa-check"></i><b>7.5.1</b> Regresión por projection pursuit</a></li>
<li class="chapter" data-level="7.5.2" data-path="pursuit.html"><a href="pursuit.html#implementación-en-r-1"><i class="fa fa-check"></i><b>7.5.2</b> Implementación en R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="neural-nets.html"><a href="neural-nets.html"><i class="fa fa-check"></i><b>8</b> Redes neuronales</a>
<ul>
<li class="chapter" data-level="8.1" data-path="single-hidden-layer-feedforward-network.html"><a href="single-hidden-layer-feedforward-network.html"><i class="fa fa-check"></i><b>8.1</b> Single-hidden-layer feedforward network</a></li>
<li class="chapter" data-level="8.2" data-path="clasificación-con-ann.html"><a href="clasificación-con-ann.html"><i class="fa fa-check"></i><b>8.2</b> Clasificación con ANN</a></li>
<li class="chapter" data-level="8.3" data-path="implementación-en-r-2.html"><a href="implementación-en-r-2.html"><i class="fa fa-check"></i><b>8.3</b> Implementación en R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliografía.html"><a href="bibliografía.html"><i class="fa fa-check"></i>Bibliografía</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Métodos predictivos de aprendizaje estadístico</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="rlm" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Regresión lineal múltiple<a href="rlm.html#rlm" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En los modelos lineales se supone que la función de regresión es lineal<a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a>:
<span class="math display">\[E( Y \vert \mathbf{X} ) = \beta_{0}+\beta_{1}X_{1}+\beta_{2}X_{2}+\ldots+\beta_{p}X_{p}\]</span>
siendo <span class="math inline">\(\left( \beta_{0},\beta_{1},\ldots,\beta_{p}\right)^t\)</span> un vector de parámetros (desconocidos).
Es decir, que el efecto de las variables explicativas sobre la respuesta es muy simple, proporcional a su valor, y por tanto la interpretación de este tipo de modelos es (en principio) muy fácil.
El coeficiente <span class="math inline">\(\beta_j\)</span> representa el incremento medio de <span class="math inline">\(Y\)</span> al aumentar en una unidad el valor de <span class="math inline">\(X_j\)</span>, manteniendo fijas el resto de las covariables.
En este contexto las variables predictoras se denominan habitualmente variables independientes, pero en la práctica es de esperar que no haya independencia entre ellas, por lo que puede no ser muy razonable pensar que al variar una de ellas el resto va a permanecer constante.</p>
<p>El ajuste de este tipo de modelos en la práctica se suele realizar empleando el método de mínimos cuadrados (ordinarios), asumiendo (implícita o explícitamente) que la distribución condicional de la respuesta es normal, lo que se conoce como el modelo de regresión lineal múltiple.
Concretamente, el método tradicional considera el siguiente modelo:
<span class="math display" id="eq:modelo-rlm">\[\begin{equation}
  Y = \beta_{0}+\beta_{1}X_{1}+\beta_{2}X_{2}+\ldots+\beta_{p}X_{p} + \varepsilon,
  \tag{2.1}
\end{equation}\]</span>
donde <span class="math inline">\(\varepsilon\)</span> es un error aleatorio normal, de media cero y varianza <span class="math inline">\(\sigma^2\)</span>, independiente de las variables predictoras. Además, los errores de las distintas observaciones son independientes entre sí.</p>
<p>Por tanto las hipótesis estructurales del modelo son: linealidad (el efecto de los predictores es lineal), homocedasticidad (varianza constante del error), normalidad (y homogeneidad: ausencia de valores atípicos y/o influyentes) e independencia de los errores.
Estas son también las hipótesis del modelo de regresión lineal simple (con una única variable explicativa); en regresión múltiple tendríamos la hipótesis adicional de que ninguna de las variables explicativas es combinación lineal de las demás.
Esto está relacionado con el fenómeno de la colinealidad (o multicolinealidad), que se tratará en la Sección <a href="rlm.html#colinealidad">2.1.1</a>, y que es de especial interés en regresión múltiple (no solo en el caso lineal).
Además, se da por hecho que el número de observaciones disponible es como mínimo el número de parámetros del modelo, <span class="math inline">\(n \geq p + 1\)</span>.</p>
<!-- ### Ajuste: función `lm` -->
<p>El procedimiento habitual para ajustar un modelo de regresión lineal a un conjunto de datos es emplear mínimos cuadrados (ordinarios; el método más eficiente bajo las hipótesis estructurales):</p>
<p><span class="math display">\[\mbox{min}_{\beta_{0},\beta_{1},\ldots,\beta_{p}}  \sum\limits_{i=1}^{n}\left(  y_{i} - \beta_0 - \beta_1 x_{1i} - \ldots - \beta_p x_{pi} \right)^{2} = \mbox{min}_{\beta_{0},\beta_{1},\ldots,\beta_{p}} \ RSS\]</span></p>
<p>denotando por RSS la suma de cuadrados residual (<em>residual sum of squares</em>), es decir, la suma de los residuos al cuadrado.</p>
<p>Para realizar este ajuste en R podemos emplear la función <a href="https://rdrr.io/r/stats/lm.html"><code>lm()</code></a>:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="rlm.html#cb76-1" aria-hidden="true" tabindex="-1"></a>ajuste <span class="ot">&lt;-</span> <span class="fu">lm</span>(formula, data, subset, weights, na.action, ...)</span></code></pre></div>
<ul>
<li><p><code>formula</code>: fórmula que especifica el modelo.</p></li>
<li><p><code>data</code>: data.frame (opcional) con las variables de la fórmula.</p></li>
<li><p><code>subset</code>: vector (opcional) que especifica un subconjunto de observaciones.</p></li>
<li><p><code>weights</code>: vector (opcional) de pesos (mínimos cuadrados ponderados, WLS).</p></li>
<li><p><code>na.action</code>: opción para manejar los datos faltantes; por defecto <code>na.omit</code>.</p></li>
</ul>
<p>Alternativamente, se puede emplear la función <code>biglm()</code> del paquete <a href="https://CRAN.R-project.org/package=biglm"><code>biglm</code></a> para ajustar modelos lineales a grandes conjuntos de datos (especialmente cuando el número de observaciones es muy grande, incluyendo el caso de que los datos excedan la capacidad de memoria del equipo).
También se podría utilizar la función <code>rlm()</code> del paquete <a href="https://CRAN.R-project.org/package=MASS"><code>MASS</code></a> para ajustar modelos lineales empleando un método robusto cuando hay datos atípicos.</p>
<!-- 
Proxeccións demográficas de Galicia 2011-2030. Análise dos resultados. Documentos de Traballo. Análise Económica (IDEGA).  
-->
<!-- ### Ejemplo -->
<p>Como ejemplo, consideraremos el conjunto de datos <a href="https://rubenfcasal.github.io/mpae/reference/bodyfat.html"><code>bodyfat</code></a> del paquete <a href="https://rubenfcasal.github.io/mpae"><code>mpae</code></a>, que contiene observaciones de grasa corporal y mediciones corporales de una muestra de 246 hombres <span class="citation">(<a href="#ref-penrose1985generalized" role="doc-biblioref">Penrose et al., 1985</a>)</span>.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="rlm.html#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mpae)</span>
<span id="cb77-2"><a href="rlm.html#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="co"># data(bodyfat, package = &quot;mpae&quot;)</span></span>
<span id="cb77-3"><a href="rlm.html#cb77-3" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.frame</span>(<span class="fu">attr</span>(bodyfat, <span class="st">&quot;variable.labels&quot;</span>))</span></code></pre></div>
<pre><code>##                     attr(bodyfat, &quot;variable.labels&quot;)
## bodyfat Percent body fat (from Siri&#39;s 1956 equation)
## age                                      Age (years)
## weight                                   Weight (kg)
## height                                   Height (cm)
## neck                         Neck circumference (cm)
## chest                       Chest circumference (cm)
## abdomen                   Abdomen circumference (cm)
## hip                           Hip circumference (cm)
## thigh                       Thigh circumference (cm)
## knee                         Knee circumference (cm)
## ankle                       Ankle circumference (cm)
## biceps          Biceps (extended) circumference (cm)
## forearm                   Forearm circumference (cm)
## wrist                       Wrist circumference (cm)</code></pre>
<p>Consideraremos como respuesta la variable <code>bodyfat</code>, que mide la grasa corporal (en porcentaje) a partir de la densidad corporal, obtenida mediante un procedimiento costoso que requiere un pesaje subacuático.
El objetivo es disponer de una forma más sencilla de estimar la grasa corporal a partir de medidas corporales.
En este caso todos los predictores son numéricos; para una introducción al tratamiento de variables predictoras categóricas ver, por ejemplo, la <a href="https://rubenfcasal.github.io/intror/modelos-lineales.html#regresion-con-variables-categoricas">Sección 8.5</a> de <span class="citation">Fernández-Casal et al. (<a href="#ref-fernandez2022intror" role="doc-biblioref">2022</a>)</span>.</p>
<p>La regresión lineal es un método clásico de estadística y, por tanto, el procedimiento habitual es emplear toda la información disponible para construir el modelo y, posteriormente (asumiendo que es el verdadero), utilizar métodos de inferencia para evaluar su precisión.
Sin embargo, seguiremos el procedimiento habitual en AE y particionaremos los datos en una muestra de entrenamiento y en otra de test.</p>
<!-- 
Pendiente: 
 Ejercicio repetir ejemplo con bodyfat.raw[-1]
 Emplear regresión robusta MASS::rlm() para evitar efecto de atípicos
 A mano y con caret
-->
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="rlm.html#cb79-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> bodyfat </span>
<span id="cb79-2"><a href="rlm.html#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb79-3"><a href="rlm.html#cb79-3" aria-hidden="true" tabindex="-1"></a>nobs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(df)</span>
<span id="cb79-4"><a href="rlm.html#cb79-4" aria-hidden="true" tabindex="-1"></a>itrain <span class="ot">&lt;-</span> <span class="fu">sample</span>(nobs, <span class="fl">0.8</span> <span class="sc">*</span> nobs)</span>
<span id="cb79-5"><a href="rlm.html#cb79-5" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> df[itrain, ]</span>
<span id="cb79-6"><a href="rlm.html#cb79-6" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> df[<span class="sc">-</span>itrain, ]</span></code></pre></div>
<p>El primer paso antes del modelado suele ser realizar un análisis descriptivo.
Por ejemplo, podemos generar un gráfico de dispersión matricial y calcular la matriz de correlaciones (lineales de Pearson).
Sin embargo, en muchos casos el número de variables es grande y en lugar de emplear gráficos de dispersión puede ser preferible representar gráficamente las correlaciones mediante un mapa de calor o algún gráfico similar.
En la Figura <a href="rlm.html#fig:corrplot">2.1</a> se combinan elipses con colores para representar las correlaciones.</p>

<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="rlm.html#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot(train) # gráfico de dispersión matricial</span></span>
<span id="cb80-2"><a href="rlm.html#cb80-2" aria-hidden="true" tabindex="-1"></a>mcor <span class="ot">&lt;-</span> <span class="fu">cor</span>(train)</span>
<span id="cb80-3"><a href="rlm.html#cb80-3" aria-hidden="true" tabindex="-1"></a>corrplot<span class="sc">::</span><span class="fu">corrplot</span>(mcor, <span class="at">method =</span> <span class="st">&quot;ellipse&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:corrplot"></span>
<img src="02-clasicos_files/figure-html/corrplot-1.png" alt="Representación de las correlaciones lineales entre las variables del conjunto de datos bodyfat, generada con la función corrplot::corrplot()." width="80%" />
<p class="caption">
Figura 2.1: Representación de las correlaciones lineales entre las variables del conjunto de datos <code>bodyfat</code>, generada con la función <code>corrplot::corrplot()</code>.
</p>
</div>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="rlm.html#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(mcor, <span class="at">digits =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>##         bodyfat      age  weight  height   neck chest abdomen     hip  thigh
## bodyfat  1.0000  0.23003  0.6174 -0.0294 0.4820 0.701   0.816  0.6259  0.542
## age      0.2300  1.00000 -0.0384 -0.2145 0.0858 0.164   0.204 -0.0718 -0.238
## weight   0.6174 -0.03838  1.0000  0.4923 0.7947 0.882   0.876  0.9313  0.849
## height  -0.0294 -0.21445  0.4923  1.0000 0.3116 0.179   0.177  0.3785  0.342
##             knee  ankle  biceps forearm wrist
## bodyfat  0.47448  0.213  0.4681   0.353 0.288
## age     -0.00612 -0.167 -0.0662  -0.124 0.153
## weight   0.83207  0.630  0.7771   0.680 0.714
## height   0.51736  0.474  0.3101   0.312 0.390
##  [ reached getOption(&quot;max.print&quot;) -- omitted 10 rows ]</code></pre>
<!-- 
Pendiente: 
gráfico compacto de correlaciones
caret::featurePlot(x = train[-1], y = train[1])
https://plotly.com/ggplot2/splom/
https://www.statology.org/scatterplot-matrix-in-r/
https://daviddalpiaz.github.io/r4sl/generative-models.html
-->
<p>Observamos que, aparentemente, hay una relación (lineal) entre la respuesta <code>bodyfat</code> y algunas de las variables explicativas (que en principio no parece razonable suponer que sean independientes).
Si consideramos un modelo de regresión lineal simple, el mejor ajuste se obtendría empleando <code>abdomen</code> como variable explicativa (ver Figura <a href="rlm.html#fig:lm1">2.2</a>), ya que es la variable más correlacionada con la respuesta (la proporción de variabilidad explicada en la muestra de entrenamiento por este modelo, el coeficiente de determinación <span class="math inline">\(R^2\)</span>, sería <span class="math inline">\(0.816^2 \approx 0.666\)</span>).</p>

<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="rlm.html#cb83-1" aria-hidden="true" tabindex="-1"></a>modelo <span class="ot">&lt;-</span> <span class="fu">lm</span>(bodyfat <span class="sc">~</span> abdomen, <span class="at">data =</span> train)</span>
<span id="cb83-2"><a href="rlm.html#cb83-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = bodyfat ~ abdomen, data = train)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -10.73  -3.49   0.25   3.08  13.02 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -41.8950     3.1071   -13.5   &lt;2e-16 ***
## abdomen       0.6579     0.0335    19.6   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.77 on 194 degrees of freedom
## Multiple R-squared:  0.666,  Adjusted R-squared:  0.664 
## F-statistic:  386 on 1 and 194 DF,  p-value: &lt;2e-16</code></pre>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="rlm.html#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(bodyfat <span class="sc">~</span> abdomen, <span class="at">data =</span> train)</span>
<span id="cb85-2"><a href="rlm.html#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(modelo)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:lm1"></span>
<img src="02-clasicos_files/figure-html/lm1-1.png" alt="Gráfico de dispersión y recta de regresión ajustada para bodyfat en función de abdomen." width="75%" />
<p class="caption">
Figura 2.2: Gráfico de dispersión y recta de regresión ajustada para <code>bodyfat</code> en función de <code>abdomen</code>.
</p>
</div>
<p>El método <code>predict()</code> permite calcular predicciones (estimaciones de la media condicional), intervalos de confianza para la media e intervalos de predicción para nuevas observaciones (la ayuda de <a href="https://rdrr.io/r/stats/predict.lm.html"><code>predict.lm()</code></a> proporciona todas las opciones disponibles).
En la Figura <a href="rlm.html#fig:lm2">2.3</a> se muestra su representación gráfica.</p>

<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="rlm.html#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicciones</span></span>
<span id="cb86-2"><a href="rlm.html#cb86-2" aria-hidden="true" tabindex="-1"></a>valores <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">70</span>, <span class="dv">130</span>, <span class="at">len =</span> <span class="dv">100</span>)</span>
<span id="cb86-3"><a href="rlm.html#cb86-3" aria-hidden="true" tabindex="-1"></a>newdata <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">abdomen =</span> valores)</span>
<span id="cb86-4"><a href="rlm.html#cb86-4" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelo, <span class="at">newdata =</span> newdata, <span class="at">interval =</span> <span class="st">&quot;confidence&quot;</span>)</span>
<span id="cb86-5"><a href="rlm.html#cb86-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Representación</span></span>
<span id="cb86-6"><a href="rlm.html#cb86-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(bodyfat <span class="sc">~</span> abdomen, <span class="at">data =</span> train)</span>
<span id="cb86-7"><a href="rlm.html#cb86-7" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(valores, pred, <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>), <span class="at">col =</span> <span class="dv">1</span>)</span>
<span id="cb86-8"><a href="rlm.html#cb86-8" aria-hidden="true" tabindex="-1"></a>pred2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelo, <span class="at">newdata =</span> newdata, <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>)</span>
<span id="cb86-9"><a href="rlm.html#cb86-9" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(valores, pred2[, <span class="sc">-</span><span class="dv">1</span>], <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="dv">1</span>)</span>
<span id="cb86-10"><a href="rlm.html#cb86-10" aria-hidden="true" tabindex="-1"></a>leyenda <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Ajuste&quot;</span>, <span class="st">&quot;Int. confianza&quot;</span>, <span class="st">&quot;Int. predicción&quot;</span>)</span>
<span id="cb86-11"><a href="rlm.html#cb86-11" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">legend =</span> leyenda, <span class="at">lty =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:lm2"></span>
<img src="02-clasicos_files/figure-html/lm2-1.png" alt="Ajuste lineal (predicciones) e intervalos de confianza y predicción (puntuales)." width="75%" />
<p class="caption">
Figura 2.3: Ajuste lineal (predicciones) e intervalos de confianza y predicción (puntuales).
</p>
</div>
<p>Para la extracción de información se puede acceder a las componentes del modelo ajustado o emplear funciones (genéricas; muchas de ellas válidas para otro tipo de modelos: <code>rlm()</code>, <code>glm()</code>…).
Algunas de las más utilizadas se muestran en la Tabla <a href="rlm.html#tab:aux-fun-lm">2.1</a>.</p>
<table>
<caption><span id="tab:aux-fun-lm">Tabla 2.1: </span> Listado de las principales funciones auxiliares para modelos ajustados.</caption>
<colgroup>
<col width="21%" />
<col width="78%" />
</colgroup>
<thead>
<tr class="header">
<th>Función</th>
<th>Descripción</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>fitted()</code></td>
<td>valores ajustados</td>
</tr>
<tr class="even">
<td><code>coef()</code></td>
<td>coeficientes estimados (y errores estándar)</td>
</tr>
<tr class="odd">
<td><code>confint()</code></td>
<td>intervalos de confianza para los coeficientes</td>
</tr>
<tr class="even">
<td><code>residuals()</code></td>
<td>residuos</td>
</tr>
<tr class="odd">
<td><code>plot()</code></td>
<td>gráficos de diagnóstico</td>
</tr>
<tr class="even">
<td><code>termplot()</code></td>
<td>gráfico de efectos parciales</td>
</tr>
<tr class="odd">
<td><code>anova()</code></td>
<td>calcula tablas de análisis de varianza (también permite comparar modelos)</td>
</tr>
<tr class="even">
<td><code>influence.measures()</code></td>
<td>  calcula medidas de diagnóstico (“dejando uno fuera”; LOOCV)</td>
</tr>
<tr class="odd">
<td><code>update()</code></td>
<td>actualiza un modelo (por ejemplo, eliminando o añadiendo variables)</td>
</tr>
</tbody>
</table>
<div class="exercise">
<p><span id="exr:aux-fun" class="exercise"><strong>Ejercicio 2.1  </strong></span>Después de particionar los datos y ajustar el modelo inicial anterior:</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="rlm.html#cb87-1" aria-hidden="true" tabindex="-1"></a>modelo <span class="ot">&lt;-</span> <span class="fu">lm</span>(bodyfat <span class="sc">~</span> abdomen, <span class="at">data =</span> train)</span></code></pre></div>
<p>ejecuta el siguiente código:</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="rlm.html#cb88-1" aria-hidden="true" tabindex="-1"></a>modelo2 <span class="ot">&lt;-</span> <span class="fu">update</span>(modelo, . <span class="sc">~</span> . <span class="sc">+</span> wrist)</span>
<span id="cb88-2"><a href="rlm.html#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo2)</span>
<span id="cb88-3"><a href="rlm.html#cb88-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(modelo2)</span>
<span id="cb88-4"><a href="rlm.html#cb88-4" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(modelo2)</span>
<span id="cb88-5"><a href="rlm.html#cb88-5" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(modelo, modelo2)</span>
<span id="cb88-6"><a href="rlm.html#cb88-6" aria-hidden="true" tabindex="-1"></a>oldpar <span class="ot">&lt;-</span> <span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb88-7"><a href="rlm.html#cb88-7" aria-hidden="true" tabindex="-1"></a><span class="fu">termplot</span>(modelo2, <span class="at">partial.resid =</span> <span class="cn">TRUE</span>)</span>
<span id="cb88-8"><a href="rlm.html#cb88-8" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(oldpar)</span></code></pre></div>
<p>y responde a las siguientes preguntas sobre el ajuste obtenido al añadir <code>wrist</code> como predictor:</p>
<ol style="list-style-type: lower-alpha">
<li><p>¿Se produce una mejora en la proporción de variabilidad explicada?</p></li>
<li><p>¿Esta mejora es significativa?</p></li>
<li><p>¿Cuáles son las estimaciones de los coeficientes?</p></li>
<li><p>Compara el intervalo de confianza para el efecto de la variable <code>abdomen</code> (rango en el que confiaríamos que variase el porcentaje de grasa al aumentar un centímetro la circunferencia del abdomen) con el del modelo de regresión lineal simple anterior.</p></li>
</ol>
</div>
<!-- Sección \@ref(colinealidad) -->
<div id="colinealidad" class="section level3 hasAnchor" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> El problema de la colinealidad<a href="rlm.html#colinealidad" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Si alguna de las variables explicativas no aporta información relevante sobre la respuesta, puede aparecer el problema de la colinealidad.
En regresión múltiple se supone que ninguna de las variables explicativas es combinación lineal de las demás.
Si una de las variables explicativas (variables independientes) es combinación lineal de las otras, no se pueden determinar los parámetros de forma única.
Sin llegar a esta situación extrema, cuando algunas variables explicativas estén altamente correlacionadas entre sí, tendremos una situación de alta colinealidad.
En este caso, las estimaciones de los parámetros pueden verse seriamente afectadas:</p>
<ul>
<li><p>Tendrán varianzas muy altas (serán poco eficientes).</p></li>
<li><p>Habrá mucha dependencia entre ellas (al modificar ligeramente el
modelo, añadiendo o eliminando una variable o una observación,
se producirán grandes cambios en las estimaciones de los efectos).</p></li>
</ul>
<p>Consideraremos un ejemplo de regresión lineal bidimensional con datos simulados en el que las dos variables explicativas están altamente correlacionadas. Además, en este ejemplo solo una de las variables explicativas tiene un efecto lineal sobre la respuesta:</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="rlm.html#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb89-2"><a href="rlm.html#cb89-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb89-3"><a href="rlm.html#cb89-3" aria-hidden="true" tabindex="-1"></a>rand.gen <span class="ot">&lt;-</span> runif</span>
<span id="cb89-4"><a href="rlm.html#cb89-4" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">rand.gen</span>(n)</span>
<span id="cb89-5"><a href="rlm.html#cb89-5" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fl">0.99</span>) <span class="co"># coeficiente de correlación</span></span>
<span id="cb89-6"><a href="rlm.html#cb89-6" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> rho<span class="sc">*</span>x1 <span class="sc">+</span> <span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">-</span> rho<span class="sc">^</span><span class="dv">2</span>)<span class="sc">*</span><span class="fu">rand.gen</span>(n)</span>
<span id="cb89-7"><a href="rlm.html#cb89-7" aria-hidden="true" tabindex="-1"></a>fit.x2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(x2 <span class="sc">~</span> x1)</span>
<span id="cb89-8"><a href="rlm.html#cb89-8" aria-hidden="true" tabindex="-1"></a><span class="co"># plot(x1, x2); summary(fit.x2)</span></span>
<span id="cb89-9"><a href="rlm.html#cb89-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Rejilla x-y para predicciones:</span></span>
<span id="cb89-10"><a href="rlm.html#cb89-10" aria-hidden="true" tabindex="-1"></a>len.grid <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb89-11"><a href="rlm.html#cb89-11" aria-hidden="true" tabindex="-1"></a>x1.range <span class="ot">&lt;-</span> <span class="fu">range</span>(x1)</span>
<span id="cb89-12"><a href="rlm.html#cb89-12" aria-hidden="true" tabindex="-1"></a>x1.grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(x1.range[<span class="dv">1</span>], x1.range[<span class="dv">2</span>], <span class="at">len =</span> len.grid)</span>
<span id="cb89-13"><a href="rlm.html#cb89-13" aria-hidden="true" tabindex="-1"></a>x2.range <span class="ot">&lt;-</span> <span class="fu">range</span>(x2)</span>
<span id="cb89-14"><a href="rlm.html#cb89-14" aria-hidden="true" tabindex="-1"></a>x2.grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(x2.range[<span class="dv">1</span>], x2.range[<span class="dv">2</span>], <span class="at">len =</span> len.grid)</span>
<span id="cb89-15"><a href="rlm.html#cb89-15" aria-hidden="true" tabindex="-1"></a>xy <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">x1 =</span> x1.grid, <span class="at">x2 =</span> x2.grid)</span>
<span id="cb89-16"><a href="rlm.html#cb89-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Modelo teórico:</span></span>
<span id="cb89-17"><a href="rlm.html#cb89-17" aria-hidden="true" tabindex="-1"></a>model.teor <span class="ot">&lt;-</span> <span class="cf">function</span>(x1, x2) x1</span>
<span id="cb89-18"><a href="rlm.html#cb89-18" aria-hidden="true" tabindex="-1"></a><span class="co"># model.teor &lt;- function(x1, x2) x1 - 0.5*x2</span></span>
<span id="cb89-19"><a href="rlm.html#cb89-19" aria-hidden="true" tabindex="-1"></a>y.grid <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">mapply</span>(model.teor, xy<span class="sc">$</span>x1, xy<span class="sc">$</span>x2), <span class="at">nrow =</span> len.grid)</span>
<span id="cb89-20"><a href="rlm.html#cb89-20" aria-hidden="true" tabindex="-1"></a>y.mean <span class="ot">&lt;-</span> <span class="fu">mapply</span>(model.teor, x1, x2)</span></code></pre></div>
<p>Los valores de las variables explicativas y la tendencia teórica se muestran en la Figura <a href="rlm.html#fig:lm3d">2.4</a>:</p>

<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="rlm.html#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plot3D)</span>
<span id="cb90-2"><a href="rlm.html#cb90-2" aria-hidden="true" tabindex="-1"></a>ylim <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">3</span>) <span class="co"># range(y, y.pred)</span></span>
<span id="cb90-3"><a href="rlm.html#cb90-3" aria-hidden="true" tabindex="-1"></a><span class="fu">scatter3D</span>(<span class="at">z =</span> y.mean, <span class="at">x =</span> x1, <span class="at">y =</span> x2, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">cex =</span> <span class="dv">1</span>, <span class="at">clim =</span> ylim, </span>
<span id="cb90-4"><a href="rlm.html#cb90-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">zlim =</span> ylim, <span class="at">theta =</span> <span class="sc">-</span><span class="dv">40</span>, <span class="at">phi =</span> <span class="dv">20</span>, <span class="at">ticktype =</span> <span class="st">&quot;detailed&quot;</span>, </span>
<span id="cb90-5"><a href="rlm.html#cb90-5" aria-hidden="true" tabindex="-1"></a>          <span class="at">xlab =</span> <span class="st">&quot;x1&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;x2&quot;</span>, <span class="at">zlab =</span> <span class="st">&quot;y&quot;</span>, </span>
<span id="cb90-6"><a href="rlm.html#cb90-6" aria-hidden="true" tabindex="-1"></a>          <span class="at">surf =</span> <span class="fu">list</span>(<span class="at">x =</span> x1.grid, <span class="at">y =</span> x2.grid, <span class="at">z =</span> y.grid, <span class="at">facets =</span> <span class="cn">NA</span>))</span>
<span id="cb90-7"><a href="rlm.html#cb90-7" aria-hidden="true" tabindex="-1"></a><span class="fu">scatter3D</span>(<span class="at">z =</span> <span class="fu">rep</span>(ylim[<span class="dv">1</span>], n), <span class="at">x =</span> x1, <span class="at">y =</span> x2, <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">colkey =</span> <span class="cn">FALSE</span>, </span>
<span id="cb90-8"><a href="rlm.html#cb90-8" aria-hidden="true" tabindex="-1"></a>           <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">cex =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>)</span>
<span id="cb90-9"><a href="rlm.html#cb90-9" aria-hidden="true" tabindex="-1"></a>x2.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit.x2, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">x1 =</span> x1.range))</span>
<span id="cb90-10"><a href="rlm.html#cb90-10" aria-hidden="true" tabindex="-1"></a><span class="fu">lines3D</span>(<span class="at">z =</span> <span class="fu">rep</span>(ylim[<span class="dv">1</span>], <span class="dv">2</span>), <span class="at">x =</span> x1.range, <span class="at">y =</span> x2.pred, <span class="at">add =</span> <span class="cn">TRUE</span>, </span>
<span id="cb90-11"><a href="rlm.html#cb90-11" aria-hidden="true" tabindex="-1"></a>        <span class="at">colkey =</span> <span class="cn">FALSE</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>) </span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:lm3d"></span>
<img src="02-clasicos_files/figure-html/lm3d-1.png" alt="Modelo teórico y valores de las variables explicativas (altamente correlacionadas, con un coeficiente de determinación de 0.99)." width="70%" />
<p class="caption">
Figura 2.4: Modelo teórico y valores de las variables explicativas (altamente correlacionadas, con un coeficiente de determinación de 0.99).
</p>
</div>
<p>Para ilustrar el efecto de la correlación en los predictores, en la Figura <a href="rlm.html#fig:multicol-movie-plot">2.5</a> se muestran ejemplos de simulaciones bajo colinealidad y los correspondientes modelos ajustados.
Los valores de la variable respuesta, los modelos ajustados y las superficies de predicción se han obtenido aplicando, reiteradamente:</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="rlm.html#cb91-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> y.mean <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, <span class="fl">0.25</span>)</span>
<span id="cb91-2"><a href="rlm.html#cb91-2" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2)</span>
<span id="cb91-3"><a href="rlm.html#cb91-3" aria-hidden="true" tabindex="-1"></a>y.pred <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">predict</span>(fit, <span class="at">newdata =</span> xy), <span class="at">nrow =</span> <span class="fu">length</span>(x1.grid)) </span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:multicol-movie-plot"></span>
<img src="images/multicol-movie.gif" alt="Ejemplo de simulaciones bajo colinelidad y correspondientes modelos ajustados." width="90%" />
<p class="caption">
Figura 2.5: Ejemplo de simulaciones bajo colinelidad y correspondientes modelos ajustados.
</p>
</div>
<p>Podemos observar una alta variabilidad en los modelos ajustados (puede haber grandes diferencias en las estimaciones de los coeficientes de los predictores).
Incluso puede ocurrir que el contraste de regresión sea significativo (alto coeficiente de determinación), pero los contrastes individuales sean no significativos.
Por ejemplo, en el último ajuste obtendríamos:</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="rlm.html#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.4546 -0.1315  0.0143  0.1632  0.3662 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  -0.1137     0.0894   -1.27     0.21
## x1            0.8708     1.1993    0.73     0.47
## x2            0.1675     1.1934    0.14     0.89
## 
## Residual standard error: 0.221 on 47 degrees of freedom
## Multiple R-squared:  0.631,  Adjusted R-squared:  0.615 
## F-statistic: 40.1 on 2 and 47 DF,  p-value: 6.78e-11</code></pre>
<p>Podemos comparar los resultados anteriores con los obtenidos, también mediante simulación, utilizando predictores incorrelados (ver Figura <a href="rlm.html#fig:indep-movie-plot">2.6</a>).
En este caso, el único cambio es generar el segundo predictor de forma independiente:</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="rlm.html#cb94-1" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> <span class="fu">rand.gen</span>(n) </span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:indep-movie-plot"></span>
<img src="images/indep-movie.gif" alt="Ejemplo de simulaciones bajo independencia y correspondientes modelos ajustados." width="90%" />
<p class="caption">
Figura 2.6: Ejemplo de simulaciones bajo independencia y correspondientes modelos ajustados.
</p>
</div>
<p>Por ejemplo, en el último ajuste obtendríamos:</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="rlm.html#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.4580 -0.0864  0.0045  0.1540  0.3366 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -0.2237     0.0851   -2.63    0.012 *  
## x1            1.0413     0.1104    9.43  2.1e-12 ***
## x2            0.2233     0.1021    2.19    0.034 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.21 on 47 degrees of freedom
## Multiple R-squared:  0.665,  Adjusted R-squared:  0.65 
## F-statistic: 46.6 on 2 and 47 DF,  p-value: 7.02e-12</code></pre>
<p>En la práctica, para la detección de colinealidad se puede emplear la función
<code>vif()</code> del paquete <a href="https://CRAN.R-project.org/package=car"><code>car</code></a>, que calcula los factores de inflación de la varianza para las variables del modelo.
Por ejemplo, en los últimos ajustes obtendríamos:</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="rlm.html#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb97-2"><a href="rlm.html#cb97-2" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(fit)</span></code></pre></div>
<pre><code>##     x1     x2 
## 107.08 107.08</code></pre>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="rlm.html#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(fit2) </span></code></pre></div>
<pre><code>##     x1     x2 
## 1.0001 1.0001</code></pre>
<p>La idea de este estadístico es que la varianza de la estimación del efecto en
regresión simple (efecto global) es menor que en regresión múltiple (efecto parcial).
El factor de inflación de la varianza mide el incremento debido a la colinealidad.
Valores grandes, por ejemplo mayores que 10, indican la posible presencia de colinealidad.</p>
<p>Las tolerancias, proporciones de variabilidad no explicada por las demás covariables, se pueden calcular con <code>1/vif(modelo)</code>.
Por ejemplo, los coeficientes de tolerancia de los últimos ajustes serían:</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="rlm.html#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">/</span><span class="fu">vif</span>(fit)</span></code></pre></div>
<pre><code>##        x1        x2 
## 0.0093387 0.0093387</code></pre>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="rlm.html#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">/</span><span class="fu">vif</span>(fit2) </span></code></pre></div>
<pre><code>##      x1      x2 
## 0.99986 0.99986</code></pre>
<p>Aunque el factor de inflación de la varianza y la tolerancia son las medidas más utilizadas, son bastante simples y puede ser preferible emplear otras como el <em>índice de condicionamiento</em>, implementado en el paquete <a href="https://CRAN.R-project.org/package=mctest"><code>mctest</code></a>.</p>
<p>Como ya se comentó en la Sección 1.4, el problema de la colinealidad se agrava al aumentar el número de dimensiones (la maldición de la dimensionalidad).
Hay que tener en cuenta también que, además de la dificultad para interpretar el efecto de los predictores, va a resultar más difícil determinar qué variables son de interés para predecir la respuesta (<em>i. e.</em> no son ruido). Debido a la aleatoriedad, predictores que realmente no están relacionados con la respuesta pueden incluirse en el modelo con mayor facilidad, especialmente si se recurre a los contrastes tradicionales para determinar si tienen un efecto significativo.</p>
<!-- Por ejemplo en el último ajuste, bajo las hipótesis del modelo de regresión lineal múltiple, se aceptaría un efecto lineal significativo de x2... -->
</div>
<div id="seleccion-rlm" class="section level3 hasAnchor" number="2.1.2">
<h3><span class="header-section-number">2.1.2</span> Selección de variables explicativas<a href="rlm.html#seleccion-rlm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Cuando se dispone de un conjunto grande de posibles variables explicativas, suele ser especialmente importante determinar cuáles de estas deberían ser incluidas en el modelo de regresión.
Solo se deben incluir las variables que contienen información relevante sobre la respuesta, porque así se simplifica la interpretación del modelo, se aumenta la precisión de la estimación y se evitan los problemas de colinealidad.
Se trataría entonces de conseguir un buen ajuste con el menor número de predictores posible.</p>
<!-- #### Búsqueda exhaustiva -->
<p>Para obtener el modelo “óptimo” lo ideal sería evaluar todas las posibles combinaciones de los predictores.
La función <a href="https://rdrr.io/pkg/leaps/man/regsubsets.html"><code>regsubsets()</code></a> del paquete <a href="https://CRAN.R-project.org/package=leaps"><code>leaps</code></a> permite seleccionar los mejores modelos fijando el número máximo de variables explicativas.
Por defecto, evalúa todos los modelos posibles con un determinado número de parámetros (variando desde 1 hasta por defecto un máximo de <code>nvmax = 8</code>) y selecciona el mejor (<code>nbest = 1</code>).</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="rlm.html#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(leaps)</span>
<span id="cb105-2"><a href="rlm.html#cb105-2" aria-hidden="true" tabindex="-1"></a>regsel <span class="ot">&lt;-</span> <span class="fu">regsubsets</span>(bodyfat <span class="sc">~</span> . , <span class="at">data =</span> train)</span>
<span id="cb105-3"><a href="rlm.html#cb105-3" aria-hidden="true" tabindex="-1"></a><span class="co"># summary(regsel)</span></span></code></pre></div>
<p>Al representar el resultado se obtiene un gráfico con los mejores modelos ordenados según el criterio determinado por el argumento<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a> <code>scale = c("bic", "Cp", "adjr2", "r2")</code> <span class="citation">(para detalles sobre estas medidas, ver por ejemplo la Sección 6.1.3 de <a href="#ref-james2021introduction" role="doc-biblioref">James et al., 2021</a>)</span>.
Se representa una matriz en la que las filas se corresponden con los modelos y las columnas con predictores, indicando los incluidos en cada modelo mediante un sombreado.
En la Figura <a href="rlm.html#fig:regsel">2.7</a> se muestra el resultado obtenido empleando el coeficiente de determinación ajustado.</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="rlm.html#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(regsel, <span class="at">scale =</span> <span class="st">&quot;adjr2&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:regsel"></span>
<img src="02-clasicos_files/figure-html/regsel-1.png" alt="Modelos obtenidos mediante búsqueda exhaustiva ordenados según su coeficiente de determinación ajustado." width="80%" />
<p class="caption">
Figura 2.7: Modelos obtenidos mediante búsqueda exhaustiva ordenados según su coeficiente de determinación ajustado.
</p>
</div>
<p>En este caso, considerando que es preferible un modelo más simple que una mejora del 1 % en la proporción de variabilidad explicada, seleccionamos como modelo final el modelo con dos predictores.
Podemos obtener fácilmente los coeficientes de este modelo:</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="rlm.html#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(regsel, <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## (Intercept)     abdomen       wrist 
##     -9.0578      0.7780     -2.4159</code></pre>
<p>pero suele ser recomendable volver a hacer el ajuste:</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="rlm.html#cb109-1" aria-hidden="true" tabindex="-1"></a>modelo <span class="ot">&lt;-</span> <span class="fu">lm</span>(bodyfat <span class="sc">~</span> abdomen <span class="sc">+</span> wrist, <span class="at">data =</span> train)</span></code></pre></div>
<!-- #### Selección por pasos -->
<p>Si el número de variables es grande, no resulta práctico evaluar todas las posibilidades.
En este caso se suele utilizar alguno (o varios) de los siguientes métodos:</p>
<ul>
<li><p>Selección progresiva (<em>forward</em>): Se parte de una situación en la
que no hay ninguna variable y en cada paso se incluye una variable aplicando
un criterio de entrada (hasta que ninguna de las restantes lo
verifican).</p></li>
<li><p>Eliminación progresiva (<em>backward</em>): Se parte del modelo con todas
las variables y en cada paso se elimina una variable aplicando un criterio
de salida (hasta que ninguna de las incluidas lo verifican).</p></li>
<li><p>Selección paso a paso (<em>stepwise</em>): Se combina un criterio de entrada y uno
de salida.
Normalmente se empieza sin ninguna variable y en cada paso puede haber
una inclusión y posteriormente la exclusión de alguna de las anteriormente
añadidas (<em>forward/backward</em>).
Otra posibilidad es partir del modelo con todas las variables, y en cada
paso puede haber una exclusión y posteriormente la inclusión de alguna de
las anteriormente eliminadas (<em>backward/forward</em>).</p></li>
</ul>
<p>Hay que tener en cuenta que se trata de algoritmos “voraces” (<em>greedy</em>, también denominados “avariciosos”), ya que en cada paso tratan de elegir la mejor opción, pero no garantizan que el resultado final sea la solución global óptima (de hecho, es bastante habitual que no coincidan los modelos finales de los distintos métodos, especialmente si el número de observaciones o de variables es grande).</p>
<p>La función <a href="https://rdrr.io/pkg/MASS/man/stepAIC.html"><code>stepAIC()</code></a> del paquete <a href="https://CRAN.R-project.org/package=MASS"><code>MASS</code></a> permite seleccionar el modelo por pasos<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a>, hacia delante o hacia atrás según el criterio AIC (<em>Akaike Information Criterion</em>) o BIC (<em>Bayesian Information Criterion</em>).
La función <a href="https://rdrr.io/pkg/RcmdrMisc/man/stepwise.html"><code>stepwise()</code></a> del paquete <a href="https://CRAN.R-project.org/package=RcmdrMisc"><code>RcmdrMisc</code></a> es una interfaz de <code>stepAIC()</code> que facilita su uso.
Los métodos disponibles son <code>"backward/forward"</code>, <code>"forward/backward"</code>, <code>"backward"</code> y <code>"forward"</code>.
Normalmente, obtendremos un modelo más simple combinando el método por pasos hacia delante con el criterio BIC:</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="rlm.html#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb110-2"><a href="rlm.html#cb110-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(RcmdrMisc)</span>
<span id="cb110-3"><a href="rlm.html#cb110-3" aria-hidden="true" tabindex="-1"></a>modelo.completo <span class="ot">&lt;-</span> <span class="fu">lm</span>(bodyfat <span class="sc">~</span> . , <span class="at">data =</span> train)</span>
<span id="cb110-4"><a href="rlm.html#cb110-4" aria-hidden="true" tabindex="-1"></a>modelo <span class="ot">&lt;-</span> <span class="fu">stepwise</span>(modelo.completo, <span class="at">direction =</span> <span class="st">&quot;forward/backward&quot;</span>, </span>
<span id="cb110-5"><a href="rlm.html#cb110-5" aria-hidden="true" tabindex="-1"></a>                   <span class="at">criterion =</span> <span class="st">&quot;BIC&quot;</span>)</span></code></pre></div>
<pre><code>## 
## Direction:  forward/backward
## Criterion:  BIC 
## 
## Start:  AIC=830.6
## bodyfat ~ 1
## 
##           Df Sum of Sq   RSS AIC
## + abdomen  1      8796  4417 621
## + chest    1      6484  6729 704
## + hip      1      5176  8037 738
## + weight   1      5036  8177 742
## + thigh    1      3889  9324 768
## + neck     1      3069 10144 784
## + knee     1      2975 10238 786
## + biceps   1      2895 10317 787
## + forearm  1      1648 11565 810
## + wrist    1      1095 12118 819
## + age      1       699 12514 825
## + ankle    1       600 12612 827
## &lt;none&gt;                 13213 831
## + height   1        11 13201 836
## 
## Step:  AIC=621.13
## bodyfat ~ abdomen
## 
##           Df Sum of Sq   RSS AIC
## + wrist    1       610  3807 597
## + weight   1       538  3879 601
## + height   1       414  4003 607
## + hip      1       313  4104 612
## + ankle    1       293  4124 613
## + neck     1       276  4142 614
## + knee     1       209  4208 617
## + chest    1       143  4274 620
## &lt;none&gt;                  4417 621
## + thigh    1        88  4329 622
## + forearm  1        78  4339 623
## + biceps   1        72  4345 623
## + age      1        56  4362 624
## - abdomen  1      8796 13213 831
## 
## Step:  AIC=597.25
## bodyfat ~ abdomen + wrist
## 
##           Df Sum of Sq   RSS AIC
## + height   1       152  3654 595
## + weight   1       136  3671 595
## + hip      1       113  3694 597
## &lt;none&gt;                  3807 597
## + age      1        74  3733 599
## + ankle    1        31  3776 601
## + knee     1        29  3778 601
## + chest    1        25  3782 601
## + neck     1        17  3790 602
## + thigh    1        14  3793 602
## + forearm  1         5  3802 602
## + biceps   1         2  3805 602
## - wrist    1       610  4417 621
## - abdomen  1      8311 12118 819
## 
## Step:  AIC=594.53
## bodyfat ~ abdomen + wrist + height
## 
##           Df Sum of Sq   RSS AIC
## &lt;none&gt;                  3654 595
## - height   1       152  3807 597
## + hip      1        40  3614 598
## + chest    1        35  3620 598
## + age      1        27  3628 598
## + weight   1        22  3632 599
## + forearm  1        15  3640 599
## + biceps   1         9  3645 599
## + neck     1         9  3646 599
## + ankle    1         2  3652 600
## + knee     1         0  3654 600
## + thigh    1         0  3654 600
## - wrist    1       349  4003 607
## - abdomen  1      8151 11805 819</code></pre>
<p>En la salida de texto de esta función, <code>"&lt;none&gt;"</code> representa el modelo actual en cada paso y se ordenan las posibles acciones dependiendo del criterio elegido (aunque siempre muestra el valor de AIC).
El algoritmo se detiene cuando ninguna de ellas mejora el modelo actual.
Como resultado devuelve el modelo ajustado final:</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="rlm.html#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = bodyfat ~ abdomen + wrist + height, data = train)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -9.743 -3.058 -0.393  3.331 10.518 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   9.1567     9.1177    1.00   0.3165    
## abdomen       0.7718     0.0373   20.69  &lt; 2e-16 ***
## wrist        -1.9548     0.4567   -4.28  2.9e-05 ***
## height       -0.1457     0.0515   -2.83   0.0052 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.36 on 192 degrees of freedom
## Multiple R-squared:  0.723,  Adjusted R-squared:  0.719 
## F-statistic:  167 on 3 and 192 DF,  p-value: &lt;2e-16</code></pre>
<p>Cuando el número de variables explicativas es muy grande (o si el tamaño de la muestra es pequeño en comparación), pueden aparecer problemas al emplear los métodos anteriores (incluso pueden no ser aplicables).
Una alternativa son los métodos de regularización (<em>ridge regression</em>, LASSO; Sección <a href="shrinkage.html#shrinkage">6.1</a>) o los de reducción de la dimensión (regresión con componentes principales o mínimos cuadrados parciales; Sección <a href="pca-pls.html#pca-pls">6.2</a>).</p>
<p>Por otra parte, en los modelos anteriores no se consideraron interacciones entre predictores <span class="citation">(para detalles sobre como incluir interacciones en modelos lineales ver, por ejemplo, la <a href="https://rubenfcasal.github.io/intror/modelos-lineales.html#interacciones" role="doc-biblioref">Sección 8.6</a> de <a href="#ref-fernandez2022intror" role="doc-biblioref">Fernández-Casal et al., 2022</a>)</span>.
Podemos considerar como modelo completo <code>respuesta ~ .*.</code> si deseamos incluir, por ejemplo, los efectos principales y las interacciones de orden 2 de todos los predictores.</p>
<p>En la práctica, es habitual comenzar con modelos aditivos y, posteriormente, estudiar posibles interacciones siguiendo un proceso interactivo.
Una posible alternativa consiste en considerar un nuevo modelo completo a partir de las variables seleccionadas en el modelo aditivo, incluyendo todas las posibles interacciones de orden 2, y posteriormente aplicar alguno de los métodos de selección anteriores.
Como vimos en el Capítulo <a href="intro-AE.html#intro-AE">1</a>, en AE interesan algoritmos que puedan detectar e incorporar automáticamente efectos de interacción (en los capítulos siguientes veremos extensiones en este sentido).</p>
</div>
<div id="analisis-rlm" class="section level3 hasAnchor" number="2.1.3">
<h3><span class="header-section-number">2.1.3</span> Análisis e interpretación del modelo<a href="rlm.html#analisis-rlm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Además del problema de la colinealidad, si no se verifican las otras hipótesis estructurales del modelo (Sección <a href="rlm.html#rlm">2.1</a>), los resultados y las conclusiones basados en la teoría estadística pueden no ser fiables, o incluso totalmente erróneos:</p>
<ul>
<li><p>La falta de linealidad “invalida” las conclusiones obtenidas
(hay que tener especial cuidado con las extrapolaciones).</p></li>
<li><p>La falta de normalidad tiene poca influencia si el
número de datos es suficientemente grande
(justificado, teóricamente, por el teorema central del límite).
En caso contrario, la estimación de la varianza, los intervalos de
confianza y los contrastes podrían verse afectados.</p></li>
<li><p>Si no hay igualdad de varianzas, los estimadores de los
parámetros no son eficientes, pero sí son insesgados. Las varianzas, los
intervalos de confianza y los contrastes podrían verse afectados.</p></li>
<li><p>La dependencia entre observaciones puede tener un efecto mucho
más grave.</p></li>
</ul>
<p>Con el método <a href="https://rdrr.io/r/stats/plot.lm.html"><code>plot()</code></a> se pueden generar gráficos de interés para la diagnosis del modelo (ver Figura <a href="rlm.html#fig:lm-plot">2.8</a>):</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="rlm.html#cb114-1" aria-hidden="true" tabindex="-1"></a>oldpar <span class="ot">&lt;-</span> <span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb114-2"><a href="rlm.html#cb114-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modelo)</span>
<span id="cb114-3"><a href="rlm.html#cb114-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(oldpar)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:lm-plot"></span>
<img src="02-clasicos_files/figure-html/lm-plot-1.png" alt="Gráficos de diagnóstico del ajuste lineal." width="90%" />
<p class="caption">
Figura 2.8: Gráficos de diagnóstico del ajuste lineal.
</p>
</div>
<p>Por defecto se muestran cuatro gráficos (ver <a href="https://rdrr.io/r/stats/plot.lm.html"><code>help(plot.lm)</code></a> para más detalles).
El primero representa los residuos frente a las predicciones y permite detectar falta de linealidad o heterocedasticidad (o el efecto de un factor omitido: mala especificación del modelo); lo ideal es no observar ningún patrón.
En este ejemplo se observa que el modelo podría no ser adecuado para la predicción en valores grandes de la respuesta (aproximadamente a partir de un 30 % de grasa corporal), por lo que se podría pensar en incluir un término cuadrático.
El segundo es el gráfico QQ y permite diagnosticar la normalidad; sus puntos deben estar cerca de la diagonal.
El tercero es el gráfico de dispersión-nivel y permite detectar la heterocedasticidad y ayudar a seleccionar una transformación para corregirla; la pendiente debe ser nula (como alternativa se puede emplear la función <a href="https://rdrr.io/pkg/MASS/man/boxcox.html"><code>boxcox()</code></a> del paquete <a href="https://CRAN.R-project.org/package=MASS"><code>MASS</code></a>).
El último gráfico permite detectar valores atípicos o influyentes; representa los residuos estandarizados en función del valor de influencia (a priori) o <em>leverage</em><a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a> y señala las observaciones atípicas (residuos fuera del intervalo <span class="math inline">\([-2,2]\)</span>) e influyentes a posteriori (estadístico de Cook mayor que 0.5 o mayor que 1).</p>
<p>Si las conclusiones obtenidas dependen en gran medida de una observación (normalmente atípica), esta se denomina influyente (a posteriori) y debe ser examinada con cuidado por el experimentador.
Se puede volver a ajustar el modelo eliminando las observaciones influyentes<a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a>, pero sería recomendable repetir todo el proceso desde la selección de variables.
Hay que tener en cuenta que los casos se identifican en los gráficos mediante los nombres de fila de las observaciones, que pueden consultarse con <code>row.names()</code>.
Salvo que se hayan definido expresamente, los nombres de fila van a coincidir con los números de fila de los datos originales, en nuestro caso <code>bodyfat</code>, pero no con los números de fila de <code>train</code>.
Otra alternativa para evitar la influencia de datos atípicos es emplear regresión lineal robusta, por ejemplo mediante la función <a href="https://rdrr.io/pkg/MASS/man/rlm.html"><code>rlm()</code></a> del paquete <a href="https://CRAN.R-project.org/package=MASS"><code>MASS</code></a> (ver Ejercicio <a href="rlm.html#exr:robust-rlm">2.2</a>).</p>
<p>Es recomendable utilizar gráficos parciales de residuos para analizar los efectos de las variables explicativas y detectar posibles problemas como la falta de linealidad.
Se pueden generar con:</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="rlm.html#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="fu">termplot</span>(modelo, <span class="at">partial.resid =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>aunque puede ser preferible emplear las funciones <a href="https://rdrr.io/pkg/car/man/crPlots.html"><code>crPlots()</code></a> ó <a href="https://rdrr.io/pkg/car/man/avPlots.html"><code>avPlots()</code></a> del paquete <a href="https://CRAN.R-project.org/package=car"><code>car</code></a><a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a> (ver Figura <a href="rlm.html#fig:crPlots">2.9</a>):</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="rlm.html#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb116-2"><a href="rlm.html#cb116-2" aria-hidden="true" tabindex="-1"></a><span class="co"># avPlots(modelo)</span></span>
<span id="cb116-3"><a href="rlm.html#cb116-3" aria-hidden="true" tabindex="-1"></a><span class="fu">crPlots</span>(modelo, <span class="at">main =</span> <span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:crPlots"></span>
<img src="02-clasicos_files/figure-html/crPlots-1.png" alt="Gráficos parciales de residuos (componentes + residuos) del ajuste lineal." width="90%" />
<p class="caption">
Figura 2.9: Gráficos parciales de residuos (componentes + residuos) del ajuste lineal.
</p>
</div>
<p>En la Tabla <a href="rlm.html#tab:diag-fun-lm">2.2</a> se incluyen algunas funciones adicionales que permiten obtener medidas de diagnosis o resúmenes numéricos de interés (ver <a href="https://rdrr.io/r/stats/influence.measures.html"><code>help(influence.measures)</code></a> para un listado más completo).</p>
<table>
<caption><span id="tab:diag-fun-lm">Tabla 2.2: </span> Principales funciones para la diagnosis del modelo ajustado.</caption>
<colgroup>
<col width="17%" />
<col width="82%" />
</colgroup>
<thead>
<tr class="header">
<th>Función</th>
<th>Descripción</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>rstandard()</code></td>
<td>residuos estandarizados (también eliminados)</td>
</tr>
<tr class="even">
<td><code>rstudent()</code></td>
<td>residuos estudentizados</td>
</tr>
<tr class="odd">
<td><code>cooks.distance()</code></td>
<td>valores del estadístico de Cook</td>
</tr>
<tr class="even">
<td><code>influence()</code></td>
<td>valores de influencia, cambios en coeficientes y varianza residual al eliminar cada dato (LOOCV)</td>
</tr>
</tbody>
</table>
<p>Hay muchas herramientas adicionales disponibles en otros paquetes, además de las que ya hemos visto de los paquetes <code>car</code> y <code>mctest</code>.
Por ejemplo, la librería <a href="https://CRAN.R-project.org/package=lmtest"><code>lmtest</code></a> proporciona herramientas para la diagnosis de modelos lineales, como el test de Breusch-Pagan para contrastar homocedasticidad, en la función <code>bptest()</code>, o el de Durbin-Watson para detectar si hay correlación en serie<a href="#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a>, en la función <code>dwtest()</code>.</p>
<p>Cuando no se satisfacen los supuestos básicos del modelo, pueden aplicarse diversas soluciones:</p>
<ul>
<li><p>Pueden llevarse a cabo transformaciones de los datos para tratar de
corregir la falta de linealidad, heterocedasticidad y/o normalidad
(habitualmente estas últimas “suelen ocurrir en la misma escala”).
También se pueden utilizar modelos lineales generalizados
(Sección <a href="reg-glm.html#reg-glm">2.2</a> y Capítulo <a href="ext-glm.html#ext-glm">6</a>).</p></li>
<li><p>Si no se logra corregir la heterocedasticidad, puede ser adecuado
utilizar mínimos cuadrados ponderados, para lo que habría que modelar la varianza.</p></li>
<li><p>Si hay dependencia, se puede tratar de modelarla y utilizar mínimos
cuadrados generalizados.</p></li>
<li><p>Si no se logra corregir la falta de linealidad, se pueden
utilizar modelos más flexibles (Capítulo <a href="ext-glm.html#ext-glm">6</a> y siguientes).</p></li>
</ul>
<p>Una alternativa a las soluciones anteriores es emplear las técnicas de aprendizaje estadístico descritas en la Sección <a href="const-eval.html#const-eval">1.3</a>.
Desde este punto de vista, podemos ignorar las hipótesis estructurales y pensar que los procedimientos clásicos, como por ejemplo el ajuste lineal mediante el método por pasos, son simplemente algoritmos de predicción.
En ese caso, después de ajustar el modelo en la muestra de entrenamiento, en lugar de emplear medidas como el coeficiente de determinación ajustado, emplearíamos la muestra de test para evaluar la capacidad predictiva en nuevas observaciones.</p>
<!-- 
Trataremos en primer lugar este último paso y posteriormente, en la Sección \@ref(selec-ae-rlm), se darán algunas nociones de como se podría haber empleado remuestreo para la selección del modelo. 
-->
<p>Una vez obtenido el ajuste final, la ventaja de emplear un modelo lineal es que resultaría muy fácil interpretar el efecto de los predictores en la respuesta a partir de las estimaciones de los coeficientes:</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="rlm.html#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(modelo)</span></code></pre></div>
<pre><code>## (Intercept)     abdomen       wrist      height 
##     9.15668     0.77181    -1.95482    -0.14570</code></pre>
<p>En este caso <code>abdomen</code> tiene un efecto positivo, mientras que el de <code>wrist</code> y <code>height</code> es negativo (ver Figura <a href="rlm.html#fig:crPlots">2.9</a>).
Por ejemplo, estimaríamos que por cada incremento de un centímetro en la circunferencia del abdomen, el porcentaje de grasa corporal aumentará un 0.77 % (siempre que no varíen los valores de <code>wrist</code> y <code>height</code>).
Es importante destacar que estos coeficientes dependen de la escala de las variables y, por tanto, no deberían ser empleados como medidas de importancia de los predictores si sus unidades de medida no son comparables.
Es preferible emplear los valores observados de los estadísticos para contrastar si su efecto es significativo (columna <code>t value</code> en el resumen del modelo ajustado):</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="rlm.html#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo)<span class="sc">$</span>coefficients[<span class="sc">-</span><span class="dv">1</span>, <span class="dv">3</span>]</span></code></pre></div>
<pre><code>## abdomen   wrist  height 
## 20.6939 -4.2806 -2.8295</code></pre>
<p>ya que son funciones del correspondiente coeficiente de correlación parcial (la correlación entre la respuesta y el predictor después de eliminar el efecto lineal del resto de predictores).
Alternativamente, se pueden emplear los denominados coeficientes estandarizados o pesos beta, por ejemplo mediante la función <a href="https://rubenfcasal.github.io/mpae/reference/scaled.coef.html"><code>scaled.coef()</code></a> del paquete <a href="https://rubenfcasal.github.io/mpae"><code>mpae</code></a>:</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="rlm.html#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="fu">scaled.coef</span>(modelo) <span class="co"># scale.response = TRUE</span></span></code></pre></div>
<pre><code>##  abdomen    wrist   height 
##  0.95710 -0.21157 -0.11681</code></pre>
<p>Estos coeficientes serían los obtenidos al ajustar el modelo tipificando previamente todas las variables<a href="#fn30" class="footnote-ref" id="fnref30"><sup>30</sup></a>.
Tanto el valor absoluto de estos coeficientes como el de los estadísticos de contraste se podrían considerar medidas de la importancia de los predictores.</p>
</div>
<div id="eval-rlm" class="section level3 hasAnchor" number="2.1.4">
<h3><span class="header-section-number">2.1.4</span> Evaluación de la precisión<a href="rlm.html#eval-rlm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para evaluar la precisión de las predicciones se puede utilizar el coeficiente de determinación ajustado:</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="rlm.html#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo)<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.71909</code></pre>
<p>que estima la proporción de variabilidad explicada en una nueva muestra.
Sin embargo, hay que tener en cuenta que su validez depende de las hipótesis estructurales (especialmente de la linealidad, homocedasticidad e independencia), ya que se obtiene a partir de estimaciones de las varianzas residual y total:</p>
<p><span class="math display">\[R_{ajus}^{2} = 1 - \frac{\hat{S}_{R}^{2}}{\hat{S}_{Y}^{2}}
= 1 - \left( \frac{n-1}{n-p-1} \right) (1-R^{2})\]</span></p>
<p>siendo <span class="math inline">\(\hat{S}_{R}^{2}=\sum_{i=1}^{n}(y_{i}-\hat{y}_{i})^{2}/(n - p - 1)\)</span>.
Algo similar ocurre con otras medidas de bondad de ajuste, como por ejemplo BIC o AIC.</p>
<p>Alternativamente, si no es razonable asumir estas hipótesis, se puede emplear el procedimiento tradicional en AE (o alguno de los otros descritos en la Sección <a href="const-eval.html#const-eval">1.3</a>).</p>
<p>Podemos evaluar el modelo ajustado en el conjunto de datos de test y comparar las predicciones frente a los valores reales (como se mostró en la Sección <a href="const-eval.html#eval-reg">1.3.4</a>; ver Figura <a href="rlm.html#fig:lm-test">2.10</a>).
En este caso, se observa una infrapredicción en valores grandes de la respuesta, especialmente en torno al 20 % de grasa corporal (como ya se ha visto en la diagnosis realizada en la sección anterior, aparentemente se debería haber incluido un término cuadrático).</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="rlm.html#cb125-1" aria-hidden="true" tabindex="-1"></a>obs <span class="ot">&lt;-</span> test<span class="sc">$</span>bodyfat</span>
<span id="cb125-2"><a href="rlm.html#cb125-2" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelo, <span class="at">newdata =</span> test)</span>
<span id="cb125-3"><a href="rlm.html#cb125-3" aria-hidden="true" tabindex="-1"></a><span class="fu">pred.plot</span>(pred, obs, <span class="at">xlab =</span> <span class="st">&quot;Predicción&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Observado&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:lm-test"></span>
<img src="02-clasicos_files/figure-html/lm-test-1.png" alt="Gráfico de dispersión de observaciones frente a predicciones, del ajuste lineal en la muestra de test." width="75%" />
<p class="caption">
Figura 2.10: Gráfico de dispersión de observaciones frente a predicciones, del ajuste lineal en la muestra de test.
</p>
</div>
<p>También podemos obtener medidas de error:</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="rlm.html#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(pred, obs)</span></code></pre></div>
<pre><code>##        me      rmse       mae       mpe      mape r.squared 
##   1.44076   4.19456   3.59129  -0.68191  21.46643   0.72802</code></pre>
<div class="exercise">
<p><span id="exr:robust-rlm" class="exercise"><strong>Ejercicio 2.2  </strong></span>El conjunto de datos <a href="https://rubenfcasal.github.io/mpae/reference/bodyfat.raw.html"><code>mpae::bodyfat.raw</code></a> contiene observaciones adicionales en las que se sospecha que hubo errores en las mediciones o en la introducción de datos.
Particiona estos datos en una muestra de entrenamiento y una de test, ajusta el modelo anterior mediante regresión robusta con la función <code>MASS::rlm()</code>:</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="rlm.html#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rlm</span>(bodyfat <span class="sc">~</span> abdomen <span class="sc">+</span> wrist <span class="sc">+</span> height, <span class="at">data =</span> train)</span></code></pre></div>
<p>evalúa las predicciones en la muestra de test y compara los resultados con los del ejemplo anterior.</p>
</div>
</div>
<div id="selec-ae-rlm" class="section level3 hasAnchor" number="2.1.5">
<h3><span class="header-section-number">2.1.5</span> Selección del modelo mediante remuestreo<a href="rlm.html#selec-ae-rlm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Los métodos de selección de variables descritos en la Sección <a href="rlm.html#seleccion-rlm">2.1.2</a> también dependen, en mayor o menor medida, de la validez de las hipótesis estructurales.
Por este motivo se podría pensar en emplear alguno de los procedimientos descritos en la Sección <a href="const-eval.html#const-eval">1.3</a>.
Por ejemplo, podríamos considerar como hiperparámetros la inclusión, o no, de cada una de las posibles variables explicativas y realizar la selección de variables (la complejidad del modelo) mediante remuestreo (ver <code>bestglm::bestglm(..., IC = c("LOOCV", "CV"))</code>).
Sin embargo, esto puede presentar dificultades computacionales.</p>
<!-- 
`bestglm::bestglm()` con argumento `IC = c("LOOCV", "CV")` y opciones adicionales en `CVArgs`
algo equivalente a regsubsets mediante cv
 
Para ello se podría intentar adaptar el algoritmo de validación cruzada empleado en la Sección \@ref(cv).

ejercicios: 

- más adelante se podría hacer bagging.

- Implementar una función stepCV
-->
<p>Otra posibilidad es emplear remuestreo para escoger entre distintos procedimientos de selección o para escoger el número de predictores incluidos en el modelo.
En este caso, el procedimiento de selección debería realizarse también en cada uno de los conjuntos de entrenamiento utilizados en la validación.
Esto último puede hacerse fácilmente con el paquete <code>caret</code>.
Este paquete implementa métodos de selección basados en el paquete <code>leaps</code>, considerando el número máximo de predictores <code>nvmax</code> como hiperparámetro y empleando búsqueda: hacia atrás (<code>"leapBackward"</code>), hacia delante (<code>"leapForward"</code>) y por pasos (<code>"leapSeq"</code>).</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="rlm.html#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb129-2"><a href="rlm.html#cb129-2" aria-hidden="true" tabindex="-1"></a><span class="fu">modelLookup</span>(<span class="st">&quot;leapSeq&quot;</span>)</span></code></pre></div>
<pre><code>##     model parameter                        label forReg forClass probModel
## 1 leapSeq     nvmax Maximum Number of Predictors   TRUE    FALSE     FALSE</code></pre>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="rlm.html#cb131-1" aria-hidden="true" tabindex="-1"></a>caret.leapSeq <span class="ot">&lt;-</span> <span class="fu">train</span>(bodyfat <span class="sc">~</span> ., <span class="at">data =</span> train, <span class="at">method =</span> <span class="st">&quot;leapSeq&quot;</span>,</span>
<span id="cb131-2"><a href="rlm.html#cb131-2" aria-hidden="true" tabindex="-1"></a>                       <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">10</span>),</span>
<span id="cb131-3"><a href="rlm.html#cb131-3" aria-hidden="true" tabindex="-1"></a>                       <span class="at">tuneGrid =</span> <span class="fu">data.frame</span>(<span class="at">nvmax =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>))</span>
<span id="cb131-4"><a href="rlm.html#cb131-4" aria-hidden="true" tabindex="-1"></a>caret.leapSeq</span></code></pre></div>
<pre><code>## Linear Regression with Stepwise Selection 
## 
## 196 samples
##  13 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 176, 176, 178, 175, 178, 176, ... 
## Resampling results across tuning parameters:
## 
##   nvmax  RMSE    Rsquared  MAE   
##   1      4.6868  0.67536   3.8501
##   2      4.3946  0.71180   3.6432
##   3      4.3309  0.72370   3.5809
##   4      4.5518  0.69680   3.7780
##   5      4.4163  0.71225   3.6770
##   6      4.4015  0.71020   3.6674
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was nvmax = 3.</code></pre>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="rlm.html#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="co"># summary(caret.leapSeq$finalModel)</span></span>
<span id="cb133-2"><a href="rlm.html#cb133-2" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(caret.leapSeq, <span class="fu">coef</span>(finalModel, bestTune<span class="sc">$</span>nvmax))</span></code></pre></div>
<pre><code>## (Intercept)      height     abdomen       wrist 
##     9.15668    -0.14570     0.77181    -1.95482</code></pre>
<p>Una vez seleccionado el modelo final<a href="#fn31" class="footnote-ref" id="fnref31"><sup>31</sup></a>, estudiaríamos la eficiencia de las predicciones en la muestra de test:</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="rlm.html#cb135-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(caret.leapSeq, <span class="at">newdata =</span> test)</span>
<span id="cb135-2"><a href="rlm.html#cb135-2" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(pred, obs)</span></code></pre></div>
<pre><code>##        me      rmse       mae       mpe      mape r.squared 
##   1.44076   4.19456   3.59129  -0.68191  21.46643   0.72802</code></pre>
<p>Además, en el caso de ajustes de modelos de este tipo, puede resultar de interés realizar un preprocesado de los datos para eliminar predictores correlados o con varianza próxima a cero,
estableciendo por ejemplo <code>preProc = c("nzv", "corr")</code> en la llamada a la función <code>train()</code>.</p>
<!-- 
Ejercicio: 
Datos atípicos
cambiar criterio de error a MAE 
-->
<!-- Sección \@ref(reg-glm) -->
</div>
</div>
<h3>Bibliografía<a href="bibliografía.html#bibliografía" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-fernandez2022intror" class="csl-entry">
Fernández-Casal, R., Roca-Pardiñas, J., Costa, J., y Oviedo-de la Fuente, M. (2022). <em>Introducción al Análisis de Datos con R</em>. <a href="https://rubenfcasal.github.io/intror" class="uri">https://rubenfcasal.github.io/intror</a>.
</div>
<div id="ref-james2021introduction" class="csl-entry">
James, G., Witten, D., Hastie, T., y Tibshirani, R. (2021). <em>An Introduction to Statistical Learning: With Applications in R</em> (2a. ed.). Springer. <a href="https://www.statlearning.com" class="uri">https://www.statlearning.com</a>.
</div>
<div id="ref-penrose1985generalized" class="csl-entry">
Penrose, K. W., Nelson, A., y Fisher, A. (1985). Generalized body composition prediction equation for men using simple measurement techniques. <em>Medicine &amp; Science in Sports &amp; Exercise</em>, <em>17</em>(2), 189. <a href="https://doi.org/10.1249/00005768-198504000-00037">https://doi.org/10.1249/00005768-198504000-00037</a>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="23">
<li id="fn23"><p>Algunos predictores podrían corresponderse con interacciones, <span class="math inline">\(X_i = X_j X_k\)</span>, o transformaciones (p. ej. <span class="math inline">\(X_i = X_j^2\)</span>) de las variables explicativas originales. También se podría haber transformado la respuesta.<a href="rlm.html#fnref23" class="footnote-back">↩︎</a></p></li>
<li id="fn24"><p>Con los criterios habituales, el mejor modelo con un número de variables prefijado no depende del criterio empleado.
Aunque estos criterios pueden diferir al comparar modelos con distinto número de predictores.<a href="rlm.html#fnref24" class="footnote-back">↩︎</a></p></li>
<li id="fn25"><p>También está disponible la función <code>step()</code> del paquete base
<code>stats</code> con menos opciones.
Además de búsqueda exhaustiva, la función <code>leaps::regsubsets()</code>
también permite emplear un criterio por pasos, mediante el argumento
<code>method = c("backward", "forward", "seqrep")</code>, pero puede ser recomendable
usar las otras alternativas para obtener directamente el modelo final.<a href="rlm.html#fnref25" class="footnote-back">↩︎</a></p></li>
<li id="fn26"><p>La influencia a priori (<em>leverage</em>) depende de los valores de las variables explicativas, y cuando es mayor que <span class="math inline">\(2(p+1)/2\)</span> se considera que la observación está muy alejada del centro de los datos.<a href="rlm.html#fnref26" class="footnote-back">↩︎</a></p></li>
<li id="fn27"><p>Normalmente se sigue un proceso iterativo, eliminando la más influyente cada vez, por ejemplo con <code>which.max(cooks.distance(modelo))</code> y <code>update()</code>.<a href="rlm.html#fnref27" class="footnote-back">↩︎</a></p></li>
<li id="fn28"><p>Estas funciones también permitirían detectar observaciones atípicas o influyentes mediante el argumento <code>id</code> (como se muestra en la Sección <a href="reg-glm.html#analisis-glm">2.2.2</a>).<a href="rlm.html#fnref28" class="footnote-back">↩︎</a></p></li>
<li id="fn29"><p>Para diagnosticar si hay problemas de dependencia temporal sería importante mantener el orden original de recogida de los datos.
En este caso no tendría sentido hacerlo con la muestra de entrenamiento, ya que al particionar los datos se seleccionaron las observaciones aleatoriamente (habría que emplear el conjunto de datos original o generar la muestra de entrenamiento teniendo en cuenta la posible dependencia).<a href="rlm.html#fnref29" class="footnote-back">↩︎</a></p></li>
<li id="fn30"><p>Por tanto, no tienen unidades y se interpretarían como el cambio en desviaciones estándar de la variable dependiente al aumentar el correspondiente predictor en una desviación estándar.<a href="rlm.html#fnref30" class="footnote-back">↩︎</a></p></li>
<li id="fn31"><p>Se podrían haber entrenado distintos métodos de selección de predictores y comparar los resultados (en las mismas muestras de validación) para escoger el modelo final.<a href="rlm.html#fnref31" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="clasicos.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="reg-glm.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": true,
    "facebook": false,
    "twitter": false,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/rubenfcasal/aprendizaje_estadistico/edit/master/02-clasicos.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["aprendizaje_estadistico.pdf"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
