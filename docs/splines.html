<!DOCTYPE html>
<html lang="es" xml:lang="es">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7.2 Splines | Métodos predictivos de aprendizaje estadístico</title>
  <meta name="description" content="7.2 Splines | Métodos predictivos de aprendizaje estadístico con R." />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="7.2 Splines | Métodos predictivos de aprendizaje estadístico" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="7.2 Splines | Métodos predictivos de aprendizaje estadístico con R." />
  <meta name="github-repo" content="rubenfcasal/book_mpae" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7.2 Splines | Métodos predictivos de aprendizaje estadístico" />
  
  <meta name="twitter:description" content="7.2 Splines | Métodos predictivos de aprendizaje estadístico con R." />
  

<meta name="author" content="Rubén Fernández Casal (ruben.fcasal@udc.es)" />
<meta name="author" content="Julián Costa Bouzas (julian.costa@udc.es)" />
<meta name="author" content="Manuel Oviedo de la Fuente (manuel.oviedo@udc.es)" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="reg-local.html"/>
<link rel="next" href="reg-gam.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.6.2/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.30/datatables.js"></script>
<link href="libs/dt-core-1.13.4/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.13.4/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.13.4/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Métodos predictivos de aprendizaje estadístico</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Bienvenida</a></li>
<li class="chapter" data-level="" data-path="prólogo.html"><a href="prólogo.html"><i class="fa fa-check"></i>Prólogo</a>
<ul>
<li class="chapter" data-level="" data-path="el-lenguaje-de-programación-r.html"><a href="el-lenguaje-de-programación-r.html"><i class="fa fa-check"></i>El lenguaje de programación R</a></li>
<li class="chapter" data-level="" data-path="organización.html"><a href="organización.html"><i class="fa fa-check"></i>Organización</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro-AE.html"><a href="intro-AE.html"><i class="fa fa-check"></i><b>1</b> Introducción al aprendizaje estadístico</a>
<ul>
<li class="chapter" data-level="1.1" data-path="aprendizaje-estadístico-vs.-aprendizaje-automático.html"><a href="aprendizaje-estadístico-vs.-aprendizaje-automático.html"><i class="fa fa-check"></i><b>1.1</b> Aprendizaje estadístico vs. aprendizaje automático</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="aprendizaje-estadístico-vs.-aprendizaje-automático.html"><a href="aprendizaje-estadístico-vs.-aprendizaje-automático.html#las-dos-culturas"><i class="fa fa-check"></i><b>1.1.1</b> Las dos culturas</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="métodos-de-aprendizaje-estadístico.html"><a href="métodos-de-aprendizaje-estadístico.html"><i class="fa fa-check"></i><b>1.2</b> Métodos de aprendizaje estadístico</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="métodos-de-aprendizaje-estadístico.html"><a href="métodos-de-aprendizaje-estadístico.html#notacion"><i class="fa fa-check"></i><b>1.2.1</b> Notación y terminología</a></li>
<li class="chapter" data-level="1.2.2" data-path="métodos-de-aprendizaje-estadístico.html"><a href="métodos-de-aprendizaje-estadístico.html#metodos-pkgs"><i class="fa fa-check"></i><b>1.2.2</b> Métodos (de aprendizaje supervisado) y paquetes de R</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="const-eval.html"><a href="const-eval.html"><i class="fa fa-check"></i><b>1.3</b> Construcción y evaluación de los modelos</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="const-eval.html"><a href="const-eval.html#bias-variance"><i class="fa fa-check"></i><b>1.3.1</b> Equilibrio entre sesgo y varianza: infraajuste y sobreajuste</a></li>
<li class="chapter" data-level="1.3.2" data-path="const-eval.html"><a href="const-eval.html#entrenamiento-test"><i class="fa fa-check"></i><b>1.3.2</b> Datos de entrenamiento y datos de test</a></li>
<li class="chapter" data-level="1.3.3" data-path="const-eval.html"><a href="const-eval.html#cv"><i class="fa fa-check"></i><b>1.3.3</b> Selección de hiperparámetros mediante validación cruzada</a></li>
<li class="chapter" data-level="1.3.4" data-path="const-eval.html"><a href="const-eval.html#eval-reg"><i class="fa fa-check"></i><b>1.3.4</b> Evaluación de un método de regresión</a></li>
<li class="chapter" data-level="1.3.5" data-path="const-eval.html"><a href="const-eval.html#eval-class"><i class="fa fa-check"></i><b>1.3.5</b> Evaluación de un método de clasificación</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="dimen-curse.html"><a href="dimen-curse.html"><i class="fa fa-check"></i><b>1.4</b> La maldición de la dimensionalidad</a></li>
<li class="chapter" data-level="1.5" data-path="analisis-modelos.html"><a href="analisis-modelos.html"><i class="fa fa-check"></i><b>1.5</b> Análisis e interpretación de los modelos</a></li>
<li class="chapter" data-level="1.6" data-path="caret.html"><a href="caret.html"><i class="fa fa-check"></i><b>1.6</b> Introducción al paquete <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="clasicos.html"><a href="clasicos.html"><i class="fa fa-check"></i><b>2</b> Métodos clásicos de estadística</a>
<ul>
<li class="chapter" data-level="2.1" data-path="rlm.html"><a href="rlm.html"><i class="fa fa-check"></i><b>2.1</b> Regresión lineal múltiple</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="rlm.html"><a href="rlm.html#colinealidad"><i class="fa fa-check"></i><b>2.1.1</b> El problema de la colinealidad</a></li>
<li class="chapter" data-level="2.1.2" data-path="rlm.html"><a href="rlm.html#seleccion-rlm"><i class="fa fa-check"></i><b>2.1.2</b> Selección de variables explicativas</a></li>
<li class="chapter" data-level="2.1.3" data-path="rlm.html"><a href="rlm.html#analisis-rlm"><i class="fa fa-check"></i><b>2.1.3</b> Análisis e interpretación del modelo</a></li>
<li class="chapter" data-level="2.1.4" data-path="rlm.html"><a href="rlm.html#eval-rlm"><i class="fa fa-check"></i><b>2.1.4</b> Evaluación de la precisión</a></li>
<li class="chapter" data-level="2.1.5" data-path="rlm.html"><a href="rlm.html#selec-ae-rlm"><i class="fa fa-check"></i><b>2.1.5</b> Selección del modelo mediante remuestreo</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="reg-glm.html"><a href="reg-glm.html"><i class="fa fa-check"></i><b>2.2</b> Modelos lineales generalizados</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="reg-glm.html"><a href="reg-glm.html#seleccion-glm"><i class="fa fa-check"></i><b>2.2.1</b> Selección de variables explicativas</a></li>
<li class="chapter" data-level="2.2.2" data-path="reg-glm.html"><a href="reg-glm.html#analisis-glm"><i class="fa fa-check"></i><b>2.2.2</b> Análisis e interpretación del modelo</a></li>
<li class="chapter" data-level="2.2.3" data-path="reg-glm.html"><a href="reg-glm.html#glm-bfan"><i class="fa fa-check"></i><b>2.2.3</b> Evaluación de la precisión</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="generadores.html"><a href="generadores.html"><i class="fa fa-check"></i><b>2.3</b> Otros métodos de clasificación</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="generadores.html"><a href="generadores.html#clas-lda"><i class="fa fa-check"></i><b>2.3.1</b> Análisis discriminante lineal</a></li>
<li class="chapter" data-level="2.3.2" data-path="generadores.html"><a href="generadores.html#clas-qda"><i class="fa fa-check"></i><b>2.3.2</b> Análisis discriminante cuadrático</a></li>
<li class="chapter" data-level="2.3.3" data-path="generadores.html"><a href="generadores.html#bayes"><i class="fa fa-check"></i><b>2.3.3</b> Bayes naíf</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="trees.html"><a href="trees.html"><i class="fa fa-check"></i><b>3</b> Árboles de decisión</a>
<ul>
<li class="chapter" data-level="3.1" data-path="árboles-de-regresión-cart.html"><a href="árboles-de-regresión-cart.html"><i class="fa fa-check"></i><b>3.1</b> Árboles de regresión CART</a></li>
<li class="chapter" data-level="3.2" data-path="árboles-de-clasificación-cart.html"><a href="árboles-de-clasificación-cart.html"><i class="fa fa-check"></i><b>3.2</b> Árboles de clasificación CART</a></li>
<li class="chapter" data-level="3.3" data-path="tree-rpart.html"><a href="tree-rpart.html"><i class="fa fa-check"></i><b>3.3</b> CART con el paquete <code>rpart</code></a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="tree-rpart.html"><a href="tree-rpart.html#reg-rpart"><i class="fa fa-check"></i><b>3.3.1</b> Ejemplo: regresión</a></li>
<li class="chapter" data-level="3.3.2" data-path="tree-rpart.html"><a href="tree-rpart.html#class-rpart"><i class="fa fa-check"></i><b>3.3.2</b> Ejemplo: modelo de clasificación</a></li>
<li class="chapter" data-level="3.3.3" data-path="tree-rpart.html"><a href="tree-rpart.html#interfaz-de-caret"><i class="fa fa-check"></i><b>3.3.3</b> Interfaz de <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="alternativas-a-los-árboles-cart.html"><a href="alternativas-a-los-árboles-cart.html"><i class="fa fa-check"></i><b>3.4</b> Alternativas a los árboles CART</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bagging-boosting.html"><a href="bagging-boosting.html"><i class="fa fa-check"></i><b>4</b> Bagging y boosting</a>
<ul>
<li class="chapter" data-level="4.1" data-path="bagging.html"><a href="bagging.html"><i class="fa fa-check"></i><b>4.1</b> Bagging</a></li>
<li class="chapter" data-level="4.2" data-path="rf.html"><a href="rf.html"><i class="fa fa-check"></i><b>4.2</b> Bosques aleatorios</a></li>
<li class="chapter" data-level="4.3" data-path="bagging-rf-r.html"><a href="bagging-rf-r.html"><i class="fa fa-check"></i><b>4.3</b> Bagging y bosques aleatorios en R</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="bagging-rf-r.html"><a href="bagging-rf-r.html#ejemplo-clasificación-con-bagging"><i class="fa fa-check"></i><b>4.3.1</b> Ejemplo: clasificación con bagging</a></li>
<li class="chapter" data-level="4.3.2" data-path="bagging-rf-r.html"><a href="bagging-rf-r.html#ejemplo-clasif-rf"><i class="fa fa-check"></i><b>4.3.2</b> Ejemplo: clasificación con bosques aleatorios</a></li>
<li class="chapter" data-level="4.3.3" data-path="bagging-rf-r.html"><a href="bagging-rf-r.html#ejemplo-bosques-aleatorios-con-caret"><i class="fa fa-check"></i><b>4.3.3</b> Ejemplo: bosques aleatorios con <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="boosting.html"><a href="boosting.html"><i class="fa fa-check"></i><b>4.4</b> Boosting</a></li>
<li class="chapter" data-level="4.5" data-path="boosting-r.html"><a href="boosting-r.html"><i class="fa fa-check"></i><b>4.5</b> Boosting en R</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="boosting-r.html"><a href="boosting-r.html#ejemplo-clasificación-con-el-paquete-ada"><i class="fa fa-check"></i><b>4.5.1</b> Ejemplo: clasificación con el paquete <code>ada</code></a></li>
<li class="chapter" data-level="4.5.2" data-path="boosting-r.html"><a href="boosting-r.html#ejemplo-regresión-con-el-paquete-gbm"><i class="fa fa-check"></i><b>4.5.2</b> Ejemplo: regresión con el paquete <code>gbm</code></a></li>
<li class="chapter" data-level="4.5.3" data-path="boosting-r.html"><a href="boosting-r.html#xgb-caret"><i class="fa fa-check"></i><b>4.5.3</b> Ejemplo: XGBoost con el paquete <code>caret</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="svm.html"><a href="svm.html"><i class="fa fa-check"></i><b>5</b> Máquinas de soporte vectorial</a>
<ul>
<li class="chapter" data-level="5.1" data-path="clasificadores-de-máximo-margen.html"><a href="clasificadores-de-máximo-margen.html"><i class="fa fa-check"></i><b>5.1</b> Clasificadores de máximo margen</a></li>
<li class="chapter" data-level="5.2" data-path="clasificadores-de-soporte-vectorial.html"><a href="clasificadores-de-soporte-vectorial.html"><i class="fa fa-check"></i><b>5.2</b> Clasificadores de soporte vectorial</a></li>
<li class="chapter" data-level="5.3" data-path="máquinas-de-soporte-vectorial.html"><a href="máquinas-de-soporte-vectorial.html"><i class="fa fa-check"></i><b>5.3</b> Máquinas de soporte vectorial</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="máquinas-de-soporte-vectorial.html"><a href="máquinas-de-soporte-vectorial.html#regresión-con-svm"><i class="fa fa-check"></i><b>5.3.1</b> Regresión con SVM</a></li>
<li class="chapter" data-level="5.3.2" data-path="máquinas-de-soporte-vectorial.html"><a href="máquinas-de-soporte-vectorial.html#ventajas-e-incovenientes"><i class="fa fa-check"></i><b>5.3.2</b> Ventajas e incovenientes</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="svm-kernlab.html"><a href="svm-kernlab.html"><i class="fa fa-check"></i><b>5.4</b> SVM en R</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ext-glm.html"><a href="ext-glm.html"><i class="fa fa-check"></i><b>6</b> Extensiones de los modelos lineales (generalizados)</a>
<ul>
<li class="chapter" data-level="6.1" data-path="shrinkage.html"><a href="shrinkage.html"><i class="fa fa-check"></i><b>6.1</b> Métodos de regularización</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="shrinkage.html"><a href="shrinkage.html#implementación-en-r"><i class="fa fa-check"></i><b>6.1.1</b> Implementación en R</a></li>
<li class="chapter" data-level="6.1.2" data-path="shrinkage.html"><a href="shrinkage.html#ejemplo-ridge-regression"><i class="fa fa-check"></i><b>6.1.2</b> Ejemplo: <em>ridge regression</em></a></li>
<li class="chapter" data-level="6.1.3" data-path="shrinkage.html"><a href="shrinkage.html#ejemplo-lasso"><i class="fa fa-check"></i><b>6.1.3</b> Ejemplo: LASSO</a></li>
<li class="chapter" data-level="6.1.4" data-path="shrinkage.html"><a href="shrinkage.html#ejemplo-elastic-net"><i class="fa fa-check"></i><b>6.1.4</b> Ejemplo: <em>elastic net</em></a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="pca-pls.html"><a href="pca-pls.html"><i class="fa fa-check"></i><b>6.2</b> Métodos de reducción de la dimensión</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="pca-pls.html"><a href="pca-pls.html#regresión-por-componentes-principales-pcr"><i class="fa fa-check"></i><b>6.2.1</b> Regresión por componentes principales (PCR)</a></li>
<li class="chapter" data-level="6.2.2" data-path="pca-pls.html"><a href="pca-pls.html#regresión-por-mínimos-cuadrados-parciales-plsr"><i class="fa fa-check"></i><b>6.2.2</b> Regresión por mínimos cuadrados parciales (PLSR)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="reg-np.html"><a href="reg-np.html"><i class="fa fa-check"></i><b>7</b> Regresión no paramétrica</a>
<ul>
<li class="chapter" data-level="7.1" data-path="reg-local.html"><a href="reg-local.html"><i class="fa fa-check"></i><b>7.1</b> Regresión local</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="reg-local.html"><a href="reg-local.html#reg-knn"><i class="fa fa-check"></i><b>7.1.1</b> Vecinos más próximos</a></li>
<li class="chapter" data-level="7.1.2" data-path="reg-local.html"><a href="reg-local.html#reg-locpol"><i class="fa fa-check"></i><b>7.1.2</b> Regresión polinómica local</a></li>
<li class="chapter" data-level="7.1.3" data-path="reg-local.html"><a href="reg-local.html#regresión-polinómica-local-robusta"><i class="fa fa-check"></i><b>7.1.3</b> Regresión polinómica local robusta</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>7.2</b> Splines</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="splines.html"><a href="splines.html#reg-splines"><i class="fa fa-check"></i><b>7.2.1</b> Splines de regresión</a></li>
<li class="chapter" data-level="7.2.2" data-path="splines.html"><a href="splines.html#splines-de-suavizado"><i class="fa fa-check"></i><b>7.2.2</b> Splines de suavizado</a></li>
<li class="chapter" data-level="7.2.3" data-path="splines.html"><a href="splines.html#splines-penalizados"><i class="fa fa-check"></i><b>7.2.3</b> Splines penalizados</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="reg-gam.html"><a href="reg-gam.html"><i class="fa fa-check"></i><b>7.3</b> Modelos aditivos</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="reg-gam.html"><a href="reg-gam.html#superficies-de-predicción"><i class="fa fa-check"></i><b>7.3.1</b> Superficies de predicción</a></li>
<li class="chapter" data-level="7.3.2" data-path="reg-gam.html"><a href="reg-gam.html#anova-gam"><i class="fa fa-check"></i><b>7.3.2</b> Comparación y selección de modelos</a></li>
<li class="chapter" data-level="7.3.3" data-path="reg-gam.html"><a href="reg-gam.html#mgcv-diagnosis"><i class="fa fa-check"></i><b>7.3.3</b> Diagnosis del modelo</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="mars.html"><a href="mars.html"><i class="fa fa-check"></i><b>7.4</b> Regresión spline adaptativa multivariante</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="mars.html"><a href="mars.html#mars-con-el-paquete-earth"><i class="fa fa-check"></i><b>7.4.1</b> MARS con el paquete <code>earth</code></a></li>
<li class="chapter" data-level="7.4.2" data-path="mars.html"><a href="mars.html#mars-con-el-paquete-caret"><i class="fa fa-check"></i><b>7.4.2</b> MARS con el paquete <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="pursuit.html"><a href="pursuit.html"><i class="fa fa-check"></i><b>7.5</b> Projection pursuit</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="pursuit.html"><a href="pursuit.html#ppr"><i class="fa fa-check"></i><b>7.5.1</b> Regresión por projection pursuit</a></li>
<li class="chapter" data-level="7.5.2" data-path="pursuit.html"><a href="pursuit.html#implementación-en-r-1"><i class="fa fa-check"></i><b>7.5.2</b> Implementación en R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="neural-nets.html"><a href="neural-nets.html"><i class="fa fa-check"></i><b>8</b> Redes neuronales</a>
<ul>
<li class="chapter" data-level="8.1" data-path="single-hidden-layer-feedforward-network.html"><a href="single-hidden-layer-feedforward-network.html"><i class="fa fa-check"></i><b>8.1</b> Single-hidden-layer feedforward network</a></li>
<li class="chapter" data-level="8.2" data-path="clasificación-con-ann.html"><a href="clasificación-con-ann.html"><i class="fa fa-check"></i><b>8.2</b> Clasificación con ANN</a></li>
<li class="chapter" data-level="8.3" data-path="implementación-en-r-2.html"><a href="implementación-en-r-2.html"><i class="fa fa-check"></i><b>8.3</b> Implementación en R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliografía.html"><a href="bibliografía.html"><i class="fa fa-check"></i>Bibliografía</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Métodos predictivos de aprendizaje estadístico</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="splines" class="section level2 hasAnchor" number="7.2">
<h2><span class="header-section-number">7.2</span> Splines<a href="splines.html#splines" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Un enfoque alternativo a los métodos de regresión local de la sección anterior consiste en trocear los datos en intervalos: se fijan unos puntos de corte <span class="math inline">\(z_i\)</span>, denominados nudos (<em>knots</em>), con <span class="math inline">\(i = 1, \ldots, k\)</span>, y se ajusta un polinomio en cada segmento, lo que se conoce como regresión segmentada (<em>piecewise regression</em>; ver Figura <a href="splines.html#fig:rsegmentada-fit">7.5</a>).
Un inconveniente de este método es que da lugar a discontinuidades en los puntos de corte, aunque pueden añadirse restricciones adicionales de continuidad (o incluso de diferenciabilidad) para evitarlo <span class="citation">(p. ej. paquete <a href="https://CRAN.R-project.org/package=segmented" role="doc-biblioref"><code>segmented</code></a>, <a href="#ref-R-segmented" role="doc-biblioref">Fasola et al., 2018</a>)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:rsegmentada-fit"></span>
<img src="07-regresion_np_files/figure-html/rsegmentada-fit-1.png" alt="Estimación mediante regresión segmentada." width="75%" />
<p class="caption">
Figura 7.5: Estimación mediante regresión segmentada.
</p>
</div>
<div id="reg-splines" class="section level3 hasAnchor" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> Splines de regresión<a href="splines.html#reg-splines" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Cuando en cada intervalo se ajustan polinomios de orden <span class="math inline">\(d\)</span> y se incluyen restricciones de forma que las derivadas sean continuas hasta el orden <span class="math inline">\(d-1\)</span>, se obtienen los denominados <em>splines de regresión</em> (<em>regression splines</em>).
Puede verse que este tipo de ajustes equivalen a transformar la variable predictora <span class="math inline">\(X\)</span>, considerando por ejemplo la <em>base de potencias truncadas</em> (<em>truncated power basis</em>):
<span class="math display">\[1, x, \ldots, x^d, (x-z_1)_+^d,\ldots,(x-z_k)_+^d\]</span>
siendo <span class="math inline">\((x - z)_+ = \max(0, x - z)\)</span>, y posteriormente realizar un ajuste lineal:
<span class="math display">\[m(x) = \beta_0 + \beta_1 b_1(x) +  \beta_2 b_2(x) + \ldots  + \beta_{k+d} b_{k+d}(x)\]</span></p>
<p>Típicamente se seleccionan polinomios de grado <span class="math inline">\(d=3\)</span>, lo que se conoce como splines cúbicos, y nodos equiespaciados.
Además, se podrían emplear otras bases equivalentes.
Por ejemplo, para evitar posibles problemas computacionales con la base anterior, se suele emplear la denominada base <span class="math inline">\(B\)</span>-<em>spline</em> <span class="citation">(<a href="#ref-de1978practical" role="doc-biblioref">De Boor y De Boor, 1978</a>)</span>, implementada en la función <code>bs()</code> del paquete <code>splines</code> (ver Figura <a href="splines.html#fig:spline-d012">7.6</a>):</p>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb401-1"><a href="splines.html#cb401-1" aria-hidden="true" tabindex="-1"></a>nknots <span class="ot">&lt;-</span> <span class="dv">9</span> <span class="co"># nodos internos; 10 intervalos</span></span>
<span id="cb401-2"><a href="splines.html#cb401-2" aria-hidden="true" tabindex="-1"></a>knots <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">min</span>(times), <span class="fu">max</span>(times), <span class="at">len =</span> nknots <span class="sc">+</span> <span class="dv">2</span>)[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span>, nknots <span class="sc">+</span> <span class="dv">2</span>)]</span>
<span id="cb401-3"><a href="splines.html#cb401-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(splines)</span>
<span id="cb401-4"><a href="splines.html#cb401-4" aria-hidden="true" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(accel <span class="sc">~</span> <span class="fu">bs</span>(times, <span class="at">knots =</span> knots, <span class="at">degree =</span> <span class="dv">1</span>))</span>
<span id="cb401-5"><a href="splines.html#cb401-5" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(accel <span class="sc">~</span> <span class="fu">bs</span>(times, <span class="at">knots =</span> knots, <span class="at">degree =</span> <span class="dv">2</span>))</span>
<span id="cb401-6"><a href="splines.html#cb401-6" aria-hidden="true" tabindex="-1"></a>fit3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(accel <span class="sc">~</span> <span class="fu">bs</span>(times, <span class="at">knots =</span> knots)) <span class="co"># degree = 3</span></span>
<span id="cb401-7"><a href="splines.html#cb401-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Representar</span></span>
<span id="cb401-8"><a href="splines.html#cb401-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(times, accel, <span class="at">col =</span> <span class="st">&#39;darkgray&#39;</span>)</span>
<span id="cb401-9"><a href="splines.html#cb401-9" aria-hidden="true" tabindex="-1"></a>newx <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">min</span>(times), <span class="fu">max</span>(times), <span class="at">len =</span> <span class="dv">200</span>)</span>
<span id="cb401-10"><a href="splines.html#cb401-10" aria-hidden="true" tabindex="-1"></a>newdata <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">times =</span> newx)</span>
<span id="cb401-11"><a href="splines.html#cb401-11" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(newx, <span class="fu">predict</span>(fit1, newdata), <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb401-12"><a href="splines.html#cb401-12" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(newx, <span class="fu">predict</span>(fit2, newdata), <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb401-13"><a href="splines.html#cb401-13" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(newx, <span class="fu">predict</span>(fit3, newdata))</span>
<span id="cb401-14"><a href="splines.html#cb401-14" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> knots, <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="st">&#39;darkgray&#39;</span>)</span>
<span id="cb401-15"><a href="splines.html#cb401-15" aria-hidden="true" tabindex="-1"></a>leyenda <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;d=1 (df=11)&quot;</span>, <span class="st">&quot;d=2 (df=12)&quot;</span>, <span class="st">&quot;d=3 (df=13)&quot;</span>)</span>
<span id="cb401-16"><a href="splines.html#cb401-16" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend =</span> leyenda, <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">1</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:spline-d012"></span>
<img src="07-regresion_np_files/figure-html/spline-d012-1.png" alt="Ajustes mediante splines de regresión (de grados 1, 2 y 3)." width="75%" />
<p class="caption">
Figura 7.6: Ajustes mediante splines de regresión (de grados 1, 2 y 3).
</p>
</div>
<p>El grado del polinomio y, sobre todo, el número de nodos, determinarán la flexibilidad del modelo.
El número de parámetros, <span class="math inline">\(k+d+1\)</span>, en el ajuste lineal (los grados de libertad) se puede utilizar como una medida de la complejidad (en la función <code>bs()</code> se puede especificar <code>df</code> en lugar de <code>knots</code>, y estos se generarán a partir de los cuantiles).</p>
<!-- 
knots <- quantile(times, 1:nknots/(nknots + 1))
bs(times, df = nknots + degree + intercept)
-->
<p>Como se comentó previamente, al aumentar el grado de un modelo polinómico se incrementa la variabilidad de las predicciones, especialmente en la frontera.
Para tratar de evitar este problema se suelen emplear los <em>splines naturales</em>, que son splines de regresión con restricciones adicionales de forma que el ajuste sea lineal en los intervalos extremos, lo que en general produce estimaciones más estables en la frontera y mejores extrapolaciones.
Estas restricciones reducen la complejidad (los grados de libertad del modelo), y al igual que en el caso de considerar únicamente las restricciones de continuidad y diferenciabilidad, resultan equivalentes a considerar una nueva base en un ajuste sin restricciones.
Por ejemplo, se puede emplear la función <code>splines::ns()</code> para ajustar un spline natural (cúbico por defecto; ver Figura <a href="splines.html#fig:spline-ns-bs">7.7</a>):</p>

<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb402-1"><a href="splines.html#cb402-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(times, accel, <span class="at">col =</span> <span class="st">&#39;darkgray&#39;</span>)</span>
<span id="cb402-2"><a href="splines.html#cb402-2" aria-hidden="true" tabindex="-1"></a>fit4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(accel <span class="sc">~</span> <span class="fu">ns</span>(times, <span class="at">knots =</span> knots))</span>
<span id="cb402-3"><a href="splines.html#cb402-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(newx, <span class="fu">predict</span>(fit4, newdata))</span>
<span id="cb402-4"><a href="splines.html#cb402-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(newx, <span class="fu">predict</span>(fit3, newdata), <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb402-5"><a href="splines.html#cb402-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> knots, <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="st">&#39;darkgray&#39;</span>)</span>
<span id="cb402-6"><a href="splines.html#cb402-6" aria-hidden="true" tabindex="-1"></a>leyenda <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;ns (d=3, df=11)&quot;</span>, <span class="st">&quot;bs (d=3, df=13)&quot;</span>)</span>
<span id="cb402-7"><a href="splines.html#cb402-7" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend =</span> leyenda, <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:spline-ns-bs"></span>
<img src="07-regresion_np_files/figure-html/spline-ns-bs-1.png" alt="Ajuste mediante splines naturales (ns) y $B$-splines (bs)." width="75%" />
<p class="caption">
Figura 7.7: Ajuste mediante splines naturales (ns) y <span class="math inline">\(B\)</span>-splines (bs).
</p>
</div>
<p>La dificultad principal es la selección de los nodos <span class="math inline">\(z_i\)</span>. Si se consideran equiespaciados (o se emplea otro criterio, como los cuantiles), se puede seleccionar su número (equivalentemente, los grados de libertad) empleando validación cruzada.
Sin embargo, es preferible utilizar más nodos donde aparentemente hay más variaciones en la función de regresión, y menos donde es más estable; esta es la idea de la regresión spline adaptativa, descrita en la Sección <a href="mars.html#mars">7.4</a>.
Otra alternativa son los splines penalizados, descritos al final de esta sección.</p>
</div>
<div id="splines-de-suavizado" class="section level3 hasAnchor" number="7.2.2">
<h3><span class="header-section-number">7.2.2</span> Splines de suavizado<a href="splines.html#splines-de-suavizado" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Los <em>splines de suavizado</em> (<em>smoothing splines</em>) se obtienen como la función <span class="math inline">\(s(x)\)</span> suave (dos veces diferenciable) que minimiza la suma de cuadrados residual más una penalización que mide su rugosidad:
<span class="math display">\[\sum_{i=1}^{n} (y_i - s(x_i))^2  + \lambda \int s^{\prime\prime}(x)^2 dx\]</span>
siendo <span class="math inline">\(0 \leq \lambda &lt; \infty\)</span> el hiperparámetro de suavizado.</p>
<p>Puede verse que la solución a este problema, en el caso univariante, es un spline natural cúbico con nodos en <span class="math inline">\(x_1, \ldots, x_n\)</span> y restricciones en los coeficientes determinadas por el valor de <span class="math inline">\(\lambda\)</span> (es una versión regularizada de un spline natural cúbico).
Por ejemplo, si <span class="math inline">\(\lambda = 0\)</span> se interpolarán las observaciones, y cuando <span class="math inline">\(\lambda \rightarrow \infty\)</span> el ajuste tenderá a una recta (con segunda derivada nula).
En el caso multivariante, <span class="math inline">\(p&gt; 1\)</span>, la solución da lugar a los denominados <em>thin plate splines</em><a href="#fn63" class="footnote-ref" id="fnref63"><sup>63</sup></a>.</p>
<p>Al igual que en el caso de la regresión polinómica local (Sección <a href="reg-local.html#reg-locpol">7.1.2</a>), estos métodos son suavizadores lineales:
<span class="math display">\[\hat{\mathbf{Y}} = S_{\lambda}\mathbf{Y}\]</span>
y para seleccionar el parámetro de suavizado <span class="math inline">\(\lambda\)</span> podemos emplear los criterios de validación cruzada (dejando uno fuera), minimizando:
<span class="math display">\[CV(\lambda)=\frac{1}{n}\sum_{i=1}^n\left(\frac{y_i-\hat{s}_{\lambda}(x_i)}{1 - \{ S_{\lambda}\}_{ii}}\right)^2\]</span>
siendo <span class="math inline">\(\{ S_{\lambda}\}_{ii}\)</span> el elemento <span class="math inline">\(i\)</span>-ésimo de la diagonal de la matriz de suavizado;
o validación cruzada generalizada (GCV), minimizando:
<span class="math display">\[GCV(\lambda)=\frac{1}{n}\sum_{i=1}^n\left(\frac{y_i-\hat{s}_{\lambda}(x_i)}{1 - \frac{1}{n}tr(S_{\lambda})}\right)^2\]</span></p>
<p>Análogamente, el número efectivo de parámetros o grados de libertad<a href="#fn64" class="footnote-ref" id="fnref64"><sup>64</sup></a> <span class="math inline">\(df_{\lambda}=tr(S_{\lambda})\)</span> sería una medida de la complejidad del modelo equivalente a <span class="math inline">\(\lambda\)</span> (muchas implementaciones permiten seleccionar la complejidad empleando <span class="math inline">\(df\)</span>).</p>
<p>Este método de suavizado está implementado en la función <code>smooth.spline()</code> del paquete base.
Por defecto emplea GCV para seleccionar el parámetro de suavizado, aunque también admite CV y se puede especificar <code>lambda</code> o <code>df</code> (ver Figura <a href="splines.html#fig:spline-smooth">7.8</a>).
Además de predicciones, el correspondiente método <code>predict()</code> también permite obtener estimaciones de las derivadas.</p>
<div class="sourceCode" id="cb403"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb403-1"><a href="splines.html#cb403-1" aria-hidden="true" tabindex="-1"></a>sspline.gcv <span class="ot">&lt;-</span> <span class="fu">smooth.spline</span>(times, accel)</span>
<span id="cb403-2"><a href="splines.html#cb403-2" aria-hidden="true" tabindex="-1"></a>sspline.cv <span class="ot">&lt;-</span> <span class="fu">smooth.spline</span>(times, accel, <span class="at">cv =</span> <span class="cn">TRUE</span>)</span>
<span id="cb403-3"><a href="splines.html#cb403-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(times, accel, <span class="at">col =</span> <span class="st">&#39;darkgray&#39;</span>)</span>
<span id="cb403-4"><a href="splines.html#cb403-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(sspline.gcv)</span>
<span id="cb403-5"><a href="splines.html#cb403-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(sspline.cv, <span class="at">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:spline-smooth"></span>
<img src="07-regresion_np_files/figure-html/spline-smooth-1.png" alt="Ajuste mediante splines de suavizado, empleando GCV (línea contínua) y CV (línea discontínua) para seleccionar el parámetro de suavizado." width="75%" />
<p class="caption">
Figura 7.8: Ajuste mediante splines de suavizado, empleando GCV (línea contínua) y CV (línea discontínua) para seleccionar el parámetro de suavizado.
</p>
</div>
<p>Cuando el número de observaciones es muy grande, y por tanto el número de nodos, pueden aparecer problemas computacionales al emplear estos métodos.</p>
</div>
<div id="splines-penalizados" class="section level3 hasAnchor" number="7.2.3">
<h3><span class="header-section-number">7.2.3</span> Splines penalizados<a href="splines.html#splines-penalizados" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Los <em>splines penalizados</em> (<em>penalized splines</em>) combinan las dos aproximaciones anteriores.
Incluyen una penalización que depende de la base considerada, y el número de nodos puede ser mucho menor que el número de observaciones (son un tipo de <em>low-rank smoothers</em>). De esta forma, se obtienen modelos spline con mejores propiedades, con un menor efecto frontera y en los que se evitan problemas en la selección de los nodos.
Entre los más utilizados se encuentran los <span class="math inline">\(P\)</span>-<em>splines</em> <span class="citation">(<a href="#ref-eilers1996flexible" role="doc-biblioref">Eilers y Marx, 1996</a>)</span>, que emplean una base <span class="math inline">\(B\)</span>-spline con una penalización simple basada en los cuadrados de diferencias de coeficientes consecutivos <span class="math inline">\((\beta_{i+1} - \beta_i)^2\)</span>.</p>
<p>Asimismo, un modelo spline penalizado se puede representar como un modelo lineal mixto, lo que permite emplear herramientas desarrolladas para este tipo de modelos; por ejemplo, las implementadas en el paquete <code>nlme</code> <span class="citation">(<a href="#ref-R-nlme" role="doc-biblioref">Pinheiro et al., 2023</a>)</span>, del que depende <code>mgcv</code> <span class="citation">(<a href="#ref-wood2017generalized" role="doc-biblioref">Wood, 2017</a>)</span>, que por defecto emplea splines penalizados.
Para más detalles, se recomiendan las secciones 5.2 y 5.3 de <span class="citation">Wood (<a href="#ref-wood2017generalized" role="doc-biblioref">2017</a>)</span>.</p>
<!-- 
?mgcv::adaptive.smooth 
Wand, M.P. (2003). Smoothing and Mixed Models. *Computational Statistics*, 18(2), 223–249
-->
</div>
</div>
<h3>Bibliografía<a href="bibliografía.html#bibliografía" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-de1978practical" class="csl-entry">
De Boor, C., y De Boor, C. (1978). <em>A practical guide to splines</em>. Springer-Verlag. <a href="https://doi.org/10.1007/978-1-4612-6333-3">https://doi.org/10.1007/978-1-4612-6333-3</a>
</div>
<div id="ref-eilers1996flexible" class="csl-entry">
Eilers, P. H., y Marx, B. D. (1996). Flexible smoothing with B-splines and penalties. <em>Statistical Science</em>, <em>11</em>(2), 89-121. <a href="https://doi.org/10.1214/ss/1038425655">https://doi.org/10.1214/ss/1038425655</a>
</div>
<div id="ref-R-segmented" class="csl-entry">
Fasola, S., Muggeo, V. M. R., y Kuchenhoff, H. (2018). A heuristic, iterative algorithm for change-point detection in abrupt change models. <em>Computational Statistics</em>, <em>33</em>(2), 997-1015.
</div>
<div id="ref-R-nlme" class="csl-entry">
Pinheiro, J., Bates, D., y R Core Team. (2023). <em><span>nlme: Linear and Nonlinear Mixed Effects Models</span></em>. <a href="https://cran.r-project.org/package=nlme">https://cran.r-project.org/package=nlme</a>
</div>
<div id="ref-wood2017generalized" class="csl-entry">
Wood, S. N. (2017). <em>Generalized Additive Models: An Introduction with R</em> (2a. ed.). Chapman &amp; Hall/CRC.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="63">
<li id="fn63"><p>Están relacionados con las funciones radiales. También hay versiones con un número reducido de nodos denominados <em>low-rank thin plate regression splines</em>, empleados en el paquete <code>mgcv</code>.<a href="splines.html#fnref63" class="footnote-back">↩︎</a></p></li>
<li id="fn64"><p>Esto también permitiría generalizar los criterios AIC o BIC.<a href="splines.html#fnref64" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="reg-local.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="reg-gam.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rubenfcasal/book_mpae/edit/master/07-regresion_np.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["book_mpae.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
