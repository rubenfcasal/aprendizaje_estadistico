<!DOCTYPE html>
<html lang="es" xml:lang="es">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.3 CART con el paquete rpart | Aprendizaje Estadístico</title>
  <meta name="description" content="Apuntes de la asignatura de Aprendizaje Estadístico del Máster en Técnicas Estadísticas." />
  <meta name="generator" content="bookdown 0.31 and GitBook 2.6.7" />

  <meta property="og:title" content="2.3 CART con el paquete rpart | Aprendizaje Estadístico" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Apuntes de la asignatura de Aprendizaje Estadístico del Máster en Técnicas Estadísticas." />
  <meta name="github-repo" content="rubenfcasal/aprendizaje_estadistico" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.3 CART con el paquete rpart | Aprendizaje Estadístico" />
  
  <meta name="twitter:description" content="Apuntes de la asignatura de Aprendizaje Estadístico del Máster en Técnicas Estadísticas." />
  

<meta name="author" content="Rubén Fernández Casal (ruben.fcasal@udc.es)" />
<meta name="author" content="Julián Costa Bouzas (julian.costa@udc.es)" />
<meta name="author" content="Manuel Oviedo de la Fuente (manuel.oviedo@udc.es)" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="árboles-de-clasificación-cart.html"/>
<link rel="next" href="alternativas-a-los-árboles-cart.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.26/datatables.js"></script>
<link href="libs/dt-core-1.12.1/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.12.1/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.12.1/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Aprendizaje Estadístico</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prólogo</a></li>
<li class="chapter" data-level="1" data-path="intro-AE.html"><a href="intro-AE.html"><i class="fa fa-check"></i><b>1</b> Introducción al Aprendizaje Estadístico</a>
<ul>
<li class="chapter" data-level="1.1" data-path="aprendizaje-estadístico-vs.-aprendizaje-automático.html"><a href="aprendizaje-estadístico-vs.-aprendizaje-automático.html"><i class="fa fa-check"></i><b>1.1</b> Aprendizaje Estadístico vs. Aprendizaje Automático</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="aprendizaje-estadístico-vs.-aprendizaje-automático.html"><a href="aprendizaje-estadístico-vs.-aprendizaje-automático.html#machine-learning-vs.-data-mining"><i class="fa fa-check"></i><b>1.1.1</b> Machine Learning vs. Data Mining</a></li>
<li class="chapter" data-level="1.1.2" data-path="aprendizaje-estadístico-vs.-aprendizaje-automático.html"><a href="aprendizaje-estadístico-vs.-aprendizaje-automático.html#las-dos-culturas"><i class="fa fa-check"></i><b>1.1.2</b> Las dos culturas</a></li>
<li class="chapter" data-level="1.1.3" data-path="aprendizaje-estadístico-vs.-aprendizaje-automático.html"><a href="aprendizaje-estadístico-vs.-aprendizaje-automático.html#machine-learning-vs.-estadística"><i class="fa fa-check"></i><b>1.1.3</b> Machine Learning vs. Estadística</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="métodos-de-aprendizaje-estadístico.html"><a href="métodos-de-aprendizaje-estadístico.html"><i class="fa fa-check"></i><b>1.2</b> Métodos de Aprendizaje Estadístico</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="métodos-de-aprendizaje-estadístico.html"><a href="métodos-de-aprendizaje-estadístico.html#notacion"><i class="fa fa-check"></i><b>1.2.1</b> Notación y terminología</a></li>
<li class="chapter" data-level="1.2.2" data-path="métodos-de-aprendizaje-estadístico.html"><a href="métodos-de-aprendizaje-estadístico.html#metodos-pkgs"><i class="fa fa-check"></i><b>1.2.2</b> Métodos (de aprendizaje supervisado) y paquetes de R</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="const-eval.html"><a href="const-eval.html"><i class="fa fa-check"></i><b>1.3</b> Construcción y evaluación de los modelos</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="const-eval.html"><a href="const-eval.html#bias-variance"><i class="fa fa-check"></i><b>1.3.1</b> Equilibrio entre sesgo y varianza: infraajuste y sobreajuste</a></li>
<li class="chapter" data-level="1.3.2" data-path="const-eval.html"><a href="const-eval.html#entrenamiento-test"><i class="fa fa-check"></i><b>1.3.2</b> Datos de entrenamiento y datos de test</a></li>
<li class="chapter" data-level="1.3.3" data-path="const-eval.html"><a href="const-eval.html#cv"><i class="fa fa-check"></i><b>1.3.3</b> Validación cruzada</a></li>
<li class="chapter" data-level="1.3.4" data-path="const-eval.html"><a href="const-eval.html#eval-reg"><i class="fa fa-check"></i><b>1.3.4</b> Evaluación de un método de regresión</a></li>
<li class="chapter" data-level="1.3.5" data-path="const-eval.html"><a href="const-eval.html#eval-class"><i class="fa fa-check"></i><b>1.3.5</b> Evaluación de un método de clasificación</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="dimen-curse.html"><a href="dimen-curse.html"><i class="fa fa-check"></i><b>1.4</b> La maldición de la dimensionalidad</a></li>
<li class="chapter" data-level="1.5" data-path="analisis-modelos.html"><a href="analisis-modelos.html"><i class="fa fa-check"></i><b>1.5</b> Análisis e interpretación de los modelos</a></li>
<li class="chapter" data-level="1.6" data-path="caret.html"><a href="caret.html"><i class="fa fa-check"></i><b>1.6</b> Introducción al paquete <code>caret</code></a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="caret.html"><a href="caret.html#métodos-implementados"><i class="fa fa-check"></i><b>1.6.1</b> Métodos implementados</a></li>
<li class="chapter" data-level="1.6.2" data-path="caret.html"><a href="caret.html#herramientas"><i class="fa fa-check"></i><b>1.6.2</b> Herramientas</a></li>
<li class="chapter" data-level="1.6.3" data-path="caret.html"><a href="caret.html#ejemplo"><i class="fa fa-check"></i><b>1.6.3</b> Ejemplo</a></li>
<li class="chapter" data-level="1.6.4" data-path="caret.html"><a href="caret.html#desarrollo-futuro"><i class="fa fa-check"></i><b>1.6.4</b> Desarrollo futuro</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="trees.html"><a href="trees.html"><i class="fa fa-check"></i><b>2</b> Árboles de decisión</a>
<ul>
<li class="chapter" data-level="2.1" data-path="árboles-de-regresión-cart.html"><a href="árboles-de-regresión-cart.html"><i class="fa fa-check"></i><b>2.1</b> Árboles de regresión CART</a></li>
<li class="chapter" data-level="2.2" data-path="árboles-de-clasificación-cart.html"><a href="árboles-de-clasificación-cart.html"><i class="fa fa-check"></i><b>2.2</b> Árboles de clasificación CART</a></li>
<li class="chapter" data-level="2.3" data-path="cart-con-el-paquete-rpart.html"><a href="cart-con-el-paquete-rpart.html"><i class="fa fa-check"></i><b>2.3</b> CART con el paquete <code>rpart</code></a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="cart-con-el-paquete-rpart.html"><a href="cart-con-el-paquete-rpart.html#ejemplo-regresión"><i class="fa fa-check"></i><b>2.3.1</b> Ejemplo: regresión</a></li>
<li class="chapter" data-level="2.3.2" data-path="cart-con-el-paquete-rpart.html"><a href="cart-con-el-paquete-rpart.html#class-rpart"><i class="fa fa-check"></i><b>2.3.2</b> Ejemplo: modelo de clasificación</a></li>
<li class="chapter" data-level="2.3.3" data-path="cart-con-el-paquete-rpart.html"><a href="cart-con-el-paquete-rpart.html#interfaz-de-caret"><i class="fa fa-check"></i><b>2.3.3</b> Interfaz de <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="alternativas-a-los-árboles-cart.html"><a href="alternativas-a-los-árboles-cart.html"><i class="fa fa-check"></i><b>2.4</b> Alternativas a los árboles CART</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="alternativas-a-los-árboles-cart.html"><a href="alternativas-a-los-árboles-cart.html#ejemplo-1"><i class="fa fa-check"></i><b>2.4.1</b> Ejemplo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="bagging-boosting.html"><a href="bagging-boosting.html"><i class="fa fa-check"></i><b>3</b> Bagging y Boosting</a>
<ul>
<li class="chapter" data-level="3.1" data-path="bagging.html"><a href="bagging.html"><i class="fa fa-check"></i><b>3.1</b> Bagging</a></li>
<li class="chapter" data-level="3.2" data-path="bosques-aleatorios.html"><a href="bosques-aleatorios.html"><i class="fa fa-check"></i><b>3.2</b> Bosques aleatorios</a></li>
<li class="chapter" data-level="3.3" data-path="bagging-rf-r.html"><a href="bagging-rf-r.html"><i class="fa fa-check"></i><b>3.3</b> Bagging y bosques aleatorios en R</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="bagging-rf-r.html"><a href="bagging-rf-r.html#ejemplo-clasificación-con-bagging"><i class="fa fa-check"></i><b>3.3.1</b> Ejemplo: Clasificación con bagging</a></li>
<li class="chapter" data-level="3.3.2" data-path="bagging-rf-r.html"><a href="bagging-rf-r.html#ejemplo-clasif-rf"><i class="fa fa-check"></i><b>3.3.2</b> Ejemplo: Clasificación con bosques aleatorios</a></li>
<li class="chapter" data-level="3.3.3" data-path="bagging-rf-r.html"><a href="bagging-rf-r.html#ejemplo-bosques-aleatorios-con-caret"><i class="fa fa-check"></i><b>3.3.3</b> Ejemplo: bosques aleatorios con <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="boosting.html"><a href="boosting.html"><i class="fa fa-check"></i><b>3.4</b> Boosting</a></li>
<li class="chapter" data-level="3.5" data-path="boosting-en-r.html"><a href="boosting-en-r.html"><i class="fa fa-check"></i><b>3.5</b> Boosting en R</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="boosting-en-r.html"><a href="boosting-en-r.html#ejemplo-clasificación-con-el-paquete-ada"><i class="fa fa-check"></i><b>3.5.1</b> Ejemplo: clasificación con el paquete <code>ada</code></a></li>
<li class="chapter" data-level="3.5.2" data-path="boosting-en-r.html"><a href="boosting-en-r.html#ejemplo-regresión-con-el-paquete-gbm"><i class="fa fa-check"></i><b>3.5.2</b> Ejemplo: regresión con el paquete <code>gbm</code></a></li>
<li class="chapter" data-level="3.5.3" data-path="boosting-en-r.html"><a href="boosting-en-r.html#xgb-caret"><i class="fa fa-check"></i><b>3.5.3</b> Ejemplo: XGBoost con el paquete <code>caret</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="svm.html"><a href="svm.html"><i class="fa fa-check"></i><b>4</b> Máquinas de soporte vectorial</a>
<ul>
<li class="chapter" data-level="4.1" data-path="clasificadores-de-máximo-margen.html"><a href="clasificadores-de-máximo-margen.html"><i class="fa fa-check"></i><b>4.1</b> Clasificadores de máximo margen</a></li>
<li class="chapter" data-level="4.2" data-path="clasificadores-de-soporte-vectorial.html"><a href="clasificadores-de-soporte-vectorial.html"><i class="fa fa-check"></i><b>4.2</b> Clasificadores de soporte vectorial</a></li>
<li class="chapter" data-level="4.3" data-path="máquinas-de-soporte-vectorial.html"><a href="máquinas-de-soporte-vectorial.html"><i class="fa fa-check"></i><b>4.3</b> Máquinas de soporte vectorial</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="máquinas-de-soporte-vectorial.html"><a href="máquinas-de-soporte-vectorial.html#regresión-con-svm"><i class="fa fa-check"></i><b>4.3.1</b> Regresión con SVM</a></li>
<li class="chapter" data-level="4.3.2" data-path="máquinas-de-soporte-vectorial.html"><a href="máquinas-de-soporte-vectorial.html#ventajas-e-incovenientes"><i class="fa fa-check"></i><b>4.3.2</b> Ventajas e incovenientes</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="svm-kernlab.html"><a href="svm-kernlab.html"><i class="fa fa-check"></i><b>4.4</b> SVM con el paquete <code>kernlab</code></a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="class-otros.html"><a href="class-otros.html"><i class="fa fa-check"></i><b>5</b> Otros métodos de clasificación</a>
<ul>
<li class="chapter" data-level="5.1" data-path="clas-lda.html"><a href="clas-lda.html"><i class="fa fa-check"></i><b>5.1</b> Análisis discriminate lineal</a></li>
<li class="chapter" data-level="5.2" data-path="clas-qda.html"><a href="clas-qda.html"><i class="fa fa-check"></i><b>5.2</b> Análisis discriminante cuadrático</a></li>
<li class="chapter" data-level="5.3" data-path="bayes.html"><a href="bayes.html"><i class="fa fa-check"></i><b>5.3</b> Naive Bayes</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="modelos-lineales.html"><a href="modelos-lineales.html"><i class="fa fa-check"></i><b>6</b> Modelos lineales y extensiones</a>
<ul>
<li class="chapter" data-level="6.1" data-path="reg-multiple.html"><a href="reg-multiple.html"><i class="fa fa-check"></i><b>6.1</b> Regresión lineal múltiple</a></li>
<li class="chapter" data-level="6.2" data-path="colinealidad.html"><a href="colinealidad.html"><i class="fa fa-check"></i><b>6.2</b> El problema de la colinealidad</a></li>
<li class="chapter" data-level="6.3" data-path="seleccion-reg-lineal.html"><a href="seleccion-reg-lineal.html"><i class="fa fa-check"></i><b>6.3</b> Selección de variables explicativas</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="seleccion-reg-lineal.html"><a href="seleccion-reg-lineal.html#búsqueda-exhaustiva"><i class="fa fa-check"></i><b>6.3.1</b> Búsqueda exhaustiva</a></li>
<li class="chapter" data-level="6.3.2" data-path="seleccion-reg-lineal.html"><a href="seleccion-reg-lineal.html#selección-por-pasos"><i class="fa fa-check"></i><b>6.3.2</b> Selección por pasos</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="analisis-reg-multiple.html"><a href="analisis-reg-multiple.html"><i class="fa fa-check"></i><b>6.4</b> Análisis e interpretación del modelo</a></li>
<li class="chapter" data-level="6.5" data-path="eval-reg-lineal.html"><a href="eval-reg-lineal.html"><i class="fa fa-check"></i><b>6.5</b> Evaluación de la precisión</a></li>
<li class="chapter" data-level="6.6" data-path="selec-ae-reg-lineal.html"><a href="selec-ae-reg-lineal.html"><i class="fa fa-check"></i><b>6.6</b> Selección del modelo mediante remuestreo</a></li>
<li class="chapter" data-level="6.7" data-path="shrinkage.html"><a href="shrinkage.html"><i class="fa fa-check"></i><b>6.7</b> Métodos de regularización</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="shrinkage.html"><a href="shrinkage.html#implementación-en-r"><i class="fa fa-check"></i><b>6.7.1</b> Implementación en R</a></li>
<li class="chapter" data-level="6.7.2" data-path="shrinkage.html"><a href="shrinkage.html#ejemplo-ridge-regression"><i class="fa fa-check"></i><b>6.7.2</b> Ejemplo: Ridge Regression</a></li>
<li class="chapter" data-level="6.7.3" data-path="shrinkage.html"><a href="shrinkage.html#ejemplo-lasso"><i class="fa fa-check"></i><b>6.7.3</b> Ejemplo: Lasso</a></li>
<li class="chapter" data-level="6.7.4" data-path="shrinkage.html"><a href="shrinkage.html#ejemplo-elastic-net"><i class="fa fa-check"></i><b>6.7.4</b> Ejemplo: Elastic Net</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="pca-pls.html"><a href="pca-pls.html"><i class="fa fa-check"></i><b>6.8</b> Métodos de reducción de la dimensión</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="pca-pls.html"><a href="pca-pls.html#regresión-por-componentes-principales-pcr"><i class="fa fa-check"></i><b>6.8.1</b> Regresión por componentes principales (PCR)</a></li>
<li class="chapter" data-level="6.8.2" data-path="pca-pls.html"><a href="pca-pls.html#regresión-por-mínimos-cuadrados-parciales-plsr"><i class="fa fa-check"></i><b>6.8.2</b> Regresión por mínimos cuadrados parciales (PLSR)</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="reg-glm.html"><a href="reg-glm.html"><i class="fa fa-check"></i><b>6.9</b> Modelos lineales generalizados</a>
<ul>
<li class="chapter" data-level="6.9.1" data-path="reg-glm.html"><a href="reg-glm.html#selección-de-variables-explicativas"><i class="fa fa-check"></i><b>6.9.1</b> Selección de variables explicativas</a></li>
<li class="chapter" data-level="6.9.2" data-path="reg-glm.html"><a href="reg-glm.html#analisis-glm"><i class="fa fa-check"></i><b>6.9.2</b> Análisis e interpretación del modelo</a></li>
<li class="chapter" data-level="6.9.3" data-path="reg-glm.html"><a href="reg-glm.html#evaluación-de-la-precisión"><i class="fa fa-check"></i><b>6.9.3</b> Evaluación de la precisión</a></li>
<li class="chapter" data-level="6.9.4" data-path="reg-glm.html"><a href="reg-glm.html#extensiones"><i class="fa fa-check"></i><b>6.9.4</b> Extensiones</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="reg-np.html"><a href="reg-np.html"><i class="fa fa-check"></i><b>7</b> Regresión no paramétrica</a>
<ul>
<li class="chapter" data-level="7.1" data-path="reg-local.html"><a href="reg-local.html"><i class="fa fa-check"></i><b>7.1</b> Regresión local</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="reg-local.html"><a href="reg-local.html#reg-knn"><i class="fa fa-check"></i><b>7.1.1</b> Vecinos más próximos</a></li>
<li class="chapter" data-level="7.1.2" data-path="reg-local.html"><a href="reg-local.html#reg-locpol"><i class="fa fa-check"></i><b>7.1.2</b> Regresión polinómica local</a></li>
<li class="chapter" data-level="7.1.3" data-path="reg-local.html"><a href="reg-local.html#regresión-polinómica-local-robusta"><i class="fa fa-check"></i><b>7.1.3</b> Regresión polinómica local robusta</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>7.2</b> Splines</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="splines.html"><a href="splines.html#reg-splines"><i class="fa fa-check"></i><b>7.2.1</b> Splines de regresión</a></li>
<li class="chapter" data-level="7.2.2" data-path="splines.html"><a href="splines.html#splines-de-suavizado"><i class="fa fa-check"></i><b>7.2.2</b> Splines de suavizado</a></li>
<li class="chapter" data-level="7.2.3" data-path="splines.html"><a href="splines.html#splines-penalizados"><i class="fa fa-check"></i><b>7.2.3</b> Splines penalizados</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="reg-gam.html"><a href="reg-gam.html"><i class="fa fa-check"></i><b>7.3</b> Modelos aditivos</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="reg-gam.html"><a href="reg-gam.html#superficies-de-predicción"><i class="fa fa-check"></i><b>7.3.1</b> Superficies de predicción</a></li>
<li class="chapter" data-level="7.3.2" data-path="reg-gam.html"><a href="reg-gam.html#comparación-y-selección-de-modelos"><i class="fa fa-check"></i><b>7.3.2</b> Comparación y selección de modelos</a></li>
<li class="chapter" data-level="7.3.3" data-path="reg-gam.html"><a href="reg-gam.html#mgcv-diagnosis"><i class="fa fa-check"></i><b>7.3.3</b> Diagnosis del modelo</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="mars.html"><a href="mars.html"><i class="fa fa-check"></i><b>7.4</b> Regresión spline adaptativa multivariante</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="mars.html"><a href="mars.html#mars-con-el-paquete-earth"><i class="fa fa-check"></i><b>7.4.1</b> MARS con el paquete <code>earth</code></a></li>
<li class="chapter" data-level="7.4.2" data-path="mars.html"><a href="mars.html#mars-con-el-paquete-caret"><i class="fa fa-check"></i><b>7.4.2</b> MARS con el paquete <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="projection-pursuit.html"><a href="projection-pursuit.html"><i class="fa fa-check"></i><b>7.5</b> Projection pursuit</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="projection-pursuit.html"><a href="projection-pursuit.html#ppr"><i class="fa fa-check"></i><b>7.5.1</b> Regresión por <em>projection pursuit</em></a></li>
<li class="chapter" data-level="7.5.2" data-path="projection-pursuit.html"><a href="projection-pursuit.html#implementación-en-r-1"><i class="fa fa-check"></i><b>7.5.2</b> Implementación en R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="neural-nets.html"><a href="neural-nets.html"><i class="fa fa-check"></i><b>8</b> Redes neuronales</a>
<ul>
<li class="chapter" data-level="8.1" data-path="single-hidden-layer-feedforward-network.html"><a href="single-hidden-layer-feedforward-network.html"><i class="fa fa-check"></i><b>8.1</b> Single-hidden-layer feedforward network</a></li>
<li class="chapter" data-level="8.2" data-path="clasificación-con-ann.html"><a href="clasificación-con-ann.html"><i class="fa fa-check"></i><b>8.2</b> Clasificación con ANN</a></li>
<li class="chapter" data-level="8.3" data-path="implementación-en-r-2.html"><a href="implementación-en-r-2.html"><i class="fa fa-check"></i><b>8.3</b> Implementación en R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a>
<ul>
<li class="chapter" data-level="" data-path="bibliografía-completa.html"><a href="bibliografía-completa.html"><i class="fa fa-check"></i>Bibliografía completa</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Aprendizaje Estadístico</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="cart-con-el-paquete-rpart" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> CART con el paquete <code>rpart</code><a href="cart-con-el-paquete-rpart.html#cart-con-el-paquete-rpart" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La metodología CART está implementada en el paquete <a href="https://CRAN.R-project.org/package=rpart"><code>rpart</code></a>
(Recursive PARTitioning)<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a>.
La función principal es <a href="https://rdrr.io/pkg/rpart/man/rpart.html"><code>rpart()</code></a> y habitualmente se emplea de la forma:</p>
<p><code>rpart(formula, data, method, parms, control, ...)</code></p>
<ul>
<li><p><code>formula</code>: permite especificar la respuesta y las variables predictoras de la forma habitual,
se suele establecer de la forma <code>respuesta ~ .</code> para incluir todas las posibles variables explicativas.</p></li>
<li><p><code>data</code>: <code>data.frame</code> (opcional; donde se evaluará la fórmula) con la muestra de entrenamiento.</p></li>
<li><p><code>method</code>: método empleado para realizar las particiones, puede ser <code>"anova"</code> (regresión), <code>"class"</code> (clasificación),
<code>"poisson"</code> (regresión de Poisson) o <code>"exp"</code> (supervivencia), o alternativamente una lista de funciones (con componentes
<code>init</code>, <code>split</code>, <code>eval</code>; ver la vignette <a href="https://cran.r-project.org/web/packages/rpart/vignettes/usercode.pdf"><em>User Written Split Functions</em></a>).
Por defecto se selecciona a partir de la variable respuesta en <code>formula</code>,
por ejemplo si es un factor (lo recomendado en clasificación) emplea <code>method = "class"</code>.</p></li>
<li><p><code>parms</code>: lista de parámetros opcionales para la partición en el caso de clasificación
(o regresión de Poisson). Puede contener los componentes <code>prior</code> (vector de probabilidades previas;
por defecto las frecuencias observadas), <code>loss</code> (matriz de pérdidas; con ceros en la diagonal y por defecto 1 en el resto)
y <code>split</code> (criterio de error; por defecto <code>"gini"</code> o alternativamente <code>"information"</code>).</p></li>
<li><p><code>control</code>: lista de opciones que controlan el algoritmo de partición, por defecto se seleccionan mediante la función <code>rpart.control</code>,
aunque también se pueden establecer en la llamada a la función principal, y los principales parámetros son:</p>
<pre><code>rpart.control(minsplit = 20, minbucket = round(minsplit/3), cp = 0.01, 
              xval = 10, maxdepth = 30, ...)</code></pre>
<ul>
<li><p><code>cp</code> es el parámetro de complejidad <span class="math inline">\(\tilde \alpha\)</span> para la poda del árbol, de forma que un valor de 1 se corresponde con un árbol sin divisiones y un valor de 0 con un árbol de profundidad máxima.
Adicionalmente, para reducir el tiempo de computación, el algoritmo empleado no realiza una partición si la proporción de reducción del error es inferior a este valor (valores más grandes simplifican el modelo y reducen el tiempo de computación).</p></li>
<li><p><code>maxdepth</code> es la profundidad máxima del árbol (la profundidad de la raíz sería 0).</p></li>
<li><p><code>minsplit</code> y <code>minbucket</code> son, respectivamente, los números mínimos de observaciones en un nodo intermedio para particionarlo
y en un nodo terminal.</p></li>
<li><p><code>xval</code> es el número de grupos (folds) para validación cruzada.</p></li>
</ul></li>
</ul>
<p>Para más detalles consultar la documentación de esta función o la vignette <a href="https://cran.r-project.org/web/packages/rpart/vignettes/longintro.pdf"><em>Introduction to Rpart</em></a>.</p>
<div id="ejemplo-regresión" class="section level3 hasAnchor" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> Ejemplo: regresión<a href="cart-con-el-paquete-rpart.html#ejemplo-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Emplearemos el conjunto de datos <em>winequality.RData</em> <span class="citation">(ver <a href="#ref-cortez2009modeling" role="doc-biblioref">Cortez et al., 2009</a>)</span>, que contiene información fisico-química
(<code>fixed.acidity</code>, <code>volatile.acidity</code>, <code>citric.acid</code>, <code>residual.sugar</code>, <code>chlorides</code>, <code>free.sulfur.dioxide</code>,
<code>total.sulfur.dioxide</code>, <code>density</code>, <code>pH</code>, <code>sulphates</code> y <code>alcohol</code>) y sensorial (<code>quality</code>)
de una muestra de 1250 vinos portugueses de la variedad <em>Vinho Verde</em>.
Como respuesta consideraremos la variable <code>quality</code>, mediana de al menos 3 evaluaciones de la calidad del vino realizadas por expertos, que los evaluaron entre 0 (muy malo) y 10 (muy excelente) como puede observarse en el gráfico de barras de la Figura <a href="cart-con-el-paquete-rpart.html#fig:barplot">2.3</a>.</p>

<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="cart-con-el-paquete-rpart.html#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">&quot;data/winequality.RData&quot;</span>)</span>
<span id="cb72-2"><a href="cart-con-el-paquete-rpart.html#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(winequality)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    1250 obs. of  12 variables:
##  $ fixed.acidity       : num  6.8 7.1 6.9 7.5 8.6 7.7 5.4 6.8 6.1 5.5 ...
##  $ volatile.acidity    : num  0.37 0.24 0.32 0.23 0.36 0.28 0.59 0.16 0.28 0.2..
##  $ citric.acid         : num  0.47 0.34 0.13 0.49 0.26 0.63 0.07 0.36 0.27 0.2..
##  $ residual.sugar      : num  11.2 1.2 7.8 7.7 11.1 11.1 7 1.3 4.7 1.6 ...
##  $ chlorides           : num  0.071 0.045 0.042 0.049 0.03 0.039 0.045 0.034 0..
##  $ free.sulfur.dioxide : num  44 6 11 61 43.5 58 36 32 56 23 ...
##  $ total.sulfur.dioxide: num  136 132 117 209 171 179 147 98 140 85 ...
##  $ density             : num  0.997 0.991 0.996 0.994 0.995 ...
##  $ pH                  : num  2.98 3.16 3.23 3.14 3.03 3.08 3.34 3.02 3.16 3.4..
##  $ sulphates           : num  0.88 0.46 0.37 0.3 0.49 0.44 0.57 0.58 0.42 0.42..
##  $ alcohol             : num  9.2 11.2 9.2 11.1 12 8.8 9.7 11.3 12.5 12.5 ...
##  $ quality             : int  5 4 5 7 5 4 6 6 8 5 ...</code></pre>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="cart-con-el-paquete-rpart.html#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="fu">barplot</span>(<span class="fu">table</span>(winequality<span class="sc">$</span>quality), <span class="at">xlab =</span> <span class="st">&quot;Calidad&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Frecuencia&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:barplot"></span>
<img src="02-arboles_files/figure-html/barplot-1.png" alt="Distribución de las evaluaciones de la calidad del vino (winequality$quality)." width="75%" />
<p class="caption">
Figura 2.3: Distribución de las evaluaciones de la calidad del vino (<code>winequality$quality</code>).
</p>
</div>
<p>En primer lugar se selecciona el 80% de los datos como muestra de entrenamiento y el 20% restante como muestra de test:</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="cart-con-el-paquete-rpart.html#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb75-2"><a href="cart-con-el-paquete-rpart.html#cb75-2" aria-hidden="true" tabindex="-1"></a>nobs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(winequality)</span>
<span id="cb75-3"><a href="cart-con-el-paquete-rpart.html#cb75-3" aria-hidden="true" tabindex="-1"></a>itrain <span class="ot">&lt;-</span> <span class="fu">sample</span>(nobs, <span class="fl">0.8</span> <span class="sc">*</span> nobs)</span>
<span id="cb75-4"><a href="cart-con-el-paquete-rpart.html#cb75-4" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> winequality[itrain, ]</span>
<span id="cb75-5"><a href="cart-con-el-paquete-rpart.html#cb75-5" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> winequality[<span class="sc">-</span>itrain, ]</span></code></pre></div>
<p>Podemos obtener el árbol de decisión con las opciones por defecto con el comando:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="cart-con-el-paquete-rpart.html#cb76-1" aria-hidden="true" tabindex="-1"></a>tree <span class="ot">&lt;-</span> <span class="fu">rpart</span>(quality <span class="sc">~</span> ., <span class="at">data =</span> train)</span></code></pre></div>
<p>Al imprimirlo se muestra el número de observaciones e información
sobre los distintos nodos (número de nodo, condición que define la partición,
número de observaciones en el nodo, función de pérdida y predicción),
marcando con un <code>*</code> los nodos terminales.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="cart-con-el-paquete-rpart.html#cb77-1" aria-hidden="true" tabindex="-1"></a>tree</span></code></pre></div>
<pre><code>## n= 1000 
## 
## node), split, n, deviance, yval
##       * denotes terminal node
## 
##  1) root 1000 768.95600 5.862000  
##    2) alcohol&lt; 10.75 622 340.81190 5.586817  
##      4) volatile.acidity&gt;=0.2575 329 154.75990 5.370821  
##        8) total.sulfur.dioxide&lt; 98.5 24  12.50000 4.750000 *
##        9) total.sulfur.dioxide&gt;=98.5 305 132.28200 5.419672  
##         18) pH&lt; 3.315 269 101.44980 5.353160 *
##         19) pH&gt;=3.315 36  20.75000 5.916667 *
##      5) volatile.acidity&lt; 0.2575 293 153.46760 5.829352  
##       10) sulphates&lt; 0.475 144  80.32639 5.659722 *
##       11) sulphates&gt;=0.475 149  64.99329 5.993289 *
##    3) alcohol&gt;=10.75 378 303.53700 6.314815  
##      6) alcohol&lt; 11.775 200 173.87500 6.075000  
##       12) free.sulfur.dioxide&lt; 11.5 15  10.93333 4.933333 *
##       13) free.sulfur.dioxide&gt;=11.5 185 141.80540 6.167568  
##         26) volatile.acidity&gt;=0.395 7  12.85714 5.142857 *
##         27) volatile.acidity&lt; 0.395 178 121.30900 6.207865  
##           54) citric.acid&gt;=0.385 31  21.93548 5.741935 *
##           55) citric.acid&lt; 0.385 147  91.22449 6.306122 *
##      7) alcohol&gt;=11.775 178 105.23600 6.584270 *</code></pre>
<p>Para representarlo se puede emplear las herramientas del paquete <a href="https://CRAN.R-project.org/package=rpart"><code>rpart</code></a> (ver Figura <a href="cart-con-el-paquete-rpart.html#fig:arbolrpart">2.4</a>):</p>

<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="cart-con-el-paquete-rpart.html#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tree)</span>
<span id="cb79-2"><a href="cart-con-el-paquete-rpart.html#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(tree)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:arbolrpart"></span>
<img src="02-arboles_files/figure-html/arbolrpart-1.png" alt="Árbol de regresión para predecir winequality$quality (obtenido con las opciones por defecto de rpart())." width="75%" />
<p class="caption">
Figura 2.4: Árbol de regresión para predecir <code>winequality$quality</code> (obtenido con las opciones por defecto de <a href="https://rdrr.io/pkg/rpart/man/rpart.html"><code>rpart()</code></a>).
</p>
</div>
<p>Pero puede ser preferible emplear el paquete <a href="https://CRAN.R-project.org/package=rpart.plot"><code>rpart.plot</code></a> (ver Figura <a href="cart-con-el-paquete-rpart.html#fig:arbolrpartplot">2.5</a>):</p>

<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="cart-con-el-paquete-rpart.html#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb80-2"><a href="cart-con-el-paquete-rpart.html#cb80-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(tree)  </span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:arbolrpartplot"></span>
<img src="02-arboles_files/figure-html/arbolrpartplot-1.png" alt="Representación del árbol de regresión generada con rpart.plot()." width="75%" />
<p class="caption">
Figura 2.5: Representación del árbol de regresión generada con <a href="https://rdrr.io/pkg/rpart.plot/man/rpart.plot.html"><code>rpart.plot()</code></a>.
</p>
</div>
<p>Nos interesa como se clasificaría a una nueva observación en los nodos terminales (en los nodos intermedios solo nos interesarían las condiciones, y el orden de las variables consideradas, hasta llegar a las hojas) y las correspondientes predicciones (la media de la respuesta en el correspondiente nodo terminal).
Para ello, puede ser de utilidad imprimir las reglas:</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="cart-con-el-paquete-rpart.html#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.rules</span>(tree, <span class="at">style =</span> <span class="st">&quot;tall&quot;</span>)</span></code></pre></div>
<pre><code>## quality is 4.8 when
##     alcohol &lt; 11
##     volatile.acidity &gt;= 0.26
##     total.sulfur.dioxide &lt; 99
## 
## quality is 4.9 when
##     alcohol is 11 to 12
##     free.sulfur.dioxide &lt; 12
## 
## quality is 5.1 when
##     alcohol is 11 to 12
##     volatile.acidity &gt;= 0.40
##     free.sulfur.dioxide &gt;= 12
## 
## quality is 5.4 when
##     alcohol &lt; 11
##     volatile.acidity &gt;= 0.26
##     total.sulfur.dioxide &gt;= 99
##     pH &lt; 3.3
## 
## quality is 5.7 when
##     alcohol &lt; 11
##     volatile.acidity &lt; 0.26
##     sulphates &lt; 0.48
## 
## quality is 5.7 when
##     alcohol is 11 to 12
##     volatile.acidity &lt; 0.40
##     free.sulfur.dioxide &gt;= 12
##     citric.acid &gt;= 0.39
## 
## quality is 5.9 when
##     alcohol &lt; 11
##     volatile.acidity &gt;= 0.26
##     total.sulfur.dioxide &gt;= 99
##     pH &gt;= 3.3
## 
## quality is 6.0 when
##     alcohol &lt; 11
##     volatile.acidity &lt; 0.26
##     sulphates &gt;= 0.48
## 
## quality is 6.3 when
##     alcohol is 11 to 12
##     volatile.acidity &lt; 0.40
##     free.sulfur.dioxide &gt;= 12
##     citric.acid &lt; 0.39
## 
## quality is 6.6 when
##     alcohol &gt;= 12</code></pre>
<p>Por defecto se poda el árbol considerando <code>cp = 0.01</code>, que puede ser adecuado en muchos casos.
Sin embargo, para seleccionar el valor óptimo de este (hiper)parámetro se puede emplear validación cruzada.
En primer lugar habría que establecer <code>cp = 0</code> para construir el árbol completo, a la profundidad máxima
(determinada por los valores de <code>minsplit</code> y <code>minbucket</code>, que se podrían seleccionar
“a mano” dependiendo del número de observaciones o también considerándolos como hiperparámetos; esto último no está implementado en <code>rpart</code>, ni en principio en <code>caret</code>)<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a>.</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="cart-con-el-paquete-rpart.html#cb83-1" aria-hidden="true" tabindex="-1"></a>tree <span class="ot">&lt;-</span> <span class="fu">rpart</span>(quality <span class="sc">~</span> ., <span class="at">data =</span> train, <span class="at">cp =</span> <span class="dv">0</span>)</span></code></pre></div>
<p>Posteriormente podemos emplear las funciones <a href="https://rdrr.io/pkg/rpart/man/printcp.html"><code>printcp()</code></a> (o <a href="https://rdrr.io/pkg/rpart/man/plotcp.html"><code>plotcp()</code></a>) para obtener (representar)
los valores de CP para los árboles (óptimos) de menor tamaño junto con su error de validación cruzada
<code>xerror</code> (reescalado de forma que el máximo de <code>rel error</code> es 1)<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a>:</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="cart-con-el-paquete-rpart.html#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="fu">printcp</span>(tree)</span></code></pre></div>
<pre><code>## 
## Regression tree:
## rpart(formula = quality ~ ., data = train, cp = 0)
## 
## Variables actually used in tree construction:
##  [1] alcohol              chlorides            citric.acid         
##  [4] density              fixed.acidity        free.sulfur.dioxide 
##  [7] pH                   residual.sugar       sulphates           
## [10] total.sulfur.dioxide volatile.acidity    
## 
## Root node error: 768.96/1000 = 0.76896
## 
## n= 1000 
## 
##            CP nsplit rel error  xerror     xstd
## 1  0.16204707      0   1.00000 1.00203 0.048591
## 2  0.04237491      1   0.83795 0.85779 0.043646
## 3  0.03176525      2   0.79558 0.82810 0.043486
## 4  0.02748696      3   0.76381 0.81350 0.042814
## 5  0.01304370      4   0.73633 0.77038 0.039654
## 6  0.01059605      6   0.71024 0.78168 0.039353
## 7  0.01026605      7   0.69964 0.78177 0.039141
## 8  0.00840800      9   0.67911 0.78172 0.039123
## 9  0.00813924     10   0.67070 0.80117 0.039915
## 10 0.00780567     11   0.66256 0.80020 0.040481
## 11 0.00684175     13   0.64695 0.79767 0.040219
## 12 0.00673843     15   0.63327 0.81381 0.040851
##  [ reached getOption(&quot;max.print&quot;) -- omitted 48 rows ]</code></pre>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="cart-con-el-paquete-rpart.html#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plotcp</span>(tree)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cp"></span>
<img src="02-arboles_files/figure-html/cp-1.png" alt="Error de validación cruzada (reescalado) dependiendo del parámetro de complejidad CP empleado en el ajuste del árbol de decisión." width="75%" />
<p class="caption">
Figura 2.6: Error de validación cruzada (reescalado) dependiendo del parámetro de complejidad CP empleado en el ajuste del árbol de decisión.
</p>
</div>
<p>La tabla con los valores de las podas (óptimas, dependiendo del parámetro de complejidad)
está almacenada en la componente <code>$cptable</code>:</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="cart-con-el-paquete-rpart.html#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(tree<span class="sc">$</span>cptable, <span class="dv">10</span>)</span></code></pre></div>
<pre><code>##             CP nsplit rel error    xerror       xstd
## 1  0.162047069      0 1.0000000 1.0020304 0.04859127
## 2  0.042374911      1 0.8379529 0.8577876 0.04364585
## 3  0.031765253      2 0.7955780 0.8281010 0.04348571
## 4  0.027486958      3 0.7638128 0.8134957 0.04281430
## 5  0.013043701      4 0.7363258 0.7703804 0.03965433
## 6  0.010596054      6 0.7102384 0.7816774 0.03935308
## 7  0.010266055      7 0.6996424 0.7817716 0.03914071
## 8  0.008408003      9 0.6791102 0.7817177 0.03912344
## 9  0.008139238     10 0.6707022 0.8011719 0.03991498
## 10 0.007805674     11 0.6625630 0.8001996 0.04048088</code></pre>
<p>A partir de la que podríamos seleccionar el valor óptimo de forma automática,
siguiendo el criterio de un error estándar de <span class="citation">Breiman et al. (<a href="#ref-breiman1984classification" role="doc-biblioref">1984</a>)</span>:</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="cart-con-el-paquete-rpart.html#cb89-1" aria-hidden="true" tabindex="-1"></a>xerror <span class="ot">&lt;-</span> tree<span class="sc">$</span>cptable[,<span class="st">&quot;xerror&quot;</span>]</span>
<span id="cb89-2"><a href="cart-con-el-paquete-rpart.html#cb89-2" aria-hidden="true" tabindex="-1"></a>imin.xerror <span class="ot">&lt;-</span> <span class="fu">which.min</span>(xerror)</span>
<span id="cb89-3"><a href="cart-con-el-paquete-rpart.html#cb89-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Valor óptimo</span></span>
<span id="cb89-4"><a href="cart-con-el-paquete-rpart.html#cb89-4" aria-hidden="true" tabindex="-1"></a>tree<span class="sc">$</span>cptable[imin.xerror, ]</span></code></pre></div>
<pre><code>##         CP     nsplit  rel error     xerror       xstd 
## 0.01304370 4.00000000 0.73632581 0.77038039 0.03965433</code></pre>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="cart-con-el-paquete-rpart.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Límite superior &quot;oneSE rule&quot; y complejidad mínima por debajo de ese valor</span></span>
<span id="cb91-2"><a href="cart-con-el-paquete-rpart.html#cb91-2" aria-hidden="true" tabindex="-1"></a>upper.xerror <span class="ot">&lt;-</span> xerror[imin.xerror] <span class="sc">+</span> tree<span class="sc">$</span>cptable[imin.xerror, <span class="st">&quot;xstd&quot;</span>]</span>
<span id="cb91-3"><a href="cart-con-el-paquete-rpart.html#cb91-3" aria-hidden="true" tabindex="-1"></a>icp <span class="ot">&lt;-</span> <span class="fu">min</span>(<span class="fu">which</span>(xerror <span class="sc">&lt;=</span> upper.xerror))</span>
<span id="cb91-4"><a href="cart-con-el-paquete-rpart.html#cb91-4" aria-hidden="true" tabindex="-1"></a>cp <span class="ot">&lt;-</span> tree<span class="sc">$</span>cptable[icp, <span class="st">&quot;CP&quot;</span>]</span></code></pre></div>
<p>Para obtener el modelo final (ver Figura <a href="cart-con-el-paquete-rpart.html#fig:arbolpoda">2.7</a>) podamos el árbol con el valor de complejidad obtenido 0.0130437 que en este caso coincide con el valor óptimo).</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="cart-con-el-paquete-rpart.html#cb92-1" aria-hidden="true" tabindex="-1"></a>tree <span class="ot">&lt;-</span> <span class="fu">prune</span>(tree, <span class="at">cp =</span> cp)</span>
<span id="cb92-2"><a href="cart-con-el-paquete-rpart.html#cb92-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(tree) </span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:arbolpoda"></span>
<img src="02-arboles_files/figure-html/arbolpoda-1.png" alt="Árbol de regresión resultante después de la poda (modelo final)." width="75%" />
<p class="caption">
Figura 2.7: Árbol de regresión resultante después de la poda (modelo final).
</p>
</div>
<p>Podríamos estudiar el modelo final, por ejemplo mediante el método <a href="https://rdrr.io/pkg/rpart/man/summary.rpart.html"><code>summary.rpart()</code></a>, que entre otras cosas muestra una medida (en porcentaje) de la importancia de las variables explicativas para la predicción de la respuesta (teniendo en cuenta todas las particiones, principales y secundarias, en las que se emplea cada variable explicativa).
Alternativamente podríamos emplear el siguiente código:</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="cart-con-el-paquete-rpart.html#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># summary(tree)</span></span>
<span id="cb93-2"><a href="cart-con-el-paquete-rpart.html#cb93-2" aria-hidden="true" tabindex="-1"></a>importance <span class="ot">&lt;-</span> tree<span class="sc">$</span>variable.importance <span class="co"># Equivalente a caret::varImp(tree) </span></span>
<span id="cb93-3"><a href="cart-con-el-paquete-rpart.html#cb93-3" aria-hidden="true" tabindex="-1"></a>importance <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="dv">100</span><span class="sc">*</span>importance<span class="sc">/</span><span class="fu">sum</span>(importance), <span class="dv">1</span>)</span>
<span id="cb93-4"><a href="cart-con-el-paquete-rpart.html#cb93-4" aria-hidden="true" tabindex="-1"></a>importance[importance <span class="sc">&gt;=</span> <span class="dv">1</span>]</span></code></pre></div>
<pre><code>##              alcohol              density            chlorides 
##                 36.1                 21.7                 11.3 
##     volatile.acidity total.sulfur.dioxide  free.sulfur.dioxide 
##                  8.7                  8.5                  5.0 
##       residual.sugar            sulphates          citric.acid 
##                  4.0                  1.9                  1.1 
##                   pH 
##                  1.1</code></pre>
<p>El último paso sería evaluarlo en la muestra de test siguiendo los pasos descritos en la Sección <a href="const-eval.html#eval-reg">1.3.4</a> (ver Figura <a href="cart-con-el-paquete-rpart.html#fig:obsXpred">2.8</a>):</p>

<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="cart-con-el-paquete-rpart.html#cb95-1" aria-hidden="true" tabindex="-1"></a>obs <span class="ot">&lt;-</span> test<span class="sc">$</span>quality</span>
<span id="cb95-2"><a href="cart-con-el-paquete-rpart.html#cb95-2" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree, <span class="at">newdata =</span> test)</span>
<span id="cb95-3"><a href="cart-con-el-paquete-rpart.html#cb95-3" aria-hidden="true" tabindex="-1"></a><span class="co"># plot(pred, obs, xlab = &quot;Predicción&quot;, ylab = &quot;Observado&quot;)</span></span>
<span id="cb95-4"><a href="cart-con-el-paquete-rpart.html#cb95-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">jitter</span>(pred), <span class="fu">jitter</span>(obs), <span class="at">xlab =</span> <span class="st">&quot;Predicción&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Observado&quot;</span>)</span>
<span id="cb95-5"><a href="cart-con-el-paquete-rpart.html#cb95-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> <span class="dv">0</span>, <span class="at">b =</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:obsXpred"></span>
<img src="02-arboles_files/figure-html/obsXpred-1.png" alt="Gráfico de observaciones frente a predicciones (test$quality; se añade una perturbación para mostrar la distribución de los valores)" width="75%" />
<p class="caption">
Figura 2.8: Gráfico de observaciones frente a predicciones (<code>test$quality</code>; se añade una perturbación para mostrar la distribución de los valores)
</p>
</div>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="cart-con-el-paquete-rpart.html#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Empleando el paquete caret </span></span>
<span id="cb96-2"><a href="cart-con-el-paquete-rpart.html#cb96-2" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(pred, obs)</span></code></pre></div>
<pre><code>##      RMSE  Rsquared       MAE 
## 0.8145614 0.1969485 0.6574264</code></pre>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="cart-con-el-paquete-rpart.html#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Con la función accuracy()</span></span>
<span id="cb98-2"><a href="cart-con-el-paquete-rpart.html#cb98-2" aria-hidden="true" tabindex="-1"></a>accuracy <span class="ot">&lt;-</span> <span class="cf">function</span>(pred, obs, <span class="at">na.rm =</span> <span class="cn">FALSE</span>, </span>
<span id="cb98-3"><a href="cart-con-el-paquete-rpart.html#cb98-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">tol =</span> <span class="fu">sqrt</span>(.Machine<span class="sc">$</span>double.eps)) {</span>
<span id="cb98-4"><a href="cart-con-el-paquete-rpart.html#cb98-4" aria-hidden="true" tabindex="-1"></a>  err <span class="ot">&lt;-</span> obs <span class="sc">-</span> pred     <span class="co"># Errores</span></span>
<span id="cb98-5"><a href="cart-con-el-paquete-rpart.html#cb98-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(na.rm) {</span>
<span id="cb98-6"><a href="cart-con-el-paquete-rpart.html#cb98-6" aria-hidden="true" tabindex="-1"></a>    is.a <span class="ot">&lt;-</span> <span class="sc">!</span><span class="fu">is.na</span>(err)</span>
<span id="cb98-7"><a href="cart-con-el-paquete-rpart.html#cb98-7" aria-hidden="true" tabindex="-1"></a>    err <span class="ot">&lt;-</span> err[is.a]</span>
<span id="cb98-8"><a href="cart-con-el-paquete-rpart.html#cb98-8" aria-hidden="true" tabindex="-1"></a>    obs <span class="ot">&lt;-</span> obs[is.a]</span>
<span id="cb98-9"><a href="cart-con-el-paquete-rpart.html#cb98-9" aria-hidden="true" tabindex="-1"></a>  }  </span>
<span id="cb98-10"><a href="cart-con-el-paquete-rpart.html#cb98-10" aria-hidden="true" tabindex="-1"></a>  perr <span class="ot">&lt;-</span> <span class="dv">100</span><span class="sc">*</span>err<span class="sc">/</span><span class="fu">pmax</span>(obs, tol)  <span class="co"># Errores porcentuales</span></span>
<span id="cb98-11"><a href="cart-con-el-paquete-rpart.html#cb98-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">c</span>(</span>
<span id="cb98-12"><a href="cart-con-el-paquete-rpart.html#cb98-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">me =</span> <span class="fu">mean</span>(err),           <span class="co"># Error medio</span></span>
<span id="cb98-13"><a href="cart-con-el-paquete-rpart.html#cb98-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">rmse =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(err<span class="sc">^</span><span class="dv">2</span>)), <span class="co"># Raíz del error cuadrático medio </span></span>
<span id="cb98-14"><a href="cart-con-el-paquete-rpart.html#cb98-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">mae =</span> <span class="fu">mean</span>(<span class="fu">abs</span>(err)),     <span class="co"># Error absoluto medio</span></span>
<span id="cb98-15"><a href="cart-con-el-paquete-rpart.html#cb98-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">mpe =</span> <span class="fu">mean</span>(perr),         <span class="co"># Error porcentual medio</span></span>
<span id="cb98-16"><a href="cart-con-el-paquete-rpart.html#cb98-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">mape =</span> <span class="fu">mean</span>(<span class="fu">abs</span>(perr)),   <span class="co"># Error porcentual absoluto medio</span></span>
<span id="cb98-17"><a href="cart-con-el-paquete-rpart.html#cb98-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">r.squared =</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">sum</span>(err<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span><span class="fu">sum</span>((obs <span class="sc">-</span> <span class="fu">mean</span>(obs))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb98-18"><a href="cart-con-el-paquete-rpart.html#cb98-18" aria-hidden="true" tabindex="-1"></a>  ))</span>
<span id="cb98-19"><a href="cart-con-el-paquete-rpart.html#cb98-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb98-20"><a href="cart-con-el-paquete-rpart.html#cb98-20" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(pred, test<span class="sc">$</span>quality)</span></code></pre></div>
<pre><code>##           me         rmse          mae          mpe         mape    r.squared 
## -0.001269398  0.814561435  0.657426365 -1.952342173 11.576716037  0.192007721</code></pre>
<p>Como se puede observar el ajuste del modelo es bastante malo, como ya se comentó esto es habitual en árboles de regresión (especialmente si son tan pequeños) y normalmente solo se utilizan en un análisis exploratorio inicial (o como base para modelos más avanzados como los mostrados en el siguiente capítulo).
En problemas de clasificación es más habitual que se puedan llegar a obtener buenos ajustes con árboles de decisión.</p>
<div class="exercise">
<p><span id="exr:efecto-semilla" class="exercise"><strong>Ejercicio 2.1  </strong></span>Como se comentó en la introducción del Capítulo <a href="intro-AE.html#intro-AE">1</a> al emplear el procedimiento habitual en AE de particionar los datos no se garantiza la reproducibilidad/repetibilidad de los resultados ya que dependen de la semilla.
El modelo ajustado puede cambiar al variar la semilla (sobre todo si el conjunto de entrenamiento es pequeño; además, en algunos modelos el método de ajuste depende también de la semilla) pero normalmente no hay grandes cambios en las predicciones.</p>
<p>Podemos ilustrar el efecto de la semilla en los resultados empleando el ejemplo anterior.
Habría que repetir el ajuste de un árbol de regresión considerando distintas semillas y comparar los resultados obtenidos.</p>
<p>La dificultad podría estar en como comparar los resultados.
Una posible solución sería mantener fija la muestra de test (que forma que no dependa de las semillas).
Por comodidad podríamos considerar las primeras <code>ntest</code> observaciones del conjunto de datos.
Posteriormente, para cada semilla, seleccionaríamos la muestra de entrenamiento de la forma habitual y ajustaríamos un árbol. Finalmente evaluaríamos los resultados en la muestra de test.</p>
<p>Como base se podría considerar el siguiente código:</p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="cart-con-el-paquete-rpart.html#cb100-1" aria-hidden="true" tabindex="-1"></a>ntest <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb100-2"><a href="cart-con-el-paquete-rpart.html#cb100-2" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> winequality[<span class="dv">1</span><span class="sc">:</span>ntest, ]</span>
<span id="cb100-3"><a href="cart-con-el-paquete-rpart.html#cb100-3" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> winequality[<span class="sc">-</span>(<span class="dv">1</span><span class="sc">:</span>ntest), ]</span>
<span id="cb100-4"><a href="cart-con-el-paquete-rpart.html#cb100-4" aria-hidden="true" tabindex="-1"></a>nobs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(df)</span>
<span id="cb100-5"><a href="cart-con-el-paquete-rpart.html#cb100-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Para las distintas semillas</span></span>
<span id="cb100-6"><a href="cart-con-el-paquete-rpart.html#cb100-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(semilla)</span>
<span id="cb100-7"><a href="cart-con-el-paquete-rpart.html#cb100-7" aria-hidden="true" tabindex="-1"></a>itrain <span class="ot">&lt;-</span> <span class="fu">sample</span>(nobs, <span class="fl">0.8</span> <span class="sc">*</span> nobs)</span>
<span id="cb100-8"><a href="cart-con-el-paquete-rpart.html#cb100-8" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> df[itrain, ]</span>
<span id="cb100-9"><a href="cart-con-el-paquete-rpart.html#cb100-9" aria-hidden="true" tabindex="-1"></a><span class="co"># tree &lt;- ...</span></span></code></pre></div>
<p>Como comentario final, en este caso el conjunto de datos no es muy grande y tampoco se obtuvo un buen ajuste con un árbol de regresión, por lo que sería de esperar que se observaran más diferencias.</p>
</div>
<div class="exercise">
<p><span id="exr:train-validate-test-tree" class="exercise"><strong>Ejercicio 2.2  </strong></span>Como ya se mostró, el paquete <code>rpart</code> implementa la selección del parámetro de complejidad mediante validación cruzada.
Como alternativa, siguiendo la idea del Ejercicio <a href="const-eval.html#exr:train-validate-test">1.1</a>, y considerando de nuevo el ejemplo anterior, particionar la muestra en datos de entrenamiento (70%), de validación (15%) y de test (15%), para ajustar los árboles de decisión, seleccionar el parámetro de complejidad (el hiperparámetro) y evaluar las predicciones del modelo final, respectivamente.</p>
</div>
<div class="exercise">
<p><span id="exr:train-boot-tree" class="exercise"><strong>Ejercicio 2.3  </strong></span>Una alternativa a particionar en entrenamiento y validación sería emplear bootstrap.
La idea es emplear una remuestra bootstrap del conjunto de datos de entrenamiento para ajustar el modelo y utilizar las observaciones no seleccionadas (se suelen denominar datos <em>out of bag</em>) como conjunto de validación.</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="cart-con-el-paquete-rpart.html#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb101-2"><a href="cart-con-el-paquete-rpart.html#cb101-2" aria-hidden="true" tabindex="-1"></a>nobs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(winequality)</span>
<span id="cb101-3"><a href="cart-con-el-paquete-rpart.html#cb101-3" aria-hidden="true" tabindex="-1"></a>itrain <span class="ot">&lt;-</span> <span class="fu">sample</span>(nobs, <span class="fl">0.8</span> <span class="sc">*</span> nobs)</span>
<span id="cb101-4"><a href="cart-con-el-paquete-rpart.html#cb101-4" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> winequality[itrain, ]</span>
<span id="cb101-5"><a href="cart-con-el-paquete-rpart.html#cb101-5" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> winequality[<span class="sc">-</span>itrain, ]</span>
<span id="cb101-6"><a href="cart-con-el-paquete-rpart.html#cb101-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Indice muestra de entrenamiento bootstrap</span></span>
<span id="cb101-7"><a href="cart-con-el-paquete-rpart.html#cb101-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb101-8"><a href="cart-con-el-paquete-rpart.html#cb101-8" aria-hidden="true" tabindex="-1"></a>ntrain <span class="ot">&lt;-</span> <span class="fu">nrow</span>(train)</span>
<span id="cb101-9"><a href="cart-con-el-paquete-rpart.html#cb101-9" aria-hidden="true" tabindex="-1"></a>itrain.boot <span class="ot">&lt;-</span> <span class="fu">sample</span>(ntrain, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb101-10"><a href="cart-con-el-paquete-rpart.html#cb101-10" aria-hidden="true" tabindex="-1"></a>train.boot <span class="ot">&lt;-</span> train[itrain.boot, ]</span></code></pre></div>
<p>La muestra bootstrap va a contener muchas observaciones repetidas y habrá observaciones no seleccionadas.
La probabilidad de que una observación no sea seleccionada es <span class="math inline">\((1 - 1/n)^n \approx e^{-1} \approx 0.37\)</span>.</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="cart-con-el-paquete-rpart.html#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Número de casos &quot;out of bag&quot;</span></span>
<span id="cb102-2"><a href="cart-con-el-paquete-rpart.html#cb102-2" aria-hidden="true" tabindex="-1"></a>ntrain <span class="sc">-</span> <span class="fu">length</span>(<span class="fu">unique</span>(itrain.boot))</span></code></pre></div>
<pre><code>## [1] 370</code></pre>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="cart-con-el-paquete-rpart.html#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Muestra &quot;out of bag&quot;</span></span>
<span id="cb104-2"><a href="cart-con-el-paquete-rpart.html#cb104-2" aria-hidden="true" tabindex="-1"></a><span class="co"># oob &lt;- train[-unique(itrain.boot), ]</span></span>
<span id="cb104-3"><a href="cart-con-el-paquete-rpart.html#cb104-3" aria-hidden="true" tabindex="-1"></a>oob <span class="ot">&lt;-</span> train[<span class="sc">-</span>itrain.boot, ]</span></code></pre></div>
<p>El resto sería igual que el caso anterior cambiando <code>train</code> por <code>train.boot</code> y <code>validate</code> por <code>oob</code>.</p>
<p>Como comentario final, lo recomendable sería repetir el proceso un número grande de veces y promediar los errores (esto está relacionado con el método de <em>bagging</em> descrito en el siguiente capítulo), especialmente cuando el tamaño muestral es pequeño, pero por simplicidad consideraremos únicamente una muestra boostrap.</p>
</div>
</div>
<div id="class-rpart" class="section level3 hasAnchor" number="2.3.2">
<h3><span class="header-section-number">2.3.2</span> Ejemplo: modelo de clasificación<a href="cart-con-el-paquete-rpart.html#class-rpart" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para ilustrar los árboles de clasificación CART, podemos emplear los datos anteriores de calidad de vino, considerando como respuesta una nueva variable <code>taste</code> que clasifica los vinos en “good” o “bad” dependiendo de si <code>winequality$quality &gt;= 5</code> (este conjunto de datos está almacenado en el archivo <em>winetaste.RData</em>).</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="cart-con-el-paquete-rpart.html#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load(&quot;data/winetaste.RData&quot;)</span></span>
<span id="cb105-2"><a href="cart-con-el-paquete-rpart.html#cb105-2" aria-hidden="true" tabindex="-1"></a>winetaste <span class="ot">&lt;-</span> winequality[, <span class="fu">colnames</span>(winequality)<span class="sc">!=</span><span class="st">&quot;quality&quot;</span>]</span>
<span id="cb105-3"><a href="cart-con-el-paquete-rpart.html#cb105-3" aria-hidden="true" tabindex="-1"></a>winetaste<span class="sc">$</span>taste <span class="ot">&lt;-</span> <span class="fu">factor</span>(winequality<span class="sc">$</span>quality <span class="sc">&lt;</span> <span class="dv">6</span>, <span class="co"># levels = c(&#39;FALSE&#39;, &#39;TRUE&#39;)</span></span>
<span id="cb105-4"><a href="cart-con-el-paquete-rpart.html#cb105-4" aria-hidden="true" tabindex="-1"></a>                          <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&#39;good&#39;</span>, <span class="st">&#39;bad&#39;</span>)) </span>
<span id="cb105-5"><a href="cart-con-el-paquete-rpart.html#cb105-5" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(winetaste)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    1250 obs. of  12 variables:
##  $ fixed.acidity       : num  6.8 7.1 6.9 7.5 8.6 7.7 5.4 6.8 6.1 5.5 ...
##  $ volatile.acidity    : num  0.37 0.24 0.32 0.23 0.36 0.28 0.59 0.16 0.28 0.2..
##  $ citric.acid         : num  0.47 0.34 0.13 0.49 0.26 0.63 0.07 0.36 0.27 0.2..
##  $ residual.sugar      : num  11.2 1.2 7.8 7.7 11.1 11.1 7 1.3 4.7 1.6 ...
##  $ chlorides           : num  0.071 0.045 0.042 0.049 0.03 0.039 0.045 0.034 0..
##  $ free.sulfur.dioxide : num  44 6 11 61 43.5 58 36 32 56 23 ...
##  $ total.sulfur.dioxide: num  136 132 117 209 171 179 147 98 140 85 ...
##  $ density             : num  0.997 0.991 0.996 0.994 0.995 ...
##  $ pH                  : num  2.98 3.16 3.23 3.14 3.03 3.08 3.34 3.02 3.16 3.4..
##  $ sulphates           : num  0.88 0.46 0.37 0.3 0.49 0.44 0.57 0.58 0.42 0.42..
##  $ alcohol             : num  9.2 11.2 9.2 11.1 12 8.8 9.7 11.3 12.5 12.5 ...
##  $ taste               : Factor w/ 2 levels &quot;good&quot;,&quot;bad&quot;: 2 2 2 1 2 2 1 1 1 2 ..</code></pre>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="cart-con-el-paquete-rpart.html#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(winetaste<span class="sc">$</span>taste)</span></code></pre></div>
<pre><code>## 
## good  bad 
##  828  422</code></pre>
<p>Como en el caso anterior, se contruyen las muestras de entrenamiento (80%) y de test (20%):</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="cart-con-el-paquete-rpart.html#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="co"># set.seed(1)</span></span>
<span id="cb109-2"><a href="cart-con-el-paquete-rpart.html#cb109-2" aria-hidden="true" tabindex="-1"></a><span class="co"># nobs &lt;- nrow(winetaste)</span></span>
<span id="cb109-3"><a href="cart-con-el-paquete-rpart.html#cb109-3" aria-hidden="true" tabindex="-1"></a><span class="co"># itrain &lt;- sample(nobs, 0.8 * nobs)</span></span>
<span id="cb109-4"><a href="cart-con-el-paquete-rpart.html#cb109-4" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> winetaste[itrain, ]</span>
<span id="cb109-5"><a href="cart-con-el-paquete-rpart.html#cb109-5" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> winetaste[<span class="sc">-</span>itrain, ]</span></code></pre></div>
<p>Al igual que en el caso anterior podemos obtener el árbol de clasificación con las opciones por defecto (<code>cp = 0.01</code> y <code>split = "gini"</code>) con el comando:</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="cart-con-el-paquete-rpart.html#cb110-1" aria-hidden="true" tabindex="-1"></a>tree <span class="ot">&lt;-</span> <span class="fu">rpart</span>(taste <span class="sc">~</span> ., <span class="at">data =</span> train)</span></code></pre></div>
<p>En este caso al imprimirlo como información de los nodos se muestra (además del número de nodo, la condición de la partición y el número de observaciones en el nodo) el número de observaciones mal clasificadas, la predicción y las proporciones estimadas (frecuencias relativas en la muestra de entrenamiento) de las clases:</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="cart-con-el-paquete-rpart.html#cb111-1" aria-hidden="true" tabindex="-1"></a>tree</span></code></pre></div>
<pre><code>## n= 1000 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##  1) root 1000 338 good (0.6620000 0.3380000)  
##    2) alcohol&gt;=10.11667 541 100 good (0.8151571 0.1848429)  
##      4) free.sulfur.dioxide&gt;=8.5 522  87 good (0.8333333 0.1666667)  
##        8) fixed.acidity&lt; 8.55 500  73 good (0.8540000 0.1460000) *
##        9) fixed.acidity&gt;=8.55 22   8 bad (0.3636364 0.6363636) *
##      5) free.sulfur.dioxide&lt; 8.5 19   6 bad (0.3157895 0.6842105) *
##    3) alcohol&lt; 10.11667 459 221 bad (0.4814815 0.5185185)  
##      6) volatile.acidity&lt; 0.2875 264 102 good (0.6136364 0.3863636)  
##       12) fixed.acidity&lt; 7.45 213  71 good (0.6666667 0.3333333)  
##         24) citric.acid&gt;=0.265 160  42 good (0.7375000 0.2625000) *
##         25) citric.acid&lt; 0.265 53  24 bad (0.4528302 0.5471698)  
##           50) free.sulfur.dioxide&lt; 42.5 33  13 good (0.6060606 0.3939394) *
##           51) free.sulfur.dioxide&gt;=42.5 20   4 bad (0.2000000 0.8000000) *
##       13) fixed.acidity&gt;=7.45 51  20 bad (0.3921569 0.6078431)  
##         26) total.sulfur.dioxide&gt;=150 26  10 good (0.6153846 0.3846154) *
##         27) total.sulfur.dioxide&lt; 150 25   4 bad (0.1600000 0.8400000) *
##      7) volatile.acidity&gt;=0.2875 195  59 bad (0.3025641 0.6974359)  
##       14) pH&gt;=3.235 49  24 bad (0.4897959 0.5102041)  
##         28) chlorides&lt; 0.0465 18   4 good (0.7777778 0.2222222) *
##         29) chlorides&gt;=0.0465 31  10 bad (0.3225806 0.6774194) *
##       15) pH&lt; 3.235 146  35 bad (0.2397260 0.7602740) *</code></pre>
<p>También puede ser preferible emplear el paquete <a href="https://CRAN.R-project.org/package=rpart.plot"><code>rpart.plot</code></a> para representarlo (ver Figura <a href="cart-con-el-paquete-rpart.html#fig:arbolclassif">2.9</a>):</p>

<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="cart-con-el-paquete-rpart.html#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb113-2"><a href="cart-con-el-paquete-rpart.html#cb113-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(tree) <span class="co"># Alternativa: rattle::fancyRpartPlot</span></span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:arbolclassif"></span>
<img src="02-arboles_files/figure-html/arbolclassif-1.png" alt="Árbol de clasificación de winetaste$taste (obtenido con las opciones por defecto)." width="75%" />
<p class="caption">
Figura 2.9: Árbol de clasificación de <code>winetaste$taste</code> (obtenido con las opciones por defecto).
</p>
</div>
<p>Nos interesa como se clasificaría a una nueva observación (como se llega a los nodos terminales) y su probabilidad estimada (la frecuencia relativa de la clase más frecuente en el correspondiente nodo terminal).
Para ello se puede modificar la información que se muestra en cada nodo (ver Figura <a href="cart-con-el-paquete-rpart.html#fig:arbolextra">2.10</a>):</p>

<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="cart-con-el-paquete-rpart.html#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(tree, </span>
<span id="cb114-2"><a href="cart-con-el-paquete-rpart.html#cb114-2" aria-hidden="true" tabindex="-1"></a>           <span class="at">extra =</span> <span class="dv">104</span>,          <span class="co"># show fitted class, probs, percentages</span></span>
<span id="cb114-3"><a href="cart-con-el-paquete-rpart.html#cb114-3" aria-hidden="true" tabindex="-1"></a>           <span class="at">box.palette =</span> <span class="st">&quot;GnBu&quot;</span>, <span class="co"># color scheme</span></span>
<span id="cb114-4"><a href="cart-con-el-paquete-rpart.html#cb114-4" aria-hidden="true" tabindex="-1"></a>           <span class="at">branch.lty =</span> <span class="dv">3</span>,       <span class="co"># dotted branch lines</span></span>
<span id="cb114-5"><a href="cart-con-el-paquete-rpart.html#cb114-5" aria-hidden="true" tabindex="-1"></a>           <span class="at">shadow.col =</span> <span class="st">&quot;gray&quot;</span>,  <span class="co"># shadows under the node boxes</span></span>
<span id="cb114-6"><a href="cart-con-el-paquete-rpart.html#cb114-6" aria-hidden="true" tabindex="-1"></a>           <span class="at">nn =</span> <span class="cn">TRUE</span>)            <span class="co"># display the node numbers </span></span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:arbolextra"></span>
<img src="02-arboles_files/figure-html/arbolextra-1.png" alt="Representación del árbol de clasificación de winetaste$taste con opciones adicionales." width="75%" />
<p class="caption">
Figura 2.10: Representación del árbol de clasificación de <code>winetaste$taste</code> con opciones adicionales.
</p>
</div>
<p>Al igual que en el caso de regresión, puede ser de utilidad imprimir las reglas:</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="cart-con-el-paquete-rpart.html#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.rules</span>(tree, <span class="at">style =</span> <span class="st">&quot;tall&quot;</span>)</span></code></pre></div>
<pre><code>## taste is 0.15 when
##     alcohol &gt;= 10
##     fixed.acidity &lt; 8.6
##     free.sulfur.dioxide &gt;= 8.5
## 
## taste is 0.22 when
##     alcohol &lt; 10
##     volatile.acidity &gt;= 0.29
##     pH &gt;= 3.2
##     chlorides &lt; 0.047
## 
## taste is 0.26 when
##     alcohol &lt; 10
##     volatile.acidity &lt; 0.29
##     fixed.acidity &lt; 7.5
##     citric.acid &gt;= 0.27
## 
## taste is 0.38 when
##     alcohol &lt; 10
##     volatile.acidity &lt; 0.29
##     fixed.acidity &gt;= 7.5
##     total.sulfur.dioxide &gt;= 150
## 
## taste is 0.39 when
##     alcohol &lt; 10
##     volatile.acidity &lt; 0.29
##     fixed.acidity &lt; 7.5
##     free.sulfur.dioxide &lt; 42.5
##     citric.acid &lt; 0.27
## 
## taste is 0.64 when
##     alcohol &gt;= 10
##     fixed.acidity &gt;= 8.6
##     free.sulfur.dioxide &gt;= 8.5
## 
## taste is 0.68 when
##     alcohol &lt; 10
##     volatile.acidity &gt;= 0.29
##     pH &gt;= 3.2
##     chlorides &gt;= 0.047
## 
## taste is 0.68 when
##     alcohol &gt;= 10
##     free.sulfur.dioxide &lt; 8.5
## 
## taste is 0.76 when
##     alcohol &lt; 10
##     volatile.acidity &gt;= 0.29
##     pH &lt; 3.2
## 
## taste is 0.80 when
##     alcohol &lt; 10
##     volatile.acidity &lt; 0.29
##     fixed.acidity &lt; 7.5
##     free.sulfur.dioxide &gt;= 42.5
##     citric.acid &lt; 0.27
## 
## taste is 0.84 when
##     alcohol &lt; 10
##     volatile.acidity &lt; 0.29
##     fixed.acidity &gt;= 7.5
##     total.sulfur.dioxide &lt; 150</code></pre>
<p>También se suele emplear el mismo procedimiento para seleccionar un valor óptimo del (hiper)parámetro de complejidad, se construye un árbol de decisión completo y se emplea validación cruzada para podarlo.
Además, si el número de observaciones es grande y las clases están más o menos balanceadas,
se podría aumentar los valores mínimos de observaciones en los nodos intermedios y terminales<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a>, por ejemplo:</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="cart-con-el-paquete-rpart.html#cb117-1" aria-hidden="true" tabindex="-1"></a>tree <span class="ot">&lt;-</span> <span class="fu">rpart</span>(taste <span class="sc">~</span> ., <span class="at">data =</span> train, <span class="at">cp =</span> <span class="dv">0</span>, <span class="at">minsplit =</span> <span class="dv">30</span>, <span class="at">minbucket =</span> <span class="dv">10</span>)</span></code></pre></div>
<p>En este caso mantenemos el resto de valores por defecto:</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="cart-con-el-paquete-rpart.html#cb118-1" aria-hidden="true" tabindex="-1"></a>tree <span class="ot">&lt;-</span> <span class="fu">rpart</span>(taste <span class="sc">~</span> ., <span class="at">data =</span> train, <span class="at">cp =</span> <span class="dv">0</span>)</span></code></pre></div>
<p>Representamos los errores (reescalados) de validación cruzada (ver Figura <a href="cart-con-el-paquete-rpart.html#fig:errorclassif">2.11</a>)</p>

<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="cart-con-el-paquete-rpart.html#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="co"># printcp(tree)</span></span>
<span id="cb119-2"><a href="cart-con-el-paquete-rpart.html#cb119-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plotcp</span>(tree)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:errorclassif"></span>
<img src="02-arboles_files/figure-html/errorclassif-1.png" alt="Evolución del error (reescalado) de validación cruzada en función del parámetro de complejidad." width="75%" />
<p class="caption">
Figura 2.11: Evolución del error (reescalado) de validación cruzada en función del parámetro de complejidad.
</p>
</div>
<p>Para obtener el modelo final, seleccionamos el valor óptimo de complejidad siguiendo el criterio de un error estándar de <span class="citation">Breiman et al. (<a href="#ref-breiman1984classification" role="doc-biblioref">1984</a>)</span> y podamos el árbol (ver Figura <a href="cart-con-el-paquete-rpart.html#fig:arbolclassifpoda">2.12</a>).</p>

<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="cart-con-el-paquete-rpart.html#cb120-1" aria-hidden="true" tabindex="-1"></a>xerror <span class="ot">&lt;-</span> tree<span class="sc">$</span>cptable[,<span class="st">&quot;xerror&quot;</span>]</span>
<span id="cb120-2"><a href="cart-con-el-paquete-rpart.html#cb120-2" aria-hidden="true" tabindex="-1"></a>imin.xerror <span class="ot">&lt;-</span> <span class="fu">which.min</span>(xerror)</span>
<span id="cb120-3"><a href="cart-con-el-paquete-rpart.html#cb120-3" aria-hidden="true" tabindex="-1"></a>upper.xerror <span class="ot">&lt;-</span> xerror[imin.xerror] <span class="sc">+</span> tree<span class="sc">$</span>cptable[imin.xerror, <span class="st">&quot;xstd&quot;</span>]</span>
<span id="cb120-4"><a href="cart-con-el-paquete-rpart.html#cb120-4" aria-hidden="true" tabindex="-1"></a>icp <span class="ot">&lt;-</span> <span class="fu">min</span>(<span class="fu">which</span>(xerror <span class="sc">&lt;=</span> upper.xerror))</span>
<span id="cb120-5"><a href="cart-con-el-paquete-rpart.html#cb120-5" aria-hidden="true" tabindex="-1"></a>cp <span class="ot">&lt;-</span> tree<span class="sc">$</span>cptable[icp, <span class="st">&quot;CP&quot;</span>]</span>
<span id="cb120-6"><a href="cart-con-el-paquete-rpart.html#cb120-6" aria-hidden="true" tabindex="-1"></a>tree <span class="ot">&lt;-</span> <span class="fu">prune</span>(tree, <span class="at">cp =</span> cp)</span>
<span id="cb120-7"><a href="cart-con-el-paquete-rpart.html#cb120-7" aria-hidden="true" tabindex="-1"></a><span class="co"># tree</span></span>
<span id="cb120-8"><a href="cart-con-el-paquete-rpart.html#cb120-8" aria-hidden="true" tabindex="-1"></a><span class="co"># summary(tree)</span></span>
<span id="cb120-9"><a href="cart-con-el-paquete-rpart.html#cb120-9" aria-hidden="true" tabindex="-1"></a><span class="co"># caret::varImp(tree)</span></span>
<span id="cb120-10"><a href="cart-con-el-paquete-rpart.html#cb120-10" aria-hidden="true" tabindex="-1"></a><span class="co"># importance &lt;- tree$variable.importance</span></span>
<span id="cb120-11"><a href="cart-con-el-paquete-rpart.html#cb120-11" aria-hidden="true" tabindex="-1"></a><span class="co"># importance &lt;- round(100*importance/sum(importance), 1)</span></span>
<span id="cb120-12"><a href="cart-con-el-paquete-rpart.html#cb120-12" aria-hidden="true" tabindex="-1"></a><span class="co"># importance[importance &gt;= 1]</span></span>
<span id="cb120-13"><a href="cart-con-el-paquete-rpart.html#cb120-13" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(tree) <span class="co">#, main=&quot;Classification tree winetaste&quot;</span></span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:arbolclassifpoda"></span>
<img src="02-arboles_files/figure-html/arbolclassifpoda-1.png" alt="Árbol de clasificación de winetaste$taste obtenido después de la poda (modelo final)." width="75%" />
<p class="caption">
Figura 2.12: Árbol de clasificación de <code>winetaste$taste</code> obtenido después de la poda (modelo final).
</p>
</div>
<p>El último paso sería evaluarlo en la muestra de test siguiendo los pasos descritos en la Sección <a href="const-eval.html#eval-class">1.3.5</a>.
El método <a href="https://rdrr.io/pkg/rpart/man/predict.rpart.html"><code>predict.rpart()</code></a> devuelve por defecto (<code>type = "prob"</code>) una matriz con las probabilidades de cada clase, por lo que habrá que establecer <code>type = "class"</code> (para más detalles consultar la ayuda de esta función).</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="cart-con-el-paquete-rpart.html#cb121-1" aria-hidden="true" tabindex="-1"></a>obs <span class="ot">&lt;-</span> test<span class="sc">$</span>taste</span>
<span id="cb121-2"><a href="cart-con-el-paquete-rpart.html#cb121-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">predict</span>(tree, <span class="at">newdata =</span> test))</span></code></pre></div>
<pre><code>##         good       bad
## 1  0.3025641 0.6974359
## 4  0.8151571 0.1848429
## 9  0.8151571 0.1848429
## 10 0.8151571 0.1848429
## 12 0.8151571 0.1848429
## 16 0.8151571 0.1848429</code></pre>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="cart-con-el-paquete-rpart.html#cb123-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree, <span class="at">newdata =</span> test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb123-2"><a href="cart-con-el-paquete-rpart.html#cb123-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(obs, pred)</span></code></pre></div>
<pre><code>##       pred
## obs    good bad
##   good  153  13
##   bad    54  30</code></pre>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="cart-con-el-paquete-rpart.html#cb125-1" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">confusionMatrix</span>(pred, obs)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction good bad
##       good  153  54
##       bad    13  30
##                                           
##                Accuracy : 0.732           
##                  95% CI : (0.6725, 0.7859)
##     No Information Rate : 0.664           
##     P-Value [Acc &gt; NIR] : 0.01247         
##                                           
##                   Kappa : 0.3171          
##                                           
##  Mcnemar&#39;s Test P-Value : 1.025e-06       
##                                           
##             Sensitivity : 0.9217          
##             Specificity : 0.3571          
##          Pos Pred Value : 0.7391          
##          Neg Pred Value : 0.6977          
##              Prevalence : 0.6640          
##          Detection Rate : 0.6120          
##    Detection Prevalence : 0.8280          
##       Balanced Accuracy : 0.6394          
##                                           
##        &#39;Positive&#39; Class : good            
## </code></pre>
</div>
<div id="interfaz-de-caret" class="section level3 hasAnchor" number="2.3.3">
<h3><span class="header-section-number">2.3.3</span> Interfaz de <code>caret</code><a href="cart-con-el-paquete-rpart.html#interfaz-de-caret" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En <code>caret</code> podemos ajustar un árbol CART seleccionando <code>method = "rpart"</code>.
Por defecto emplea bootstrap de las observaciones para seleccionar el valor óptimo del hiperparámetro <code>cp</code> (considerando únicamente tres posibles valores).
Si queremos emplear validación cruzada como en el caso anterior podemos emplear la función auxiliar <a href="https://rdrr.io/pkg/caret/man/trainControl.html"><code>trainControl()</code></a> y para considerar un mayor rango de posibles valores, el argumento <code>tuneLength</code> (ver Figura <a href="cart-con-el-paquete-rpart.html#fig:arbolclassifggplot">2.13</a>).</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="cart-con-el-paquete-rpart.html#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb127-2"><a href="cart-con-el-paquete-rpart.html#cb127-2" aria-hidden="true" tabindex="-1"></a><span class="co"># modelLookup(&quot;rpart&quot;)  # Información sobre hiperparámetros</span></span>
<span id="cb127-3"><a href="cart-con-el-paquete-rpart.html#cb127-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb127-4"><a href="cart-con-el-paquete-rpart.html#cb127-4" aria-hidden="true" tabindex="-1"></a><span class="co"># itrain &lt;- createDataPartition(winetaste$taste, p = 0.8, list = FALSE)</span></span>
<span id="cb127-5"><a href="cart-con-el-paquete-rpart.html#cb127-5" aria-hidden="true" tabindex="-1"></a><span class="co"># train &lt;- winetaste[itrain, ]</span></span>
<span id="cb127-6"><a href="cart-con-el-paquete-rpart.html#cb127-6" aria-hidden="true" tabindex="-1"></a><span class="co"># test &lt;- winetaste[-itrain, ]</span></span>
<span id="cb127-7"><a href="cart-con-el-paquete-rpart.html#cb127-7" aria-hidden="true" tabindex="-1"></a>caret.rpart <span class="ot">&lt;-</span> <span class="fu">train</span>(taste <span class="sc">~</span> ., <span class="at">method =</span> <span class="st">&quot;rpart&quot;</span>, <span class="at">data =</span> train, <span class="at">tuneLength =</span> <span class="dv">20</span>,</span>
<span id="cb127-8"><a href="cart-con-el-paquete-rpart.html#cb127-8" aria-hidden="true" tabindex="-1"></a>                     <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">10</span>)) </span>
<span id="cb127-9"><a href="cart-con-el-paquete-rpart.html#cb127-9" aria-hidden="true" tabindex="-1"></a>caret.rpart</span></code></pre></div>
<pre><code>## CART 
## 
## 1000 samples
##   11 predictor
##    2 classes: &#39;good&#39;, &#39;bad&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 901, 900, 900, 900, 900, 900, ... 
## Resampling results across tuning parameters:
## 
##   cp           Accuracy   Kappa    
##   0.000000000  0.7018843  0.3487338
##   0.005995017  0.7330356  0.3870552
##   0.011990034  0.7410655  0.3878517
##   0.017985051  0.7230748  0.3374518
##   0.023980069  0.7360748  0.3698691
##   0.029975086  0.7340748  0.3506377
##   0.035970103  0.7320748  0.3418235
##   0.041965120  0.7350849  0.3422651
##   0.047960137  0.7350849  0.3422651
##   0.053955154  0.7350849  0.3422651
##   0.059950171  0.7350849  0.3422651
##   0.065945188  0.7350849  0.3422651
##   0.071940206  0.7350849  0.3422651
##   0.077935223  0.7350849  0.3422651
##   0.083930240  0.7350849  0.3422651
##   0.089925257  0.7350849  0.3422651
##   0.095920274  0.7350849  0.3422651
##   0.101915291  0.7350849  0.3422651
##   0.107910308  0.7229637  0.2943312
##   0.113905325  0.6809637  0.1087694
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was cp = 0.01199003.</code></pre>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="cart-con-el-paquete-rpart.html#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(caret.rpart)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:arbolclassifggplot"></span>
<img src="02-arboles_files/figure-html/arbolclassifggplot-1.png" alt="Evolución de la precisión (obtenida mediante validación cruzada) dependiendo del parámetro de complejidad." width="75%" />
<p class="caption">
Figura 2.13: Evolución de la precisión (obtenida mediante validación cruzada) dependiendo del parámetro de complejidad.
</p>
</div>
<p>El modelo final se devuelve en la componente <code>$finalModel</code> (ver Figura <a href="cart-con-el-paquete-rpart.html#fig:arbolfinalcaret">2.14</a>):</p>

<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="cart-con-el-paquete-rpart.html#cb130-1" aria-hidden="true" tabindex="-1"></a>caret.rpart<span class="sc">$</span>finalModel</span></code></pre></div>
<pre><code>## n= 1000 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##  1) root 1000 338 good (0.6620000 0.3380000)  
##    2) alcohol&gt;=10.11667 541 100 good (0.8151571 0.1848429)  
##      4) free.sulfur.dioxide&gt;=8.5 522  87 good (0.8333333 0.1666667)  
##        8) fixed.acidity&lt; 8.55 500  73 good (0.8540000 0.1460000) *
##        9) fixed.acidity&gt;=8.55 22   8 bad (0.3636364 0.6363636) *
##      5) free.sulfur.dioxide&lt; 8.5 19   6 bad (0.3157895 0.6842105) *
##    3) alcohol&lt; 10.11667 459 221 bad (0.4814815 0.5185185)  
##      6) volatile.acidity&lt; 0.2875 264 102 good (0.6136364 0.3863636)  
##       12) fixed.acidity&lt; 7.45 213  71 good (0.6666667 0.3333333)  
##         24) citric.acid&gt;=0.265 160  42 good (0.7375000 0.2625000) *
##         25) citric.acid&lt; 0.265 53  24 bad (0.4528302 0.5471698)  
##           50) free.sulfur.dioxide&lt; 42.5 33  13 good (0.6060606 0.3939394) *
##           51) free.sulfur.dioxide&gt;=42.5 20   4 bad (0.2000000 0.8000000) *
##       13) fixed.acidity&gt;=7.45 51  20 bad (0.3921569 0.6078431)  
##         26) total.sulfur.dioxide&gt;=150 26  10 good (0.6153846 0.3846154) *
##         27) total.sulfur.dioxide&lt; 150 25   4 bad (0.1600000 0.8400000) *
##      7) volatile.acidity&gt;=0.2875 195  59 bad (0.3025641 0.6974359)  
##       14) pH&gt;=3.235 49  24 bad (0.4897959 0.5102041)  
##         28) chlorides&lt; 0.0465 18   4 good (0.7777778 0.2222222) *
##         29) chlorides&gt;=0.0465 31  10 bad (0.3225806 0.6774194) *
##       15) pH&lt; 3.235 146  35 bad (0.2397260 0.7602740) *</code></pre>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="cart-con-el-paquete-rpart.html#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(caret.rpart<span class="sc">$</span>finalModel)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:arbolfinalcaret"></span>
<img src="02-arboles_files/figure-html/arbolfinalcaret-1.png" alt="Árbol de clasificación de winetaste$taste, obtenido con la complejidad “óptima” (empleando caret)." width="75%" />
<p class="caption">
Figura 2.14: Árbol de clasificación de <code>winetaste$taste</code>, obtenido con la complejidad “óptima” (empleando <code>caret</code>).
</p>
</div>
<p>Para utilizar la regla de “un error estándar” se puede añadir <code>selectionFunction = "oneSE"</code> en las opciones de entrenamiento<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a>(ver Figura <a href="cart-con-el-paquete-rpart.html#fig:arbolclassifoneSE">2.15</a>):</p>

<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="cart-con-el-paquete-rpart.html#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb133-2"><a href="cart-con-el-paquete-rpart.html#cb133-2" aria-hidden="true" tabindex="-1"></a>caret.rpart <span class="ot">&lt;-</span> <span class="fu">train</span>(taste <span class="sc">~</span> ., <span class="at">method =</span> <span class="st">&quot;rpart&quot;</span>, <span class="at">data =</span> train, <span class="at">tuneLength =</span> <span class="dv">20</span>,</span>
<span id="cb133-3"><a href="cart-con-el-paquete-rpart.html#cb133-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">10</span>,</span>
<span id="cb133-4"><a href="cart-con-el-paquete-rpart.html#cb133-4" aria-hidden="true" tabindex="-1"></a>                                              <span class="at">selectionFunction =</span> <span class="st">&quot;oneSE&quot;</span>)) </span>
<span id="cb133-5"><a href="cart-con-el-paquete-rpart.html#cb133-5" aria-hidden="true" tabindex="-1"></a>caret.rpart</span></code></pre></div>
<pre><code>## CART 
## 
## 1000 samples
##   11 predictor
##    2 classes: &#39;good&#39;, &#39;bad&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 901, 900, 900, 900, 900, 900, ... 
## Resampling results across tuning parameters:
## 
##   cp           Accuracy   Kappa    
##   0.000000000  0.7018843  0.3487338
##   0.005995017  0.7330356  0.3870552
##   0.011990034  0.7410655  0.3878517
##   0.017985051  0.7230748  0.3374518
##   0.023980069  0.7360748  0.3698691
##   0.029975086  0.7340748  0.3506377
##   0.035970103  0.7320748  0.3418235
##   0.041965120  0.7350849  0.3422651
##   0.047960137  0.7350849  0.3422651
##   0.053955154  0.7350849  0.3422651
##   0.059950171  0.7350849  0.3422651
##   0.065945188  0.7350849  0.3422651
##   0.071940206  0.7350849  0.3422651
##   0.077935223  0.7350849  0.3422651
##   0.083930240  0.7350849  0.3422651
##   0.089925257  0.7350849  0.3422651
##   0.095920274  0.7350849  0.3422651
##   0.101915291  0.7350849  0.3422651
##   0.107910308  0.7229637  0.2943312
##   0.113905325  0.6809637  0.1087694
## 
## Accuracy was used to select the optimal model using  the one SE rule.
## The final value used for the model was cp = 0.1019153.</code></pre>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="cart-con-el-paquete-rpart.html#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ggplot(caret.rpart)</span></span>
<span id="cb135-2"><a href="cart-con-el-paquete-rpart.html#cb135-2" aria-hidden="true" tabindex="-1"></a>caret.rpart<span class="sc">$</span>finalModel</span></code></pre></div>
<pre><code>## n= 1000 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
## 1) root 1000 338 good (0.6620000 0.3380000)  
##   2) alcohol&gt;=10.11667 541 100 good (0.8151571 0.1848429) *
##   3) alcohol&lt; 10.11667 459 221 bad (0.4814815 0.5185185)  
##     6) volatile.acidity&lt; 0.2875 264 102 good (0.6136364 0.3863636) *
##     7) volatile.acidity&gt;=0.2875 195  59 bad (0.3025641 0.6974359) *</code></pre>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="cart-con-el-paquete-rpart.html#cb137-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(caret.rpart<span class="sc">$</span>finalModel)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:arbolclassifoneSE"></span>
<img src="02-arboles_files/figure-html/arbolclassifoneSE-1.png" alt="Árbol de clasificación de winetaste$taste, obtenido con la regla de un error estándar para seleccionar la complejidad (empleando caret)." width="75%" />
<p class="caption">
Figura 2.15: Árbol de clasificación de <code>winetaste$taste</code>, obtenido con la regla de un error estándar para seleccionar la complejidad (empleando <code>caret</code>).
</p>
</div>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="cart-con-el-paquete-rpart.html#cb138-1" aria-hidden="true" tabindex="-1"></a>var.imp <span class="ot">&lt;-</span> <span class="fu">varImp</span>(caret.rpart)</span>
<span id="cb138-2"><a href="cart-con-el-paquete-rpart.html#cb138-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(var.imp)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:arbolImpor"></span>
<img src="02-arboles_files/figure-html/arbolImpor-1.png" alt="Importancia de los (posibles) predictores según el modelo obtenido con la regla de un error estándar." width="75%" />
<p class="caption">
Figura 2.16: Importancia de los (posibles) predictores según el modelo obtenido con la regla de un error estándar.
</p>
</div>
<p>Para calcular las predicciones (o las estimaciones de las probabilidades) podemos emplear el método <a href="https://rdrr.io/pkg/caret/man/predict.train.html"><code>predict.train()</code></a> y posteriormente <a href="https://rdrr.io/pkg/caret/man/confusionMatrix.html"><code>confusionMatrix()</code></a> para evaluar su precisión:</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="cart-con-el-paquete-rpart.html#cb139-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(caret.rpart, <span class="at">newdata =</span> test)</span>
<span id="cb139-2"><a href="cart-con-el-paquete-rpart.html#cb139-2" aria-hidden="true" tabindex="-1"></a><span class="co"># p.est &lt;- predict(caret.rpart, newdata = test, type = &quot;prob&quot;)</span></span>
<span id="cb139-3"><a href="cart-con-el-paquete-rpart.html#cb139-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(pred, test<span class="sc">$</span>taste)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction good bad
##       good  153  54
##       bad    13  30
##                                           
##                Accuracy : 0.732           
##                  95% CI : (0.6725, 0.7859)
##     No Information Rate : 0.664           
##     P-Value [Acc &gt; NIR] : 0.01247         
##                                           
##                   Kappa : 0.3171          
##                                           
##  Mcnemar&#39;s Test P-Value : 1.025e-06       
##                                           
##             Sensitivity : 0.9217          
##             Specificity : 0.3571          
##          Pos Pred Value : 0.7391          
##          Neg Pred Value : 0.6977          
##              Prevalence : 0.6640          
##          Detection Rate : 0.6120          
##    Detection Prevalence : 0.8280          
##       Balanced Accuracy : 0.6394          
##                                           
##        &#39;Positive&#39; Class : good            
## </code></pre>
<!-- 

NOTA: En principio también se podría utilizar la regla de "un error estándar" seleccionando `method = "rpart1SE"` (pero `caret` implementa internamente este método y en ocasiones no se obtienen los resultados esperados).


```r
set.seed(1)
caret.rpart <- train(taste ~ ., method = "rpart1SE", data = train) 
caret.rpart
printcp(caret.rpart$finalModel)
caret.rpart$finalModel
rpart.plot(caret.rpart$finalModel) #, main = "Classification tree winetaste"
varImp(caret.rpart)
```

Como alternativas al uso de la metodología CART desde `caret` se  puede considerar las opciones de los metapaquetes: 

* [`mlr3`](https://mlr-org.com), que incorpora una llamada a `rpart::rpart()` desde sus **learners** `lrn("regr.rpart")` y `lrn("classif.rpart")`.
* [`h2o`](https://www.h2o.ai/blog/finally-you-can-plot-h2o-decision-trees-in-r/), que aunque no ofrece una implementación de los árboles CART, sí ofrece dos alternativas más sofisticadas usando bosques aleatorios `h2o.randomForest()` y los procedimientos basados en el aumento del gradiente `h2o.gbm()`.
-->
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-breiman1984classification" class="csl-entry">
Breiman, L., Friedman, J. H., Stone, C. J., y Olshen, R. A. (1984). <em>Classification and Regression Trees</em>. Taylor; Francis.
</div>
<div id="ref-cortez2009modeling" class="csl-entry">
Cortez, P., Cerdeira, A., Almeida, F., Matos, T., y Reis, J. (2009). Modeling wine preferences by data mining from physicochemical properties. <em>Decision Support Systems</em>, <em>47</em>(4), 547-553. <a href="https://doi.org/10.1016/j.dss.2009.05.016">https://doi.org/10.1016/j.dss.2009.05.016</a>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="18">
<li id="fn18"><p>El paquete <a href="https://CRAN.R-project.org/package=tree"><code>tree</code></a> es una traducción del original en S.<a href="cart-con-el-paquete-rpart.html#fnref18" class="footnote-back">↩︎</a></p></li>
<li id="fn19"><p>Los parámetros <code>maxsurrogate</code>, <code>usesurrogate</code> y <code>surrogatestyle</code> serían de utilidad si hay datos faltantes.<a href="cart-con-el-paquete-rpart.html#fnref19" class="footnote-back">↩︎</a></p></li>
<li id="fn20"><p>Realmente en la tabla de texto se muestra el valor mínimo de CP, ya que se obtendría la misma solución para un rango de valores de CP (desde ese valor hasta el anterior, sin incluirlo), mientras que en el gráfico generado por <a href="https://rdrr.io/pkg/rpart/man/plotcp.html"><code>plotcp()</code></a> se representa la media geométrica de los extremos de ese intervalo (ver Figura <a href="cart-con-el-paquete-rpart.html#fig:cp">2.6</a>).<a href="cart-con-el-paquete-rpart.html#fnref20" class="footnote-back">↩︎</a></p></li>
<li id="fn21"><p>Otra opción, más interesante para regresión, sería considerar estos valores como hiperparámetros.<a href="cart-con-el-paquete-rpart.html#fnref21" class="footnote-back">↩︎</a></p></li>
<li id="fn22"><p>En principio también se podría utilizar la regla de un error estándar estableciendo <code>method = "rpart1SE"</code> en la llamada a <code>train()</code>, pero <code>caret</code> implementa internamente este método y en ocasiones no se obtienen los resultados esperados.<a href="cart-con-el-paquete-rpart.html#fnref22" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="árboles-de-clasificación-cart.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="alternativas-a-los-árboles-cart.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rubenfcasal/aprendizaje_estadistico/edit/master/02-arboles.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["aprendizaje_estadistico.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
