% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  spanish,
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Aprendizaje Estadístico},
  pdfauthor={Rubén Fernández Casal (ruben.fcasal@udc.es); Julián Costa Bouzas (julian.costa@udc.es); Manuel Oviedo de la Fuente (manuel.oviedo@udc.es)},
  pdflang={es},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{amsthm}
\usepackage[a4paper, top=3.25cm, bottom=2.5cm, left=3cm, right=2.5cm]{geometry}
%\usepackage{animate}
%\usepackage{fontspec}
%\setmainfont{Arial}
% Espacio después de teorema
% https://tex.stackexchange.com/questions/37797/theorem-environment-line-break-after-label
\newtheoremstyle{break}
  {\topsep}{\topsep}%
  {\itshape}{}%
  {\bfseries}{}%
  {\newline}%
  {}%

\theoremstyle{break}

\ifxetex
  \usepackage{polyglossia}
  \setmainlanguage{spanish}
  % Tabla en lugar de cuadro
  \gappto\captionsspanish{\renewcommand{\tablename}{Tabla}
          \renewcommand{\listtablename}{Índice de tablas}}

\else
  \usepackage[spanish,es-tabla]{babel}
\fi
\makeatletter
\def\thm@space@setup{
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother
\ifxetex
  % Load polyglossia as late as possible: uses bidi with RTL langages (e.g. Hebrew, Arabic)
  \usepackage{polyglossia}
  \setmainlanguage[]{spanish}
\else
  \usepackage[main=spanish]{babel}
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
\fi
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1 \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces\fi
  % set entry spacing
  \ifnum #2 > 0
  \setlength{\parskip}{#2\baselineskip}
  \fi
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\title{Aprendizaje Estadístico}
\author{Rubén Fernández Casal (\href{mailto:ruben.fcasal@udc.es}{\nolinkurl{ruben.fcasal@udc.es}}) \and Julián Costa Bouzas (\href{mailto:julian.costa@udc.es}{\nolinkurl{julian.costa@udc.es}}) \and Manuel Oviedo de la Fuente (\href{mailto:manuel.oviedo@udc.es}{\nolinkurl{manuel.oviedo@udc.es}})}
\date{Edición: Septiembre de 2021. Impresión: 2022-11-29}

\usepackage{amsthm}
\newtheorem{theorem}{Teorema}[chapter]
\newtheorem{lemma}{Lema}[chapter]
\newtheorem{corollary}{Corolario}[chapter]
\newtheorem{proposition}{Proposición}[chapter]
\newtheorem{conjecture}{Algoritmo}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definición}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Ejemplo}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Ejercicio}[chapter]
\theoremstyle{definition}
\newtheorem{hypothesis}{Hypothesis}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Nota: }
\newtheorem*{solution}{Solución}
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{pruxf3logo}{%
\chapter*{Prólogo}\label{pruxf3logo}}
\addcontentsline{toc}{chapter}{Prólogo}

Este libro contiene los apuntes de la asignatura de \href{http://eamo.usc.es/pub/mte/index.php?option=com_content\&view=article\&id=74}{Aprendizaje Estadístico} del \href{http://eio.usc.es/pub/mte}{Máster en Técnicas Estadísticas}.

Este libro ha sido escrito en \href{http://rmarkdown.rstudio.com}{R-Markdown} empleando el paquete \href{https://bookdown.org/yihui/bookdown/}{\texttt{bookdown}} y está disponible en el repositorio Github: \href{https://github.com/rubenfcasal/aprendizaje_estadistico}{rubenfcasal/aprendizaje\_estadistico}.
Se puede acceder a la versión en línea a través del siguiente enlace:

\url{https://rubenfcasal.github.io/aprendizaje_estadistico}.

donde puede descargarse en formato \href{https://rubenfcasal.github.io/aprendizaje_estadistico/aprendizaje_estadistico.pdf}{pdf}.

Para ejecutar los ejemplos mostrados en el libro sería necesario tener instalados los siguientes paquetes:
\href{https://CRAN.R-project.org/package=caret}{\texttt{caret}}, \href{https://CRAN.R-project.org/package=rattle}{\texttt{rattle}}, \href{https://CRAN.R-project.org/package=gbm}{\texttt{gbm}}, \href{https://CRAN.R-project.org/package=car}{\texttt{car}}, \href{https://CRAN.R-project.org/package=leaps}{\texttt{leaps}}, \href{https://CRAN.R-project.org/package=MASS}{\texttt{MASS}}, \href{https://CRAN.R-project.org/package=RcmdrMisc}{\texttt{RcmdrMisc}}, \href{https://CRAN.R-project.org/package=lmtest}{\texttt{lmtest}}, \href{https://CRAN.R-project.org/package=glmnet}{\texttt{glmnet}}, \href{https://CRAN.R-project.org/package=mgcv}{\texttt{mgcv}}, \href{https://CRAN.R-project.org/package=np}{\texttt{np}}, \href{https://CRAN.R-project.org/package=NeuralNetTools}{\texttt{NeuralNetTools}}, \href{https://CRAN.R-project.org/package=pdp}{\texttt{pdp}}, \href{https://CRAN.R-project.org/package=vivid}{\texttt{vivid}}, \href{https://CRAN.R-project.org/package=plot3D}{\texttt{plot3D}}, \href{https://CRAN.R-project.org/package=AppliedPredictiveModeling}{\texttt{AppliedPredictiveModeling}}, \href{https://CRAN.R-project.org/package=ISLR}{\texttt{ISLR}}.
Por ejemplo mediante los siguientes comandos:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pkgs }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"caret"}\NormalTok{, }\StringTok{"rattle"}\NormalTok{, }\StringTok{"gbm"}\NormalTok{, }\StringTok{"car"}\NormalTok{, }\StringTok{"leaps"}\NormalTok{, }\StringTok{"MASS"}\NormalTok{, }\StringTok{"RcmdrMisc"}\NormalTok{, }
          \StringTok{"lmtest"}\NormalTok{, }\StringTok{"glmnet"}\NormalTok{, }\StringTok{"mgcv"}\NormalTok{, }\StringTok{"np"}\NormalTok{, }\StringTok{"NeuralNetTools"}\NormalTok{, }\StringTok{"pdp"}\NormalTok{, }\StringTok{"vivid"}\NormalTok{,}
          \StringTok{"plot3D"}\NormalTok{, }\StringTok{"AppliedPredictiveModeling"}\NormalTok{, }\StringTok{"ISLR"}\NormalTok{)}

\FunctionTok{install.packages}\NormalTok{(}\FunctionTok{setdiff}\NormalTok{(pkgs, }\FunctionTok{installed.packages}\NormalTok{()[,}\StringTok{"Package"}\NormalTok{]), }\AttributeTok{dependencies =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\# Si aparecen errores (normalmente debidos a incompatibilidades con versiones ya instaladas), }
\CommentTok{\# probar a ejecutar en lugar de lo anterior:}
\CommentTok{\# install.packages(pkgs, dependencies=TRUE) \# Instala todos...}
\end{Highlighting}
\end{Shaded}

Para generar el libro (compilar) serán necesarios paquetes adicionales,
para lo que se recomendaría consultar el libro de \href{https://rubenfcasal.github.io/bookdown_intro}{``Escritura de libros con bookdown''} en castellano.

\includegraphics[width=1.22in]{images/by-nc-nd-88x31}

Este obra está bajo una licencia de \href{https://creativecommons.org/licenses/by-nc-nd/4.0/deed.es_ES}{Creative Commons Reconocimiento-NoComercial-SinObraDerivada 4.0 Internacional}
(esperamos poder liberarlo bajo una licencia menos restrictiva más adelante\ldots).

\hypertarget{intro-AE}{%
\chapter{Introducción al Aprendizaje Estadístico}\label{intro-AE}}

La denominada \emph{Ciencia de Datos} (Data Science; también denominada \emph{Science of Learning}) se ha vuelto muy popular hoy en día.
Se trata de un campo multidisciplicar, con importantes aportaciones estadísticas e informáticas, dentro del que se incluirían disciplinas como \emph{Minería de Datos} (Data Mining), \emph{Aprendizaje Automático} (Machine Learning), \emph{Aprendizaje Profundo} (Deep Learning), \emph{Modelado Predictivo} (Predictive Modeling), \emph{Extracción de Conocimiento} (Knowlegde Discovery) y también el \emph{Aprendizaje Estadístico} (Statistical Learning).

Podríamos definir la Ciencia de Datos como el conjunto de conocimientos y herramientas utilizados en las distintas etapas del análisis de datos (ver Figura \ref{fig:esquema}). Otras definiciones podrían ser:

\begin{itemize}
\item
  El arte y la ciencia del análisis inteligente de los datos.
\item
  El conjunto de herramientas para entender y modelizar conjuntos
  (complejos) de datos.
\item
  El proceso de descubrir patrones y obtener conocimiento a partir de
  grandes conjuntos de datos (\emph{Big Data}).
\end{itemize}

Aunque esta ciencia incluiría también la gestión (sin olvidarnos del proceso de obtención) y la manipulación de los datos.

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{images/esquema2} 

}

\caption{Etapas del proceso}\label{fig:esquema}
\end{figure}

Una de estas etapas (que están interrelacionadas) es la construcción de modelos a partir de los datos para aprender y predecir. Podríamos decir que el Aprendizaje Estadístico (AE) se encarga de este problema desde el punto de vista estadístico.

En Estadística se consideran modelos estocásticos (con componente aleatoria), para tratar de tener en cuenta la incertidumbre debida a que no se disponga de toda la información sobre las variables que influyen en el fenómeno de interés.
Esto es lo que se conoce como \emph{aleatoriedad aparente}:

\begin{quote}
``Nothing in Nature is random\ldots{} a thing appears random only through the incompleteness of our knowledge.''

--- Spinoza, Baruch (Ethics, 1677)
\end{quote}

Aunque hoy en día gana peso la idea de la física cuántica de que en el fondo hay una \emph{aleatoriedad intrínseca}:

\begin{quote}
``To my mind, although Spinoza lived and thought long before Darwin, Freud, Einstein, and the startling implications of quantum theory, he had a vision of truth beyond what is normally granted to human beings.''

--- Shirley, Samuel (Complete Works, 2002). Traductor de la obra completa de Spinoza al inglés.
\end{quote}

La Inferencia Estadística proporciona herramientas para ajustar este tipo de modelos a los datos observados (seleccionar un modelo adecuado, estimar sus parámetros y contrastar su validez).
Sin embargo, en la aproximación estadística clásica como primer objetivo se trata de explicar por completo lo que ocurre en la población y suponiendo que esto se puede hacer con modelos tratables analíticamente, emplear resultados teóricos (típicamente resultados asintóticos) para realizar inferencias (entre ellas la predicción).
Los avances en computación han permitido el uso de modelos estadísticos más avanzados, principalmente métodos no paramétricos, muchos de los cuales no pueden ser tratados analíticamente (por lo menos no por completo o no inicialmente), este es el campo de la Estadística Computacional\footnote{\protect\hyperlink{ref-lauro1996computational}{Lauro} (\protect\hyperlink{ref-lauro1996computational}{1996}) definió la Estadística Computacional como la disciplina que tiene como objetivo ``diseñar algoritmos para implementar métodos estadísticos en computadoras, incluidos los impensables antes de la era de las computadoras (por ejemplo, bootstrap, simulación), así como hacer frente a problemas analíticamente intratables''.}. Desde este punto de vista, el AE se enmarcaría dentro del campo de la Estadística Computacional.

Cuando pensamos en AE pensamos en:

\begin{itemize}
\item
  Flexibilidad (hay menos suposiciones sobre los datos).
\item
  Procesamiento automático de datos.
\item
  Big Data (en el sentido amplio, donde ``big'' puede hacer referencia a datos complejos).
\item
  Predicción.
\end{itemize}

Por el contrario, muchos de los métodos del AE no se preocupan (o se preocupan poco) por:

\begin{itemize}
\item
  Reproducibilidad/repetibilidad.
\item
  Cuantificación de la incertidumbre (en términos de probabilidad).
\item
  Inferencia.
\end{itemize}

La idea es ``dejar hablar a los datos'' y no ``encorsetarlos'' a priori, dándoles mayor peso que a los modelos.
Sin embargo, esta aproximación puede presentar diversos inconvenientes:

\begin{itemize}
\item
  Algunos métodos son poco interpretables (se sacrifica la interpretabilidad por la precisión de las predicciones).
\item
  Pueden aparecer problemas de sobreajuste (\emph{overfitting}; en los métodos estadísticos clásicos es más habitual que aparezcan problemas de infraajuste, \emph{underfitting}).
\item
  Pueden presentar más problemas al extrapolar o interpolar (en comparación con los métodos clásicos).
\end{itemize}

\hypertarget{aprendizaje-estaduxedstico-vs.-aprendizaje-automuxe1tico}{%
\section{Aprendizaje Estadístico vs.~Aprendizaje Automático}\label{aprendizaje-estaduxedstico-vs.-aprendizaje-automuxe1tico}}

El término \emph{Machine Learning} (ML; Aprendizaje Automático) se utiliza en el campo de la \emph{Intelingencia Artificial} desde 1959 para hacer referencia, fundamentalmente, a algoritmos de predicción (inicialmente para reconocimiento de patrones).
Muchas de las herramientas que utilizan provienen del campo de la Estadística y, en cualquier caso, la Estadística (y por tanto las Matemáticas) es la base de todos estos enfoques para analizar datos (y no conviene perder la base formal).
Por este motivo desde la Estadística Computacional se introdujo el término \emph{Statistical Learning} (Aprendizaje Estadístico) para hacer referencia a este tipo de herramientas, pero desde el punto de vista estadístico (teniendo en cuenta la incertidumbre debida a no disponer de toda la información).

Tradicionalmente ML no se preocupa del origen de los datos e incluso es habitual que se considere que un conjunto enorme de datos es equivalente a disponer de toda la información (i.e.~a la población).

\begin{quote}
``The sheer volume of data would obviate the need of theory and even
scientific method''

--- Chris Anderson, físico y periodista, 2008
\end{quote}

Por el contrario en el caso del AE se trata de comprender, si es posible, el proceso subyacente del que provienen los datos y si estos son representativos de la población de interés (i.e.~si tienen algún tipo de sesgo, especialmente de selección\footnote{También es importante detectar la presencia de algún tipo de error de medición, al menos como primer paso para tratar de predecir la respuesta libre de ruido.}).
No obstante, en este libro se considerará en general ambos términos como sinónimos.

ML/AE hacen un importante uso de la programación matemática, ya que muchos de sus problemas se plantean en términos de la optimización de funciones bajo restricciones.
Recíprocamente, en optimización también se utilizan algoritmos de ML/AE.

\hypertarget{machine-learning-vs.-data-mining}{%
\subsection{Machine Learning vs.~Data Mining}\label{machine-learning-vs.-data-mining}}

Mucha gente utiliza indistintamente los nombres ML y \emph{Data Mining} (DM).
Sin embargo, aunque tienen mucho solapamiento, lo cierto es que hacen referencia a conceptos ligeramente distintos.

ML es un conjunto de algoritmos principalmente dedicados a hacer predicciones y que son esencialmente automáticos minimizando la intervención humana.

DM intenta \emph{entender} conjuntos de datos (en el sentido de encontrar sus patrones), requiere de una intervención humana activa (al igual que la Inferencia Estadística tradicional), pero utiliza entre otras las técnicas automáticas de ML. Por tanto podríamos pensar que es más parecido al AE.

\hypertarget{las-dos-culturas-breiman2001statistical}{%
\subsection{\texorpdfstring{Las dos culturas (\protect\hyperlink{ref-breiman2001statistical}{Breiman, 2001b})}{Las dos culturas (Breiman, 2001b)}}\label{las-dos-culturas-breiman2001statistical}}

Breiman diferencia dos objetivos en el análisis de datos, que él llama \emph{información} (en el sentido de \emph{inferencia}) y \emph{predicción}.
Cada uno de estos objetivos da lugar a una cultura:

\begin{itemize}
\item
  \emph{Modelización de datos}: desarrollo de modelos (estocásticos) que permitan ajustar los datos y hacer inferencia. Es el trabajo habitual de los estadísticos académicos.
\item
  \emph{Modelización algorítmica} (en el sentido de predictiva): esta cultura no está interesada en los mecanismos que generan los datos, sólo en los algoritmos de predicción. Es el trabajo habitual de muchos estadísticos industriales y de muchos ingenieros informáticos. El ML es el núcleo de esta cultura que pone todo el énfasis en la precisión predictiva (así, un importante elemento dinamizador
  son las competiciones entre algoritmos predictivos, al estilo del \href{https://en.wikipedia.org/wiki/Netflix_Prize}{Netflix Challenge}).
\end{itemize}

\hypertarget{machine-learning-vs.-estaduxedstica-dunson2018statistics}{%
\subsection{\texorpdfstring{Machine Learning vs.~Estadística (\protect\hyperlink{ref-dunson2018statistics}{Dunson, 2018})}{Machine Learning vs.~Estadística (Dunson, 2018)}}\label{machine-learning-vs.-estaduxedstica-dunson2018statistics}}

Dunson también expone las diferencias entre ambas culturas, por ejemplo en investigación (la forma en que evolucionan):

\begin{itemize}
\item
  ``Machine learning: The main publication outlets tend to be peer-reviewed conference proceedings and the style of research is very fast paced, trendy, and driven by performance metrics in prediction and related tasks''.
\item
  ``Statistical community: The main publication outlets are peer-reviewed journals, most of which have a long drawn out review process, and the style of research tends to be careful, slower paced, intellectual as opposed to primarily performance driven, emphasizing theoretical support (e.g., through asymptotic properties), under-stated, and conservative''.
\end{itemize}

también en los principales campos de aplicación y en el tipo de datos que manejan:

\begin{itemize}
\item
  ``\emph{Big data} in ML typically means that the number of examples (i.e.~sample size) is very large''.
\item
  ``In statistics (\ldots) it has become common to collect high dimensional, complex and intricately structured data. Often the dimensionality of the data vastly exceeds the available sample size, and the fundamental challenge of the statistical analysis is obtaining new insights from these huge data, while maintaining reproducibility/replicability and reliability of the results''.
\end{itemize}

En las conclusiones, además de alertar de los peligros:

\begin{itemize}
\item
  ``Big data that are subject to substantial selection bias and measurement errors, without information in the data about the magnitude,sources and types of errors, should not be used to inform important decisions without substantial care and skepticism''.
\item
  ``There is vast interest in automated methods for complex data analysis. However, there is a lack of consideration of (1) interpretability, (2) uncertainty quantification, (3) applications with limited training data, and (4) selection bias. Statistical methods can achieve (1)-(4) with a change in focus'' (Resumen del artículo).
\end{itemize}

destaca la importancia de tener en cuenta el punto de vista estadístico.

\begin{quote}
``Such developments will likely require a close collaboration between the Stats and ML-communities and mindsets.
The emerging field of data science provides a key opportunity to forge a new approach for analyzing and interpreting large and complex data merging multiple fields.''

--- Dunson, D.B. (2018).
\end{quote}

\hypertarget{muxe9todos-de-aprendizaje-estaduxedstico}{%
\section{Métodos de Aprendizaje Estadístico}\label{muxe9todos-de-aprendizaje-estaduxedstico}}

Dentro de los problemas que aborda el Aprendizaje Estadístico se suelen diferenciar dos grandes bloques: el aprendizaje no supervisado y el supervisado. El \emph{aprendizaje no supervisado} comprende los métodos exploratorios, es decir, aquellos en los que no hay una variable respuesta (al menos no de forma explícita). El principal objetivo de estos métodos es entender las relaciones entre los datos y su estructura, y pueden clasificarse en las siguientes categorías:

\begin{itemize}
\item
  Análisis descriptivo.
\item
  Métodos de reducción de la dimensión (análisis de componentes principales, análisis factorial\ldots).
\item
  Clúster.
\item
  Detección de datos atípicos.
\end{itemize}

El \emph{aprendizaje supervisado} engloba los métodos predictivos, en los que una de las variables está definida como variable respuesta. Su principal objetivo es la construcción de modelos que posteriormente se utilizarán, sobre todo, para hacer predicciones. Dependiendo del tipo de variable respuesta se diferencia entre:

\begin{itemize}
\item
  Clasificación: respuesta categórica (también se emplea la denominación de variable cualitativa, discreta o factor).
\item
  Regresión: respuesta numérica (cuantitativa).
\end{itemize}

En este libro nos centraremos únicamente en el campo del aprendizaje supervisado y combinaremos la terminología propia de la Estadística con la empleada en AE (por ejemplo, en Estadística es habitual considerar un problema de clasificación como un caso particular de regresión).

\hypertarget{notacion}{%
\subsection{Notación y terminología}\label{notacion}}

Denotaremos por \(\mathbf{X}=(X_1, X_2, \ldots, X_p)\) al vector formado por las variables predictoras
(variables explicativas o variables independientes; también \emph{inputs} o \emph{features} en la terminología de ML), cada una de las cuales podría ser tanto numérica como categórica\footnote{Aunque hay que tener en cuenta que algunos métodos están diseñados para predictores numéricos, otros para categóricos y algunos para ambos tipos.}.
En general (ver comentarios más adelante), emplearemos \(Y\left(\mathbf{X} \right)\) para referirnos a la variable objetivo (variable respuesta o variable dependiente; también \emph{output} en la terminología de ML), que como ya se comentó puede ser una variable numérica (regresión) o categórica (clasificación).

Supondremos que el objetivo principal es, a partir de una muestra:
\[\left\{ \left( x_{1i}, \ldots, x_{pi}, y_{i} \right)  : i = 1, \ldots, n \right\},\]
obtener (futuras) predicciones \(\hat Y\left(\mathbf{x} \right)\) de la respuesta para \(\mathbf{X}=\mathbf{x}=\left(x_{1}, \ldots, x_{p}\right)\).

En regresión consideraremos como base el siguiente modelo general (podría ser después de una transformación de la respuesta):
\begin{equation} 
  Y(\mathbf{X})=m(\mathbf{X})+\varepsilon,
  \label{eq:modelogeneral}
\end{equation}
donde \(m(\mathbf{x}) = E\left( \left. Y\right\vert_{\mathbf{X}=\mathbf{x}} \right)\) es la media condicional, denominada función de regresión (o tendencia), y \(\varepsilon\) es un error aleatorio de media cero y varianza \(\sigma^2\), independiente de \(\mathbf{X}\).
Este modelo puede generalizarse de diversas formas, por ejemplo, asumiendo que la distribución del error depende de \(\mathbf{X}\) (considerando \(\varepsilon(\mathbf{X})\) en lugar de \(\varepsilon\)) podríamos incluir dependencia y heterocedasticidad.
En estos casos normalmente se supone que lo hace únicamente a través de la varianza (error heterocedástico independiente), denotando por \(\sigma^2(\mathbf{x}) = Var\left( \left. Y\right\vert_{\mathbf{X}=\mathbf{x}} \right)\) la varianza condicional\footnote{Por ejemplo considerando en el modelo base \(\sigma(\mathbf{X})\varepsilon\) como termino de error y suponiendo adicionalmente que \(\varepsilon\) tiene varianza uno.}.

Como ya se comentó se podría considerar clasificación como un caso particular, por ejemplo definiendo \(Y\left(\mathbf{X} \right)\) de forma que tome los valores \(1, 2, \ldots, K\), etiquetas que identifican las \(K\) posibles categorías (también se habla de modalidades, niveles, clases o grupos).
Sin embargo, muchos métodos de clasificación emplean variables auxiliares (variables \emph{dummy}), indicadoras de las distintas categorías, y emplearemos la notación anterior para referirnos a estas variables (también denominadas variables \emph{target}). En cuyo caso, denotaremos por \(G \left(\mathbf{X} \right)\) la respuesta categórica (la clase verdadera; \(g_i\), \(i =1, \ldots, n\), serían los valores observados) y por \(\hat G \left(\mathbf{X} \right)\) el predictor.

Por ejemplo, en el caso de dos categorías, se suele definir \(Y\) de forma que toma el valor 1 en la categoría de interés (también denominada \emph{éxito} o \emph{resultado positivo}) y 0 en caso contrario (\emph{fracaso} o \emph{resultado negativo})\footnote{Otra alternativa sería emplear 1 y -1, algo que simplifica las expresiones de algunos métodos.}.
Además, en este caso, los modelos típicamente devuelven estimaciones de la probabilidad de la clase de interés en lugar de predecir directamente la clase, por lo que se empleará \(\hat p\) en lugar de \(\hat Y\).
A partir de esa estimación se obtiene una predicción de la categoría.
Normalmente se predice la clase más probable, lo que se conoce como la \emph{regla de Bayes}, i.e.~``éxito'' si \(\hat p(\mathbf{x}) > c = 0.5\) y ``fracaso'' en caso contrario (con probabilidad estimada \(1 - \hat p(\mathbf{x})\)).

Resulta claro que el modelo base general \eqref{eq:modelogeneral} puede no ser adecuado para modelar variables indicadoras (o probabilidades).
Muchos de los métodos de AE emplean \eqref{eq:modelogeneral} para una variable auxiliar numérica (denominada puntuación o \emph{score}) que se transforma a escala de probabilidades mediante la función logística (denominada función sigmoidal, \emph{sigmoid function}, en ML)\footnote{De especial interés en regresión logística y en redes neuronales artificiales.}:
\[\operatorname{sigmoid}(s) = \frac{e^s}{1 + e^s}= \frac{1}{1 + e^{-s}},\]
de forma que \(\hat p(\mathbf{x}) = \operatorname{sigmoid}(\hat Y(\mathbf{x}))\).
Reciprocamente, empleando su inversa, la \emph{función logit}:
\[\operatorname{logit}(p)=\log\left( \frac{p}{1-p} \right),\]
se pueden transformar las probabilidades a la escala de puntuaciones.

Lo anterior se puede generalizar para el caso de múltiples categorías, considerando variables indicadoras de cada categoría \(Y_1, \ldots, Y_K\), lo que se conoce como la estrategia de ``uno contra todos'' (\emph{One-vs-Rest}, OVR). En este caso típicamente:
\[\hat G \left(\mathbf{x} \right) = \underset{k}{\operatorname{argmax}} \left\{ \hat p_k(\mathbf{x}) : k = 1, 2, \ldots, K \right\}.\]

Otra posible estrategia es la denominada ``uno contra uno'' (\emph{One-vs-One}, OVO) o también conocido por ``votación mayoritaria'' (\emph{majority voting}), que requiere entrenar un clasificador para cada par de categorías (se consideran \(K(K-1)/2\) subproblemas de clasificación binaria).
En este caso se suele seleccionar como predicción la categoría que recibe más votos (la que resultó seleccionada por el mayor número de los clasificadores binarios).

Otros métodos (como por ejemplo los árboles de decisión, que se tratarán en el Tema \ref{trees}) permiten la estimación directa de las probabilidades de cada clase.

\hypertarget{metodos-pkgs}{%
\subsection{Métodos (de aprendizaje supervisado) y paquetes de R}\label{metodos-pkgs}}

Hay una gran cantidad de métodos de aprendizaje supervisado implementados en centenares de paquetes de \texttt{R} (ver por ejemplo \href{https://cran.r-project.org/web/views/MachineLearning.html}{CRAN Task View: Machine Learning \& Statistical Learning}).
A continuación se muestran los principales métodos y algunos de los paquetes de R que los implementan (muchos son válidos para regresión y clasificación, como por ejemplo los basados en árboles, aunque aquí aparecen en su aplicación habitual).

Métodos de Clasificación:

\begin{itemize}
\item
  Análisis discriminante (lineal, cuadrático), Regresión logística, multinomial\ldots:
  \texttt{stats}, \texttt{MASS}\ldots{}
\item
  Árboles de decisión, \emph{bagging}, \emph{random forest}, \emph{boosting}:
  \texttt{rpart}, \texttt{party}, \texttt{C50}, \texttt{Cubist}, \texttt{randomForest}, \texttt{adabag}, \texttt{xgboost}\ldots{}
\item
  \emph{Support vector machines} (SVM):
  \texttt{kernlab}, \texttt{e1071}\ldots{}
\end{itemize}

Métodos de regresión:

\begin{itemize}
\item
  Modelos lineales:

  \begin{itemize}
  \item
    Regresión lineal: \texttt{lm()}, \texttt{lme()}, \texttt{biglm}\ldots{}
  \item
    Regresión lineal robusta: \texttt{MASS::rlm()}\ldots{}
  \item
    Métodos de regularización (Ridge regression, Lasso):
    \texttt{glmnet}, \texttt{elasticnet}\ldots{}
  \end{itemize}
\item
  Modelos lineales generalizados: \texttt{glm()}, \texttt{bigglm}\ldots{}
\item
  Modelos paramétricos no lineales: \texttt{nls()}, \texttt{nlme}\ldots{}
\item
  Regresión local (vecinos más próximos y métodos de suavizado):
  \texttt{kknn}, \texttt{loess()}, \texttt{KernSmooth}, \texttt{sm}, \texttt{np}\ldots{}
\item
  Modelos aditivos generalizados (GAM): \texttt{mgcv}, \texttt{gam}\ldots{}
\item
  Regresión spline adaptativa multivariante (MARS): \texttt{earth}
\item
  Regresión por \emph{projection pursuit} (incluyendo \emph{single index model}): \texttt{caret::ppr()}, \texttt{np::npindex()}\ldots{}
\item
  Redes neuronales: \texttt{nnet}, \texttt{neuralnet}\ldots{}
\end{itemize}

También existen paquetes de \texttt{R} que permiten utilizar plataformas de ML externas, como por ejemplo \href{https://github.com/h2oai/h2o-3/tree/master/h2o-r}{\texttt{h2o}} o \href{https://CRAN.R-project.org/package=RWeka}{\texttt{RWeka}}.

Como todos estos paquetes emplean opciones, estructuras y convenciones sintácticas diferentes, se han desarrollado paquetes que proporcionan interfaces unificadas a muchas de estas implementaciones.
Entre ellos podríamos citar \href{https://topepo.github.io/caret}{\texttt{caret}}, \href{https://mlr3.mlr-org.com}{\texttt{mlr3}} y \href{https://www.tidymodels.org}{\texttt{tidymodels}}.
En la Sección \ref{caret} se incluye una breve introducción al paquete \href{https://topepo.github.io/caret}{\texttt{caret}} que será empleado en diversas ocasiones a lo largo del presente libro.

Adicionalmente hay paquetes de R que disponen de entornos gráficos que permiten emplear estos métodos evitando el uso de comandos.
Entre ellos estarían R-Commander con el plugin FactoMineR (\texttt{Rcmdr}, \texttt{RcmdrPlugin.FactoMineR}), \href{https://rattle.togaware.com}{\texttt{rattle}} y \href{https://github.com/radiant-rstats/radiant}{\texttt{radiant}}.

\hypertarget{const-eval}{%
\section{Construcción y evaluación de los modelos}\label{const-eval}}

En Inferencia Estadística clásica el procedimiento habitual es emplear toda la información disponible para construir un modelo válido (que refleje de la forma más fiel posible lo que ocurre en la población) y asumiendo que el modelo es el verdadero (lo que en general sería falso) utilizar métodos de inferencia para evaluar su precisión.
Por ejemplo, en el caso de regresión lineal múltiple, el coeficiente de determinación ajustado sería una medida del la precisión del modelo para predecir nuevas observaciones (no se debería emplear el coeficiente de determinación sin ajustar; aunque, en cualquier caso, su validez dependería de la de las suposiciones estructurales del modelo).

Alternativamente, en Estadística Computacional es habitual emplear técnicas de remuestreo para evaluar la precisión (entrenando también el modelo con todos los datos disponibles), principalmente validación cruzada (leave-one-out, k-fold), jackknife o bootstrap.

Por otra parte, como ya se comentó, algunos de los modelos empleados en AE son muy flexibles (están hiperparametrizados) y pueden aparecer problemas si se permite que se ajusten demasiado bien a las observaciones (podrían llegar a interpolar los datos).
En estos casos habrá que controlar el procedimiento de aprendizaje, típicamente a traves de parámetros relacionados con la complejidad del modelo (ver sección siguiente).

En AE se distingue entre parámetros estructurales, los que van a ser estimados al ajustar el modelo a los datos (en el entrenamiento), e hiperparámetros (\emph{tuning parameters} o parámetros de ajuste), que imponen restricciones al aprendizaje del modelo (por ejemplo determinando el número de parámetros estructurales).
Si los hiperparámetros seleccionados producen un modelo demasiado complejo aparecerán problemas de sobreajuste (\emph{overfitting}) y en caso contrario de infraajuste (\emph{undefitting}).

Hay que tener en cuenta también que al aumentar la complejidad disminuye la interpretabilidad de los modelos.
Se trataría entonces de conseguir buenas predicciones (habrá que evaluar la capacidad predictiva) con el modelo más sencillo posible.

\hypertarget{bias-variance}{%
\subsection{Equilibrio entre sesgo y varianza: infraajuste y sobreajuste}\label{bias-variance}}

La idea es que queremos aprender más allá de los datos empleados en el entrenamiento (en Estadística diríamos que queremos hacer inferencia sobre nuevas observaciones).
Como ya se comentó, en AE hay que tener especial cuidado con el sobreajuste.
Este problema ocurre cuando el modelo se ajusta demasiado bien a los datos de entrenamiento pero falla cuando se utiliza en un nuevo conjunto de datos (nunca antes visto).

Como ejemplo ilustrativo emplearemos regresión polinómica, considerando el grado del polinomio como un hiperparámetro que determina la complejidad del modelo.
En primer lugar simulamos una muestra y ajustamos modelos polinómicos con distintos grados de complejidad.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simulación datos}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{30}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{length =}\NormalTok{ n)}
\NormalTok{mu }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{+} \DecValTok{4}\SpecialCharTok{*}\NormalTok{(}\DecValTok{5}\SpecialCharTok{*}\NormalTok{x }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{(}\DecValTok{4}\SpecialCharTok{*}\NormalTok{x }\SpecialCharTok{{-}} \DecValTok{2}\NormalTok{)}\SpecialCharTok{*}\NormalTok{(x }\SpecialCharTok{{-}} \FloatTok{0.8}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \CommentTok{\# grado 4}
\NormalTok{sd }\OtherTok{\textless{}{-}} \FloatTok{0.5}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ mu }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, sd)}
\FunctionTok{plot}\NormalTok{(x, y) }
\FunctionTok{lines}\NormalTok{(x, mu, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)}
\CommentTok{\# Ajuste de los modelos}
\NormalTok{fit1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x)}
\FunctionTok{lines}\NormalTok{(x, }\FunctionTok{fitted}\NormalTok{(fit1))}
\NormalTok{fit2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{poly}\NormalTok{(x, }\DecValTok{4}\NormalTok{))}
\FunctionTok{lines}\NormalTok{(x, }\FunctionTok{fitted}\NormalTok{(fit2), }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\NormalTok{fit3 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{poly}\NormalTok{(x, }\DecValTok{20}\NormalTok{)) }
\CommentTok{\# NOTA: poly(x, degree, raw = FALSE) tiene un problema de desbordamiento si degree \textgreater{} 25}
\FunctionTok{lines}\NormalTok{(x, }\FunctionTok{fitted}\NormalTok{(fit3), }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }\AttributeTok{legend =} \FunctionTok{c}\NormalTok{(}\StringTok{"Verdadero"}\NormalTok{, }\StringTok{"Ajuste con grado 1"}\NormalTok{, }
                              \StringTok{"Ajuste con grado 4"}\NormalTok{, }\StringTok{"Ajuste con grado 20"}\NormalTok{), }
       \AttributeTok{lty =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{), }\AttributeTok{lwd =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{01-introduccion_files/figure-latex/polyfit-1} 

}

\caption{Muestra (simulada) y ajustes polinómicos con distinta complejidad.}\label{fig:polyfit}
\end{figure}

Como se observa en la Figura \ref{fig:polyfit} al aumentar la complejidad del modelo se consigue un mejor ajuste a los datos observados (empleados en el entrenamiento), a costa de un incremento en la variabilidad de las predicciones, lo que puede producir un mal comportamiento del modelo a ser empleado en un conjunto de datos distinto del observado.

Si calculamos medidas de bondad de ajuste, como el error cuadrático medio (MSE) o el coeficiente de determinación, se obtienen mejores resultados al aumentar la complejidad.
Como se trata de modelos lineales, podríamos obtener también el coeficiente de determinación ajustado, que sería preferible (en principio, ya que dependería de la validez de las hipótesis estructurales del modelo) para medir la precisión al emplear los modelos en un nuevo conjunto de datos.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}\FunctionTok{t}\NormalTok{(}\FunctionTok{sapply}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{Fit1 =}\NormalTok{ fit1, }\AttributeTok{Fit2 =}\NormalTok{ fit2, }\AttributeTok{Fit3 =}\NormalTok{ fit3), }
    \ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{with}\NormalTok{(}\FunctionTok{summary}\NormalTok{(x), }
        \FunctionTok{c}\NormalTok{(}\AttributeTok{MSE =} \FunctionTok{mean}\NormalTok{(residuals}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{), }\AttributeTok{R2 =}\NormalTok{ r.squared, }\AttributeTok{R2adj =}\NormalTok{ adj.r.squared)))), }
    \AttributeTok{caption=}\StringTok{"Medidas de bondad de ajuste de los modelos polinómicos."}\NormalTok{, }\AttributeTok{digits =} \DecValTok{2}\NormalTok{, }\AttributeTok{position =} \StringTok{"!htb"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!htb]

\caption{\label{tab:unnamed-chunk-2}Medidas de bondad de ajuste de los modelos polinómicos.}
\centering
\begin{tabular}[t]{l|r|r|r}
\hline
  & MSE & R2 & R2adj\\
\hline
Fit1 & 1.22 & 0.20 & 0.17\\
\hline
Fit2 & 0.19 & 0.87 & 0.85\\
\hline
Fit3 & 0.07 & 0.95 & 0.84\\
\hline
\end{tabular}
\end{table}

Por ejemplo, si generamos nuevas respuestas de este proceso, la precisión del modelo más complejo empeorará considerablemente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y.new }\OtherTok{\textless{}{-}}\NormalTok{ mu }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, sd)}
\FunctionTok{plot}\NormalTok{(x, y) }
\FunctionTok{points}\NormalTok{(x, y.new, }\AttributeTok{pch =} \DecValTok{2}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(x, mu, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(x, }\FunctionTok{fitted}\NormalTok{(fit1))}
\FunctionTok{lines}\NormalTok{(x, }\FunctionTok{fitted}\NormalTok{(fit2), }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(x, }\FunctionTok{fitted}\NormalTok{(fit3), }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }\AttributeTok{legend =} \FunctionTok{c}\NormalTok{(}\StringTok{"Verdadero"}\NormalTok{, }\StringTok{"Muestra"}\NormalTok{, }\StringTok{"Ajuste con grado 1"}\NormalTok{, }\StringTok{"Ajuste con grado 4"}\NormalTok{, }
                              \StringTok{"Ajuste con grado 20"}\NormalTok{, }\StringTok{"Nuevas observaciones"}\NormalTok{), }
       \AttributeTok{lty =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\ConstantTok{NA}\NormalTok{), }\AttributeTok{lwd =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\ConstantTok{NA}\NormalTok{), }\AttributeTok{pch =} \FunctionTok{c}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\DecValTok{1}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{01-introduccion_files/figure-latex/polyfit2-1} 

}

\caption{Muestra con ajustes polinómicos con distinta complejidad y nuevas observaciones.}\label{fig:polyfit2}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{MSEP }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{fit1 =}\NormalTok{ fit1, }\AttributeTok{fit2 =}\NormalTok{ fit2, }\AttributeTok{fit3 =}\NormalTok{ fit3), }
               \ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{mean}\NormalTok{((y.new }\SpecialCharTok{{-}} \FunctionTok{fitted}\NormalTok{(x))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}
\NormalTok{MSEP}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      fit1      fit2      fit3 
## 1.4983208 0.1711238 0.2621064
\end{verbatim}

Como ejemplo adicional, para evitar el efecto de la aleatoriedad de la muestra, en el siguiente código se simulan 100 muestras del proceso anterior a las que se les ajustan modelos polinómicos variando el grado de 1 a 20. Posteriormente se evalua la precisión en la muestra empleada en el ajuste y en un nuevo conjunto de datos procedente de la misma población.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nsim }\OtherTok{\textless{}{-}} \DecValTok{100}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{grado.max }\OtherTok{\textless{}{-}} \DecValTok{20}
\NormalTok{grados }\OtherTok{\textless{}{-}} \FunctionTok{seq\_len}\NormalTok{(grado.max) }
\NormalTok{mse }\OtherTok{\textless{}{-}}\NormalTok{ mse.new }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\AttributeTok{nrow =}\NormalTok{ grado.max, }\AttributeTok{ncol =}\NormalTok{ nsim) }\CommentTok{\# Error cuadrático medio}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(nsim)) \{}
\NormalTok{  y }\OtherTok{\textless{}{-}}\NormalTok{ mu }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, sd)}
\NormalTok{  y.new }\OtherTok{\textless{}{-}}\NormalTok{ mu }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, sd)}
  \ControlFlowTok{for}\NormalTok{ (grado }\ControlFlowTok{in}\NormalTok{ grados) \{ }\CommentTok{\# grado \textless{}{-} 1}
\NormalTok{    fit }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{poly}\NormalTok{(x, grado))}
\NormalTok{    mse[grado, i] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(}\FunctionTok{residuals}\NormalTok{(fit)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{    mse.new[grado, i] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{((y.new }\SpecialCharTok{{-}} \FunctionTok{fitted}\NormalTok{(fit))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{\}}
\CommentTok{\# Simulaciones}
\FunctionTok{matplot}\NormalTok{(grados, mse, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{col =} \StringTok{"lightgray"}\NormalTok{, }\AttributeTok{lty =} \DecValTok{1}\NormalTok{, }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{2}\NormalTok{),}
        \AttributeTok{xlab =} \StringTok{"Grado del polinomio (complejidad)"}\NormalTok{,}
        \AttributeTok{ylab =} \StringTok{"Error cuadrático medio"}\NormalTok{)}
\FunctionTok{matlines}\NormalTok{(grados, mse.new, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{, }\AttributeTok{col =} \StringTok{"lightgray"}\NormalTok{) }
\CommentTok{\# Global}
\NormalTok{precision }\OtherTok{\textless{}{-}} \FunctionTok{rowMeans}\NormalTok{(mse)}
\NormalTok{precision.new }\OtherTok{\textless{}{-}} \FunctionTok{rowMeans}\NormalTok{(mse.new)}
\FunctionTok{lines}\NormalTok{(grados, precision, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(grados, precision.new, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =}\NormalTok{ sd}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{, }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =} \DecValTok{4}\NormalTok{, }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }\AttributeTok{legend =} \FunctionTok{c}\NormalTok{(}\StringTok{"Muestras"}\NormalTok{, }\StringTok{"Nuevas observaciones"}\NormalTok{), }\AttributeTok{lty =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{01-introduccion_files/figure-latex/polyfitsim-1} 

}

\caption{Precisiones (errores cuadráticos medios) de ajustes polinómicos variando la complejidad, en las muestras empleadas en el ajuste y en nuevas observaciones (simulados).}\label{fig:polyfitsim}
\end{figure}

Como se puede observar en la Figura \ref{fig:polyfitsim} los errores de entrenamiento disminuyen a medida que aumenta la complejidad del modelo.
Sin embargo los errores de predicción en nuevas observaciones primero disminuyen hasta alcanzar un mínimo, marcado por la línea de puntos vertical que se corresponde con el modelo de grado 4, y después aumentan (la línea de puntos horizontal es la varianza del proceso; el error cuadrático medio de predicción asintótico).
La línea vertical representa el equilibrio entre el sesgo y la varianza.
Considerando un valor de complejidad a la izquierda de esa línea tendríamos infraajuste (mayor sesgo y menor varianza) y a la derecha sobreajuste (menor sesgo y mayor varianza).

Desde un punto de vista más formal, considerando el modelo \eqref{eq:modelogeneral} y una función de pérdidas cuadrática, el predictor óptimo (desconocido) sería la media condicional \(m(\mathbf{x}) = E\left( \left. Y\right\vert_{\mathbf{X}=\mathbf{x}} \right)\)\footnote{Se podrían considerar otras funciones de pérdida, por ejemplo con la distancia \(L_1\) sería la mediana condicional, pero las consideraciones serían análogas.}.
Por tanto los predictores serían realmente estimaciones de la función de regresión, \(\hat Y(\mathbf{x}) = \hat m(\mathbf{x})\) y podemos expresar la media del error cuadrático de predicción en términos del sesgo y la varianza:
\[
\begin{aligned}
E \left( Y(\mathbf{x}_0) - \hat Y(\mathbf{x}_0) \right)^2 & = E \left( m(\mathbf{x}_0) + \varepsilon - \hat m(\mathbf{x}_0) \right)^2 = E \left( m(\mathbf{x}_0) - \hat m(\mathbf{x}_0) \right)^2 + \sigma^2 \\
& = E^2 \left( m(\mathbf{x}_0) - \hat m(\mathbf{x}_0) \right) + Var\left( \hat m(\mathbf{x}_0) \right) + \sigma^2 \\
& = \text{sesgo}^2 + \text{varianza} + \text{error irreducible}
\end{aligned}
\]
donde \(\mathbf{x}_0\) hace referencia al vector de valores de las variables explicativas de una nueva observación (no empleada en la construcción del predictor).

En general, al aumentar la complejidad disminuye el sesgo y aumenta la varianza (y viceversa).
Esto es lo que se conoce como el dilema o compromiso entre el sesgo y la varianza (\emph{bias-variance tradeoff}).
La recomendación sería por tanto seleccionar los hiperparámetros (el modelo final) tratando de que haya un equilibrio entre el sesgo y la varianza (ver Figura \ref{fig:biasvar}).

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{images/Bias-variance_tradeoff} 

}

\caption{Equilibrio entre sesgo y varianza}\label{fig:biasvar}
\end{figure}

\hypertarget{entrenamiento-test}{%
\subsection{Datos de entrenamiento y datos de test}\label{entrenamiento-test}}

Como se mostró en la sección anterior hay que tener mucho cuidado si se pretende evaluar la precisión de las predicciones empleando la muestra de entrenamiento.

Si el número de observaciones no es muy grande, se puede entrenar el modelo con todos los datos y emplear técnicas de remuestreo para evaluar la precisión (típicamente validación cruzada o bootstrap).
Habría que asegurase de que el procedimiento de remuestreo empleado es adecuado (por ejemplo, la presencia de dependencia requeriría de métodos más sofisticados).

Sin embargo, si el número de observaciones es grande, se suele emplear el procedimiento tradicional en ML, que consiste en particionar la base de datos en 2 (o incluso en 3) conjuntos (disjuntos):

\begin{itemize}
\item
  Conjunto de datos de entrenamiento (o aprendizaje) para construir los modelos.
\item
  Conjunto de datos de test para evaluar el rendimiento de los modelos (los errores observados en esta muestra servirán para aproximar lo que ocurriría con nuevas observaciones).
\end{itemize}

Típicamente se selecciona al azar el 80\% de los datos como muestra de entrenamiento y el 20\% restante como muestra de test, aunque esto dependería del número de datos (los resultados serán aleatorios, aunque su variabilidad dependerá principalmente del tamaño de las muestras).
En R se puede realizar el particionamiento de los datos empleando la función \texttt{sample()} del paquete base (otra alternativa sería emplear la función \texttt{createDataPartition} del paquete \texttt{caret} como se describe en la Sección \ref{caret}).

Como ejemplo consideraremos el conjunto de datos \texttt{Boston} del paquete \texttt{MASS} que contiene, entre otros datos, la valoración de las viviendas (\texttt{medv}, mediana de los valores de las viviendas ocupadas, en miles de dólares) y el porcentaje de población con ``menor estatus'' (\texttt{lstat}) en los suburbios de Boston.
Podemos construir las muestras de entrenamiento (80\%) y de test (20\%) con el siguiente código:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(Boston, }\AttributeTok{package =} \StringTok{"MASS"}\NormalTok{)}
\CommentTok{\# ?Boston}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{nobs }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(Boston)}
\NormalTok{itrain }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(nobs, }\FloatTok{0.8} \SpecialCharTok{*}\NormalTok{ nobs)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ Boston[itrain, ]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ Boston[}\SpecialCharTok{{-}}\NormalTok{itrain, ]}
\end{Highlighting}
\end{Shaded}

Los datos de test deberían utilizarse únicamente para evaluar los modelos finales, no se deberían emplear para seleccionar hiperparámetros.
Para seleccionarlos se podría volver a particionar los datos de entrenamiento, es decir, dividir la muestra en tres subconjuntos: datos de entrenamiento, de validación y de test (por ejemplo considerando un 70\%, 15\% y 15\% de las observaciones, respectivamente).
Para cada combinación de hiperparámetros se ajustaría el correspondiente modelo con los datos de entrenamiento, se emplearían los de validación para evaluarlos y posteriormente seleccionar los valores ``óptimos''. Por último, se emplean los datos de test para evaluar el rendimiento del modelo seleccionado.
No obstante, lo más habitual es seleccionar los hiperparámetros empleando validación cruzada (o otro tipo de remuestreo) en la muestra de entrenamiento, en lugar de considerar una muestra adicional de validación.
En la siguiente sección se describirá esta última aproximación.

\hypertarget{cv}{%
\subsection{Validación cruzada}\label{cv}}

Como ya se comentó, una herramienta para evaluar la calidad predictiva de un modelo es la \emph{validación cruzada}, que permite cuantificar el error de predicción utilizando una única muestra de datos.

En su versión más simple, validación cruzada dejando uno fuera (\emph{Leave-one-out cross-validation}, LOOCV), para cada observación de la muestra se realiza un ajuste empleando el resto de observaciones, y se mide el error de predicción en esa observación (único dato no utilizado en el ajuste del modelo).
Finalmente, combinando todos los errores individuales se puede obtener medidas globales del error de predicción (o aproximar características de su distribución).

El método de LOOCV requeriría, en principio (ver comentarios más adelante), el ajuste de un modelo para cada observación por lo que pueden aparecer problemas computacionales si el conjunto de datos es grande.
En este caso se suele emplear grupos de observaciones en lugar de observaciones individuales.
Si se particiona el conjunto de datos en \emph{k} grupos, típicamente 10 o 5 grupos, se denomina \emph{k-fold cross-validation} (LOOCV sería un caso particular considerando un número de grupos igual al número de observaciones)\footnote{La partición en k-fold CV se suele realizar al azar. Hay que tener en cuenta la aleatoriedad al emplear k-fold CV, algo que no ocurre con LOOCV.}.
Hay muchas variaciones de este método, entre ellas particionar repetidamente de forma aleatoria los datos en un conjunto de entrenamiento y otro de validación (de esta forma algunas observaciones podrían aparecer repetidas veces y otras ninguna en las muestras de validación).

Continuando con el ejemplo anterior, supongamos que queremos emplear regresión polinómica para explicar la valoración de las viviendas a partir del ``estatus'' de los residentes (ver Figura \ref{fig:boston-mass}).
Al igual que se hizo en la Sección \ref{bias-variance}, consideraremos el grado del polinomio como un hiperparámetro.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lstat, }\AttributeTok{data =}\NormalTok{ train)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{01-introduccion_files/figure-latex/boston-mass-1} 

}

\caption{Gráfico de dispersión de las valoraciones de las viviendas (`medv`) frente al porcentaje de población con "menor estatus" (`lstat`).}\label{fig:boston-mass}
\end{figure}

Podríamos emplear la siguiente función que devuelve para cada observación (fila) de una muestra de entrenamiento, el error de predicción en esa observación ajustando un modelo lineal con todas las demás observaciones:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cv.lm0 }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(formula, datos) \{}
\NormalTok{    respuesta }\OtherTok{\textless{}{-}} \FunctionTok{as.character}\NormalTok{(formula)[}\DecValTok{2}\NormalTok{] }\CommentTok{\# extraer nombre variable respuesta}
\NormalTok{    n }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(datos)}
\NormalTok{    cv.res }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(n)}
    \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{n) \{}
\NormalTok{        modelo }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(formula, datos[}\SpecialCharTok{{-}}\NormalTok{i, ])}
\NormalTok{        cv.pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(modelo, }\AttributeTok{newdata =}\NormalTok{ datos[i, ])}
\NormalTok{        cv.res[i] }\OtherTok{\textless{}{-}}\NormalTok{ cv.pred }\SpecialCharTok{{-}}\NormalTok{ datos[i, respuesta]}
\NormalTok{    \}}
    \FunctionTok{return}\NormalTok{(cv.res)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

La función anterior no es muy eficiente, pero podría modificarse fácilmente para emplear otros métodos de regresión\footnote{También puede ser de interés la función \texttt{cv.glm()} del paquete \texttt{boot}.}.
En el caso de regresión lineal múltiple (y de otros predictores lineales), se pueden obtener fácilmente las predicciones eliminando una de las observaciones a partir del ajuste con todos los datos.
Por ejemplo, en lugar de la anterior sería preferible emplear la siguiente función (ver \texttt{?rstandard}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cv.lm }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(formula, datos) \{}
\NormalTok{    modelo }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(formula, datos)}
    \FunctionTok{return}\NormalTok{(}\FunctionTok{rstandard}\NormalTok{(modelo, }\AttributeTok{type =} \StringTok{"predictive"}\NormalTok{))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Empleando esta función, podemos calcular una medida del error de predicción de validación cruzada (en este caso el \emph{error cuadrático medio}) para cada valor del hiperparámetro (grado del ajuste polinómico) y seleccionar el que lo minimiza.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grado.max }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{grados }\OtherTok{\textless{}{-}} \FunctionTok{seq\_len}\NormalTok{(grado.max) }
\NormalTok{cv.mse }\OtherTok{\textless{}{-}}\NormalTok{ cv.mse.sd }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(grado.max)}
\ControlFlowTok{for}\NormalTok{(grado }\ControlFlowTok{in}\NormalTok{ grados)\{}
  \CommentTok{\# cv.res \textless{}{-} cv.lm0(medv \textasciitilde{} poly(lstat, grado), train) \# Tiempo de computación elevado!}
\NormalTok{  cv.res }\OtherTok{\textless{}{-}} \FunctionTok{cv.lm}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}} \FunctionTok{poly}\NormalTok{(lstat, grado), train)}
\NormalTok{  se }\OtherTok{\textless{}{-}}\NormalTok{ cv.res}\SpecialCharTok{\^{}}\DecValTok{2}
\NormalTok{  cv.mse[grado] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(se)}
\NormalTok{  cv.mse.sd[grado] }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(se)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{length}\NormalTok{(se))}
\NormalTok{\}}
\FunctionTok{plot}\NormalTok{(grados, cv.mse, }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{25}\NormalTok{, }\DecValTok{45}\NormalTok{),}
  \AttributeTok{xlab =} \StringTok{"Grado del polinomio"}\NormalTok{)}
\CommentTok{\# Valor óptimo}
\NormalTok{imin.mse }\OtherTok{\textless{}{-}} \FunctionTok{which.min}\NormalTok{(cv.mse)}
\NormalTok{grado.op }\OtherTok{\textless{}{-}}\NormalTok{ grados[imin.mse]}
\FunctionTok{points}\NormalTok{(grado.op, cv.mse[imin.mse], }\AttributeTok{pch =} \DecValTok{16}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{01-introduccion_files/figure-latex/cv-mse-1} 

}

\caption{Error cuadrático medio de validación cruzada dependiendo del grado del polinomio (complejidad) y valor óptimo.}\label{fig:cv-mse}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grado.op}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5
\end{verbatim}

En lugar de emplear los valores óptimos de los hiperparámetros, \protect\hyperlink{ref-breiman1984classification}{Breiman et~al.} (\protect\hyperlink{ref-breiman1984classification}{1984}) propusieron la regla de ``un error estándar'' para seleccionar la complejidad del modelo.
La idea es que estamos trabajando con estimaciones de la precisión y pueden presentar variabilidad (si cambiamos la muestra o cambiamos la partición los resultados seguramente cambiarán),
por lo que la sugerencia es seleccionar el modelo más simple\footnote{Suponiendo que los modelos se pueden ordenar del más simple al más complejo.} dentro de un error estándar de la precisión del modelo correspondiente al valor óptimo
(se consideraría que no hay diferencias significativas en la precisión;
además, se mitigaría el efecto de la variabilidad debida a aleatoriedad/semilla).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(grados, cv.mse, }\AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\DecValTok{25}\NormalTok{, }\DecValTok{45}\NormalTok{),}
  \AttributeTok{xlab =} \StringTok{"Grado del polinomio"}\NormalTok{)}
\FunctionTok{segments}\NormalTok{(grados, cv.mse }\SpecialCharTok{{-}}\NormalTok{ cv.mse.sd, grados, cv.mse }\SpecialCharTok{+}\NormalTok{ cv.mse.sd)}
\CommentTok{\# Límite superior "oneSE rule" y complejidad mínima por debajo de ese valor}
\NormalTok{upper.cv.mse }\OtherTok{\textless{}{-}}\NormalTok{ cv.mse[imin.mse] }\SpecialCharTok{+}\NormalTok{ cv.mse.sd[imin.mse]}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =}\NormalTok{ upper.cv.mse, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\NormalTok{imin}\FloatTok{.1}\NormalTok{se }\OtherTok{\textless{}{-}} \FunctionTok{min}\NormalTok{(}\FunctionTok{which}\NormalTok{(cv.mse }\SpecialCharTok{\textless{}=}\NormalTok{ upper.cv.mse))}
\NormalTok{grado}\FloatTok{.1}\NormalTok{se }\OtherTok{\textless{}{-}}\NormalTok{ grados[imin}\FloatTok{.1}\NormalTok{se]}
\FunctionTok{points}\NormalTok{(grado}\FloatTok{.1}\NormalTok{se, cv.mse[imin}\FloatTok{.1}\NormalTok{se], }\AttributeTok{pch =} \DecValTok{16}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{01-introduccion_files/figure-latex/cv-onese-1} 

}

\caption{Error cuadrático medio de validación cruzada dependiendo del grado del polinomio (complejidad) y valor seleccionado con el criterio de un error estándar.}\label{fig:cv-onese}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grado}\FloatTok{.1}\NormalTok{se}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lstat, }\AttributeTok{data =}\NormalTok{ train)}
\NormalTok{fit.op }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}} \FunctionTok{poly}\NormalTok{(lstat, grado.op), train)}
\NormalTok{fit}\FloatTok{.1}\NormalTok{se }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}} \FunctionTok{poly}\NormalTok{(lstat, grado}\FloatTok{.1}\NormalTok{se), train)}
\NormalTok{newdata }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{lstat =} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{40}\NormalTok{, }\AttributeTok{len =} \DecValTok{100}\NormalTok{))}
\FunctionTok{lines}\NormalTok{(newdata}\SpecialCharTok{$}\NormalTok{lstat, }\FunctionTok{predict}\NormalTok{(fit.op, }\AttributeTok{newdata =}\NormalTok{ newdata))}
\FunctionTok{lines}\NormalTok{(newdata}\SpecialCharTok{$}\NormalTok{lstat, }\FunctionTok{predict}\NormalTok{(fit}\FloatTok{.1}\NormalTok{se, }\AttributeTok{newdata =}\NormalTok{ newdata), }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }\AttributeTok{legend =} \FunctionTok{c}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Grado óptimo:"}\NormalTok{, grado.op), }\FunctionTok{paste}\NormalTok{(}\StringTok{"oneSE rule:"}\NormalTok{, grado}\FloatTok{.1}\NormalTok{se)), }
       \AttributeTok{lty =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{01-introduccion_files/figure-latex/boston-final-1} 

}

\caption{Ajuste de los modelos finales, empleando el valor óptimo y el criterio de un error estándar para seleccionar el grado del polinomio mediante validación cruzada.}\label{fig:boston-final}
\end{figure}

\hypertarget{eval-reg}{%
\subsection{Evaluación de un método de regresión}\label{eval-reg}}

Para estudiar la precisión de las predicciones de un método de regresión se evalúa el
modelo en el conjunto de datos de test y se comparan las predicciones frente a los valores reales.
Los resultados servirán como medidas globales de la calidad de las predicciones con nuevas observaciones.

Si generamos un gráfico de dispersión de observaciones frente a predicciones, los puntos deberían estar en torno a la recta \(y=x\) (ver Figura \ref{fig:obs-pred-plot}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{obs }\OtherTok{\textless{}{-}}\NormalTok{ test}\SpecialCharTok{$}\NormalTok{medv}
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(fit.op, }\AttributeTok{newdata =}\NormalTok{ test)}

\FunctionTok{plot}\NormalTok{(pred, obs, }\AttributeTok{xlab =} \StringTok{"Predicción"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Observado"}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{a =} \DecValTok{0}\NormalTok{, }\AttributeTok{b =} \DecValTok{1}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(obs }\SpecialCharTok{\textasciitilde{}}\NormalTok{ pred)}
\CommentTok{\# summary(res)}
\FunctionTok{abline}\NormalTok{(res, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{01-introduccion_files/figure-latex/obs-pred-plot-1} 

}

\caption{Gráfico de dispersión de observaciones frente a predicciones (incluyendo la identidad, línea continua, y el ajuste lineal, línea discontinua).}\label{fig:obs-pred-plot}
\end{figure}

También es habitual calcular distintas medidas de error.
Por ejemplo, podríamos emplear la función \texttt{postResample()} del paquete \texttt{caret}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{caret}\SpecialCharTok{::}\FunctionTok{postResample}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      RMSE  Rsquared       MAE 
## 4.8526718 0.6259583 3.6671847
\end{verbatim}

La función anterior, además de las medidas de error habituales (que dependen en su mayoría de la escala de la variable respuesta) calcula un \emph{pseudo R-cuadrado}.
En este paquete (también en \texttt{rattle}) se emplea uno de los más utilizados, el cuadrado del coeficiente de correlación entre las predicciones y los valores observados (que se corresponde con la línea discontinua en la figura anterior).
Estos valores se interpretarían como el coeficiente de determinación en regresión lineal, debería ser próximo a 1.
Hay otras alternativas (ver \protect\hyperlink{ref-kvaalseth1985cautionary}{Kvålseth, 1985}), pero la idea es que deberían medir la proporción de variabilidad de la respuesta explicada por el modelo, algo que en general no es cierto con el anterior\footnote{Por ejemplo obtendríamos el mismo valor si desplazamos las predicciones sumando una constante (i.e.~no tiene en cuenta el sesgo). Lo que interesaría sería medir la proximidad de los puntos a la recta \(y=x\).}.
La recomendación sería emplear:
\[\tilde R^2 = 1 - \frac{\sum_{i=1}^n(y_i - \hat y_i)^2}{\sum_{i=1}^n(y_i - \bar y)^2}\]
implementado junto con otras medidas en la siguiente función:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{accuracy }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(pred, obs, }\AttributeTok{na.rm =} \ConstantTok{FALSE}\NormalTok{, }
                     \AttributeTok{tol =} \FunctionTok{sqrt}\NormalTok{(.Machine}\SpecialCharTok{$}\NormalTok{double.eps)) \{}
\NormalTok{  err }\OtherTok{\textless{}{-}}\NormalTok{ obs }\SpecialCharTok{{-}}\NormalTok{ pred     }\CommentTok{\# Errores}
  \ControlFlowTok{if}\NormalTok{(na.rm) \{}
\NormalTok{    is.a }\OtherTok{\textless{}{-}} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(err)}
\NormalTok{    err }\OtherTok{\textless{}{-}}\NormalTok{ err[is.a]}
\NormalTok{    obs }\OtherTok{\textless{}{-}}\NormalTok{ obs[is.a]}
\NormalTok{  \}  }
\NormalTok{  perr }\OtherTok{\textless{}{-}} \DecValTok{100}\SpecialCharTok{*}\NormalTok{err}\SpecialCharTok{/}\FunctionTok{pmax}\NormalTok{(obs, tol)  }\CommentTok{\# Errores porcentuales}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
    \AttributeTok{me =} \FunctionTok{mean}\NormalTok{(err),           }\CommentTok{\# Error medio}
    \AttributeTok{rmse =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{(err}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)), }\CommentTok{\# Raíz del error cuadrático medio }
    \AttributeTok{mae =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(err)),     }\CommentTok{\# Error absoluto medio}
    \AttributeTok{mpe =} \FunctionTok{mean}\NormalTok{(perr),         }\CommentTok{\# Error porcentual medio}
    \AttributeTok{mape =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(perr)),   }\CommentTok{\# Error porcentual absoluto medio}
    \AttributeTok{r.squared =} \DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{sum}\NormalTok{(err}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{sum}\NormalTok{((obs }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(obs))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\CommentTok{\# Pseudo R{-}cuadrado}
\NormalTok{  ))}
\NormalTok{\}}
\FunctionTok{accuracy}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         me       rmse        mae        mpe       mape  r.squared 
## -0.6731294  4.8526718  3.6671847 -8.2322506 19.7097373  0.6086704
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{accuracy}\NormalTok{(}\FunctionTok{predict}\NormalTok{(fit}\FloatTok{.1}\NormalTok{se, }\AttributeTok{newdata =}\NormalTok{ test), obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         me       rmse        mae        mpe       mape  r.squared 
## -0.9236280  5.2797360  4.1252053 -9.0029771 21.6512406  0.5367608
\end{verbatim}

\begin{exercise}
\protect\hypertarget{exr:train-validate-test}{}{\label{exr:train-validate-test} }
\end{exercise}

Considerando de nuevo el ejemplo anterior, particionar la muestra en datos de entrenamiento (70\%), de validación (15\%) y de test (15\%), para entrenar los modelos polinómicos, seleccionar el grado óptimo (el hiperparámetro) y evaluar las predicciones del modelo final, respectivamente.

Podría ser de utilidad el siguiente código (basado en la aproximación de \texttt{rattle}), que particiona los datos suponiendo que están almacenados en el data.frame \texttt{df}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ Boston}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{nobs }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(df)}
\NormalTok{itrain }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(nobs, }\FloatTok{0.7} \SpecialCharTok{*}\NormalTok{ nobs)}
\NormalTok{inotrain }\OtherTok{\textless{}{-}} \FunctionTok{setdiff}\NormalTok{(}\FunctionTok{seq\_len}\NormalTok{(nobs), itrain)}
\NormalTok{ivalidate }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(inotrain, }\FloatTok{0.15} \SpecialCharTok{*}\NormalTok{ nobs)}
\NormalTok{itest }\OtherTok{\textless{}{-}} \FunctionTok{setdiff}\NormalTok{(inotrain, ivalidate)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ df[itrain, ]}
\NormalTok{validate }\OtherTok{\textless{}{-}}\NormalTok{ df[ivalidate, ]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ df[itest, ]}
\end{Highlighting}
\end{Shaded}

Alternativamente podríamos emplear la función \texttt{split()} creando un factor que divida aleatoriamente los datos en tres grupos (versión ``simplificada'' de una propuesta en este \href{https://stackoverflow.com/questions/36068963/r-how-to-split-a-data-frame-into-training-validation-and-test-sets}{post}):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{p }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\AttributeTok{train =} \FloatTok{0.7}\NormalTok{, }\AttributeTok{validate =} \FloatTok{0.15}\NormalTok{, }\AttributeTok{test =} \FloatTok{0.15}\NormalTok{)}
\NormalTok{f }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{( }\FunctionTok{rep}\NormalTok{(}\FunctionTok{factor}\NormalTok{(}\FunctionTok{seq\_along}\NormalTok{(p), }\AttributeTok{labels =} \FunctionTok{names}\NormalTok{(p)),}
                 \AttributeTok{times =} \FunctionTok{nrow}\NormalTok{(df)}\SpecialCharTok{*}\NormalTok{p}\SpecialCharTok{/}\FunctionTok{sum}\NormalTok{(p)) )}
\NormalTok{samples }\OtherTok{\textless{}{-}} \FunctionTok{suppressWarnings}\NormalTok{(}\FunctionTok{split}\NormalTok{(df, f))}
\FunctionTok{str}\NormalTok{(samples, }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## List of 3
##  $ train   :'data.frame':    356 obs. of  14 variables:
##  $ validate:'data.frame':    75 obs. of  14 variables:
##  $ test    :'data.frame':    75 obs. of  14 variables:
\end{verbatim}

\hypertarget{eval-class}{%
\subsection{Evaluación de un método de clasificación}\label{eval-class}}

Para estudiar la eficiencia de un método de clasificación supervisada típicamente se obtienen las predicciones para el conjunto de datos de test y se genera una tabla de contingencia, denominada \emph{matriz de confusión}, con las predicciones frente a los valores reales.

En primer lugar consideraremos el caso de dos categorías.
La matriz de confusión será de la forma:

\begin{longtable}[]{@{}ccc@{}}
\toprule
Observado\textbackslash Predicción & Positivo & Negativo \\
\midrule
\endhead
Positivo & Verdaderos positivos (TP) & Falsos negativos (FN) \\
Negativo & Falsos positivos (FP) & Verdaderos negativos (TN) \\
\bottomrule
\end{longtable}

A partir de esta tabla se pueden obtener distintas medidas de la precisión de las predicciones (serían medidas globales de la calidad de la predicción de nuevas observaciones).
Por ejemplo, dos de las más utilizadas son la tasa de verdaderos positivos y la de verdaderos negativos (tasas de acierto en positivos y negativos), también denominadas \emph{sensibilidad} y \emph{especificidad}:

\begin{itemize}
\item
  Sensibilidad (\emph{sensitivity}, \emph{recall}, \emph{hit rate}, \emph{true positive rate}; TPR):
  \[TPR = \frac{TP}{P} = \frac{TP}{TP+FN}\]
\item
  Especificidad (\emph{specificity}, \emph{true negative rate}; TNR):
  \[TNR = \frac{TN}{TN+FP}\]
\end{itemize}

La precisión global o tasa de aciertos (\emph{accuracy}; ACC) sería:
\[ACC = \frac{TP + TN}{P + N} = \frac{TP+TN}{TP+TN+FP+FN}\]
Sin embargo hay que tener cuidado con esta medida cuando las clases no están balanceadas.
Otras medidas de la precisión global que tratan de evitar este problema son la \emph{precisión balanceada} (\emph{balanced accuracy}, BA):
\[BA = \frac{TPR + TNR}{2}\]
(media aritmética de TPR y TNR) o la \emph{puntuación F1} (\emph{F1 score}; media armónica de TPR y el valor predictivo positivo, PPV, descrito más adelante):
\[F_1 = \frac{2TP}{2TP+FP+FN}\]
Otra medida global es el coeficiente kappa de Cohen, que compara la tasa de aciertos con la obtenida en una clasificación al azar
(un valor de 1 indicaría máxima precisión y 0 que la precisión es igual a la que obtendríamos clasificando al azar; empleando la tasa de positivos, denominada \emph{prevalencia}, para predecir positivo).

También hay que tener cuidado las medidas que utilizan como estimación de la probabilidad de positivo (\emph{prevalencia}) la tasa de positivos en la muestra de test, como el valor (o índice) predictivo positivo (\emph{precision}, \emph{positive predictive value}; PPV):
\[PPV = \frac{TP}{TP+FP}\]
(que no debe ser confundido con la precisión global ACC) y el valor predictivo negativo negativo (NPV):
\[NPV = \frac{TN}{TN+FN},\]
si la muestra de test no refleja lo que ocurre en la población (por ejemplo si la clase de interés está sobrerrepresentada en la muestra).
En estos casos habrá que recalcularlos empleando estimaciones válidas de las probabilidades de la clases (por ejemplo, en estos casos, la función \texttt{caret::confusionMatrix()} permite establecer estimaciones válidas mediante el argumento \texttt{prevalence}).

Como ejemplo emplearemos los datos anteriores de valoraciones de viviendas y estatus de la población, considerando como respuesta una nueva variable \texttt{fmedv} que clasifica las valoraciones en ``Bajo'' o ``Alto'' dependiendo de si \texttt{medv\ \textgreater{}\ 25}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# data(Boston, package = "MASS")}
\NormalTok{datos }\OtherTok{\textless{}{-}}\NormalTok{ Boston}
\NormalTok{datos}\SpecialCharTok{$}\NormalTok{fmedv }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(datos}\SpecialCharTok{$}\NormalTok{medv }\SpecialCharTok{\textgreater{}} \DecValTok{25}\NormalTok{, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Bajo"}\NormalTok{, }\StringTok{"Alto"}\NormalTok{)) }\CommentTok{\# levels = c(\textquotesingle{}FALSE\textquotesingle{}, \textquotesingle{}TRUE\textquotesingle{})}
\CommentTok{\# En este caso las clases no están balanceadas}
\FunctionTok{table}\NormalTok{(datos}\SpecialCharTok{$}\NormalTok{fmedv)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Bajo Alto 
##  382  124
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{caret}\SpecialCharTok{::}\FunctionTok{featurePlot}\NormalTok{(datos}\SpecialCharTok{$}\NormalTok{lstat, datos}\SpecialCharTok{$}\NormalTok{fmedv, }\AttributeTok{plot =} \StringTok{"density"}\NormalTok{,}
            \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"lstat"}\NormalTok{, }\StringTok{"Density"}\NormalTok{), }\AttributeTok{auto.key =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{01-introduccion_files/figure-latex/featureplot-1} 

}

\caption{Distribución del estatus de la población dependiendo del nivel de valoración de las viviendas.}\label{fig:featureplot}
\end{figure}

El siguiente código realiza la partición de los datos y posteriormente ajusta un modelo de regresión logística en la muestra de entrenamiento considerando \texttt{lstat} como única variable explicativa (en la Sección \ref{reg-glm} se darán más detalles sobre este tipo de modelos):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Particionado de los datos}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{nobs }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(datos)}
\NormalTok{itrain }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(nobs, }\FloatTok{0.8} \SpecialCharTok{*}\NormalTok{ nobs)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ datos[itrain, ]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ datos[}\SpecialCharTok{{-}}\NormalTok{itrain, ]}
\CommentTok{\# Ajuste modelo}
\NormalTok{modelo }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(fmedv }\SpecialCharTok{\textasciitilde{}}\NormalTok{ lstat, }\AttributeTok{family =}\NormalTok{ binomial, }\AttributeTok{data =}\NormalTok{ train)}
\FunctionTok{summary}\NormalTok{(modelo)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = fmedv ~ lstat, family = binomial, data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.9749  -0.4161  -0.0890   0.3785   3.6450  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  3.74366    0.47901   7.815 5.48e-15 ***
## lstat       -0.54231    0.06134  -8.842  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 460.84  on 403  degrees of freedom
## Residual deviance: 243.34  on 402  degrees of freedom
## AIC: 247.34
## 
## Number of Fisher Scoring iterations: 7
\end{verbatim}

En este caso podemos obtener las estimaciones de la probabilidad de la segunda categoría empleando \texttt{predict()} con \texttt{type\ =\ "response"}, a partir de las cuales podemos establecer las predicciones como la categoría más probable:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{obs }\OtherTok{\textless{}{-}}\NormalTok{ test}\SpecialCharTok{$}\NormalTok{fmedv}
\NormalTok{p.est }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(modelo, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{, }\AttributeTok{newdata =}\NormalTok{ test)}
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(p.est }\SpecialCharTok{\textgreater{}} \FloatTok{0.5}\NormalTok{, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Bajo"}\NormalTok{, }\StringTok{"Alto"}\NormalTok{)) }\CommentTok{\# levels = c(\textquotesingle{}FALSE\textquotesingle{}, \textquotesingle{}TRUE\textquotesingle{})}
\end{Highlighting}
\end{Shaded}

Finalmente podemos obtener la matriz de confusión con el siguiente código:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tabla }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(obs, pred)}
\CommentTok{\# addmargins(tabla, FUN = list(Total = sum))}
\NormalTok{tabla}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       pred
## obs    Bajo Alto
##   Bajo   71   11
##   Alto    8   12
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Porcentajes respecto al total}
\FunctionTok{print}\NormalTok{(}\DecValTok{100}\SpecialCharTok{*}\FunctionTok{prop.table}\NormalTok{(tabla), }\AttributeTok{digits =} \DecValTok{2}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       pred
## obs    Bajo Alto
##   Bajo 69.6 10.8
##   Alto  7.8 11.8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Porcentajes (de aciertos y fallos) por categorías}
\FunctionTok{print}\NormalTok{(}\DecValTok{100}\SpecialCharTok{*}\FunctionTok{prop.table}\NormalTok{(tabla, }\DecValTok{1}\NormalTok{), }\AttributeTok{digits =} \DecValTok{3}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       pred
## obs    Bajo Alto
##   Bajo 86.6 13.4
##   Alto 40.0 60.0
\end{verbatim}

Alternativamente se podría emplear la función \texttt{confusionMatrix()} del paquete \texttt{caret} que permite obtener distintas medidas de la precisión:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{caret}\SpecialCharTok{::}\FunctionTok{confusionMatrix}\NormalTok{(pred, obs, }\AttributeTok{positive =} \StringTok{"Alto"}\NormalTok{, }\AttributeTok{mode =} \StringTok{"everything"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction Bajo Alto
##       Bajo   71    8
##       Alto   11   12
##                                          
##                Accuracy : 0.8137         
##                  95% CI : (0.7245, 0.884)
##     No Information Rate : 0.8039         
##     P-Value [Acc > NIR] : 0.4604         
##                                          
##                   Kappa : 0.4409         
##                                          
##  Mcnemar's Test P-Value : 0.6464         
##                                          
##             Sensitivity : 0.6000         
##             Specificity : 0.8659         
##          Pos Pred Value : 0.5217         
##          Neg Pred Value : 0.8987         
##               Precision : 0.5217         
##                  Recall : 0.6000         
##                      F1 : 0.5581         
##              Prevalence : 0.1961         
##          Detection Rate : 0.1176         
##    Detection Prevalence : 0.2255         
##       Balanced Accuracy : 0.7329         
##                                          
##        'Positive' Class : Alto           
## 
\end{verbatim}

Si el método de clasificación proporciona estimaciones de las probabilidades de las categorías, disponemos de más información en la clasificación que también podemos emplear en la evaluación del rendimiento.
Por ejemplo, se puede realizar un análisis descriptivo de las probabilidades estimadas y las categorías observadas en la muestra de test:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Imitamos la función caret::plotClassProbs()}
\FunctionTok{library}\NormalTok{(lattice) }
\FunctionTok{histogram}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ p.est }\SpecialCharTok{|}\NormalTok{ obs, }\AttributeTok{xlab =} \StringTok{"Probabilidad estimada"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{01-introduccion_files/figure-latex/classprob-1} 

}

\caption{Distribución de las probabilidades estimadas de valoración alta de la vivienda dependiendo de la categoría observada.}\label{fig:classprob}
\end{figure}

Para evaluar las estimaciones de las probabilidades se suele emplear la curva ROC (\emph{receiver operating characteristics}, característica operativa del receptor; diseñada inicialmente en el campo de la detección de señales).
Como ya se comentó, normalmente se emplea \(c = 0.5\) como punto de corte para clasificar en la categoría de interés (\emph{regla de Bayes}), aunque se podrían considerar otros valores (por ejemplo para mejorar la clasificación en una de las categorías, a costa de empeorar la precisión global).
En la curva ROC se representa la sensibilidad (TPR) frente a la tasa de falsos negativos (FNR = 1 - TNR = 1 - especificidad) para distintos valores de corte.
Para ello se puede emplear el paquete \texttt{pROC}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(pROC)}
\NormalTok{roc\_glm }\OtherTok{\textless{}{-}} \FunctionTok{roc}\NormalTok{(}\AttributeTok{response =}\NormalTok{ obs, }\AttributeTok{predictor =}\NormalTok{ p.est)}
\CommentTok{\# View((as.data.frame(roc\_glm[2:4])))}
\FunctionTok{plot}\NormalTok{(roc\_glm)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{01-introduccion_files/figure-latex/ROC-curve-1} 

}

\caption{Curva ROC correspondiente al modelo de regresión logística.}\label{fig:ROC-curve}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot(roc\_glm, legacy.axes = TRUE, print.thres = 0.5)}
\end{Highlighting}
\end{Shaded}

Lo ideal sería que la curva se aproximase a la esquina superior izquierda (máxima sensibilidad y especificidad).
La recta diagonal se correspondería con un clasificador aleatorio.
Una medida global del rendimiento del clasificador es el área bajo la curva ROC (AUC; equivalente al estadístico U de Mann-Whitney o al índice de Gini).
Un clasificador perfecto tendría un valor de 1 y 0.5 uno aleatorio.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# roc\_glm$auc}
\NormalTok{roc\_glm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## roc.default(response = obs, predictor = p.est)
## 
## Data: p.est in 82 controls (obs Bajo) < 20 cases (obs Alto).
## Area under the curve: 0.8427
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ci.auc}\NormalTok{(roc\_glm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 95% CI: 0.7428-0.9426 (DeLong)
\end{verbatim}

Como comentario adicional, aunque se puede modificar el punto de corte para mejorar la clasificación en la categoría de interés (de hecho, algunas herramientas como \texttt{h2o} lo modifican por defecto; en este caso concreto para maximizar \(F_1\) en la muestra de entrenamiento), muchos métodos de clasificación (como los basados en árboles descritos en el Capítulo 2) admiten como opción una matriz de pérdidas que se tendrá en cuenta para medir la eficiencia durante el aprendizaje y normalmente esta sería la aproximación recomendada.

En el caso de más de dos categorías podríamos generar una matriz de confusión de forma análoga,
aunque en este caso en principio solo podríamos calcular medidas globales de la precisión como la tasa de aciertos o el coeficiente kappa de Cohen.
Podríamos obtener también medidas por clase, como la sensibilidad y la especificidad, siguiendo la estrategia ``uno contra todos'' descrita en la Sección \ref{notacion}.
Esta aproximación es la que sigue la función \texttt{confusionMatrix()} del paquete \texttt{caret} (devuelve las medidas comparando cada categoría con las restantes en el componente \texttt{\$byClass}).

Como ejemplo ilustrativo consideraremos el conocido conjunto de datos \texttt{iris} (\protect\hyperlink{ref-fisher1936use}{Fisher, 1936}) en el que el objetivo es clasificar flores de lirio en tres especies (\texttt{Species}) a partir del largo y ancho de sépalos y pétalos, aunque en este caso emplearemos un clasificador aleatorio.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(iris)}
\CommentTok{\# Partición de los datos}
\NormalTok{datos }\OtherTok{\textless{}{-}}\NormalTok{ iris}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{nobs }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(datos)}
\NormalTok{itrain }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(nobs, }\FloatTok{0.8} \SpecialCharTok{*}\NormalTok{ nobs)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ datos[itrain, ]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ datos[}\SpecialCharTok{{-}}\NormalTok{itrain, ]}
\CommentTok{\# Entrenamiento }
\NormalTok{prevalences }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(train}\SpecialCharTok{$}\NormalTok{Species)}\SpecialCharTok{/}\FunctionTok{nrow}\NormalTok{(train)}
\NormalTok{prevalences}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##     setosa versicolor  virginica 
##  0.3250000  0.3166667  0.3583333
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Calculo de las predicciones}
\NormalTok{levels }\OtherTok{\textless{}{-}} \FunctionTok{names}\NormalTok{(prevalences) }\CommentTok{\# levels(train$Species)}
\NormalTok{f }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(levels, }\AttributeTok{levels =}\NormalTok{ levels) }\CommentTok{\# factor(levels) valdría en este caso al estar por orden alfabético}
\NormalTok{pred.rand }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(f, }\FunctionTok{nrow}\NormalTok{(test), }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{prob =}\NormalTok{ prevalences)}
\CommentTok{\# Evaluación}
\NormalTok{caret}\SpecialCharTok{::}\FunctionTok{confusionMatrix}\NormalTok{(pred.rand, test}\SpecialCharTok{$}\NormalTok{Species)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa          3          3         1
##   versicolor      4          2         5
##   virginica       4          7         1
## 
## Overall Statistics
##                                           
##                Accuracy : 0.2             
##                  95% CI : (0.0771, 0.3857)
##     No Information Rate : 0.4             
##     P-Value [Acc > NIR] : 0.9943          
##                                           
##                   Kappa : -0.1862         
##                                           
##  Mcnemar's Test P-Value : 0.5171          
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 0.2727           0.16667          0.14286
## Specificity                 0.7895           0.50000          0.52174
## Pos Pred Value              0.4286           0.18182          0.08333
## Neg Pred Value              0.6522           0.47368          0.66667
## Prevalence                  0.3667           0.40000          0.23333
## Detection Rate              0.1000           0.06667          0.03333
## Detection Prevalence        0.2333           0.36667          0.40000
## Balanced Accuracy           0.5311           0.33333          0.33230
\end{verbatim}

\hypertarget{dimen-curse}{%
\section{La maldición de la dimensionalidad}\label{dimen-curse}}

Podríamos pensar que al aumentar el número de variables explicativas se mejora la capacidad predictiva de los modelos. Lo cual, en general, sería cierto si realmente los predictores fuesen de utilidad para explicar la respuesta.
Sin embargo, al aumentar el número de dimensiones se pueden agravar notablemente muchos de los problemas que ya pueden aparecer en dimensiones menores, esto es lo que se conoce como la \emph{maldición de la dimensionalidad} (\emph{curse of dimensionality}, \protect\hyperlink{ref-bellman1961adaptive}{Bellman, 1961}).

Uno de estos problemas es el denominado \emph{efecto frontera} que ya puede aparecer en una dimensión, especialmente al trabajar con modelos flexibles (como ajustes polinómicos con grados altos o los métodos locales que trataremos en el Capítulo 6).
La idea es que en la ``frontera'' del rango de valores de una variable explicativa vamos a disponer de pocos datos y los errores de predicción van a tener gran variabilidad (se están haciendo extrapolaciones de los datos, más que interpolaciones, y van a ser menos fiables).

Como ejemplo consideraremos un problema de regresión simple, con un conjunto de datos simulados (del proceso ya considerado en la Sección \ref{bias-variance}) con 100 observaciones (que ya podríamos considerar que no es muy pequeño).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simulación datos}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{length =}\NormalTok{ n)}
\NormalTok{mu }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{+} \DecValTok{4}\SpecialCharTok{*}\NormalTok{(}\DecValTok{5}\SpecialCharTok{*}\NormalTok{x }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{(}\DecValTok{4}\SpecialCharTok{*}\NormalTok{x }\SpecialCharTok{{-}} \DecValTok{2}\NormalTok{)}\SpecialCharTok{*}\NormalTok{(x }\SpecialCharTok{{-}} \FloatTok{0.8}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \CommentTok{\# grado 4}
\NormalTok{sd }\OtherTok{\textless{}{-}} \FloatTok{0.5}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ mu }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, sd)}
\NormalTok{datos }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y)}
\FunctionTok{plot}\NormalTok{(x, y) }
\FunctionTok{lines}\NormalTok{(x, mu, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{col =} \StringTok{"lightgray"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{01-introduccion_files/figure-latex/simdat100-1} 

}

\caption{Muestra simulada y tendencia teórica.}\label{fig:simdat100}
\end{figure}

Cuando el número de datos es más o menos grande podríamos pensar en predecir la respuesta a partir de lo que ocurre en las observaciones cercanas a la posición de predicción, esta es la idea de los métodos locales (Capítulo \ref{modelos-lineales}).
Uno de los métodos de este tipo más conocidos es el de los \emph{k-vecinos más cercanos} (\emph{k-nearest neighbors}; KNN).
Se trata de un método muy simple, pero que puede ser muy efectivo, que se basa en la idea de que localmente la media condicional (la predicción óptima) es constante.
Concretamente, dados un entero \(k\) (hiperparámetro) y un conjunto de entrenamiento \(\mathcal{T}\), para obtener la predicción correspondiente a un vector de valores de las variables explicativas \(\mathbf{x}\), el método de regresión\footnote{En el caso de clasificación se considerarían las variables indicadoras de las categorías y se obtendrían las frecuencias relativas en el vecindario como estimaciones de las probabilidades de las clases.} KNN promedia las observaciones en un vecindario \(\mathcal{N}_k(\mathbf{x}, \mathcal{T})\) formado por las \(k\) observaciones más cercanas a \(\mathbf{x}\):
\[\hat{Y}(\mathbf{x}) = \hat{m}(\mathbf{x}) = \frac{1}{k} \sum_{i \in \mathcal{N}_k(\mathbf{x}, \mathcal{T})} Y_i\]
(sería necesario definir una distancia, normalmente la distancia euclídea de los predictores estandarizados).

Este método está implementado en numerosos paquetes, por ejemplo en la función \texttt{knnreg()} del paquete \texttt{caret}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}

\CommentTok{\# Ajuste de los modelos}
\NormalTok{fit1 }\OtherTok{\textless{}{-}} \FunctionTok{knnreg}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, }\AttributeTok{data =}\NormalTok{ datos, }\AttributeTok{k =} \DecValTok{5}\NormalTok{) }\CommentTok{\# 5 observaciones más cercanas (5\% de los datos)}
\NormalTok{fit2 }\OtherTok{\textless{}{-}} \FunctionTok{knnreg}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, }\AttributeTok{data =}\NormalTok{ datos, }\AttributeTok{k =} \DecValTok{10}\NormalTok{)}
\NormalTok{fit3 }\OtherTok{\textless{}{-}} \FunctionTok{knnreg}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, }\AttributeTok{data =}\NormalTok{ datos, }\AttributeTok{k =} \DecValTok{20}\NormalTok{)}

\FunctionTok{plot}\NormalTok{(x, y) }
\FunctionTok{lines}\NormalTok{(x, mu, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{col =} \StringTok{"lightgray"}\NormalTok{)}
\NormalTok{newdata }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x)}
\FunctionTok{lines}\NormalTok{(x, }\FunctionTok{predict}\NormalTok{(fit1, newdata), }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(x, }\FunctionTok{predict}\NormalTok{(fit2, newdata), }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(x, }\FunctionTok{predict}\NormalTok{(fit3, newdata), }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }\AttributeTok{legend =} \FunctionTok{c}\NormalTok{(}\StringTok{"Verdadero"}\NormalTok{, }\StringTok{"5{-}NN"}\NormalTok{, }\StringTok{"10{-}NN"}\NormalTok{, }\StringTok{"20{-}NN"}\NormalTok{), }
       \AttributeTok{lty =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"lightgray"}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{01-introduccion_files/figure-latex/knnfit2-1} 

}

\caption{Predicciones con el método KNN y distintos vecindarios}\label{fig:knnfit2}
\end{figure}

A medida que aumenta \(k\) disminuye la complejidad del modelo y se observa un incremento del efecto frontera.
Habría que seleccionar un valor óptimo de \(k\) (buscando un equilibro entre sesgo y varianza, como se mostró en la Sección \ref{bias-variance} y se ilustrará en la última sección de este capítulo empleando este método con el paquete \texttt{caret}), que dependerá de la tendencia teórica y del número de datos.
En este caso, para \(k=5\), podríamos pensar que el efecto frontera aparece en el 10\% más externo del rango de la variable explicativa (con un número mayor de datos podría bajar al 1\%).
Al aumentar el número de variables explicativas, considerando que el 10\% más externo del rango de cada una de ellas constituye la ``frontera'' de los datos, tendríamos que la proporción de frontera sería \(1-0.9^d\), siendo \(d\) el número de dimensiones.
Lo que se traduce que con \(d = 10\) el 65\% del espacio predictivo sería frontera y en torno al 88\% para \(d=20\), es decir, al aumentar el número de dimensiones el problema del efecto frontera será generalizado.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{curve}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.9}\SpecialCharTok{\^{}}\NormalTok{x, }\DecValTok{0}\NormalTok{, }\DecValTok{200}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}Proporción de frontera\textquotesingle{}}\NormalTok{, }\AttributeTok{xlab =} \StringTok{\textquotesingle{}Número de dimensiones\textquotesingle{}}\NormalTok{)}
\FunctionTok{curve}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.95}\SpecialCharTok{\^{}}\NormalTok{x, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{, }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{curve}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.99}\SpecialCharTok{\^{}}\NormalTok{x, }\AttributeTok{lty =} \DecValTok{3}\NormalTok{, }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{col =} \StringTok{"lightgray"}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"bottomright"}\NormalTok{, }\AttributeTok{title =} \StringTok{"Rango en cada dimensión"}\NormalTok{, }\AttributeTok{legend =} \FunctionTok{c}\NormalTok{(}\StringTok{"10\%"}\NormalTok{ , }\StringTok{"5\%"}\NormalTok{, }\StringTok{"1\%"}\NormalTok{), }
       \AttributeTok{lty =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{01-introduccion_files/figure-latex/pfrontera-1} 

}

\caption{Proporción de "frontera" dependiendo del número de dimensiones y del porcentaje de valores considerados extremos en cada dimensión.}\label{fig:pfrontera}
\end{figure}

Desde otro punto de vista, suponiendo que los predictores se distribuyen de forma uniforme, la densidad de las observaciones es proporcional a \(n^{1/d}\), siendo \(n\) el tamaño muestral.
Por lo que si consideramos que una muestra de tamaño \(n=100\) es suficientemente densa en una dimensión, para obtener la misma densidad muestral en 10 dimensiones tendríamos que disponer de un tamaño muestral de \(n = 100^{10} = 10^{20}\).
Por tanto, cuando el número de dimensiones es grande no va a haber muchas observaciones en el entorno de la posición de predicción y puede haber serios problemas de sobreajuste si se pretende emplear un modelo demasiado flexible (por ejemplo KNN con \(k\) pequeño). Hay que tener en cuenta que, en general, fijado el tamaño muestral, la flexibilidad de los modelos aumenta al aumentar el número de dimensiones del espacio predictivo.

Para concluir, otro de los problemas que se agravan notablemente al aumentar el número de dimensiones es el de colinealidad (o concurvidad) que puede producir que muchos métodos (como los modelos lineales o las redes neuronales) sean muy poco eficientes o inestables (llegando incluso a que no se puedan aplicar), además de que complica notablemente la interpretación de cualquier método.
Esto está relacionado también con la dificultad para determinar que variables son de interés para predecir la respuesta (i.e.~no son ruido).
Debido a la aleatoriedad, predictores que realmente no están relacionados con la respuesta pueden ser tenidos en cuenta por el modelo con mayor facilidad (KNN con las opciones habituales tiene en cuenta todos los predictores con el mismo peso).
Lo que resulta claro es que si se agrega ruido se producirá un incremento en el error de predicción.
Incluso si las variables añadidas resultan de interés, si el número de observaciones es pequeño en comparación, el incremento en la variabilidad de las predicciones puede no compensar la disminución del sesgo de predicción.

Como conclusión, en el caso multidimensional habrá que tratar de emplear métodos que minimicen estos problemas.

\hypertarget{analisis-modelos}{%
\section{Análisis e interpretación de los modelos}\label{analisis-modelos}}

El análisis e interpretación de modelos es un campo muy activo en AE/ML, para el que recientemente se ha acuñado el término de \emph{interpretable machine learning} (IML).
A continuación se resumen brevemente algunas de las principales ideas, para más detalles ver por ejemplo (\protect\hyperlink{ref-molnar2020interpretable}{Molnar, 2020}).

Como ya se comentó, a medida que aumenta la complejidad de los modelos generalmente disminuye su interpretabilidad, por lo que normalmente interesa encontrar el modelo más simple posible que resulte de utilidad para los objetivos propuestos.
Aunque el principal objetivo sea la predicción, una vez obtenido el modelo final suele interesar medir la importancia de cada predictor en el modelo y si es posible como influyen en la predicción de la respuesta, es decir, estudiar el efecto de las variables explicativas.
Esto puede presentar serias dificultades especialmente en modelos complejos en los que hay interacciones entre los predictores (el efecto de una variable explicativa depende de los valores de otras).

La mayoría de los métodos de aprendizaje supervisado permiten obtener medidas de la importancia de las variables explicativas en la predicción (ver p.e. la \href{https://topepo.github.io/caret/variable-importance.html}{ayuda} de la función \texttt{caret::varImp()}; algunos, como los basados en árboles, incluso de las no incluidas en el modelo final).
Muchos de los métodos de clasificación, en lugar de proporcionar medidas globales, calculan medidas para cada categoría.
Alternativamente también se pueden obtener medidas de la importancia de las variables mediante procedimientos generales (en el sentido de que se pueden aplicar a cualquier modelo), pero suelen requerir de mucho más tiempo de computación (ver p.e. \href{https://christophm.github.io/interpretable-ml-book}{Molnar, 2020}, \href{https://christophm.github.io/interpretable-ml-book/agnostic.htm}{Capítulo 5}).

En algunos de los métodos se modela explícitamente los efectos de los distintos predictores y estos se pueden analizar con (mas o menos) facilidad.
Hay que tener en cuenta que, al margen de las interacciones, la colinealidad/concurvidad dificulta notablemente el estudio de los efectos de las variables explicativas.
Otros métodos son más del tipo ``caja negra'' (\emph{black box}) y precisan de aproximaciones más generales, como los gráficos PDP (\emph{Partial Dependence Plots}; \protect\hyperlink{ref-friedman2008predictive}{Friedman y Popescu} (\protect\hyperlink{ref-friedman2008predictive}{2008}); ver también \protect\hyperlink{ref-greenwell2020dblp}{Greenwell} (\protect\hyperlink{ref-greenwell2020dblp}{2017})) o las curvas ICE \emph{Individual Conditional Expectation}, ver \protect\hyperlink{ref-goldstein2015peeking}{Goldstein et~al.} (\protect\hyperlink{ref-goldstein2015peeking}{2015}).
Estos métodos tratan de estimar el efecto marginal de las variables explicativas.
En ese sentido son similares a los gráficos parciales de residuos (habitualmente empleados en los modelos lineales o aditivos; ver p.e. las funciones \texttt{termplot()}, \texttt{car::crPlots()} o \texttt{car::avPlots()}, Sección 6.4, y \texttt{mgcv::plot.gam()}, Sección 7.3), que muestran la variación en la predicción a medida que varía una variable explicativa manteniendo constantes el resto (algo que tiene sentido si asumimos que los predictores son independientes), pero en este caso se admite que el resto de predictores también pueden variar.

En el caso de los gráficos PDP se tiene en cuenta el efecto marginal de los demás predictores del modelo.
Suponiendo que estamos interesados en un conjunto \(\mathbf X^S\) de predictores, de forma que \(\mathbf X = [\mathbf X^S, \mathbf X^C]\) y \(f_{\mathbf X^C}(\mathbf x^C) = \int f(\mathbf x) d\mathbf x^S\) es la densidad marginal de \(\mathbf X^C = \mathbf X \setminus \mathbf X^S\), se trata de aproximar:
\[\hat Y_S(\mathbf x^S) = E_{\mathbf X^C}\left[\hat{Y}(\mathbf x^S,\mathbf X^C)\right]=\int\hat{Y}(\mathbf x^S,\mathbf x^C)f_{\mathbf X^C}(\mathbf x^C)d\mathbf x^C\]
mediante:
\[\hat{y}_{\mathbf x^S}(\mathbf x^S)=\frac{1}{n}\sum_{i=1}^n\hat{y}(\mathbf x^S, \mathbf x^C_i)\]
donde \(n\) en el tamaño de la muestra de entrenamiento y \(\mathbf x^C_i\) son los valores observados de las variables explicativas en las que no estamos interesados.
La principal diferencia con los gráficos ICE es que, en lugar de mostrar una única curva promedio de la respuesta, estos muestran una curva para cada observación (para más detalles ver las referencias anteriores).
En la Sección \ref{ejemplo-clasif-rf} se incluyen algunos ejemplos.

En problemas de clasificación también se están empleando la teoría de juegos cooperativos y las técnicas de optimización de Investigación Operativa para evaluar la importancia de las variables predictoras y determinar las más influyentes.
Por citar algunos, \protect\hyperlink{ref-strumbelj2010efficient}{Strumbelj y Kononenko} (\protect\hyperlink{ref-strumbelj2010efficient}{2010}) propusieron un procedimiento general basado en el valor de Shapley de juegos cooperativos (ver p.e. \texttt{iml::Shapley()}), y en \protect\hyperlink{ref-agor2019feature}{Agor y Özaltın} (\protect\hyperlink{ref-agor2019feature}{2019}) se propone el uso de algoritmos genéticos para determinar los predictores más influyentes.

Paquetes y funciones de R:

\begin{itemize}
\item
  \href{https://bgreenwell.github.io/pdp/index.html}{\texttt{pdp}}: Partial Dependence Plots

  (también implementa curvas ICE y es compatible con \texttt{caret})
\item
  \href{https://christophm.github.io/iml}{\texttt{iml}}: Interpretable Machine Learning
\item
  \href{https://modeloriented.github.io/DALEX}{\texttt{DALEX}}: moDel Agnostic Language for Exploration and eXplanation
\item
  \href{https://lime.data-imaginist.com}{\texttt{lime}}: Local Interpretable Model-Agnostic Explanations
\item
  \href{https://koalaverse.github.io/vip/index.html}{\texttt{vip}}: Variable Importance Plots
\item
  \href{https://github.com/AlanInglis/vivid}{\texttt{vivid}}: Variable Importance and Variable Interaction Displays
\item
  \href{https://CRAN.R-project.org/package=ICEbox}{\texttt{ICEbox}} ICEbox: Individual Conditional Expectation Plot Toolbox.
\item
  \href{http://www.milbo.users.sonic.net/}{\texttt{plotmo}}: Plot a Model's Residuals, Response, and Partial Dependence Plots.
\item
  \href{https://modeloriented.github.io/randomForestExplainer}{\texttt{randomForestExplainer}}: Explaining and Visualizing Random Forests in Terms of Variable Importance.
\end{itemize}

En este caso también puede ser de utilidad \texttt{caret::varImp()}, \texttt{h2o::h2o.partialPplot()}\ldots{}

En los siguientes capítulos se mostrarán ejemplos empleando algunas de estas herramientas.

\hypertarget{caret}{%
\section{\texorpdfstring{Introducción al paquete \texttt{caret}}{Introducción al paquete caret}}\label{caret}}

Como ya se comentó en la Sección \ref{metodos-pkgs}, el paquete \texttt{caret} {[}\emph{Classification And REgression Training}; \protect\hyperlink{ref-kuhn2008building}{Kuhn} (\protect\hyperlink{ref-kuhn2008building}{2008}){]} proporciona una interfaz unificada que simplifica el proceso de modelado empleando la mayoría de los métodos de AE implementados en R (actualmente admite 239 métodos; ver el \href{https://topepo.github.io/caret/available-models.html}{Capítulo 6} del \href{https://topepo.github.io/caret}{manual} de este paquete).
Además de proporcionar rutinas para los principales pasos del proceso, incluye también numerosas funciones auxiliares que permitirían implementar nuevos procedimientos.

En esta sección se describirán de forma esquemática las principales herramientas disponibles en este paquete, para más detalles se recomendaría consultar el \href{https://topepo.github.io/caret}{manual del paquete caret}.
También está disponible una pequeña introducción en la vignette del paquete: \href{https://cran.r-project.org/web/packages/caret/vignettes/caret.html}{A Short Introduction to the caret Package} y una ``chuleta'': \href{https://raw.githubusercontent.com/rstudio/cheatsheets/master/caret.pdf}{Caret Cheat Sheet}.

\hypertarget{muxe9todos-implementados}{%
\subsection{Métodos implementados}\label{muxe9todos-implementados}}

La función principal es \texttt{train()} (descrita en la siguiente subsección), que incluye un parámetro \texttt{method} que permite establecer el modelo mediante una cadena de texto.
Podemos obtener información sobre los modelos disponibles con las funciones \texttt{getModelInfo()} y \texttt{modelLookup()} (puede haber varias implementaciones del mismo método con distintas configuraciones de hiperparámetros; también se pueden definir nuevos modelos, ver el \href{https://topepo.github.io/caret/using-your-own-model-in-train.html}{Capítulo 13} del \href{https://topepo.github.io/caret}{manual}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}
\FunctionTok{str}\NormalTok{(}\FunctionTok{names}\NormalTok{(}\FunctionTok{getModelInfo}\NormalTok{())) }\CommentTok{\# Listado de todos los métodos disponibles}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  chr [1:239] "ada" "AdaBag" "AdaBoost.M1" "adaboost" "amdai" "ANFIS" ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# names(getModelInfo("knn", regex = TRUE)) \# Por defecto devuelve coincidencias parciales}
\FunctionTok{modelLookup}\NormalTok{(}\StringTok{"knn"}\NormalTok{)  }\CommentTok{\# Información sobre hiperparámetros}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   model parameter      label forReg forClass probModel
## 1   knn         k #Neighbors   TRUE     TRUE      TRUE
\end{verbatim}

En la versión online del libro se incluye una \href{https://rubenfcasal.github.io/aprendizaje_estadistico/caret.html}{tabla dinámica} con los métodos actualmente disponibles.

\hypertarget{herramientas}{%
\subsection{Herramientas}\label{herramientas}}

Este paquete permite, entre otras cosas:

\begin{itemize}
\item
  Partición de los datos

  \begin{itemize}
  \item
    \texttt{createDataPartition(y,\ p\ =\ 0.5,\ list\ =\ TRUE,\ ...)}: crea particiones balanceadas de los datos.

    \begin{itemize}
    \item
      En el caso de que la respuesta \texttt{y} sea categórica realiza el muestreo en cada clase. Para respuestas numéricas emplea cuantiles (definidos por el argumento \texttt{groups\ =\ min(5,\ length(y))}).
    \item
      \texttt{p}: proporción de datos en la muestra de entrenamiento.
    \item
      \texttt{list}: lógico; determina si el resultado es una lista con las muestras o un vector (o matriz) de índices
    \end{itemize}
  \item
    Funciones auxiliares: \texttt{createFolds()}, \texttt{createMultiFolds()}, \texttt{groupKFold()}, \texttt{createResample()}, \texttt{createTimeSlices()}
  \end{itemize}
\item
  Análisis descriptivo: \texttt{featurePlot()}
\item
  Preprocesado de los datos:

  \begin{itemize}
  \item
    La función principal es \texttt{preProcess(x,\ method\ =\ c("center",\ "scale"),\ ...)}, aunque se puede integrar en el entrenamiento (función \texttt{train()}) para estimar los parámetros de las transformaciones a partir de la muestra de entrenamiento y posteriormente aplicarlas automáticamente al hacer nuevas predicciones (p.e. en la muestra de test).
  \item
    El parámetro \texttt{method} permite establecer una lista de procesados:

    \begin{itemize}
    \item
      Imputación: \texttt{"knnImpute"}, \texttt{"bagImpute"} o \texttt{"medianImpute"}
    \item
      Creación y transformación de variables explicativas: \texttt{"center"}, \texttt{"scale"}, \texttt{"range"}, \texttt{"BoxCox"}, \texttt{"YeoJohnson"}, \texttt{"expoTrans"}, \texttt{"spatialSign"}

\begin{verbatim}
Funciones auxiliares: `dummyVars()`...
\end{verbatim}
    \item
      Selección de predictores y extracción de componentes: \texttt{"corr"}, \texttt{"nzv"}, \texttt{"zv"}, \texttt{"conditionalX"}, \texttt{"pca"}, \texttt{"ica"}

\begin{verbatim}
Funciones auxiliares: `rfe()`...
\end{verbatim}
    \end{itemize}
  \end{itemize}
\item
  Entrenamiento y selección de los hiperparámetros del modelo:

  \begin{itemize}
  \item
    La función principal es \texttt{train(formula,\ data,\ method\ =\ "rf",\ trControl\ =\ trainControl(),\ tuneGrid\ =\ NULL,\ tuneLength\ =\ 3,\ ...)}

    \begin{itemize}
    \item
      \texttt{trControl}: permite establecer el método de remuestreo para la evaluación de los hiperparámetros y el método para seleccionar el óptimo, incluyendo las medidas de precisión. Por ejemplo \texttt{trControl\ =\ trainControl(method\ =\ "cv",\ number\ =\ 10,\ selectionFunction\ =\ "oneSE")}.

      Los métodos disponibles son: \texttt{"boot"}, \texttt{"boot632"}, \texttt{"optimism\_boot"}, \texttt{"boot\_all"}, \texttt{"cv"}, \texttt{"repeatedcv"}, \texttt{"LOOCV"}, \texttt{"LGOCV"}, \texttt{"timeslice"}, \texttt{"adaptive\_cv"}, \texttt{"adaptive\_boot"} o \texttt{"adaptive\_LGOCV"}
    \item
      \texttt{tuneLength} y \texttt{tuneGrid}: permite establecer cuantos hiperparámetros serán evaluados (por defecto 3) o una rejilla con las combinaciones de hiperparámetros.
    \item
      \texttt{...} permite establecer opciones específicas de los métodos.
    \end{itemize}
  \item
    También admite matrices \texttt{x}, \texttt{y} en lugar de fórmulas (o \emph{recetas}: \texttt{recipe()}).
  \item
    Si se imputan datos en el preprocesado será necesario establecer \texttt{na.action\ =\ na.pass}.
  \end{itemize}
\item
  Predicción: Una de las ventajas es que incorpora un único método \texttt{predict()} para objetos de tipo \texttt{train} con dos únicas opciones\footnote{En lugar de la variedad de opciones que emplean los distintos paquetes (e.g.: \texttt{type\ =\ "response"}, \texttt{"class"}, \texttt{"posterior"}, \texttt{"probability"}\ldots{} ).} \texttt{type\ =\ c("raw",\ "prob")}, la primera para obtener predicciones de la respuesta y la segunda para obtener estimaciones de las probabilidades (en los métodos de clasificación que lo admitan).

  Además, si se incluyo un preprocesado en el entrenamiento, se emplearán las mismas transformaciones en un nuevo conjunto de datos \texttt{newdata}.
\item
  Evaluación de los modelos

  \begin{itemize}
  \item
    \texttt{postResample(pred,\ obs,\ ...)}: regresión
  \item
    \texttt{confusionMatrix(pred,\ obs,\ ...)}: clasificación

    \begin{itemize}
    \tightlist
    \item
      Funciones auxiliares: \texttt{twoClassSummary()}, \texttt{prSummary()}\ldots{}
    \end{itemize}
  \end{itemize}
\item
  Analisis de la importancia de los predictores:

  \begin{itemize}
  \tightlist
  \item
    \texttt{varImp()}: interfaz a las medidas específicas de los métodos de aprendizaje supervisado (\href{https://topepo.github.io/caret/variable-importance.html\#model-specific-metrics}{Sección 15.1} del manual) o medidas genéricas (\href{https://topepo.github.io/caret/variable-importance.html\#model-independent-metrics}{Sección 15.2}).
  \end{itemize}
\end{itemize}

\hypertarget{ejemplo}{%
\subsection{Ejemplo}\label{ejemplo}}

Como ejemplo consideraremos el problema de regresión anterior empleando KNN en caret:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(Boston, }\AttributeTok{package =} \StringTok{"MASS"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(caret)}
\end{Highlighting}
\end{Shaded}

Particionamos los datos:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{itrain }\OtherTok{\textless{}{-}} \FunctionTok{createDataPartition}\NormalTok{(Boston}\SpecialCharTok{$}\NormalTok{medv, }\AttributeTok{p =} \FloatTok{0.8}\NormalTok{, }\AttributeTok{list =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ Boston[itrain, ]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ Boston[}\SpecialCharTok{{-}}\NormalTok{itrain, ]}
\end{Highlighting}
\end{Shaded}

Entrenamiento, con preprocesado de los datos (se almacenan las transformaciones para volver a aplicarlas en la predicción con nuevos datos) y empleando validación cruzada con 10 grupos para la selección de hiperparámetros:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{knn }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(medv }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train,}
             \AttributeTok{method =} \StringTok{"knn"}\NormalTok{,}
             \AttributeTok{preProc =} \FunctionTok{c}\NormalTok{(}\StringTok{"center"}\NormalTok{, }\StringTok{"scale"}\NormalTok{),}
             \AttributeTok{tuneGrid =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{k =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{),}
             \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{number =} \DecValTok{10}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(knn) }\CommentTok{\# Alternativamente: ggplot(knn, highlight = TRUE)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{01-introduccion_files/figure-latex/unnamed-chunk-20-1} 

}

\caption{Raíz del error cuadrático medio de validación cruzada dependiendo del valor del hiperparámetro.}\label{fig:unnamed-chunk-20}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knn}\SpecialCharTok{$}\NormalTok{bestTune}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   k
## 3 3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knn}\SpecialCharTok{$}\NormalTok{finalModel}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 3-nearest neighbor regression model
\end{verbatim}

Importancia de las variables (interpretación del modelo final)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{varImp}\NormalTok{(knn)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## loess r-squared variable importance
## 
##         Overall
## lstat    100.00
## rm        88.26
## indus     36.29
## ptratio   33.27
## tax       30.58
## crim      28.33
## nox       23.44
## black     21.29
## age       20.47
## rad       17.16
## zn        15.11
## dis       14.35
## chas       0.00
\end{verbatim}

Evaluación del modelo final en la muestra de test:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{postResample}\NormalTok{(}\FunctionTok{predict}\NormalTok{(knn, }\AttributeTok{newdata =}\NormalTok{ test), test}\SpecialCharTok{$}\NormalTok{medv)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     RMSE Rsquared      MAE 
## 4.960971 0.733945 2.724242
\end{verbatim}

\hypertarget{desarrollo-futuro}{%
\subsection{Desarrollo futuro}\label{desarrollo-futuro}}

Como comenta el autor del paquete \texttt{caret}:

\begin{quote}
``While I'm still supporting caret, the majority of my development effort has gone into the tidyverse modeling packages (called tidymodels)''.

--- Max Kuhn (actualmente ingeniero de software en RStudio).
\end{quote}

este paquete ha dejado de desarrollarse de forma activa, aunque podemos considerar que la alternativa \href{https://www.tidymodels.org}{\texttt{tidymodels}} todavía está en una fase inicial de desarrollo.
Este es uno de los motivos por los que se ha optado por mantener el uso de \texttt{caret} en este libro, aunque la intención es incluir apéndices adicionales en próximas versiones ilustrando el uso de otras herramientas (como \texttt{tidymodels}, \protect\hyperlink{ref-kuhn2020tidymodels}{Kuhn y Wickham, 2020}; o incluso \texttt{mlr3}, \protect\hyperlink{ref-becker2021mlr3}{Becker et~al., 2021}).

\hypertarget{trees}{%
\chapter{Árboles de decisión}\label{trees}}

Los \emph{árboles de decisión} son uno de los métodos más simples y fáciles de interpretar para realizar predicciones en problemas de clasificación y de regresión.
Se desarrollan a partir de los años 70 del siglo pasado como una alternativa versátil a los métodos clásicos de la estadística, fuertemente basados en las hipótesis de linealidad y de normalidad, y enseguida se convierten en una técnica básica del aprendizaje automático.
Aunque su calidad predictiva es mediocre (especialmente en el caso de regresión), constituyen la base de otros métodos altamente competitivos (bagging, bosques aleatorios, boosting) en los que se combinan múltiples árboles para mejorar la predicción, pagando el precio, eso sí, de hacer más difícil la interpretación del modelo resultante.

La idea de este método consiste en la segmentación (partición) del \emph{espacio predictor} (es decir, del conjunto de posibles valores de las variables predictoras) en regiones tan simples que el proceso se pueda representar mediante un árbol binario.
Se parte de un nodo inicial que representa a toda la muestra (se utiliza la muestra de entrenamiento), del que salen dos ramas que dividen la muestra en dos subconjuntos, cada uno representado por un nuevo nodo.
Como se muestra en la Figura \ref{fig:arbol} este proceso se repite un número finito de veces hasta obtener las hojas del árbol, es decir, los nodos terminales, que son los que se utilizan para realizar la predicción.
Una vez construido el árbol, la predicción se realizará en cada nodo terminal utilizando, típicamente, la media en un problema de regresión y la moda en un problema de clasificación.

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{02-arboles_files/figure-latex/arbol-1} 

}

\caption{Ejemplo de un árbol de decisión obtenido al realizar una partición binaria recursiva de un espacio bidimensional.}\label{fig:arbol}
\end{figure}

Al final de este proceso iterativo el espacio predictor se ha particionado en regiones de forma rectangular en la que la predicción de la respuesta es constante (ver Figura \ref{fig:predictor}).
Si la relación entre las variables predictoras y la variable respuesta no se puede describir adecuadamente mediante rectángulos, la calidad predictiva del árbol será limitada.
Como vemos, la simplicidad del modelo es su principal argumento, pero también su talón de Aquiles.

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{02-arboles_files/figure-latex/predictor-1} 

}

\caption{Ejemplo de la superficie de predicción correspondiente a un árbol de decisión.}\label{fig:predictor}
\end{figure}

Como se ha dicho antes, cada nodo padre se divide, a través de dos ramas, en dos nodos hijos.
Esto se hace seleccionando una variable predictora y dando respuesta a una pregunta dicotómica sobre ella.
Por ejemplo, ¿es el sueldo anual menor que 30000 euros?, o ¿es el género igual a \emph{mujer}?
Lo que se persigue con esta partición recursiva es que los nodos terminales sean homogéneos respecto a la variable respuesta \(Y\).

Por ejemplo, en un problema de clasificación, la homogeneidad de los nodos terminales significaría que en cada uno de ellos sólo hay elementos de una clase (categoría), y diríamos que los nodos son \emph{puros}.
En la práctica, esto siempre se puede conseguir construyendo árboles suficientemente profundos, con muchas hojas.
Pero esta solución no es interesante, ya que va a dar lugar a un modelo excesivamente complejo y por tanto sobreajustado y de difícil interpretación.
Será necesario encontrar un equilibrio entre la complejidad del árbol y la pureza de los nodos terminales.

En resumen:

\begin{itemize}
\item
  Métodos simples y fácilmente interpretables.
\item
  Se representan mediante árboles binarios.
\item
  Técnica clásica de apendizaje automático (computación).
\item
  Válidos para regresión y para clasificación.
\item
  Válidos para predictores numéricos y categóricos.
\end{itemize}

La metodología CART (Classification and Regresion Trees, \protect\hyperlink{ref-breiman1984classification}{Breiman et~al., 1984}) es la más popular para la construcción de árboles de decisión y es la que se va a explicar con algo de detalle en las siguientes secciones.

En primer lugar se tratarán los \emph{árboles de regresión} (árboles de decisión en un problema de regresión, en el que la variable respuesta \(Y\) es numérica) y después veremos los \emph{árboles de clasificación} (respuesta categórica) que son los más utilizados en la práctica (los primeros se suelen emplear únicamente como métodos descriptivos o como base de métodos más complejos).
Las variables predictoras \(\mathbf{X}=(X_1, X_2, \ldots, X_p)\) pueden ser tanto numéricas como categóricas.
Además, con la metodología CART, las variables explicativas podrían contener datos faltantes.
Se pueden establecer ``particiones sustitutas'' (\emph{surrogate splits}), de forma que cuando falta un valor en una variable que determina una división, se usa una variable alternativa que produce una partición similar.

\hypertarget{uxe1rboles-de-regresiuxf3n-cart}{%
\section{Árboles de regresión CART}\label{uxe1rboles-de-regresiuxf3n-cart}}

Como ya se comentó, la construcción del modelo se hace a partir de la muestra de entrenamiento, y
consiste en la partición del espacio predictor en \(J\) regiones
\(R_1, R_2, \ldots, R_J\), para cada una de las cuales se va a calcular una constante:
la media de la variable respuesta \(Y\) para las observaciones de entranamiento que
caen en la región. Estas constantes son las que se van a utilizar para
la predicción de nuevas observaciones; para ello solo hay que comprobar cuál es
la región que le corresponde.

La cuestión clave es cómo se elige la partición del espacio predictor, para lo
que vamos a utilizar como criterio de error el RSS (suma de los residuos al cuadrado).
Como hemos dicho, vamos a modelizar la respuesta en cada región como una constante,
por tanto en la región \(R_j\) nos interesa el
\(min_{c_j} \sum_{i\in R_j} (y_i - c_j)^2\), que se alcanza en la media de las
respuestas \(y_i\) (de la muestra de entrenamiento) en la región \(R_j\),
a la que llamaremos \(\widehat y_{R_j}\).
Por tanto, se deben seleccionar las regiones \(R_1, R_2, \ldots, R_J\) que minimicen

\[RSS = \sum_{j=1}^{J} \sum_{i\in R_j} (y_i - \widehat y_{R_j})^2\]
(Obsérvese el abuso de notación \(i\in R_j\), que significa las observaciones
\(i\in N\) que verifican \(x_i \in R_j\)).

Pero este problema es, en la práctica, intratable y vamos a tener que simplificarlo.
El método CART busca un compromiso
entre rendimiento, por una parte, y sencillez e interpretabilidad, por otra, y por ello
en lugar de hacer una búsqueda por todas las particiones posibles sigue un proceso
iterativo (recursivo) en el que va realizando cortes binarios. En la primera iteración
se trabaja con todos los datos:

\begin{itemize}
\item
  Una variable explicativa \(X_j\) y un punto de corte \(s\) definen dos hiperplanos
  \(R_1 = \{ X \mid X_j \le s \}\) y \(R_2 = \{ X \mid X_j > s \}\).
\item
  Se seleccionan los valores de \(j\) y \(s\) que minimizen
\end{itemize}

\[ \sum_{i\in R_1} (y_i - \widehat y_{R_1})^2 + \sum_{i\in R_2} (y_i - \widehat y_{R_2})^2\]

A diferencia del problema original, este se soluciona de forma muy rápida. A continuación
se repite el proceso en cada una de las dos regiones \(R_1\) y \(R_2\), y así sucesivamente
hasta alcanzar un criterio de parada.

Fijémonos en que este método hace dos concesiones importantes: no solo restringe la forma
que pueden adoptar las particiones, sino que además sigue un criterio de error \emph{greedy}:
en cada iteración busca minimizar el RSS de las dos regiones resultantes, sin preocuparse
del error que se va a cometer en iteraciones sucesivas. Y fijémonos también en que este
proceso se puede representar en forma de árbol binario (en el sentido de que de cada nodo
salen dos ramas, o ninguna cuando se llega al final), de ahí la terminología de \emph{hacer
crecer} el árbol.

¿Y cuándo paramos? Se puede parar cuando se alcance una profundidad máxima, aunque lo
más habitual es, para dividir un nodo (es decir, una región), exigirle un número mínimo
de observaciones.

\begin{itemize}
\item
  Si el árbol resultante es demasiado grande, va a ser un modelo demasiado complejo,
  por tanto va a ser difícil de interpretar y, sobre todo,
  va a provocar un sobreajuste de los datos. Cuando se evalúe el rendimiento utilizando
  la muestra de validación, los resultados van a ser malos. Dicho de otra manera, tendremos un
  modelo con poco sesgo pero con mucha varianza y en consecuencia inestable (pequeños
  cambios en los datos darán lugar a modelos muy distintos). Más adelante veremos que esto
  justifica la utilización del \emph{bagging} como técnica para reducir la varianza.
\item
  Si el árbol es demasiado pequeño, va a tener menos varianza (menos inestable) a costa
  de más sesgo. Más adelante veremos que esto justifica la utilización del \emph{boosting}. Los
  árboles pequeños son más fáciles de interpretar ya que permiten identificar las variables
  explicativas que más influyen en la predicción.
\end{itemize}

Sin entrar por ahora en métodos combinados (métodos \emph{ensemble}, tipo \emph{bagging} o \emph{boosting}),
vamos a explicar cómo encontrar un equilibrio entre sesgo y varianza. Lo que se hace es
construir un árbol grande para a continuación empezar a \emph{podarlo}. Podar un árbol significa
colapsar cualquier cantidad de sus nodos internos (no terminales), dando lugar a otro árbol más
pequeño al que llamaremos \emph{subárbol} del árbol original. Sabemos que el árbol completo es
el que va a tener menor error si utilizamos la muestra de entrenamiento, pero lo que
realmente nos interesa es encontrar el subárbol con un menor error al utilizar la muestra
de validación. Lamentablemente, no es una buena estrategia el evaluar todos los subárboles:
simplemente, hay demasiados. Lo que se hace es, mediante un
hiperparámetro (\emph{tuning parameter} o parámetro de ajuste) controlar el tamaño del árbol,
es decir, la complejidad del modelo, seleccionando el subárbol \emph{óptimo} (para los datos
de los que disponemos, claro). Veamos la idea.

Dado un subárbol \(T\) con \(R_1, R_2, \ldots, R_t\) nodos terminales, consideramos como
medida del error el RSS más una penalización que depende de un hiperparámetro
no negativo \(\alpha \ge 0\)

\begin{equation} 
RSS_{\alpha} = \sum_{j=1}^t \sum_{i\in R_j} (y_i - \widehat y_{R_j})^2 + \alpha t
\label{eq:rss-alpha}
\end{equation}

Para cada valor del parámetro \(\alpha\) existe un único subárbol \emph{más pequeño}
que minimiza este error (obsérvese que aunque hay un continuo de valores
distinos de \(\alpha\), sólo hay una cantidad finita de subárboles).
Evidentemente, cuando \(\alpha = 0\), ese subárbol será el árbol completo, algo que
no nos interesa. Pero a medida que se incrementa \(\alpha\) se penalizan los subárboles
con muchos nodos terminales, dando lugar a una solución más pequeña.
Encontrarla puede parecer muy costoso computacionalmente, pero lo
cierto es que no lo es. El algoritmo consistente en ir colapsando nodos de forma
sucesiva, de cada vez el nodo que produzca el menor incremento en el RSS (corregido por
un factor que depende del tamaño), da
lugar a una sucesión finita de subárboles que contiene, para todo \(\alpha\), la
solución.

Para finalizar, sólo resta seleccionar un valor de \(\alpha\).
Para ello, como se comentó en la Sección \ref{entrenamiento-test}, se podría dividir la muestra en tres subconjuntos: datos de entrenamiento, de validación y de test.
Para cada valor del parámetro de complejidad \(\alpha\) hemos utilizado la muestra de entrenamiento para obtener un árbol
(en la jerga, para cada valor del hiperparámetro \(\alpha\) se entrena un modelo).
Se emplea la muestra independiente de validación para seleccionar el valor de \(\alpha\) (y por tanto el árbol) con el que nos quedamos.
Y por último emplearemos la muestra de test (independiente de las otras dos) para evaluar el rendimiento del árbol seleccionado.
No obstante, lo más habitual para seleccionar el valor del hiperparámetro \(\alpha\) es emplear validación cruzada (o otro tipo de remuestreo) en la muestra de entrenamiento en lugar de considerar una muestra adicional de validación.

Hay dos opciones muy utilizadas en la práctica para seleccionar el valor de \(\alpha\):
se puede utilizar directamente el valor que minimice el error; o se puede forzar
que el modelo sea un poco más sencillo con la regla \emph{one-standard-error}, que selecciona
el árbol más pequeño que esté a una distancia de un error estándar del árbol obtenido
mediante la opción anterior.

También es habitual escribir la Ecuación \eqref{eq:rss-alpha} reescalando el parámetro de complejidad como \(\tilde \alpha = \alpha / RSS_0\), siendo \(RSS_0 = \sum_{i=1}^{n} (y_i - \bar y)^2\) la variabilidad total (la suma de cuadrados residual del árbol sin divisiones):
\[RSS_{\tilde \alpha}=RSS + \tilde \alpha RSS_0 t\]

De esta forma se podría interpretar el hiperparámetro \(\tilde \alpha\) como una penalización en la proporción de variabilidad explicada, ya que dividiendo la expresión anterior por \(RSS_0\) obtendríamos la proporción de variabilidad residual y a partir de ella podríamos definir:
\[R^2_{\tilde \alpha}=R^2 - \tilde \alpha  t\]

\hypertarget{uxe1rboles-de-clasificaciuxf3n-cart}{%
\section{Árboles de clasificación CART}\label{uxe1rboles-de-clasificaciuxf3n-cart}}

En un problema de clasificación la variable respuesta puede tomar los valores
\(1, 2, \ldots, K\), etiquetas que identifican las \(K\) categorías del problema.
Una vez construido el árbol, se comprueba cuál es la categoría modal de cada
región: considerando la muestra de entrenamiento, la categoría más frecuente.
Dada una observación, se predice que pertenece a la categoría modal de la
región a la que pertenece.

El resto del proceso es idéntico al de los árboles de regresión ya explicado,
con una única salvedad: no podemos utilizar RSS como medida del error. Es
necesario buscar una medida del error adaptada a este contexto.
Fijada una región, vamos a denotar por
\(\widehat p_{k}\), con \(k = 1, 2, \ldots, K\), a la proporción de observaciones
(de la muestra de entrenamiento) en la región que pertenecen a la categoría \(k\).
Se utilizan tres medidas distintas del error en la región:

\begin{itemize}
\item
  Proporción de errores de clasificación:
  \[1 - max_{k} (\widehat p_{k})\]
\item
  Índice de Gini:
  \[\sum_{k=1}^K \widehat p_{k} (1 - \widehat p_{k})\]
\item
  Entropía\footnote{La entropía es un concepto básico de la teoría de la información (\protect\hyperlink{ref-shannon1948mathematical}{Shannon, 1948}) y se mide en \emph{bits} (cuando en la definición se utilizan \(log_2\)).} (\emph{cross-entropy}):
  \[- \sum_{k=1}^K \widehat p_{k} \text{log}(\widehat p_{k})\]
\end{itemize}

Aunque la proporción de errores de clasificación es la medida del error más intuitiva, en la práctica sólo se utiliza para la fase de poda. Fijémonos que en el cálculo de esta medida sólo interviene \(max_{k} (\widehat p_{k})\), mientras que en las medidas alternativas intervienen las proporciones \(\widehat p_{k}\) de todas las categorías. Para la fase de crecimiento se utilizan indistintamente el índice de Gini o la entropía. Cuando nos interesa el error no en una única región sino en varias (al romper un nodo en dos, o al considerar todos los nodos terminales), se suman los errores de cada región previa ponderación por el número de observaciones que hay en cada una de ellas.

En la introducción de este tema se comentó que los árboles de decisión admiten tanto variables predictoras numéricas como categóricas, y esto es cierto tanto para árboles de regresión como para árboles de clasificación. Veamos brevemente como se tratarían los predictores categóricos a la hora de incorporarlos al árbol. El problema radica en qué se entiende por hacer un corte si las categorías del predictor no están ordenadas. Hay dos soluciones básicas:

\begin{itemize}
\item
  Definir variables predictoras \emph{dummy}. Se trata de variables indicadoras, una por cada una de las categorías que tiene el predictor. Este criterio de \emph{uno contra todos} tiene la ventaja de que estas variables son fácilmente interpretables, pero tiene el inconveniente de que puede aumentar mucho el número de variables predictoras.
\item
  Ordenar las categorías de la variable predictora. Lo ideal sería considerar todas las ordenaciones posibles, pero eso es desde luego poco práctico: el incremento es factorial. El truco consiste en utilizar un único órden basado en algún criterio \emph{greedy}. Por ejemplo, si la variable respuesta \(Y\) también es categórica, se puede seleccionar una de sus categorías que resulte especialmente interesante y ordenar las categorías del predictor según su proporción en la categoría de \(Y\). Este enfoque no añade complejidad al modelo, pero puede dar lugar a resultados de difícil interpretación.
\end{itemize}

\hypertarget{cart-con-el-paquete-rpart}{%
\section{\texorpdfstring{CART con el paquete \texttt{rpart}}{CART con el paquete rpart}}\label{cart-con-el-paquete-rpart}}

La metodología CART está implementada en el paquete \href{https://CRAN.R-project.org/package=rpart}{\texttt{rpart}}
(Recursive PARTitioning)\footnote{El paquete \href{https://CRAN.R-project.org/package=tree}{\texttt{tree}} es una traducción del original en S.}.
La función principal es \texttt{rpart()} y habitualmente se emplea de la forma:

\texttt{rpart(formula,\ data,\ method,\ parms,\ control,\ ...)}

\begin{itemize}
\item
  \texttt{formula}: permite especificar la respuesta y las variables predictoras de la forma habitual,
  se suele establecer de la forma \texttt{respuesta\ \textasciitilde{}\ .} para incluir todas las posibles variables explicativas.
\item
  \texttt{data}: \texttt{data.frame} (opcional; donde se evaluará la fórmula) con la muestra de entrenamiento.
\item
  \texttt{method}: método empleado para realizar las particiones, puede ser \texttt{"anova"} (regresión), \texttt{"class"} (clasificación),
  \texttt{"poisson"} (regresión de Poisson) o \texttt{"exp"} (supervivencia), o alternativamente una lista de funciones (con componentes
  \texttt{init}, \texttt{split}, \texttt{eval}; ver la vignette \href{https://cran.r-project.org/web/packages/rpart/vignettes/usercode.pdf}{\emph{User Written Split Functions}}).
  Por defecto se selecciona a partir de la variable respuesta en \texttt{formula},
  por ejemplo si es un factor (lo recomendado en clasificación) emplea \texttt{method\ =\ "class"}.
\item
  \texttt{parms}: lista de parámetros opcionales para la partición en el caso de clasificación
  (o regresión de Poisson). Puede contener los componentes \texttt{prior} (vector de probabilidades previas;
  por defecto las frecuencias observadas), \texttt{loss} (matriz de pérdidas; con ceros en la diagonal y por defecto 1 en el resto)
  y \texttt{split} (criterio de error; por defecto \texttt{"gini"} o alternativamente \texttt{"information"}).
\item
  \texttt{control}: lista de opciones que controlan el algoritmo de partición, por defecto se seleccionan mediante la función \texttt{rpart.control},
  aunque también se pueden establecer en la llamada a la función principal, y los principales parámetros son:

  \texttt{rpart.control(minsplit\ =\ 20,\ minbucket\ =\ round(minsplit/3),\ cp\ =\ 0.01,\ xval\ =\ 10,\ maxdepth\ =\ 30,\ ...)}

  \begin{itemize}
  \item
    \texttt{cp} es el parámetro de complejidad \(\tilde \alpha\) para la poda del árbol, de forma que un valor de 1 se corresponde con un árbol sin divisiones y un valor de 0 con un árbol de profundidad máxima.
    Adicionalmente, para reducir el tiempo de computación, el algoritmo empleado no realiza una partición si la proporción de reducción del error es inferior a este valor (valores más grandes simplifican el modelo y reducen el tiempo de computación).
  \item
    \texttt{maxdepth} es la profundidad máxima del árbol (la profundidad de la raíz sería 0).
  \item
    \texttt{minsplit} y \texttt{minbucket} son, respectivamente, los números mínimos de observaciones en un nodo intermedio para particionarlo
    y en un nodo terminal.
  \item
    \texttt{xval} es el número de grupos (folds) para validación cruzada.
  \end{itemize}
\end{itemize}

Para más detalles consultar la documentación de esta función o la vignette \href{https://cran.r-project.org/web/packages/rpart/vignettes/longintro.pdf}{\emph{Introduction to Rpart}}.

\hypertarget{ejemplo-regresiuxf3n}{%
\subsection{Ejemplo: regresión}\label{ejemplo-regresiuxf3n}}

Emplearemos el conjunto de datos \emph{winequality.RData} (ver \protect\hyperlink{ref-cortez2009modeling}{Cortez et~al., 2009}), que contiene información fisico-química
(\texttt{fixed.acidity}, \texttt{volatile.acidity}, \texttt{citric.acid}, \texttt{residual.sugar}, \texttt{chlorides}, \texttt{free.sulfur.dioxide},
\texttt{total.sulfur.dioxide}, \texttt{density}, \texttt{pH}, \texttt{sulphates} y \texttt{alcohol}) y sensorial (\texttt{quality})
de una muestra de 1250 vinos portugueses de la variedad \emph{Vinho Verde}.
Como respuesta consideraremos la variable \texttt{quality} , mediana de al menos 3 evaluaciones de la calidad del vino realizadas por expertos, que los evaluaron entre 0 (muy malo) y 10 (muy excelente) como puede observarse en el gráfico de barras de la Figura \ref{fig:barplot}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"data/winequality.RData"}\NormalTok{)}
\FunctionTok{str}\NormalTok{(winequality)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    1250 obs. of  12 variables:
##  $ fixed.acidity       : num  6.8 7.1 6.9 7.5 8.6 7.7 5.4 6.8 6.1 5.5 ...
##  $ volatile.acidity    : num  0.37 0.24 0.32 0.23 0.36 0.28 0.59 0.16 0.28 0.28 ...
##  $ citric.acid         : num  0.47 0.34 0.13 0.49 0.26 0.63 0.07 0.36 0.27 0.21 ...
##  $ residual.sugar      : num  11.2 1.2 7.8 7.7 11.1 11.1 7 1.3 4.7 1.6 ...
##  $ chlorides           : num  0.071 0.045 0.042 0.049 0.03 0.039 0.045 0.034 0.03 0.032 ...
##  $ free.sulfur.dioxide : num  44 6 11 61 43.5 58 36 32 56 23 ...
##  $ total.sulfur.dioxide: num  136 132 117 209 171 179 147 98 140 85 ...
##  $ density             : num  0.997 0.991 0.996 0.994 0.995 ...
##  $ pH                  : num  2.98 3.16 3.23 3.14 3.03 3.08 3.34 3.02 3.16 3.42 ...
##  $ sulphates           : num  0.88 0.46 0.37 0.3 0.49 0.44 0.57 0.58 0.42 0.42 ...
##  $ alcohol             : num  9.2 11.2 9.2 11.1 12 8.8 9.7 11.3 12.5 12.5 ...
##  $ quality             : int  5 4 5 7 5 4 6 6 8 5 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{barplot}\NormalTok{(}\FunctionTok{table}\NormalTok{(winequality}\SpecialCharTok{$}\NormalTok{quality))}
\end{Highlighting}
\end{Shaded}

\textbackslash begin\{figure\}{[}!htb{]}

\{\centering \includegraphics[width=0.8\linewidth]{02-arboles_files/figure-latex/barplot-1}

\}

\textbackslash caption\{Distribución de frecuencias de la calidad del vino (\texttt{winequality\$quality}).\}\label{fig:barplot}
\textbackslash end\{figure\}

En primer lugar se selecciona el 80\% de los datos como muestra de entrenamiento y el 20\% restante como muestra de test:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{nobs }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(winequality)}
\NormalTok{itrain }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(nobs, }\FloatTok{0.8} \SpecialCharTok{*}\NormalTok{ nobs)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ winequality[itrain, ]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ winequality[}\SpecialCharTok{{-}}\NormalTok{itrain, ]}
\end{Highlighting}
\end{Shaded}

Podemos obtener el árbol de decisión con las opciones por defecto con el comando:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tree }\OtherTok{\textless{}{-}} \FunctionTok{rpart}\NormalTok{(quality }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train)}
\end{Highlighting}
\end{Shaded}

Al imprimirlo se muestra el número de observaciones e información
sobre los distintos nodos (número de nodo, condición que define la partición,
número de observaciones en el nodo, función de pérdida y predicción),
marcando con un \texttt{*} los nodos terminales.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tree}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## n= 1000 
## 
## node), split, n, deviance, yval
##       * denotes terminal node
## 
##  1) root 1000 768.95600 5.862000  
##    2) alcohol< 10.75 622 340.81190 5.586817  
##      4) volatile.acidity>=0.2575 329 154.75990 5.370821  
##        8) total.sulfur.dioxide< 98.5 24  12.50000 4.750000 *
##        9) total.sulfur.dioxide>=98.5 305 132.28200 5.419672  
##         18) pH< 3.315 269 101.44980 5.353160 *
##         19) pH>=3.315 36  20.75000 5.916667 *
##      5) volatile.acidity< 0.2575 293 153.46760 5.829352  
##       10) sulphates< 0.475 144  80.32639 5.659722 *
##       11) sulphates>=0.475 149  64.99329 5.993289 *
##    3) alcohol>=10.75 378 303.53700 6.314815  
##      6) alcohol< 11.775 200 173.87500 6.075000  
##       12) free.sulfur.dioxide< 11.5 15  10.93333 4.933333 *
##       13) free.sulfur.dioxide>=11.5 185 141.80540 6.167568  
##         26) volatile.acidity>=0.395 7  12.85714 5.142857 *
##         27) volatile.acidity< 0.395 178 121.30900 6.207865  
##           54) citric.acid>=0.385 31  21.93548 5.741935 *
##           55) citric.acid< 0.385 147  91.22449 6.306122 *
##      7) alcohol>=11.775 178 105.23600 6.584270 *
\end{verbatim}

Para representarlo se puede emplear las herramientas del paquete \href{https://CRAN.R-project.org/package=rpart}{\texttt{rpart}} (ver Figura \ref{fig:arbolrpart}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(tree)}
\FunctionTok{text}\NormalTok{(tree)}
\end{Highlighting}
\end{Shaded}

\textbackslash begin\{figure\}{[}!htb{]}

\{\centering \includegraphics[width=0.8\linewidth]{02-arboles_files/figure-latex/arbolrpart-1}

\}

\textbackslash caption\{Árbol de regresión para predecir \texttt{winequality\$quality} (obtenido con las opciones por defecto de \texttt{rpart()}).\}\label{fig:arbolrpart}
\textbackslash end\{figure\}

Pero puede ser preferible emplear el paquete \href{https://CRAN.R-project.org/package=rpart.plot}{\texttt{rpart.plot}} (ver Figura \ref{fig:arbolrpartplot}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(rpart.plot)}
\FunctionTok{rpart.plot}\NormalTok{(tree)  }
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{02-arboles_files/figure-latex/arbolrpartplot-1} 

}

\caption{Representación del árbol de regresión obtenida con `rpart.plot()`.}\label{fig:arbolrpartplot}
\end{figure}

Nos interesa como se clasificaría a una nueva observación en los nodos terminales (en los nodos intermedios solo nos interesarían las condiciones, y el orden de las variables consideradas, hasta llegar a las hojas) y las correspondientes predicciones (la media de la respuesta en el correspondiente nodo terminal).
Para ello, puede ser de utilidad imprimir las reglas:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rpart.rules}\NormalTok{(tree, }\AttributeTok{style =} \StringTok{"tall"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## quality is 4.8 when
##     alcohol < 11
##     volatile.acidity >= 0.26
##     total.sulfur.dioxide < 99
## 
## quality is 4.9 when
##     alcohol is 11 to 12
##     free.sulfur.dioxide < 12
## 
## quality is 5.1 when
##     alcohol is 11 to 12
##     volatile.acidity >= 0.40
##     free.sulfur.dioxide >= 12
## 
## quality is 5.4 when
##     alcohol < 11
##     volatile.acidity >= 0.26
##     total.sulfur.dioxide >= 99
##     pH < 3.3
## 
## quality is 5.7 when
##     alcohol < 11
##     volatile.acidity < 0.26
##     sulphates < 0.48
## 
## quality is 5.7 when
##     alcohol is 11 to 12
##     volatile.acidity < 0.40
##     free.sulfur.dioxide >= 12
##     citric.acid >= 0.39
## 
## quality is 5.9 when
##     alcohol < 11
##     volatile.acidity >= 0.26
##     total.sulfur.dioxide >= 99
##     pH >= 3.3
## 
## quality is 6.0 when
##     alcohol < 11
##     volatile.acidity < 0.26
##     sulphates >= 0.48
## 
## quality is 6.3 when
##     alcohol is 11 to 12
##     volatile.acidity < 0.40
##     free.sulfur.dioxide >= 12
##     citric.acid < 0.39
## 
## quality is 6.6 when
##     alcohol >= 12
\end{verbatim}

Por defecto se poda el árbol considerando \texttt{cp\ =\ 0.01}, que puede ser adecuado en muchos casos.
Sin embargo, para seleccionar el valor óptimo de este (hiper)parámetro se puede emplear validación cruzada.
En primer lugar habría que establecer \texttt{cp\ =\ 0} para construir el árbol completo, a la profundidad máxima
(determinada por los valores de \texttt{minsplit} y \texttt{minbucket}, que se podrían seleccionar
``a mano'' dependiendo del número de observaciones o también considerándolos como hiperparámetos; esto último no está implementado en \texttt{rpart}, ni en principio en \texttt{caret})\footnote{Los parámetros \texttt{maxsurrogate}, \texttt{usesurrogate} y \texttt{surrogatestyle} serían de utilidad si hay datos faltantes.}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tree }\OtherTok{\textless{}{-}} \FunctionTok{rpart}\NormalTok{(quality }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{cp =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Posteriormente podemos emplear las funciones \texttt{printcp()} (o \texttt{plotcp()}) para obtener (representar)
los valores de CP para los árboles (óptimos) de menor tamaño junto con su error de validación cruzada
\texttt{xerror} (reescalado de forma que el máximo de \texttt{rel\ error} es 1)\footnote{Realmente en la tabla de texto se muestra el valor mínimo de CP, ya que se obtendría la misma solución para un rango de valores de CP (desde ese valor hasta el anterior, sin incluirlo), mientras que en el gráfico generado por \texttt{plotcp()} se representa la media geométrica de los extremos de ese intervalo (ver Figura \ref{fig:cp}).}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{printcp}\NormalTok{(tree)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Regression tree:
## rpart(formula = quality ~ ., data = train, cp = 0)
## 
## Variables actually used in tree construction:
##  [1] alcohol              chlorides            citric.acid         
##  [4] density              fixed.acidity        free.sulfur.dioxide 
##  [7] pH                   residual.sugar       sulphates           
## [10] total.sulfur.dioxide volatile.acidity    
## 
## Root node error: 768.96/1000 = 0.76896
## 
## n= 1000 
## 
##            CP nsplit rel error  xerror     xstd
## 1  0.16204707      0   1.00000 1.00203 0.048591
## 2  0.04237491      1   0.83795 0.85779 0.043646
## 3  0.03176525      2   0.79558 0.82810 0.043486
## 4  0.02748696      3   0.76381 0.81350 0.042814
## 5  0.01304370      4   0.73633 0.77038 0.039654
## 6  0.01059605      6   0.71024 0.78168 0.039353
## 7  0.01026605      7   0.69964 0.78177 0.039141
## 8  0.00840800      9   0.67911 0.78172 0.039123
## 9  0.00813924     10   0.67070 0.80117 0.039915
## 10 0.00780567     11   0.66256 0.80020 0.040481
## 11 0.00684175     13   0.64695 0.79767 0.040219
## 12 0.00673843     15   0.63327 0.81381 0.040851
## 13 0.00643577     18   0.61305 0.82059 0.041240
## 14 0.00641137     19   0.60662 0.82323 0.041271
## 15 0.00549694     21   0.59379 0.84187 0.042714
## 16 0.00489406     23   0.58280 0.84748 0.042744
## 17 0.00483045     24   0.57791 0.85910 0.043897
## 18 0.00473741     25   0.57308 0.86553 0.045463
## 19 0.00468372     26   0.56834 0.86455 0.045413
## 20 0.00450496     28   0.55897 0.87049 0.045777
## 21 0.00448365     32   0.54095 0.87263 0.045824
## 22 0.00437484     33   0.53647 0.87260 0.045846
## 23 0.00435280     35   0.52772 0.87772 0.046022
## 24 0.00428623     36   0.52337 0.87999 0.046124
## 25 0.00412515     37   0.51908 0.88151 0.046505
## 26 0.00390866     39   0.51083 0.89242 0.047068
## 27 0.00375301     42   0.49910 0.90128 0.047319
## 28 0.00370055     43   0.49535 0.90965 0.047991
## 29 0.00351987     45   0.48795 0.91404 0.048079
## 30 0.00308860     47   0.48091 0.92132 0.048336
## 31 0.00305781     49   0.47473 0.93168 0.049699
## 32 0.00299018     51   0.46862 0.93258 0.049701
## 33 0.00295148     52   0.46563 0.93062 0.049644
## 34 0.00286138     54   0.45972 0.93786 0.050366
## 35 0.00283972     55   0.45686 0.93474 0.050404
## 36 0.00274809     56   0.45402 0.93307 0.050390
## 37 0.00273457     58   0.44853 0.93642 0.050406
## 38 0.00260607     59   0.44579 0.93726 0.050543
## 39 0.00252978     60   0.44318 0.93692 0.050323
## 40 0.00252428     62   0.43813 0.93778 0.050381
## 41 0.00250804     64   0.43308 0.93778 0.050381
## 42 0.00232226     65   0.43057 0.93642 0.050081
## 43 0.00227625     66   0.42825 0.93915 0.050166
## 44 0.00225146     67   0.42597 0.94101 0.050195
## 45 0.00224774     68   0.42372 0.94101 0.050195
## 46 0.00216406     69   0.42147 0.94067 0.050124
## 47 0.00204851     70   0.41931 0.94263 0.050366
## 48 0.00194517     72   0.41521 0.94203 0.050360
## 49 0.00188139     73   0.41326 0.93521 0.050349
## 50 0.00154129     75   0.40950 0.93500 0.050277
## 51 0.00143642     76   0.40796 0.93396 0.050329
## 52 0.00118294     77   0.40652 0.93289 0.050325
## 53 0.00117607     78   0.40534 0.93738 0.050406
## 54 0.00108561     79   0.40417 0.93738 0.050406
## 55 0.00097821     80   0.40308 0.93670 0.050406
## 56 0.00093107     81   0.40210 0.93752 0.050589
## 57 0.00090075     82   0.40117 0.93752 0.050589
## 58 0.00082968     83   0.40027 0.93634 0.050561
## 59 0.00048303     85   0.39861 0.93670 0.050557
## 60 0.00000000     86   0.39813 0.93745 0.050558
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotcp}\NormalTok{(tree)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{02-arboles_files/figure-latex/cp-1} 

}

\caption{Error de validación cruzada (reescalado) dependiendo del parámetro de complejidad CP empleado en el ajuste del árbol de decisión.}\label{fig:cp}
\end{figure}

La tabla con los valores de las podas (óptimas, dependiendo del parámetro de complejidad)
está almacenada en la componente \texttt{\$cptable}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(tree}\SpecialCharTok{$}\NormalTok{cptable, }\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             CP nsplit rel error    xerror       xstd
## 1  0.162047069      0 1.0000000 1.0020304 0.04859127
## 2  0.042374911      1 0.8379529 0.8577876 0.04364585
## 3  0.031765253      2 0.7955780 0.8281010 0.04348571
## 4  0.027486958      3 0.7638128 0.8134957 0.04281430
## 5  0.013043701      4 0.7363258 0.7703804 0.03965433
## 6  0.010596054      6 0.7102384 0.7816774 0.03935308
## 7  0.010266055      7 0.6996424 0.7817716 0.03914071
## 8  0.008408003      9 0.6791102 0.7817177 0.03912344
## 9  0.008139238     10 0.6707022 0.8011719 0.03991498
## 10 0.007805674     11 0.6625630 0.8001996 0.04048088
\end{verbatim}

A partir de la que podríamos seleccionar el valor óptimo de forma automática,
siguiendo el criterio de un error estándar de \protect\hyperlink{ref-breiman1984classification}{Breiman et~al.} (\protect\hyperlink{ref-breiman1984classification}{1984}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{xerror }\OtherTok{\textless{}{-}}\NormalTok{ tree}\SpecialCharTok{$}\NormalTok{cptable[,}\StringTok{"xerror"}\NormalTok{]}
\NormalTok{imin.xerror }\OtherTok{\textless{}{-}} \FunctionTok{which.min}\NormalTok{(xerror)}
\CommentTok{\# Valor óptimo}
\NormalTok{tree}\SpecialCharTok{$}\NormalTok{cptable[imin.xerror, ]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         CP     nsplit  rel error     xerror       xstd 
## 0.01304370 4.00000000 0.73632581 0.77038039 0.03965433
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Límite superior "oneSE rule" y complejidad mínima por debajo de ese valor}
\NormalTok{upper.xerror }\OtherTok{\textless{}{-}}\NormalTok{ xerror[imin.xerror] }\SpecialCharTok{+}\NormalTok{ tree}\SpecialCharTok{$}\NormalTok{cptable[imin.xerror, }\StringTok{"xstd"}\NormalTok{]}
\NormalTok{icp }\OtherTok{\textless{}{-}} \FunctionTok{min}\NormalTok{(}\FunctionTok{which}\NormalTok{(xerror }\SpecialCharTok{\textless{}=}\NormalTok{ upper.xerror))}
\NormalTok{cp }\OtherTok{\textless{}{-}}\NormalTok{ tree}\SpecialCharTok{$}\NormalTok{cptable[icp, }\StringTok{"CP"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

Para obtener el modelo final (ver Figura \ref{fig:arbolpoda}) podamos el árbol con el valor de complejidad obtenido 0.0130437 que en este caso coincide con el valor óptimo).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tree }\OtherTok{\textless{}{-}} \FunctionTok{prune}\NormalTok{(tree, }\AttributeTok{cp =}\NormalTok{ cp)}
\FunctionTok{rpart.plot}\NormalTok{(tree) }
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{02-arboles_files/figure-latex/arbolpoda-1} 

}

\caption{Árbol de regresión resultante después de la poda (modelo final).}\label{fig:arbolpoda}
\end{figure}

Podríamos estudiar el modelo final, por ejemplo mediante el método \texttt{summary()}, que entre otras cosas muestra una medida (en porcentaje) de la importancia de las variables explicativas para la predicción de la respuesta (teniendo en cuenta todas las particiones, principales y secundarias, en las que se emplea cada variable explicativa).
Alternativamente podríamos emplear el siguiente código:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# summary(tree)}
\NormalTok{importance }\OtherTok{\textless{}{-}}\NormalTok{ tree}\SpecialCharTok{$}\NormalTok{variable.importance }\CommentTok{\# Equivalente a caret::varImp(tree) }
\NormalTok{importance }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\DecValTok{100}\SpecialCharTok{*}\NormalTok{importance}\SpecialCharTok{/}\FunctionTok{sum}\NormalTok{(importance), }\DecValTok{1}\NormalTok{)}
\NormalTok{importance[importance }\SpecialCharTok{\textgreater{}=} \DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              alcohol              density            chlorides 
##                 36.1                 21.7                 11.3 
##     volatile.acidity total.sulfur.dioxide  free.sulfur.dioxide 
##                  8.7                  8.5                  5.0 
##       residual.sugar            sulphates          citric.acid 
##                  4.0                  1.9                  1.1 
##                   pH 
##                  1.1
\end{verbatim}

El último paso sería evaluarlo en la muestra de test siguiendo los pasos descritos en la Sección \ref{eval-reg}. A continuación se muestra el código necesario (la Figura \ref{fig:obsXpred} muestra dicho rendimiento a través de remuestreo).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{obs }\OtherTok{\textless{}{-}}\NormalTok{ test}\SpecialCharTok{$}\NormalTok{quality}
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(tree, }\AttributeTok{newdata =}\NormalTok{ test)}

\CommentTok{\# plot(pred, obs, main = "Observado frente a predicciones (quality)",}
\CommentTok{\#      xlab = "Predicción", ylab = "Observado")}
\FunctionTok{plot}\NormalTok{(}\FunctionTok{jitter}\NormalTok{(pred), }\FunctionTok{jitter}\NormalTok{(obs), }\AttributeTok{xlab =} \StringTok{"Predicción"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Observado"}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{a =} \DecValTok{0}\NormalTok{, }\AttributeTok{b =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbackslash begin\{figure\}{[}!htb{]}

\{\centering \includegraphics[width=0.8\linewidth]{02-arboles_files/figure-latex/obsXpred-1}

\}

\textbackslash caption\{Gráfico de observaciones frente a predicciones (\texttt{test\$quality}; se añade una perturbación para mostrar la distribución de los valores).\}\label{fig:obsXpred}
\textbackslash end\{figure\}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Empleando el paquete caret }
\NormalTok{caret}\SpecialCharTok{::}\FunctionTok{postResample}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      RMSE  Rsquared       MAE 
## 0.8145614 0.1969485 0.6574264
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Con la función accuracy()}
\NormalTok{accuracy }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(pred, obs, }\AttributeTok{na.rm =} \ConstantTok{FALSE}\NormalTok{, }
                     \AttributeTok{tol =} \FunctionTok{sqrt}\NormalTok{(.Machine}\SpecialCharTok{$}\NormalTok{double.eps)) \{}
\NormalTok{  err }\OtherTok{\textless{}{-}}\NormalTok{ obs }\SpecialCharTok{{-}}\NormalTok{ pred     }\CommentTok{\# Errores}
  \ControlFlowTok{if}\NormalTok{(na.rm) \{}
\NormalTok{    is.a }\OtherTok{\textless{}{-}} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(err)}
\NormalTok{    err }\OtherTok{\textless{}{-}}\NormalTok{ err[is.a]}
\NormalTok{    obs }\OtherTok{\textless{}{-}}\NormalTok{ obs[is.a]}
\NormalTok{  \}  }
\NormalTok{  perr }\OtherTok{\textless{}{-}} \DecValTok{100}\SpecialCharTok{*}\NormalTok{err}\SpecialCharTok{/}\FunctionTok{pmax}\NormalTok{(obs, tol)  }\CommentTok{\# Errores porcentuales}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
    \AttributeTok{me =} \FunctionTok{mean}\NormalTok{(err),           }\CommentTok{\# Error medio}
    \AttributeTok{rmse =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{(err}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)), }\CommentTok{\# Raíz del error cuadrático medio }
    \AttributeTok{mae =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(err)),     }\CommentTok{\# Error absoluto medio}
    \AttributeTok{mpe =} \FunctionTok{mean}\NormalTok{(perr),         }\CommentTok{\# Error porcentual medio}
    \AttributeTok{mape =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(perr)),   }\CommentTok{\# Error porcentual absoluto medio}
    \AttributeTok{r.squared =} \DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{sum}\NormalTok{(err}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{sum}\NormalTok{((obs }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(obs))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{  ))}
\NormalTok{\}}
\FunctionTok{accuracy}\NormalTok{(pred, test}\SpecialCharTok{$}\NormalTok{quality)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           me         rmse          mae          mpe         mape    r.squared 
## -0.001269398  0.814561435  0.657426365 -1.952342173 11.576716037  0.192007721
\end{verbatim}

Como se puede observar el ajuste del modelo es bastante malo, como ya se comentó esto es habitual en árboles de regresión (especialmente si son tan pequeños) y normalmente solo se utilizan en un análisis exploratorio inicial (o como base para modelos más avanzados como los mostrados en el siguiente capítulo).
En problemas de clasificación es más habitual que se puedan llegar a obtener buenos ajustes con árboles de decisión.

\begin{exercise}
\protect\hypertarget{exr:efecto-semilla}{}{\label{exr:efecto-semilla} }
\end{exercise}

Como se comentó en la introducción del Capítulo \ref{intro-AE} al emplear el procedimiento habitual en AE de particionar los datos no se garantiza la reproducibilidad/repetibilidad de los resultados ya que dependen de la semilla.
El modelo ajustado puede cambiar al variar la semilla (sobre todo si el conjunto de entrenamiento es pequeño; además, en algunos modelos el método de ajuste depende también de la semilla) pero normalmente no hay grandes cambios en las predicciones.

Podemos ilustrar el efecto de la semilla en los resultados empleando el ejemplo anterior.
Habría que repetir el ajuste de un árbol de regresión considerando distintas semillas y comparar los resultados obtenidos.

La dificultad podría estar en como comparar los resultados.
Una posible solución sería mantener fija la muestra de test (que forma que no dependa de las semillas).
Por comodidad podríamos considerar las primeras \texttt{ntest} observaciones del conjunto de datos.
Posteriormente, para cada semilla, seleccionaríamos la muestra de entrenamiento de la forma habitual y ajustaríamos un árbol. Finalmente evaluaríamos los resultados en la muestra de test.

Como base se podría considerar el siguiente código:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ntest }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ winequality[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{ntest, ]}
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ winequality[}\SpecialCharTok{{-}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{ntest), ]}
\NormalTok{nobs }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(df)}

\CommentTok{\# Para las distintas semillas}
\FunctionTok{set.seed}\NormalTok{(semilla)}
\NormalTok{itrain }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(nobs, }\FloatTok{0.8} \SpecialCharTok{*}\NormalTok{ nobs)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ df[itrain, ]}

\CommentTok{\# tree \textless{}{-} ...}
\end{Highlighting}
\end{Shaded}

Como comentario final, en este caso el conjunto de datos no es muy grande y tampoco se obtuvo un buen ajuste con un árbol de regresión, por lo que sería de esperar que se observaran más diferencias.

\begin{exercise}
\protect\hypertarget{exr:train-validate-test-tree}{}{\label{exr:train-validate-test-tree} }
\end{exercise}

Como ya se mostró, el paquete \texttt{rpart} implementa la selección del parámetro de complejidad mediante validación cruzada.
Como alternativa, siguiendo la idea del Ejercicio \ref{exr:train-validate-test}, y considerando de nuevo el ejemplo anterior, particionar la muestra en datos de entrenamiento (70\%), de validación (15\%) y de test (15\%), para ajustar los árboles de decisión, seleccionar el parámetro de complejidad (el hiperparámetro) y evaluar las predicciones del modelo final, respectivamente.

\begin{exercise}
\protect\hypertarget{exr:train-boot-tree}{}{\label{exr:train-boot-tree} }
\end{exercise}

Una alternativa a particionar en entrenamiento y validación sería emplear bootstrap.
La idea es emplear una remuestra bootstrap del conjunto de datos de entrenamiento para ajustar el modelo y utilizar las observaciones no seleccionadas (se suelen denominar datos \emph{out of bag}) como conjunto de validación.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{nobs }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(winequality)}
\NormalTok{itrain }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(nobs, }\FloatTok{0.8} \SpecialCharTok{*}\NormalTok{ nobs)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ winequality[itrain, ]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ winequality[}\SpecialCharTok{{-}}\NormalTok{itrain, ]}

\CommentTok{\# Indice muestra de entrenamiento bootstrap}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{ntrain }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(train)}
\NormalTok{itrain.boot }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(ntrain, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{train.boot }\OtherTok{\textless{}{-}}\NormalTok{ train[itrain.boot, ]}
\end{Highlighting}
\end{Shaded}

La muestra bootstrap va a contener muchas observaciones repetidas y habrá observaciones no seleccionadas.
La probabilidad de que una observación no sea seleccionada es \((1 - 1/n)^n \approx e^{-1} \approx 0.37\).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Número de casos "out of bag"}
\NormalTok{ntrain }\SpecialCharTok{{-}} \FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(itrain.boot))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 370
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Muestra "out of bag"}
\CommentTok{\# oob \textless{}{-} train[{-}unique(itrain.boot), ]}
\NormalTok{oob }\OtherTok{\textless{}{-}}\NormalTok{ train[}\SpecialCharTok{{-}}\NormalTok{itrain.boot, ]}
\end{Highlighting}
\end{Shaded}

El resto sería igual que el caso anterior cambiando \texttt{train} por \texttt{train.boot} y \texttt{validate} por \texttt{oob}.

Como comentario final, lo recomendable sería repetir el proceso un número grande de veces y promediar los errores (esto está relacionado con el método de \emph{bagging} descrito en el siguiente capítulo), especialmente cuando el tamaño muestral es pequeño, pero por simplicidad consideraremos únicamente una muestra boostrap.

\hypertarget{class-rpart}{%
\subsection{Ejemplo: modelo de clasificación}\label{class-rpart}}

Para ilustrar los árboles de clasificación CART, podemos emplear los datos anteriores de calidad de vino, considerando como respuesta una nueva variable \texttt{taste} que clasifica los vinos en ``good'' o ``bad'' dependiendo de si \texttt{winequality\$quality\ \textgreater{}=\ 5} (este conjunto de datos está almacenado en el archivo \emph{winetaste.RData}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load("data/winetaste.RData")}
\NormalTok{winetaste }\OtherTok{\textless{}{-}}\NormalTok{ winequality[, }\FunctionTok{colnames}\NormalTok{(winequality)}\SpecialCharTok{!=}\StringTok{"quality"}\NormalTok{]}
\NormalTok{winetaste}\SpecialCharTok{$}\NormalTok{taste }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(winequality}\SpecialCharTok{$}\NormalTok{quality }\SpecialCharTok{\textless{}} \DecValTok{6}\NormalTok{, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}good\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}bad\textquotesingle{}}\NormalTok{)) }\CommentTok{\# levels = c(\textquotesingle{}FALSE\textquotesingle{}, \textquotesingle{}TRUE\textquotesingle{})}
\FunctionTok{str}\NormalTok{(winetaste)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    1250 obs. of  12 variables:
##  $ fixed.acidity       : num  6.8 7.1 6.9 7.5 8.6 7.7 5.4 6.8 6.1 5.5 ...
##  $ volatile.acidity    : num  0.37 0.24 0.32 0.23 0.36 0.28 0.59 0.16 0.28 0.28 ...
##  $ citric.acid         : num  0.47 0.34 0.13 0.49 0.26 0.63 0.07 0.36 0.27 0.21 ...
##  $ residual.sugar      : num  11.2 1.2 7.8 7.7 11.1 11.1 7 1.3 4.7 1.6 ...
##  $ chlorides           : num  0.071 0.045 0.042 0.049 0.03 0.039 0.045 0.034 0.03 0.032 ...
##  $ free.sulfur.dioxide : num  44 6 11 61 43.5 58 36 32 56 23 ...
##  $ total.sulfur.dioxide: num  136 132 117 209 171 179 147 98 140 85 ...
##  $ density             : num  0.997 0.991 0.996 0.994 0.995 ...
##  $ pH                  : num  2.98 3.16 3.23 3.14 3.03 3.08 3.34 3.02 3.16 3.42 ...
##  $ sulphates           : num  0.88 0.46 0.37 0.3 0.49 0.44 0.57 0.58 0.42 0.42 ...
##  $ alcohol             : num  9.2 11.2 9.2 11.1 12 8.8 9.7 11.3 12.5 12.5 ...
##  $ taste               : Factor w/ 2 levels "good","bad": 2 2 2 1 2 2 1 1 1 2 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(winetaste}\SpecialCharTok{$}\NormalTok{taste)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## good  bad 
##  828  422
\end{verbatim}

Como en el caso anterior, se contruyen las muestras de entrenamiento (80\%) y de test (20\%):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set.seed(1)}
\CommentTok{\# nobs \textless{}{-} nrow(winetaste)}
\CommentTok{\# itrain \textless{}{-} sample(nobs, 0.8 * nobs)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ winetaste[itrain, ]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ winetaste[}\SpecialCharTok{{-}}\NormalTok{itrain, ]}
\end{Highlighting}
\end{Shaded}

Al igual que en el caso anterior podemos obtener el árbol de clasificación con las opciones por defecto (\texttt{cp\ =\ 0.01} y \texttt{split\ =\ "gini"}) con el comando:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tree }\OtherTok{\textless{}{-}} \FunctionTok{rpart}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train)}
\end{Highlighting}
\end{Shaded}

En este caso al imprimirlo como información de los nodos se muestra (además del número de nodo, la condición de la partición y el número de observaciones en el nodo) el número de observaciones mal clasificadas, la predicción y las proporciones estimadas (frecuencias relativas en la muestra de entrenamiento) de las clases:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tree}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## n= 1000 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##  1) root 1000 338 good (0.6620000 0.3380000)  
##    2) alcohol>=10.11667 541 100 good (0.8151571 0.1848429)  
##      4) free.sulfur.dioxide>=8.5 522  87 good (0.8333333 0.1666667)  
##        8) fixed.acidity< 8.55 500  73 good (0.8540000 0.1460000) *
##        9) fixed.acidity>=8.55 22   8 bad (0.3636364 0.6363636) *
##      5) free.sulfur.dioxide< 8.5 19   6 bad (0.3157895 0.6842105) *
##    3) alcohol< 10.11667 459 221 bad (0.4814815 0.5185185)  
##      6) volatile.acidity< 0.2875 264 102 good (0.6136364 0.3863636)  
##       12) fixed.acidity< 7.45 213  71 good (0.6666667 0.3333333)  
##         24) citric.acid>=0.265 160  42 good (0.7375000 0.2625000) *
##         25) citric.acid< 0.265 53  24 bad (0.4528302 0.5471698)  
##           50) free.sulfur.dioxide< 42.5 33  13 good (0.6060606 0.3939394) *
##           51) free.sulfur.dioxide>=42.5 20   4 bad (0.2000000 0.8000000) *
##       13) fixed.acidity>=7.45 51  20 bad (0.3921569 0.6078431)  
##         26) total.sulfur.dioxide>=150 26  10 good (0.6153846 0.3846154) *
##         27) total.sulfur.dioxide< 150 25   4 bad (0.1600000 0.8400000) *
##      7) volatile.acidity>=0.2875 195  59 bad (0.3025641 0.6974359)  
##       14) pH>=3.235 49  24 bad (0.4897959 0.5102041)  
##         28) chlorides< 0.0465 18   4 good (0.7777778 0.2222222) *
##         29) chlorides>=0.0465 31  10 bad (0.3225806 0.6774194) *
##       15) pH< 3.235 146  35 bad (0.2397260 0.7602740) *
\end{verbatim}

También puede ser preferible emplear el paquete \href{https://CRAN.R-project.org/package=rpart.plot}{\texttt{rpart.plot}} para representarlo (ver Figura \ref{fig:arbolclassif}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(rpart.plot)}
\FunctionTok{rpart.plot}\NormalTok{(tree) }\CommentTok{\# Alternativa: rattle::fancyRpartPlot}
\end{Highlighting}
\end{Shaded}

\textbackslash begin\{figure\}{[}!htb{]}

\{\centering \includegraphics[width=0.8\linewidth]{02-arboles_files/figure-latex/arbolclassif-1}

\}

\textbackslash caption\{Árbol de clasificación de \texttt{winetaste\$taste} (obtenido con las opciones por defecto).\}\label{fig:arbolclassif}
\textbackslash end\{figure\}

Nos interesa como se clasificaría a una nueva observación (como se llega a los nodos terminales) y su probabilidad estimada (la frecuencia relativa de la clase más frecuente en el correspondiente nodo terminal). Para ello se puede modificar la información que se muestra en cada nodo (ver Figura \ref{fig:arbolextra}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rpart.plot}\NormalTok{(tree, }
           \AttributeTok{extra =} \DecValTok{104}\NormalTok{,          }\CommentTok{\# show fitted class, probs, percentages}
           \AttributeTok{box.palette =} \StringTok{"GnBu"}\NormalTok{, }\CommentTok{\# color scheme}
           \AttributeTok{branch.lty =} \DecValTok{3}\NormalTok{,       }\CommentTok{\# dotted branch lines}
           \AttributeTok{shadow.col =} \StringTok{"gray"}\NormalTok{,  }\CommentTok{\# shadows under the node boxes}
           \AttributeTok{nn =} \ConstantTok{TRUE}\NormalTok{)            }\CommentTok{\# display the node numbers }
\end{Highlighting}
\end{Shaded}

\textbackslash begin\{figure\}{[}!htb{]}

\{\centering \includegraphics[width=0.8\linewidth]{02-arboles_files/figure-latex/arbolextra-1}

\}

\textbackslash caption\{Representación del árbol de clasificación de \texttt{winetaste\$taste} incluyendo información adicional en los nodos.\}\label{fig:arbolextra}
\textbackslash end\{figure\}
Al igual que en el caso de regresión, puede ser de utilidad imprimir las reglas:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rpart.rules}\NormalTok{(tree, }\AttributeTok{style =} \StringTok{"tall"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## taste is 0.15 when
##     alcohol >= 10
##     fixed.acidity < 8.6
##     free.sulfur.dioxide >= 8.5
## 
## taste is 0.22 when
##     alcohol < 10
##     volatile.acidity >= 0.29
##     pH >= 3.2
##     chlorides < 0.047
## 
## taste is 0.26 when
##     alcohol < 10
##     volatile.acidity < 0.29
##     fixed.acidity < 7.5
##     citric.acid >= 0.27
## 
## taste is 0.38 when
##     alcohol < 10
##     volatile.acidity < 0.29
##     fixed.acidity >= 7.5
##     total.sulfur.dioxide >= 150
## 
## taste is 0.39 when
##     alcohol < 10
##     volatile.acidity < 0.29
##     fixed.acidity < 7.5
##     free.sulfur.dioxide < 42.5
##     citric.acid < 0.27
## 
## taste is 0.64 when
##     alcohol >= 10
##     fixed.acidity >= 8.6
##     free.sulfur.dioxide >= 8.5
## 
## taste is 0.68 when
##     alcohol < 10
##     volatile.acidity >= 0.29
##     pH >= 3.2
##     chlorides >= 0.047
## 
## taste is 0.68 when
##     alcohol >= 10
##     free.sulfur.dioxide < 8.5
## 
## taste is 0.76 when
##     alcohol < 10
##     volatile.acidity >= 0.29
##     pH < 3.2
## 
## taste is 0.80 when
##     alcohol < 10
##     volatile.acidity < 0.29
##     fixed.acidity < 7.5
##     free.sulfur.dioxide >= 42.5
##     citric.acid < 0.27
## 
## taste is 0.84 when
##     alcohol < 10
##     volatile.acidity < 0.29
##     fixed.acidity >= 7.5
##     total.sulfur.dioxide < 150
\end{verbatim}

También se suele emplear el mismo procedimiento para seleccionar un valor óptimo del (hiper)parámetro de complejidad, se construye un árbol de decisión completo y se emplea validación cruzada para podarlo.
Además, si el número de observaciones es grande y las clases están más o menos balanceadas,
se podría aumentar los valores mínimos de observaciones en los nodos intermedios y terminales\footnote{Otra opción, más interesante para regresión, sería considerar estos valores como hiperparámetros.}, por ejemplo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tree }\OtherTok{\textless{}{-}} \FunctionTok{rpart}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{cp =} \DecValTok{0}\NormalTok{, }\AttributeTok{minsplit =} \DecValTok{30}\NormalTok{, }\AttributeTok{minbucket =} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

En este caso mantenemos el resto de valores por defecto:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tree }\OtherTok{\textless{}{-}} \FunctionTok{rpart}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{cp =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Representamos los errores (reescalados) de validación cruzada (ver Figura \ref{fig:errorclassif})

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# printcp(tree)}
\FunctionTok{plotcp}\NormalTok{(tree)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{02-arboles_files/figure-latex/errorclassif-1} 

}

\caption{Evolución del error (reescalado) de validación cruzada en función del parámetro de complejidad.}\label{fig:errorclassif}
\end{figure}

Para obtener el modelo final, seleccionamos el valor óptimo de complejidad siguiendo el criterio de un error estándar de \protect\hyperlink{ref-breiman1984classification}{Breiman et~al.} (\protect\hyperlink{ref-breiman1984classification}{1984}) y podamos el árbol (ver Figura \ref{fig:arbolclassifpoda}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{xerror }\OtherTok{\textless{}{-}}\NormalTok{ tree}\SpecialCharTok{$}\NormalTok{cptable[,}\StringTok{"xerror"}\NormalTok{]}
\NormalTok{imin.xerror }\OtherTok{\textless{}{-}} \FunctionTok{which.min}\NormalTok{(xerror)}
\NormalTok{upper.xerror }\OtherTok{\textless{}{-}}\NormalTok{ xerror[imin.xerror] }\SpecialCharTok{+}\NormalTok{ tree}\SpecialCharTok{$}\NormalTok{cptable[imin.xerror, }\StringTok{"xstd"}\NormalTok{]}
\NormalTok{icp }\OtherTok{\textless{}{-}} \FunctionTok{min}\NormalTok{(}\FunctionTok{which}\NormalTok{(xerror }\SpecialCharTok{\textless{}=}\NormalTok{ upper.xerror))}
\NormalTok{cp }\OtherTok{\textless{}{-}}\NormalTok{ tree}\SpecialCharTok{$}\NormalTok{cptable[icp, }\StringTok{"CP"}\NormalTok{]}
\NormalTok{tree }\OtherTok{\textless{}{-}} \FunctionTok{prune}\NormalTok{(tree, }\AttributeTok{cp =}\NormalTok{ cp)}
\CommentTok{\# tree}
\CommentTok{\# summary(tree)}
\CommentTok{\# caret::varImp(tree)}
\CommentTok{\# importance \textless{}{-} tree$variable.importance}
\CommentTok{\# importance \textless{}{-} round(100*importance/sum(importance), 1)}
\CommentTok{\# importance[importance \textgreater{}= 1]}
\FunctionTok{rpart.plot}\NormalTok{(tree) }\CommentTok{\#, main="Classification tree winetaste"}
\end{Highlighting}
\end{Shaded}

\textbackslash begin\{figure\}{[}!htb{]}

\{\centering \includegraphics[width=0.8\linewidth]{02-arboles_files/figure-latex/arbolclassifpoda-1}

\}

\textbackslash caption\{Árbol de clasificación de \texttt{winetaste\$taste} obtenido después de la poda (modelo final).\}\label{fig:arbolclassifpoda}
\textbackslash end\{figure\}

El último paso sería evaluarlo en la muestra de test siguiendo los pasos descritos en la Sección \ref{eval-class}.
El método \texttt{predict()} por defecto (\texttt{type\ =\ "prob"}) devuelve una matriz con las probabilidades de cada clase, habrá que establecer \texttt{type\ =\ "class"} (para más detalles consultar la ayuda de \texttt{predic.rpart()}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{obs }\OtherTok{\textless{}{-}}\NormalTok{ test}\SpecialCharTok{$}\NormalTok{taste}
\FunctionTok{head}\NormalTok{(}\FunctionTok{predict}\NormalTok{(tree, }\AttributeTok{newdata =}\NormalTok{ test))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         good       bad
## 1  0.3025641 0.6974359
## 4  0.8151571 0.1848429
## 9  0.8151571 0.1848429
## 10 0.8151571 0.1848429
## 12 0.8151571 0.1848429
## 16 0.8151571 0.1848429
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(tree, }\AttributeTok{newdata =}\NormalTok{ test, }\AttributeTok{type =} \StringTok{"class"}\NormalTok{)}
\FunctionTok{table}\NormalTok{(obs, pred)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       pred
## obs    good bad
##   good  153  13
##   bad    54  30
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{caret}\SpecialCharTok{::}\FunctionTok{confusionMatrix}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction good bad
##       good  153  54
##       bad    13  30
##                                           
##                Accuracy : 0.732           
##                  95% CI : (0.6725, 0.7859)
##     No Information Rate : 0.664           
##     P-Value [Acc > NIR] : 0.01247         
##                                           
##                   Kappa : 0.3171          
##                                           
##  Mcnemar's Test P-Value : 1.025e-06       
##                                           
##             Sensitivity : 0.9217          
##             Specificity : 0.3571          
##          Pos Pred Value : 0.7391          
##          Neg Pred Value : 0.6977          
##              Prevalence : 0.6640          
##          Detection Rate : 0.6120          
##    Detection Prevalence : 0.8280          
##       Balanced Accuracy : 0.6394          
##                                           
##        'Positive' Class : good            
## 
\end{verbatim}

\hypertarget{interfaz-de-caret}{%
\subsection{\texorpdfstring{Interfaz de \texttt{caret}}{Interfaz de caret}}\label{interfaz-de-caret}}

En \texttt{caret} podemos ajustar un árbol CART seleccionando \texttt{method\ =\ "rpart"}.
Por defecto emplea bootstrap de las observaciones para seleccionar el valor óptimo del hiperparámetro \texttt{cp} (considerando únicamente tres posibles valores).
Si queremos emplear validación cruzada como en el caso anterior podemos emplear la función auxiliar \texttt{trainControl()} y para considerar un mayor rango de posibles valores, el argumento \texttt{tuneLength} (ver Figura \ref{fig:arbolclassifggplot}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}
\CommentTok{\# names(getModelInfo()) \# Listado de todos los métodos disponibles}
\CommentTok{\# modelLookup("rpart")  \# Información sobre hiperparámetros}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\CommentTok{\# itrain \textless{}{-} createDataPartition(winetaste$taste, p = 0.8, list = FALSE)}
\CommentTok{\# train \textless{}{-} winetaste[itrain, ]}
\CommentTok{\# test \textless{}{-} winetaste[{-}itrain, ]}
\NormalTok{caret.rpart }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{method =} \StringTok{"rpart"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ train, }
                     \AttributeTok{tuneLength =} \DecValTok{20}\NormalTok{,}
                     \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{number =} \DecValTok{10}\NormalTok{)) }
\NormalTok{caret.rpart}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## CART 
## 
## 1000 samples
##   11 predictor
##    2 classes: 'good', 'bad' 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 901, 900, 900, 900, 900, 900, ... 
## Resampling results across tuning parameters:
## 
##   cp           Accuracy   Kappa    
##   0.000000000  0.7018843  0.3487338
##   0.005995017  0.7330356  0.3870552
##   0.011990034  0.7410655  0.3878517
##   0.017985051  0.7230748  0.3374518
##   0.023980069  0.7360748  0.3698691
##   0.029975086  0.7340748  0.3506377
##   0.035970103  0.7320748  0.3418235
##   0.041965120  0.7350849  0.3422651
##   0.047960137  0.7350849  0.3422651
##   0.053955154  0.7350849  0.3422651
##   0.059950171  0.7350849  0.3422651
##   0.065945188  0.7350849  0.3422651
##   0.071940206  0.7350849  0.3422651
##   0.077935223  0.7350849  0.3422651
##   0.083930240  0.7350849  0.3422651
##   0.089925257  0.7350849  0.3422651
##   0.095920274  0.7350849  0.3422651
##   0.101915291  0.7350849  0.3422651
##   0.107910308  0.7229637  0.2943312
##   0.113905325  0.6809637  0.1087694
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was cp = 0.01199003.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(caret.rpart)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{02-arboles_files/figure-latex/arbolclassifggplot-1} 

}

\caption{Evolución de la precisión (obtenida mediante validación cruzada) dependiendo del parámetro de complejidad.}\label{fig:arbolclassifggplot}
\end{figure}

El modelo final es el siguiente (ver Figura \ref{fig:arbolfinalcaret})

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{caret.rpart}\SpecialCharTok{$}\NormalTok{finalModel}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## n= 1000 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##  1) root 1000 338 good (0.6620000 0.3380000)  
##    2) alcohol>=10.11667 541 100 good (0.8151571 0.1848429)  
##      4) free.sulfur.dioxide>=8.5 522  87 good (0.8333333 0.1666667)  
##        8) fixed.acidity< 8.55 500  73 good (0.8540000 0.1460000) *
##        9) fixed.acidity>=8.55 22   8 bad (0.3636364 0.6363636) *
##      5) free.sulfur.dioxide< 8.5 19   6 bad (0.3157895 0.6842105) *
##    3) alcohol< 10.11667 459 221 bad (0.4814815 0.5185185)  
##      6) volatile.acidity< 0.2875 264 102 good (0.6136364 0.3863636)  
##       12) fixed.acidity< 7.45 213  71 good (0.6666667 0.3333333)  
##         24) citric.acid>=0.265 160  42 good (0.7375000 0.2625000) *
##         25) citric.acid< 0.265 53  24 bad (0.4528302 0.5471698)  
##           50) free.sulfur.dioxide< 42.5 33  13 good (0.6060606 0.3939394) *
##           51) free.sulfur.dioxide>=42.5 20   4 bad (0.2000000 0.8000000) *
##       13) fixed.acidity>=7.45 51  20 bad (0.3921569 0.6078431)  
##         26) total.sulfur.dioxide>=150 26  10 good (0.6153846 0.3846154) *
##         27) total.sulfur.dioxide< 150 25   4 bad (0.1600000 0.8400000) *
##      7) volatile.acidity>=0.2875 195  59 bad (0.3025641 0.6974359)  
##       14) pH>=3.235 49  24 bad (0.4897959 0.5102041)  
##         28) chlorides< 0.0465 18   4 good (0.7777778 0.2222222) *
##         29) chlorides>=0.0465 31  10 bad (0.3225806 0.6774194) *
##       15) pH< 3.235 146  35 bad (0.2397260 0.7602740) *
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rpart.plot}\NormalTok{(caret.rpart}\SpecialCharTok{$}\NormalTok{finalModel) }\CommentTok{\#, main="Classification tree winetaste"}
\end{Highlighting}
\end{Shaded}

\textbackslash begin\{figure\}{[}!htb{]}

\{\centering \includegraphics[width=0.8\linewidth]{02-arboles_files/figure-latex/arbolfinalcaret-1}

\}

\textbackslash caption\{Árbol de clasificación de \texttt{winetaste\$taste}, obtenido con la complejidad ``óptima'' (empleando \texttt{caret}).\}\label{fig:arbolfinalcaret}
\textbackslash end\{figure\}

Para utilizar la regla de ``un error estándar'' se puede añadir \texttt{selectionFunction\ =\ "oneSE"}. A continuacióno se muestra dicho código y en la Figura \ref{fig:arbolclassifoneSE} el árbol resultante.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{caret.rpart }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{method =} \StringTok{"rpart"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ train, }
                     \AttributeTok{tuneLength =} \DecValTok{20}\NormalTok{,}
                     \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{number =} \DecValTok{10}\NormalTok{,}
                                              \AttributeTok{selectionFunction =} \StringTok{"oneSE"}\NormalTok{)) }
\NormalTok{caret.rpart}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## CART 
## 
## 1000 samples
##   11 predictor
##    2 classes: 'good', 'bad' 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 901, 900, 900, 900, 900, 900, ... 
## Resampling results across tuning parameters:
## 
##   cp           Accuracy   Kappa    
##   0.000000000  0.7018843  0.3487338
##   0.005995017  0.7330356  0.3870552
##   0.011990034  0.7410655  0.3878517
##   0.017985051  0.7230748  0.3374518
##   0.023980069  0.7360748  0.3698691
##   0.029975086  0.7340748  0.3506377
##   0.035970103  0.7320748  0.3418235
##   0.041965120  0.7350849  0.3422651
##   0.047960137  0.7350849  0.3422651
##   0.053955154  0.7350849  0.3422651
##   0.059950171  0.7350849  0.3422651
##   0.065945188  0.7350849  0.3422651
##   0.071940206  0.7350849  0.3422651
##   0.077935223  0.7350849  0.3422651
##   0.083930240  0.7350849  0.3422651
##   0.089925257  0.7350849  0.3422651
##   0.095920274  0.7350849  0.3422651
##   0.101915291  0.7350849  0.3422651
##   0.107910308  0.7229637  0.2943312
##   0.113905325  0.6809637  0.1087694
## 
## Accuracy was used to select the optimal model using  the one SE rule.
## The final value used for the model was cp = 0.1019153.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# ggplot(caret.rpart)}
\NormalTok{caret.rpart}\SpecialCharTok{$}\NormalTok{finalModel}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## n= 1000 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
## 1) root 1000 338 good (0.6620000 0.3380000)  
##   2) alcohol>=10.11667 541 100 good (0.8151571 0.1848429) *
##   3) alcohol< 10.11667 459 221 bad (0.4814815 0.5185185)  
##     6) volatile.acidity< 0.2875 264 102 good (0.6136364 0.3863636) *
##     7) volatile.acidity>=0.2875 195  59 bad (0.3025641 0.6974359) *
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rpart.plot}\NormalTok{(caret.rpart}\SpecialCharTok{$}\NormalTok{finalModel)}\CommentTok{\#, main = "Classification tree winetaste"}
\end{Highlighting}
\end{Shaded}

\textbackslash begin\{figure\}{[}!htb{]}

\{\centering \includegraphics[width=0.8\linewidth]{02-arboles_files/figure-latex/arbolclassifoneSE-1}

\}

\textbackslash caption\{Árbol de clasificación de \texttt{winetaste\$taste}, obtenido con la regla de un error estándar para seleccionar la complejidad (empleando \texttt{caret}).\}\label{fig:arbolclassifoneSE}
\textbackslash end\{figure\}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{var.imp }\OtherTok{\textless{}{-}} \FunctionTok{varImp}\NormalTok{(caret.rpart)}
\FunctionTok{plot}\NormalTok{(var.imp)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{02-arboles_files/figure-latex/arbolImpor-1} 

}

\caption{Importancia de los (posibles) predictores según el modelo obtenido con la regla de un error estándar.}\label{fig:arbolImpor}
\end{figure}

Para calcular las predicciones (o las estimaciones de las probabilidades) podemos emplear el método \texttt{predict.train()} y posteriormente \texttt{confusionMatrix()} para evaluar su precisión:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(caret.rpart, }\AttributeTok{newdata =}\NormalTok{ test)}
\CommentTok{\# p.est \textless{}{-} predict(caret.rpart, newdata = test, type = "prob")}
\FunctionTok{confusionMatrix}\NormalTok{(pred, test}\SpecialCharTok{$}\NormalTok{taste)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction good bad
##       good  153  54
##       bad    13  30
##                                           
##                Accuracy : 0.732           
##                  95% CI : (0.6725, 0.7859)
##     No Information Rate : 0.664           
##     P-Value [Acc > NIR] : 0.01247         
##                                           
##                   Kappa : 0.3171          
##                                           
##  Mcnemar's Test P-Value : 1.025e-06       
##                                           
##             Sensitivity : 0.9217          
##             Specificity : 0.3571          
##          Pos Pred Value : 0.7391          
##          Neg Pred Value : 0.6977          
##              Prevalence : 0.6640          
##          Detection Rate : 0.6120          
##    Detection Prevalence : 0.8280          
##       Balanced Accuracy : 0.6394          
##                                           
##        'Positive' Class : good            
## 
\end{verbatim}

NOTA: En principio también se podría utilizar la regla de ``un error estándar'' seleccionando \texttt{method\ =\ "rpart1SE"} (pero \texttt{caret} implementa internamente este método y en ocasiones no se obtienen los resultados esperados).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{caret.rpart }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{method =} \StringTok{"rpart1SE"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ train) }
\NormalTok{caret.rpart}
\FunctionTok{printcp}\NormalTok{(caret.rpart}\SpecialCharTok{$}\NormalTok{finalModel)}
\NormalTok{caret.rpart}\SpecialCharTok{$}\NormalTok{finalModel}
\FunctionTok{rpart.plot}\NormalTok{(caret.rpart}\SpecialCharTok{$}\NormalTok{finalModel) }\CommentTok{\#, main = "Classification tree winetaste"}
\FunctionTok{varImp}\NormalTok{(caret.rpart)}
\end{Highlighting}
\end{Shaded}

Como alternativas al uso de la metodología CART desde \texttt{cartet} se puede considerar las opciones de los metapaquetes:

\begin{itemize}
\tightlist
\item
  \href{https://mlr3book.mlr-org.com/mlr3book.pdf}{\texttt{mlr3}}, que incorpora una llamada a \texttt{rpart::rpart()} desde sus \textbf{learners} \texttt{lrn("regr.rpart")} y \texttt{lrn("classif.rpart")}.
\item
  \href{https://www.h2o.ai/blog/finally-you-can-plot-h2o-decision-trees-in-r/}{\texttt{h2o}}, que aunque no ofrece una implementación de los árboles CART, sí ofrece dos alternativas más sofisticadas usando bosques aleatorios \texttt{h2o.randomForest()} y los procedimientos basados en el aumento del gradiente \texttt{h2o.gbm()}.
\end{itemize}

\hypertarget{alternativas-a-los-uxe1rboles-cart}{%
\section{Alternativas a los árboles CART}\label{alternativas-a-los-uxe1rboles-cart}}

Una de las alternativas más populares es la metodología C4.5 (\protect\hyperlink{ref-quinlan1993c4}{Quinlan, 1993}), evolución de ID3 (1986), que en estos momentos se encuentra en la versión C5.0 (y es ya muy similar a CART).
C5.0 se utiliza sólo para clasificación e incorpora \emph{boosting} (que veremos en el tema siguiente).
Esta metodología está implementada en el paquete \href{https://topepo.github.io/C5.0/index.html}{\texttt{C50}}.

Ross Quinlan desarrolló también la metodologia M5 (\protect\hyperlink{ref-quinlan1992learning}{Quinlan y others, 1992}) para regresión.
Su principal característica es que los nodos terminales, en lugar de contener un número, contienen un modelo (de regresión) lineal.
El paquete \href{https://topepo.github.io/Cubist}{\texttt{Cubist}} es una evolución de M5 que incorpora un método \emph{ensemble} similar a \emph{boosting}.

La motivación detrás de M5 es que, si la predicción que aporta un nodo terminal se limita a un único número (como hace la metodología CART), entonces el modelo va a predecir muy mal los valores que \emph{realmente} son muy extremos, ya que el número de posibles valores predichos está limitado por el número de nodos terminales, y en cada uno de ellos se utiliza una media.
Por ello M5 le asocia a cada nodo un modelo de regresión lineal, para cuyo ajuste se utilizan los datos del nodo y todas las variables que están en la ruta del nodo.
Para evaluar los posibles cortes que conducen al siguiente nodo, se utilizan los propios modelos lineales para calcular la medida del error.

Una vez se ha construido todo el árbol, para realizar la predicción se puede utilizar el modelo lineal que está en el nodo terminal correspondiente, pero funciona mejor si se utiliza una combinación lineal del modelo del nodo terminal y de todos sus nodos ascendientes (es decir, los que están en su camino).

Otra opción es CHAID (CHi-squared Automated Interaction Detection, \protect\hyperlink{ref-kass1980exploratory}{Kass, 1980}), que se basa en una idea diferente. Es un método de construcción de árboles de clasificación que se utiliza cuando las variables predictoras son cualitativas o discretas; en caso contrario deben ser categorizadas previamente.
Y se basa en el contraste chi-cuadrado de independencia para tablas de contingencia.

Para cada par \((X_i, Y)\), se considera su tabla de contingencia y se calcula el \emph{p}-valor del contraste chi-cuadrado, seleccionándose la variable predictora que tenga un \emph{p}-valor más pequeño, ya que se asume que las variables predictoras más relacionadas con la respuesta \(Y\) son las que van a tener \emph{p}-valores más pequeños y darán lugar a mejores predicciones.
Se divide el nodo de acuerdo con los distintos valores de la variable predictora seleccionada, y se repite el proceso mientras haya variables \emph{significativas}.
Como el método exige que el \emph{p}-valor sea menor que 0.05 (o el nivel de significación que se elija), y hay que hacer muchas comparaciones es necesario aplicar una corrección para comparaciones múltiples, por ejemplo la de Bonferroni.

Lo que acabamos de explicar daría lugar a árboles no necesariamente binarios.
Como se desea trabajar con árboles binarios (si se admite que de un nodo salga cualquier número de ramas, con muy pocos niveles de profundidad del árbol ya nos quedaríamos sin datos), es necesario hacer algo más: forzar a que las variables predictoras tengan sólo dos categorías mediante un proceso de fusión.
Se van haciendo pruebas chi-cuadrado entre pares de categorías y la variable respuesta, y se fusiona el par con el \emph{p}-valor más alto, ya que se trata de fusionar las categorías que sean más similares.

Para árboles de regresión hay metodologías que, al igual que CHAID, se basan en el cálculo de \emph{p}-valores, en este caso de contrastes de igualdes de medias.
Una de las más utilizadas son los \emph{conditional inference trees} (\protect\hyperlink{ref-hothorn2006unbiased}{Hothorn et~al., 2006})\footnote{Otra alternativa es GUIDE (Generalized, Unbiased, Interaction Detection and Estimation; \protect\hyperlink{ref-loh2002regression}{Loh} (\protect\hyperlink{ref-loh2002regression}{2002})).}, implementada en la función \texttt{ctree()} del paquete \href{https://CRAN.R-project.org/package=party}{\texttt{party}}.

Un problema conocido de los árboles CART es que sufren un sesgo de selección de variables: los predictores con más valores distintos son favorecidos.
Esta es una de las motivaciones de utilizar estos métodos basados en contrastes de hipótesis.
Por otra parte hay que ser conscientes de que los contrastes de hipótesis y la calidad predictiva son cosas distintas.

\hypertarget{ejemplo-1}{%
\subsection{Ejemplo}\label{ejemplo-1}}

Siguiendo con el problema de clasificación anterior, podríamos ajustar un árbol de decisión empleando la metodología de \emph{inferencia condicional} mediante el siguiente código:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(party)}
\NormalTok{tree2 }\OtherTok{\textless{}{-}} \FunctionTok{ctree}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train) }
\FunctionTok{plot}\NormalTok{(tree2)}
\end{Highlighting}
\end{Shaded}

\textbackslash begin\{figure\}{[}!htb{]}

\{\centering \includegraphics[width=0.8\linewidth]{02-arboles_files/figure-latex/ctree-plot-1}

\}

\textbackslash caption\{Árbol de decisión para clasificar la calidad del vino (\texttt{winetaste\$taste}) obtenido con el método condicional.\}\label{fig:ctree-plot}
\textbackslash end\{figure\}

Para más detalles ver la vignette del paquete \href{https://cran.r-project.org/web/packages/party/vignettes/party.pdf}{\emph{party: A Laboratory for Recursive Partytioning}}.

\hypertarget{bagging-boosting}{%
\chapter{Bagging y Boosting}\label{bagging-boosting}}

Tanto el \emph{bagging} como el \emph{boosting} son procedimientos generales para la reducción de la varianza de un método estadístico de aprendizaje.

La idea básica consiste en combinar métodos de predicción sencillos (débiles), es decir, con poca capacidad predictiva, para obtener un método de predicción muy potente (y robusto).
Estas ideas se pueden aplicar tanto a problemas de regresión como de clasificación.

Son muy empleados con árboles de decisión: son predictores débiles y se generan de forma rápida.
Lo que se hace es construir muchos modelos (crecer muchos árboles) que luego se combinan para producir predicciones (promediando o por consenso).

\hypertarget{bagging}{%
\section{Bagging}\label{bagging}}

En la década de 1990 empiezan a utilizarse los métodos \emph{ensemble} (métodos combinados), esto es, métodos predictivos que se basan en combinar las predicciones de cientos de modelos.
Uno de los primeros métodos combinados que se utilizó fue el \emph{bagging} (nombre que viene de \emph{bootstrap aggregation}), propuesto en \protect\hyperlink{ref-breiman1996bagging}{Breiman} (\protect\hyperlink{ref-breiman1996bagging}{1996}).
Es un método general de reducción de la varianza que se basa en la utilización del bootstrap junto con un modelo de regresión o de clasificación, como puede ser un árbol de decisión.

La idea es muy sencilla.
Si disponemos de muchas muestras de entrenamiento, podemos utilizar cada una de ellas para entrenar un modelo que después nos servirá para hacer una predicción.
De este modo tendremos tantas predicciones como modelos y por tanto tantas predicciones como muestras de entrenamiento.
El procedimiento consistente en promediar todas las predicciones anteriores tiene dos ventajas importantes: simplifica la solución y reduce mucho la varianza.

El problema es que en la práctica no suele disponerse más que de una única muestra de entrenamiento.
Aquí es donde entra en juego el bootstrap, técnica especialmente útil para estimar varianzas, pero que en esta aplicación se utiliza para reducir la varianza.
Lo que se hace es generar cientos o miles de muestras bootstrap a partir de la muestra de entrenamiento, y después utilizar cada una de estas muestras bootstrap como una muestra de entrenamiento (\emph{bootstrapped training data set}).

Para un modelo que tenga intrínsecamente poca variabilidad, como puede ser una regresión lineal, aplicar bagging puede ser poco interesante, ya que hay poco margen para mejorar el rendimiento.
Por contra, es un método muy importante para los árboles de decisión, porque un árbol con mucha profundidad (sin podar) tiene mucha variabilidad: si modificamos ligeramente los datos de entrenamiento es muy posible que se obtenga un nuevo árbol completamente distinto al anterior; y esto se ve como un inconveniente.
Por esa razón, en este contexto encaja perfectamente la metodología bagging.

Así, para árboles de regresión se hacen crecer muchos árboles (sin poda) y se calcula la media de las predicciones.
En el caso de los árboles de clasificación lo más sencillo es sustituir la media por la moda y utilizar el criterio del voto mayoritario: cada modelo tiene el mismo peso y por tanto cada modelo aporta un voto.
Además, la proporción de votos de cada categoría es una estimación de su probabilidad.

Una ventaja adicional del bagging es que permite estimar el error de la predicción de forma directa, sin necesidad de utilizar una muestra de test o de aplicar validación cruzada u, otra vez, remuestreo, y se obtiene un resultado similar al que obtendríamos con estos métodos.
Es bien sabido que una muestra bootstrap va a contener muchas observaciones repetidas y que, en promedio, sólo utiliza aproximadamente dos tercios de los datos (para ser más precisos, \(1 - (1 - 1/n)^n \approx 1 - e^{-1} = 0.6321\) al aumentar el tamaño del conjunto de datos de entrenamiento).
Un dato que no es utilizado para construir un árbol se denomina un dato \emph{out-of-bag} (OOB).
De este modo, para cada observación se pueden utilizar los árboles para los que esa observación es \emph{out-of-bag} (aproximadamente una tercera parte de los árboles construidos) para generar una única predicción para ella.
Repitiendo el proceso para todas las observaciones se obtiene una medida del error.

Una decisión que hay que tomar es cuántas muestras bootstrap se toman (o lo que es lo mismo, cuántos árboles se construyen).
Realmente se trata de una aproximación Monte Carlo, por lo que típicamente se estudia gráficamente la convergencia del error OOB al aumentar el número de árboles (para más detalles ver p.e. \protect\hyperlink{ref-fernandez2020simbook}{Fernández-Casal y Cao, 2020, pp. Sección 4.1}).
Si aparentemente hay convergencia con unos pocos cientos de árboles, no va a variar mucho el nivel de error al aumentar el número.
Por tanto aumentar mucho el número de árboles no mejora las predicciones, aunque tampoco aumenta el riesgo de sobreajuste.
Los costes computacionales aumentan con el número de árboles, pero la construcción y evaluación del modelo son fácilmente paralelizables (aunque pueden llegar a requerir mucha memoria si el conjunto de datos es muy grande).
Por otra parte si el número de árboles es demasiado pequeño puede que se obtengan pocas (o incluso ninguna) predicciones OOB para alguna de las observaciones de la muestra de entrenamiento.

Una ventaja que ya sabemos que tienen los árboles de decisión es su fácil interpretabilidad.
En un árbol resulta evidente cuales son los predictores más influyentes.
Al utilizar bagging se mejora (mucho) la predicción, pero se pierde la interpretabilidad.
Aún así, hay formas de calcular la importancia de los predictores.
Por ejemplo, si fijamos un predictor y una medida del error podemos, para cada uno de los árboles, medir la reducción del error que se consigue cada vez que hay un corte que utilice ese predictor particular.
Promediando sobre todos los árboles bagging se obtiene una medida global de la importancia: un valor alto en la reducción del error sugiere que el predictor es importante.

En resumen:

\begin{itemize}
\item
  Se remuestrea repetidamente el conjunto de datos de entrenamiento.
\item
  Con cada conjunto de datos se entrena un modelo.
\item
  Las predicciones se obtienen promediando las predicciones de los
  modelos (la decisión mayoritaria en el caso de clasificación).
\item
  Se puede estimar la precisión de las predicciones con el error OOB (out-of-bag).
\end{itemize}

\hypertarget{bosques-aleatorios}{%
\section{Bosques aleatorios}\label{bosques-aleatorios}}

Los bosques aleatorios (\emph{random forest}) son una variante de bagging específicamente diseñados para trabajar con árboles de decisión.
Las muestras bootstrap que se generan al hacer bagging introducen un elemento de aleatoriedad que en la práctica provoca que todos los árboles sean distintos, pero en ocasiones no son lo \emph{suficientemente} distintos.
Es decir, suele ocurrir que los árboles tengan estructuras muy similares, especialmente en la parte alta, aunque después se vayan diferenciando según se desciende por ellos.
Esta característica se conoce como correlación entre árboles y se da cuando el árbol es un modelo adecuado para describir la relación ente los predictores y la respuesta, y también cuándo uno de los predictores es muy fuerte, es decir, es especialmente relevante, con lo cual casi siempre va a estar en el primer corte.
Esta correlación entre árboles se va a traducir en una correlación entre sus predicciones (más formalmente, entre los predictores).

Promediar variables altamente correladas produce una reducción de la varianza mucho menor que si promediamos variables incorreladas.
La solución pasa por añadir aleatoriedad al proceso de construcción de los árboles, para que estos dejen de estar correlados.
Hubo varios intentos, entre los que destaca \protect\hyperlink{ref-dietterich2000experimental}{Dietterich} (\protect\hyperlink{ref-dietterich2000experimental}{2000}) al proponer la idea de introducir aleatorieadad en la selección de las variables de cada corte.
\protect\hyperlink{ref-breiman2001statistical}{Breiman} (\protect\hyperlink{ref-breiman2001statistical}{2001b}) propuso un algoritmo unificado al que llamó bosques aleatorios.
En la construcción de cada uno de los árboles que finalmente constituirán el bosque, se van haciendo cortes binarios, y para cada corte hay que seleccionar una variable predictora.
La modificación introducida fue que antes de hacer cada uno de los cortes, de todas las \(p\) variables predictoras, se seleccionan al azar \(m < p\) predictores que van a ser los candidatos para el corte.

El hiperparámetro de los bosques aleatorios es \(m\), y se puede seleccionar mediante las técnicas habituales.
Como puntos de partida razonables se pueden considerar \(m = \sqrt{p}\) (para problemas de clasificación) y \(m = p/3\) (para problemas de regresión).
El número de árboles que van a constituir el bosque también puede tratarse como un hiperparámetro, aunque es más frecuente tratarlo como un problema de convergencia.
En general, van a hacer falta más árboles que en bagging.

Los bosques aleatorios son computacionalmente más eficientes que bagging porque, aunque como acabamos de decir requieren más árboles, la construcción de cada árbol es mucho más rápida al evaluarse sólo unos pocos predictores en cada corte.

Este método también puede ser empleado para aprendizaje no supervisado,
por ejemplo se puede construir una matriz de proximidad entre observaciones a partir de la proporción de veces que están en un mismo nodo terminal (para más detalles ver \protect\hyperlink{ref-liaw2002classification}{Liaw y Wiener, 2002}).

En resumen:

\begin{itemize}
\item
  Los bosques aleatorios son una modificación del bagging para el caso de árboles de decisión.
\item
  También se introduce aleatoriedad en las variables, no sólo en las observaciones.
\item
  Para evitar dependencias, los posibles predictores se seleccionan al azar en cada nodo (e.g.~\(m=\sqrt{p}\)).
\item
  Se utilizan árboles sin podar.
\item
  Estos métodos dificultan la interpretación.
\item
  Se puede medir la importancia de las variables (índices de importancia).

  \begin{itemize}
  \item
    Por ejemplo, para cada árbol se suman las reducciones en el
    índice de Gini correspondientes a las divisiones de un
    predictor y posteriormente se promedian los valores de todos
    los árboles.
  \item
    Alternativamente (\protect\hyperlink{ref-breiman2001statistical}{Breiman, 2001b}) se puede medir el incremento en el error de
    predicción OOB al permutar aleatoriamente los valores de la
    variable explicativa en las muestras OOB (manteniendo el resto
    sin cambios).
  \end{itemize}
\end{itemize}

\hypertarget{bagging-rf-r}{%
\section{Bagging y bosques aleatorios en R}\label{bagging-rf-r}}

Estos algoritmos son de los más populares en AE y están implementados en numerosos paquetes de R, aunque la referencia es el paquete \href{https://CRAN.R-project.org/package=randomForest}{\texttt{randomForest}} (que emplea el código Fortran desarrollado por Leo Breiman y Adele Cutler).
La función principal es \texttt{randomForest()} y se suele emplear de la forma:

\texttt{randomForest(formula,\ data,\ ntree,\ mtry,\ nodesize,\ ...)}

\begin{itemize}
\item
  \texttt{formula} y \texttt{data} (opcional): permiten especificar la respuesta y las variables predictoras de la forma habitual (típicamente \texttt{respuesta\ \textasciitilde{}\ .}), aunque si el conjunto de datos es muy grande puede ser preferible emplear una matriz o un data.frame para establecer los predictores y un vector para la respuesta (sustituyendo estos argumentos por \texttt{x} e \texttt{y}).
  Si la respuesta es un factor asumirá que se trata de un problema de clasificación y de regresión en caso contrario.
\item
  \texttt{ntree}: número de árboles que se crecerán; por defecto 500.
\item
  \texttt{mtry}: número de predictores seleccionados al azar en cada división; por defecto \texttt{max(floor(p/3),\ 1)} en el caso de regresión y \texttt{floor(sqrt(p))} en clasificación, siendo \texttt{p\ =\ ncol(x)\ =\ ncol(data)\ -\ 1} el número de predictores.
\item
  \texttt{nodesize}: número mínimo de observaciones en un nodo terminal; por defecto 1 en clasificación y 5 en regresión (puede ser recomendable incrementarlo si el conjunto de datos es muy grande, para evitar posibles problemas de sobreajuste, disminuir el tiempo de computación y los requerimientos de memoria; también podría ser considerado como un hiperparámetro).
\end{itemize}

Otros argumentos que pueden ser de interés\footnote{Si se quiere minimizar el uso de memoria, por ejemplo mientras se seleccionan hiperparámetros, se puede establecer \texttt{keep.forest=FALSE}.} son:

\begin{itemize}
\item
  \texttt{maxnodes}: número máximo de nodos terminales (como alternativa para la establecer la complejidad).
\item
  \texttt{importance\ =\ TRUE}: permite obtener medidas adicionales de importancia.
\item
  \texttt{proximity\ =\ TRUE}: permite obtener una matriz de proximidades (componente \texttt{\$proximity}) entre las observaciones (frecuencia con la que los pares de observaciones están en el mismo nodo terminal).
\item
  \texttt{na.action\ =\ na.fail}: por defecto no admite datos faltantes con la interfaz de fórmulas. Si los hubiese, se podrían imputar estableciendo \texttt{na.action\ =\ na.roughfix} (empleando medias o modas) o llamando previamente a \texttt{rfImpute()} (que emplea proximidades obtenidas con un bosque aleatorio).
\end{itemize}

Más detalles en la ayuda de esta función o en \href{https://www.r-project.org/doc/Rnews/Rnews_2002-3.pdf}{Liaw y Wiener (2002)}.

Entre las numerosas alternativas, además de las implementadas en paquetes que integran colecciones de métodos como \texttt{h2o} o \texttt{RWeka}, una de las más utilizadas son los bosques aleatorios con \emph{conditional inference trees}, implementada en la función \texttt{cforest()} del paquete \href{https://CRAN.R-project.org/package=party}{\texttt{party}}.

\hypertarget{ejemplo-clasificaciuxf3n-con-bagging}{%
\subsection{Ejemplo: Clasificación con bagging}\label{ejemplo-clasificaciuxf3n-con-bagging}}

Como ejemplo consideraremos el conjunto de datos de calidad de vino empleado en la Sección \ref{class-rpart} (para hacer comparaciones con el ajuste de un único árbol).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"data/winetaste.RData"}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ winetaste}
\NormalTok{nobs }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(df)}
\NormalTok{itrain }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(nobs, }\FloatTok{0.8} \SpecialCharTok{*}\NormalTok{ nobs)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ df[itrain, ]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ df[}\SpecialCharTok{{-}}\NormalTok{itrain, ]}
\end{Highlighting}
\end{Shaded}

Al ser bagging con árboles un caso particular de bosques aleatorios, cuando \(m = p\), también podemos emplear \texttt{randomForest}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(randomForest)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{4}\NormalTok{) }\CommentTok{\# NOTA: Fijamos esta semilla para ilustrar dependencia}
\NormalTok{bagtrees }\OtherTok{\textless{}{-}} \FunctionTok{randomForest}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{mtry =} \FunctionTok{ncol}\NormalTok{(train) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
\NormalTok{bagtrees}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
##  randomForest(formula = taste ~ ., data = train, mtry = ncol(train) -      1) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 11
## 
##         OOB estimate of  error rate: 23.5%
## Confusion matrix:
##      good bad class.error
## good  565  97   0.1465257
## bad   138 200   0.4082840
\end{verbatim}

Con el método \texttt{plot()} podemos examinar la convergencia del error en las muestras OOB (simplemente emplea \texttt{matplot()} para representar la componente \texttt{\$err.rate} como se muestra en la Figura \ref{fig:bagging-conv}):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(bagtrees, }\AttributeTok{main =} \StringTok{""}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"right"}\NormalTok{, }\FunctionTok{colnames}\NormalTok{(bagtrees}\SpecialCharTok{$}\NormalTok{err.rate), }\AttributeTok{lty =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{, }\AttributeTok{col =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbackslash begin\{figure\}{[}!htb{]}

\{\centering \includegraphics[width=0.8\linewidth]{03-bagging_boosting_files/figure-latex/bagging-conv-1}

\}

\textbackslash caption\{Tasas de error OOB al usar bagging para la predicción de \texttt{winetaste\$taste} (realizado empleando \texttt{randomForest()} con \texttt{mtry} igual al número de predictores).\}\label{fig:bagging-conv}
\textbackslash end\{figure\}

Como vemos que los errores se estabilizan podríamos pensar que aparentemente hay convergencia (aunque situaciones de alta dependencia entre los árboles dificultarían su interpretación).

Con la función \texttt{getTree()} podemos extraer los árboles individuales.
Por ejemplo el siguiente código permite extraer la variable seleccionada para la primera división:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# View(getTree(bagtrees, 1, labelVar=TRUE))}
\NormalTok{split\_var\_1 }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\FunctionTok{seq\_len}\NormalTok{(bagtrees}\SpecialCharTok{$}\NormalTok{ntree),}
                      \ControlFlowTok{function}\NormalTok{(i) }\FunctionTok{getTree}\NormalTok{(bagtrees, i, }\AttributeTok{labelVar=}\ConstantTok{TRUE}\NormalTok{)[}\DecValTok{1}\NormalTok{, }\StringTok{"split var"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

En este caso concreto podemos observar que siempre es la misma, lo que indicaría una alta dependencia entre los distintos árboles:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(split\_var\_1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## split_var_1
##              alcohol            chlorides          citric.acid 
##                  500                    0                    0 
##              density        fixed.acidity  free.sulfur.dioxide 
##                    0                    0                    0 
##                   pH       residual.sugar            sulphates 
##                    0                    0                    0 
## total.sulfur.dioxide     volatile.acidity 
##                    0                    0
\end{verbatim}

Por último evaluamos la precisión en la muestra de test:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(bagtrees, }\AttributeTok{newdata =}\NormalTok{ test)}
\NormalTok{caret}\SpecialCharTok{::}\FunctionTok{confusionMatrix}\NormalTok{(pred, test}\SpecialCharTok{$}\NormalTok{taste)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction good bad
##       good  145  42
##       bad    21  42
##                                           
##                Accuracy : 0.748           
##                  95% CI : (0.6894, 0.8006)
##     No Information Rate : 0.664           
##     P-Value [Acc > NIR] : 0.002535        
##                                           
##                   Kappa : 0.3981          
##                                           
##  Mcnemar's Test P-Value : 0.011743        
##                                           
##             Sensitivity : 0.8735          
##             Specificity : 0.5000          
##          Pos Pred Value : 0.7754          
##          Neg Pred Value : 0.6667          
##              Prevalence : 0.6640          
##          Detection Rate : 0.5800          
##    Detection Prevalence : 0.7480          
##       Balanced Accuracy : 0.6867          
##                                           
##        'Positive' Class : good            
## 
\end{verbatim}

\hypertarget{ejemplo-clasif-rf}{%
\subsection{Ejemplo: Clasificación con bosques aleatorios}\label{ejemplo-clasif-rf}}

Continuando con el ejemplo anterior, empleamos la función \texttt{randomForest()} con las opciones por defecto para ajustar un bosque aleatorio:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load("data/winetaste.RData")}
\CommentTok{\# set.seed(1)}
\CommentTok{\# df \textless{}{-} winetaste}
\CommentTok{\# nobs \textless{}{-} nrow(df)}
\CommentTok{\# itrain \textless{}{-} sample(nobs, 0.8 * nobs)}
\CommentTok{\# train \textless{}{-} df[itrain, ]}
\CommentTok{\# test \textless{}{-} df[{-}itrain, ]}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{rf }\OtherTok{\textless{}{-}} \FunctionTok{randomForest}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train)}
\NormalTok{rf}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
##  randomForest(formula = taste ~ ., data = train) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 22%
## Confusion matrix:
##      good bad class.error
## good  578  84   0.1268882
## bad   136 202   0.4023669
\end{verbatim}

En este caso también observamos en la Figura \ref{fig:rf-plot} que aparentemente hay convergencia y tampoco sería necesario incrementar el número de árboles:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(rf,}\AttributeTok{main=}\StringTok{""}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"right"}\NormalTok{, }\FunctionTok{colnames}\NormalTok{(rf}\SpecialCharTok{$}\NormalTok{err.rate), }\AttributeTok{lty =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{, }\AttributeTok{col =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbackslash begin\{figure\}{[}!htb{]}

\{\centering \includegraphics[width=0.8\linewidth]{03-bagging_boosting_files/figure-latex/rf-plot-1}

\}

\textbackslash caption\{Tasas de error OOB al usar bosques aleatorios para la predicción de \texttt{winetaste\$taste} (empleando \texttt{randomForest()} con las opciones por defecto).\}\label{fig:rf-plot}
\textbackslash end\{figure\}

Podemos mostrar la importancia de las variables predictoras (utilizadas en el bosque aleatorio y sus sustituas) con la función \texttt{importance()} o representarlas con \texttt{varImpPlot()} (ver Figura \ref{fig:rf-importance}):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{importance}\NormalTok{(rf)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                      MeanDecreaseGini
## fixed.acidity                37.77155
## volatile.acidity             43.99769
## citric.acid                  41.50069
## residual.sugar               36.79932
## chlorides                    33.62100
## free.sulfur.dioxide          42.29122
## total.sulfur.dioxide         39.63738
## density                      45.38724
## pH                           32.31442
## sulphates                    30.32322
## alcohol                      63.89185
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{varImpPlot}\NormalTok{(rf)}
\end{Highlighting}
\end{Shaded}

\textbackslash begin\{figure\}{[}!htb{]}

\{\centering \includegraphics[width=0.8\linewidth]{03-bagging_boosting_files/figure-latex/rf-importance-1}

\}

\textbackslash caption\{Importancia de las variables predictoras al emplear bosques aleatorios para la predicción de \texttt{winetaste\$taste}.\}\label{fig:rf-importance}
\textbackslash end\{figure\}

Si evaluamos la precisión en la muestra de test podemos observar un ligero incremento en la precisión en comparación con el método anterior:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(rf, }\AttributeTok{newdata =}\NormalTok{ test)}
\NormalTok{caret}\SpecialCharTok{::}\FunctionTok{confusionMatrix}\NormalTok{(pred, test}\SpecialCharTok{$}\NormalTok{taste)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction good bad
##       good  153  43
##       bad    13  41
##                                           
##                Accuracy : 0.776           
##                  95% CI : (0.7192, 0.8261)
##     No Information Rate : 0.664           
##     P-Value [Acc > NIR] : 7.227e-05       
##                                           
##                   Kappa : 0.4494          
##                                           
##  Mcnemar's Test P-Value : 0.0001065       
##                                           
##             Sensitivity : 0.9217          
##             Specificity : 0.4881          
##          Pos Pred Value : 0.7806          
##          Neg Pred Value : 0.7593          
##              Prevalence : 0.6640          
##          Detection Rate : 0.6120          
##    Detection Prevalence : 0.7840          
##       Balanced Accuracy : 0.7049          
##                                           
##        'Positive' Class : good            
## 
\end{verbatim}

Esta mejora sería debida a que en este caso la dependencia entre los árboles es menor:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{split\_var\_1 }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\FunctionTok{seq\_len}\NormalTok{(rf}\SpecialCharTok{$}\NormalTok{ntree),}
                      \ControlFlowTok{function}\NormalTok{(i) }\FunctionTok{getTree}\NormalTok{(rf, i, }\AttributeTok{labelVar=}\ConstantTok{TRUE}\NormalTok{)[}\DecValTok{1}\NormalTok{, }\StringTok{"split var"}\NormalTok{])}
\FunctionTok{table}\NormalTok{(split\_var\_1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## split_var_1
##              alcohol            chlorides          citric.acid 
##                  150                   49                   38 
##              density        fixed.acidity  free.sulfur.dioxide 
##                  114                   23                   20 
##                   pH       residual.sugar            sulphates 
##                   11                    0                    5 
## total.sulfur.dioxide     volatile.acidity 
##                   49                   41
\end{verbatim}

El análisis e interpretación del modelo puede resultar más complicado en este tipo de métodos.
Para estudiar el efecto de los predictores en la respuesta se suelen emplear alguna de las herramientas descritas en la Sección \ref{analisis-modelos}.
Por ejemplo, empleando la función \texttt{pdp::partial()}, podemos generar gráficos PDP estimando los efectos individuales de los predictores (ver Figura \ref{fig:rf-pdp-uni-plot}):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages("pdp")}
\FunctionTok{library}\NormalTok{(pdp)}
\NormalTok{pdp1 }\OtherTok{\textless{}{-}} \FunctionTok{partial}\NormalTok{(rf, }\StringTok{"alcohol"}\NormalTok{)}
\NormalTok{p1 }\OtherTok{\textless{}{-}} \FunctionTok{plotPartial}\NormalTok{(pdp1)}
\NormalTok{pdp2 }\OtherTok{\textless{}{-}} \FunctionTok{partial}\NormalTok{(rf, }\FunctionTok{c}\NormalTok{(}\StringTok{"density"}\NormalTok{))}
\NormalTok{p2 }\OtherTok{\textless{}{-}} \FunctionTok{plotPartial}\NormalTok{(pdp2)}
\FunctionTok{grid.arrange}\NormalTok{(p1, p2, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.9\linewidth]{images/rf-pdp-uni-1} 

}

\caption{Efecto parcial del alcochol (panel izquierdo) y la densidad (panel derecho) sobre la respuesta.}\label{fig:rf-pdp-uni-plot}
\end{figure}

O gráficos PDP considerando la interacción entre dos predictores (ver Figura \ref{fig:rf-pdp-plot}) (cuidado, puede requerir de mucho tiempo de computación):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pdp12 }\OtherTok{\textless{}{-}} \FunctionTok{partial}\NormalTok{(rf, }\FunctionTok{c}\NormalTok{(}\StringTok{"alcohol"}\NormalTok{, }\StringTok{"density"}\NormalTok{))}
\FunctionTok{plotPartial}\NormalTok{(pdp12)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{images/rf-pdp-1} 

}

\caption{Efecto parcial de la interacción del alcochol y la densidad sobre la respuesta.}\label{fig:rf-pdp-plot}
\end{figure}

Adicionalmente, estableciendo \texttt{ice\ =\ TRUE} se calculan las curvas de expectativa condicional individual (ICE). Estos gráficos ICE extienden los PDP, ya que además de mostrar la variación del promedio (ver línea roja en la Figura \ref{fig:rf-ice-plot}), también muestra la variación de los valores predichos para cada observación (ver líneas en negro en la Figura \ref{fig:rf-ice-plot}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ice1 }\OtherTok{\textless{}{-}} \FunctionTok{partial}\NormalTok{(rf, }\AttributeTok{pred.var =} \StringTok{"alcohol"}\NormalTok{, }\AttributeTok{ice =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{ice2 }\OtherTok{\textless{}{-}} \FunctionTok{partial}\NormalTok{(rf, }\AttributeTok{pred.var =} \StringTok{"density"}\NormalTok{, }\AttributeTok{ice =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{p1 }\OtherTok{\textless{}{-}} \FunctionTok{plotPartial}\NormalTok{(ice1, }\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{)}
\NormalTok{p2 }\OtherTok{\textless{}{-}} \FunctionTok{plotPartial}\NormalTok{(ice2, }\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{)}
\FunctionTok{grid.arrange}\NormalTok{(p1, p2, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{images/rf-ice-1} 

}

\caption{Efecto individual de cada observación de alcochol (panel izquierdo) y densidad (panel derecho) sobre la respuesta.}\label{fig:rf-ice-plot}
\end{figure}

Gráficos similares pueden crearse utilizando otros paquetes indicados en la Sección \ref{analisis-modelos}. En particular, el paquete \texttt{vivid} muestra en la diagonal del Figura \ref{fig:rf-vivid-plot} la importancia de los cinco primeros predictores (\emph{Vimp}) y fuera de la diagonal las interacciones 2 a 2 (\emph{Vint}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(vivid)}
\NormalTok{fit\_rf  }\OtherTok{\textless{}{-}} \FunctionTok{vivi}\NormalTok{(}\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{fit =}\NormalTok{ rf, }\AttributeTok{response =} \StringTok{"taste"}\NormalTok{, }\AttributeTok{importanceType =} \StringTok{"\%IncMSE"}\NormalTok{)}
\FunctionTok{viviHeatmap}\NormalTok{(}\AttributeTok{mat =}\NormalTok{ fit\_rf[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{images/rf-vivid-1} 

}

\caption{Mapa de calor para la importancia e interaciones del ajuste de un bosque aleatorio usando vivid.}\label{fig:rf-vivid-plot}
\end{figure}

Alternativamente, también se pueden visualizar las relaciones mediante un gráfico de red (ver Figura \ref{fig:rf-vivid-plot}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{require}\NormalTok{(igraph)}
\FunctionTok{viviNetwork}\NormalTok{(}\AttributeTok{mat =}\NormalTok{ fit\_rf)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{images/rf-vivid2-1} 

}

\caption{Gráfico de red para la importancia e interaciones del ajuste de un bosque aleatorio usando vivid.}\label{fig:rf-vivid2-plot}
\end{figure}

\hypertarget{ejemplo-bosques-aleatorios-con-caret}{%
\subsection{\texorpdfstring{Ejemplo: bosques aleatorios con \texttt{caret}}{Ejemplo: bosques aleatorios con caret}}\label{ejemplo-bosques-aleatorios-con-caret}}

En paquete \texttt{caret} hay varias implementaciones de bagging y bosques aleatorios\footnote{Se puede hacer una búsqueda en la tabla del \href{https://topepo.github.io/caret/available-models.html}{Capítulo 6: Available Models} del manual.}, incluyendo el algoritmo del paquete \texttt{randomForest} considerando como hiperparámetro el número de predictores seleccionados al azar en cada división \texttt{mtry}.
Para ajustar este modelo a una muestra de entrenamiento hay que establecer \texttt{method\ =\ "rf"} en la llamada a \texttt{train()}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}
\CommentTok{\# str(getModelInfo("rf", regex = FALSE))}
\FunctionTok{modelLookup}\NormalTok{(}\StringTok{"rf"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   model parameter                         label forReg forClass probModel
## 1    rf      mtry #Randomly Selected Predictors   TRUE     TRUE      TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load("data/winetaste.RData")}
\CommentTok{\# set.seed(1)}
\CommentTok{\# df \textless{}{-} winetaste}
\CommentTok{\# nobs \textless{}{-} nrow(df)}
\CommentTok{\# itrain \textless{}{-} sample(nobs, 0.8 * nobs)}
\CommentTok{\# train \textless{}{-} df[itrain, ]}
\CommentTok{\# test \textless{}{-} df[{-}itrain, ]}
\end{Highlighting}
\end{Shaded}

Con las opciones por defecto únicamente evalúa tres valores posibles del hiperparámetro (ver Figura \ref{fig:rf-caret-train}).
Opcionalmente se podría aumentar el número valores a evaluar con \texttt{tuneLength} o directamente especificarlos con \texttt{tuneGrid}.
En cualquier caso el tiempo de computación puede ser demasiado alto, por lo que puede ser recomendable reducir el valor de \texttt{nodesize}, paralelizar los cálculos o emplear otros paquetes con implementaciones más eficientes.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{rf.caret }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{method =} \StringTok{"rf"}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(rf.caret)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{03-bagging_boosting_files/figure-latex/rf-caret-train-1} 

}

\caption{Evolución de la precisión de un bosque aleatorio dependiendo del número de predictores seleccionados.}\label{fig:rf-caret-train}
\end{figure}

\protect\hyperlink{ref-breiman2001random}{Breiman} (\protect\hyperlink{ref-breiman2001random}{2001a}) sugiere emplear el valor por defecto para \texttt{mtry}, la mitad y el doble (ver Figura \ref{fig:rf-caret-grid}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtry.class }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{ncol}\NormalTok{(train) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
\NormalTok{tuneGrid }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{mtry =} \FunctionTok{floor}\NormalTok{(}\FunctionTok{c}\NormalTok{(mtry.class}\SpecialCharTok{/}\DecValTok{2}\NormalTok{, mtry.class, }\DecValTok{2}\SpecialCharTok{*}\NormalTok{mtry.class)))}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{rf.caret }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train,}
                  \AttributeTok{method =} \StringTok{"rf"}\NormalTok{, }\AttributeTok{tuneGrid =}\NormalTok{ tuneGrid)}
\FunctionTok{plot}\NormalTok{(rf.caret)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{03-bagging_boosting_files/figure-latex/rf-caret-grid-1} 

}

\caption{Evolución de la precisión de un bosque aleatorio con `caret` usando el argumento `tuneGrid`.}\label{fig:rf-caret-grid}
\end{figure}

\begin{exercise}
\protect\hypertarget{exr:rf-tunegrid}{}{\label{exr:rf-tunegrid} }
\end{exercise}

Como acabamos de ver, \texttt{caret} permite ajustar un bosque aleatorio considerando \texttt{mtry} como único hiperparámetro, pero nos podría interesar buscar también valores adecuados para otros parámetros, como por ejemplo \texttt{nodesize}.
Esto se puede realizar fácilmente empleando directamente la función \texttt{randomForest()}.
En primer lugar habría que construir la rejilla de búsqueda, con las combinaciones de los valores de los hiperparámetros que se quieren evaluar (para ello se puede utilizar la función \texttt{expand.grid()}).
Posteriormente se ajustaría un bosque aleatorio en la muestra de entrenamiento con cada una de las combinaciones (por ejemplo utilizando un bucle \texttt{for}) y se emplearía el error OOB para seleccionar la combinación óptima (al que podemos acceder empleando \texttt{with(fit,\ err.rate{[}ntree,\ "OOB"{]})} suponiendo que \texttt{fit} contiene el bosque aleatorio ajustado).

Continuando con el mismo conjunto de datos de calidad de vino, emplear la función \texttt{randomForest()} para ajustar un bosque aleatorio con el fin de clasificar la calidad del vino \texttt{taste}, considerando 500 árboles y empleando el error OOB para seleccionar los valores ``óptimos'' de los hiperparámetros considerando las posibles combinaciones de \texttt{mtry\ =\ floor(c(mtry.class/2,\ mtry.class,\ 2*mtry.class))} (siendo \texttt{mtry.class\ \textless{}-\ sqrt(ncol(train)\ -\ 1)}) y \texttt{nodesize\ =\ c(1,\ 3,\ 5,\ 10)}.

\hypertarget{boosting}{%
\section{Boosting}\label{boosting}}

La metodología \emph{boosting} es una metodología general de aprendizaje lento en la que se combinan muchos modelos obtenidos mediante un método con poca capacidad predictiva para, \emph{impulsados}, dar lugar a un mejor predictor. Los árboles de decisión pequeños (construidos con poca profundidad) resultan perfectos para esta tarea, al ser realmente malos predictores (\emph{weak learners}), fáciles de combinar y generarse de forma muy rápida.

El boosting nació en el contexto de los problemas de clasificación y tardó varios años en poderse extender a los problemas de regresión. Por ese motivo vamos a empezar viendo el boosting en clasificación.

La idea del boosting la desarrollaron \protect\hyperlink{ref-valiant1984theory}{Valiant} (\protect\hyperlink{ref-valiant1984theory}{1984}) y \protect\hyperlink{ref-kearns_cryptographic_1994}{Kearns y Valiant} (\protect\hyperlink{ref-kearns_cryptographic_1994}{1994}), pero encontrar una implementación efectiva fue una tarea difícil que no se resolvió satisfactoriamente hasta que \protect\hyperlink{ref-freund1996schapire}{Freund y Schapire} (\protect\hyperlink{ref-freund1996schapire}{1996}) presentaron el algoritmo \emph{AdaBoost}, que rápidamente se convirtió en un éxito.

Veamos, de forma muy esquemática, en que consiste el algoritmo AdaBoost para un problema de clasificación en el que sólo hay dos categorías y en el que se utiliza como clasificador débil un árbol de decisión con pocos nodos terminales, sólo marginalmente superior a un clasificador aleatorio.
En este caso resulta más cómodo recodificar la variable indicadora \(Y\) como 1 si éxito y -1 si fracaso.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Seleccionar \(B\), número de iteraciones.
\item
  Se les asigna el mismo peso a todas las observaciones de la muestra de entrenamiento (\(1/n\)).
\item
  Para \(b = 1, 2,\ldots, B\), repetir:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    Ajustar el árbol utilizando las observaciones ponderadas.
  \item
    Calcular la proporción de errores en la clasificación \(e_b\).
  \item
    Calcular \(s_b = \text{log}((1 - e_b)/e_b)\).
  \item
    Actualizar los pesos de las observaciones. Los pesos de las observaciones correctamente clasificadas no cambian; se les da más peso a las observaciones incorrectamente clasificadas, multiplicando su peso anterior por \((1 - e_b)/e_b\).
  \end{enumerate}
\item
  Dada una observación \(\mathbf{x}\), si denotamos por \(\hat y_b ( \mathbf{x} )\) su clasificación utilizando árbol \(b\)-ésimo, entonces \(\hat y( \mathbf{x} ) = signo \left( \sum_b s_b \hat y_b ( \mathbf{x} ) \right)\) (si la suma es positiva, se clasifica la observación como perteneciente a la clase +1, en caso contrario a la clase -1).
\end{enumerate}

Vemos que el algoritmo AdaBoost no combina árboles independientes (como sería el caso de los bosques aleatorios, por ejemplo), sino que estos se van generando en una secuencia en la que cada árbol depende del anterior. Se utiliza siempre el mismo conjunto de datos (de entrenamiento), pero a estos datos se les van poniendo unos pesos en cada iteración que dependen de lo que ha ocurrido en la iteración anterior: se les da más peso a las observaciones mal clasificadas para que en sucesivas iteraciones se clasifiquen bien. Finalmente, la combinación de los árboles se hace mediante una suma ponderada de las \(B\) clasificaciones realizadas. Los pesos de esta suma son los valores \(s_b\). Un árbol que clasifique de forma aleatoria \(e_b = 0.5\) va a tener un peso \(s_b = 0\) y cuando mejor clasifique el árbol mayor será su peso. Al estar utilizando clasificadores débiles (árboles pequeños) es de esperar que los pesos sean en general próximos a cero.

El siguiente hito fue la aparición del método \emph{gradient boosting machine} (\protect\hyperlink{ref-friedman2001greedy}{Friedman, 2001}), perteneciente a la familia de los métodos iterativos de descenso de gradientes.
Entre otras muchas ventajas, este método permitió resolver no sólo problemas de clasificación sino también de regresión; y permitió la conexión con lo que se estaba haciendo en otros campos próximos como pueden ser los modelos aditivos o la regresión logística.
La idea es encontrar un modelo aditivo que minimice una función de perdida utilizando predictores débiles (por ejemplo árboles).

Si como función de pérdida se utiliza RSS, entonces la pérdida de utilizar \(m(x)\) para predecir \(y\) en los datos de entrenamiento es \[L(m) = \sum_{i=1}^n L(y_i, m(x_i)) = \sum_{i=1}^n (y_i - m(x_i))^2\]

Se desea minimizar \(L(m)\) con respecto a \(m\) mediante el método de los gradientes, pero estos son precisamente los residuos: si \(L(m)= \frac{1}{2} (y_i - m(x_i))^2\), entonces
\[- \frac{\partial L(y_i, m(x_i))} {\partial m(x_i)} = y_i - m(x_i) = r_i\]
Una ventaja de esta aproximación es que puede extenderse a otras funciones de pérdida, por ejemplo si hay valores atípicos se puede considerar como función de pérdida el error absoluto.

Veamos el algoritmo para un problema de regresión utilizando árboles de decisión. Es un proceso iterativo en el que lo que se \emph{ataca} no son los datos directamente, sino los residuos (gradientes) que van quedando con los sucesivos ajustes, siguiendo una idea greedy (la optimización se resuelve en cada iteración, no globalmente).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Seleccionar el número de iteraciones \(B\), el parámetro de regularización \(\lambda\) y el número de cortes de cada árbol \(d\).
\item
  Establecer una predicción inicial constante y calcular los residuos de los datos \(i\) de la muestra de entrenamiento: \[\hat m (x) = 0, \ r_i = y_i\]
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Para \(b = 1, 2,\ldots, B\), repetir:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    Ajustar un árbol de regresión \(\hat m^b\) con \(d\) cortes utilizando los residuos como respuesta: \((X, r)\).
  \item
    Calcular la versión regularizada del árbol:
    \[\lambda \hat m^b (x)\]
  \item
    Actualizar los residuos:
    \[r_i \leftarrow r_i - \lambda \hat m^b (x_i)\]
  \end{enumerate}
\item
  Calcular el modelo boosting:
  \[\hat m (x) = \sum_{b=1}^{B} \lambda \hat m^b (x)\]
\end{enumerate}

Comprobamos que este método depende de 3 hiperparámetros, \(B\), \(d\) y \(\lambda\), susceptibles de ser seleccionados de forma \emph{óptima}:

\begin{itemize}
\item
  \(B\) es el número de árboles. Un valor muy grande podría llegar a provocar un sobreajuste (algo que no ocurre ni con bagging ni con bosques aleatorios, ya que estos son métodos en los que se construyen árboles independientes). En cada iteración, el objetivo es ajustar de forma óptima el gradiente (en nuestro caso, los residuos), pero este enfoque greedy no garantiza el óptimo global y puede dar lugar a sobreajustes.
\item
  Al ser necesario que el aprendizaje sea lento se utilizan árboles muy pequeños. Esto consigue que poco a poco se vayan cubriendo las zonas en las que es más difícil predecir bien. En muchas situaciones funciona bien utilizar \(d = 1\), es decir, con un único corte. En este caso en cada \(\hat m^b\) interviene una única variable, y por tanto \(\hat m\) es un ajuste de un modelo aditivo. Si \(d>1\) se puede interpretar como un parámetro que mide el órden de interacción entre las variables.
\item
  \(0 < \lambda < 1\), parámetro de regularización. Las primeras versiones del algorimo utilizaban un \(\lambda = 1\), pero no funcionaba bien del todo. Se mejoró mucho el rendimiento \emph{ralentizando} aún más el aprendizaje al incorporar al modelo el parámetro \(\lambda\), que se puede interpretar como una proporción de aprendizaje (la velocidad a la que aprende, \emph{learning rate}). Valores pequeños de \(\lambda\) evitan el problema del sobreajuste, siendo habitual utilizar \(\lambda = 0.01\) o \(\lambda = 0.001\). Como ya se ha dicho, lo ideal es seleccionar su valor utilizando, por ejemplo, validación cruzada. Por supuesto, cuanto más pequeño sea el valor de \(\lambda\), más lento va a ser el proceso de aprendizaje y serán necesarias más iteraciones, lo cual incrementa los tiempos de cómputo.
\end{itemize}

El propio Friedman propuso una mejora de su algoritmo (\protect\hyperlink{ref-friedman2002stochastic}{Friedman, 2002}), inspirado por la técnica bagging de Breiman. Esta variante, conocida como \emph{stochastic gradient boosting} (SGB), es a día de hoy una de las más utilizadas.
La única diferencia respecto al algoritmo anterior es en la primera línea dentro del bucle: al hacer el ajuste de \((X, r)\), no se considera toda la muestra de entrenamiento, sino que se selecciona al azar un subconjunto.
Esto incorpora un nuevo hiperparámetro a la metodología, la fracción que se utiliza de los datos.
Lo ideal es seleccionar un valor por algún método automático (\emph{tunearlo}) tipo validación cruzada; una selección manual típica es 0.5.
Hay otras variantes, como por ejemplo la selección aleatoria de predictores antes de crecer cada árbol o antes de cada corte (ver por ejemplo la documentación de \href{http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/gbm.html}{\texttt{h2o::gbm}}).

Este sería un ejemplo de un método con muchos hiperparámetros y diseñar una buena estrategia para ajustarlos (\emph{tunearlos}) puede resultar mucho más complicado (puede haber problemas de mínimos locales, problemas computacionales, etc.).

SGB incorpora dos ventajas importantes: reduce la varianza y reduce los tiempos de cómputo.
En terminos de rendimiento tanto el método SGB como \emph{random forest} son muy competitivos, y por tanto son muy utilizando en la práctica.
Los bosques aleatorios tienen la ventaja de que, al construir árboles de forma independiente, es paralelizable y eso puede reducir los tiempos de cómputo.

Otro método reciente que está ganando popularidad es \emph{extreme gradient boosting}, también conocido como \emph{XGBoost} (\protect\hyperlink{ref-chen2016xgboost}{Chen y Guestrin, 2016}).
Es un metodo más complejo que el anterior que, entre otras modificaciones, utiliza una función de pérdida con una penalización por complejidad y, para evitar el sobreajuste, regulariza utilizando la hessiana de la función de pérdida (necesita calcular las derivadas parciales de primer y de segundo orden), e incorpora parámetros de regularización adicionales para evitar el sobreajuste.

Por último, la importancia de las variables se puede medir de forma similar a lo que ya hemos visto en otros métodos: dentro de cada árbol se sumas las reducciones del error que consigue cada predictor, y se promedia entre todos los árboles utilizados.

En resumen:

\begin{itemize}
\item
  La idea es hacer un ``aprendizaje lento''.
\item
  Los arboles se crecen de forma secuencial, se trata de mejorar la
  clasificación anterior.
\item
  Se utilizan arboles pequeños.
\item
  A diferencia de bagging y bosques aleatorios puede haber problemas de sobreajuste (si el número de árboles es grande y la tasa de aprendizaje es alta).
\item
  Se puede pensar que se ponderan las observaciones iterativamente, se
  asigna más peso a las que resultaron más difíciles de clasificar.
\item
  El modelo final es un modelo aditivo (media ponderada de los
  árboles).
\end{itemize}

\hypertarget{boosting-en-r}{%
\section{Boosting en R}\label{boosting-en-r}}

Estos métodos son también de los más populares en AE y están implementados en numerosos paquetes de R: \href{https://CRAN.R-project.org/package=ada}{\texttt{ada}}, \href{https://CRAN.R-project.org/package=adabag}{\texttt{adabag}}, \href{https://CRAN.R-project.org/package=mboost}{\texttt{mboost}}, \href{https://CRAN.R-project.org/package=gbm}{\texttt{gbm}}, \href{https://github.com/dmlc/xgboost/tree/master/R-package}{\texttt{xgboost}}\ldots{}

\hypertarget{ejemplo-clasificaciuxf3n-con-el-paquete-ada}{%
\subsection{\texorpdfstring{Ejemplo: clasificación con el paquete \texttt{ada}}{Ejemplo: clasificación con el paquete ada}}\label{ejemplo-clasificaciuxf3n-con-el-paquete-ada}}

La función \texttt{ada()} del paquete \href{https://CRAN.R-project.org/package=ada}{\texttt{ada}} (\protect\hyperlink{ref-culp2006ada}{Culp et~al., 2006}) implementa diversos métodos boosting (incluyendo el algoritmo original AdaBoost).
Emplea \texttt{rpart} para la construcción de los árboles, aunque solo admite respuestas dicotómicas y dos funciones de pérdida (exponencial y logística).
Además, un posible problema al emplear esta función es que ordena alfabéticamente los niveles del factor, lo que puede llevar a una mala interpretación de los resultados.

Los principales parámetros son los siguientes:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ada}\NormalTok{(formula, data, }\AttributeTok{loss =} \FunctionTok{c}\NormalTok{(}\StringTok{"exponential"}\NormalTok{, }\StringTok{"logistic"}\NormalTok{),}
    \AttributeTok{type =} \FunctionTok{c}\NormalTok{(}\StringTok{"discrete"}\NormalTok{, }\StringTok{"real"}\NormalTok{, }\StringTok{"gentle"}\NormalTok{), }\AttributeTok{iter =} \DecValTok{50}\NormalTok{, }
    \AttributeTok{nu =} \FloatTok{0.1}\NormalTok{, }\AttributeTok{bag.frac =} \FloatTok{0.5}\NormalTok{, ...)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\item
  \texttt{formula} y \texttt{data} (opcional): permiten especificar la respuesta y las variables predictoras de la forma habitual (típicamente \texttt{respuesta\ \textasciitilde{}\ .}; también admite matrices \texttt{x} e \texttt{y} en lugar de fórmulas).
\item
  \texttt{loss}: función de pérdida; por defecto \texttt{"exponential"} (algoritmo AdaBoost).
\item
  \texttt{type}: algoritmo boosting; por defecto \texttt{"discrete"} que implementa el algoritmo AdaBoost original que predice la variable respuesta. Otras alternativas son \texttt{"real"}, que implementa el algoritmo \emph{Real AdaBoost} (\protect\hyperlink{ref-friedman2000additive}{J. Friedman et~al., 2000}) que permite estimar las probabilidades, y \texttt{"gentle"} , versión modificada del anterior que emplea un método Newton de optimización por pasos (en lugar de optimización exacta).
\item
  \texttt{iter}: número de iteraciones boosting; por defecto 50.
\item
  \texttt{nu}: parámetro de regularización \(\lambda\); por defecto 0.1 (disminuyendo este parámetro es de esperar que se obtenga una mejora en la precisión de las predicciones pero requería aumentar \texttt{iter} aumentando notablemente el tiempo de computación y los requerimientos de memoria).
\item
  \texttt{bag.frac}: proporción de observaciones seleccionadas al azar para crecer cada árbol; por defecto 0.5.
\item
  \texttt{...}: argumentos adicionales para \texttt{rpart.control}; por defecto \texttt{rpart.control(maxdepth\ =\ 1,\ cp\ =\ -1,\ minsplit\ =\ 0,\ xval\ =\ 0)}.
\end{itemize}

Como ejemplo consideraremos el conjunto de datos de calidad de vino empleado en las secciones \ref{class-rpart} y \ref{bagging-rf-r}, pero para evitar problemas reordenamos alfabéticamente los niveles de la respuesta.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"data/winetaste.RData"}\NormalTok{)}
\CommentTok{\# Reordenar alfabéticamente los niveles de winetaste$taste}
\CommentTok{\# winetaste$taste \textless{}{-} factor(winetaste$taste, sort(levels(winetaste$taste)))}
\NormalTok{winetaste}\SpecialCharTok{$}\NormalTok{taste }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(}\FunctionTok{as.character}\NormalTok{(winetaste}\SpecialCharTok{$}\NormalTok{taste))}
\CommentTok{\# Partición de los datos}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ winetaste}
\NormalTok{nobs }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(df)}
\NormalTok{itrain }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(nobs, }\FloatTok{0.8} \SpecialCharTok{*}\NormalTok{ nobs)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ df[itrain, ]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ df[}\SpecialCharTok{{-}}\NormalTok{itrain, ]}
\end{Highlighting}
\end{Shaded}

Por ejemplo, el siguiente código llama a la función \texttt{ada()} con la opción para estimar probabilidades (\texttt{type\ =\ "real"}, Real AdaBoost), considerando interacciones (de orden 2) entre los predictores (\texttt{maxdepth\ =\ 2}), disminuyendo ligeramente el valor del parámetro de aprendizaje y aumentando el número de iteraciones:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ada)}
\NormalTok{ada.boost }\OtherTok{\textless{}{-}} \FunctionTok{ada}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{type =} \StringTok{"real"}\NormalTok{,}
             \AttributeTok{control =} \FunctionTok{rpart.control}\NormalTok{(}\AttributeTok{maxdepth =} \DecValTok{2}\NormalTok{, }\AttributeTok{cp =} \DecValTok{0}\NormalTok{, }\AttributeTok{minsplit =} \DecValTok{10}\NormalTok{, }\AttributeTok{xval =} \DecValTok{0}\NormalTok{),}
             \AttributeTok{iter =} \DecValTok{100}\NormalTok{, }\AttributeTok{nu =} \FloatTok{0.05}\NormalTok{)}
\NormalTok{ada.boost}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call:
## ada(taste ~ ., data = train, type = "real", control = rpart.control(maxdepth = 2, 
##     cp = 0, minsplit = 10, xval = 0), iter = 100, nu = 0.05)
## 
## Loss: exponential Method: real   Iteration: 100 
## 
## Final Confusion Matrix for Data:
##           Final Prediction
## True value bad good
##       bad  162  176
##       good  46  616
## 
## Train Error: 0.222 
## 
## Out-Of-Bag Error:  0.233  iteration= 99 
## 
## Additional Estimates of number of iterations:
## 
## train.err1 train.kap1 
##         93         93
\end{verbatim}

Con el método \texttt{plot()} podemos representar la evolución del error de clasificación al aumentar el número de iteraciones (ver Figura \ref{fig:ada-plot}):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(ada.boost)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{03-bagging_boosting_files/figure-latex/ada-plot-1} 

}

\caption{Evolución de la tasa de error utilizando `ada()`.}\label{fig:ada-plot}
\end{figure}

Podemos evaluar la precisión en la muestra de test empleando el procedimiento habitual:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(ada.boost, }\AttributeTok{newdata =}\NormalTok{ test)}
\NormalTok{caret}\SpecialCharTok{::}\FunctionTok{confusionMatrix}\NormalTok{(pred, test}\SpecialCharTok{$}\NormalTok{taste, }\AttributeTok{positive =} \StringTok{"good"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction bad good
##       bad   34   16
##       good  50  150
##                                           
##                Accuracy : 0.736           
##                  95% CI : (0.6768, 0.7895)
##     No Information Rate : 0.664           
##     P-Value [Acc > NIR] : 0.008615        
##                                           
##                   Kappa : 0.3426          
##                                           
##  Mcnemar's Test P-Value : 4.865e-05       
##                                           
##             Sensitivity : 0.9036          
##             Specificity : 0.4048          
##          Pos Pred Value : 0.7500          
##          Neg Pred Value : 0.6800          
##              Prevalence : 0.6640          
##          Detection Rate : 0.6000          
##    Detection Prevalence : 0.8000          
##       Balanced Accuracy : 0.6542          
##                                           
##        'Positive' Class : good            
## 
\end{verbatim}

Para obtener las estimaciones de las probabilidades, habría que establecer \texttt{type\ =\ "probs"} al predecir (devolverá una matriz con columnas correspondientes a los niveles):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p.est }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(ada.boost, }\AttributeTok{newdata =}\NormalTok{ test, }\AttributeTok{type =} \StringTok{"probs"}\NormalTok{)}
\FunctionTok{head}\NormalTok{(p.est)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          [,1]      [,2]
## 1  0.49877103 0.5012290
## 4  0.30922187 0.6907781
## 9  0.02774336 0.9722566
## 10 0.04596187 0.9540381
## 12 0.44274407 0.5572559
## 16 0.37375910 0.6262409
\end{verbatim}

Este procedimiento también está implementado en el paquete \texttt{caret} seleccionando el método \texttt{"ada"}, que considera como hiperparámetros:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}
\FunctionTok{modelLookup}\NormalTok{(}\StringTok{"ada"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   model parameter          label forReg forClass probModel
## 1   ada      iter         #Trees  FALSE     TRUE      TRUE
## 2   ada  maxdepth Max Tree Depth  FALSE     TRUE      TRUE
## 3   ada        nu  Learning Rate  FALSE     TRUE      TRUE
\end{verbatim}

Aunque por defecto la función \texttt{train()} solo considera nueve combinaciones de hiperparámetros:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{caret.ada0 }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{method =} \StringTok{"ada"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ train,}
                   \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{number =} \DecValTok{5}\NormalTok{))}
\NormalTok{caret.ada0}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Boosted Classification Trees 
## 
## 1000 samples
##   11 predictor
##    2 classes: 'bad', 'good' 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 800, 801, 800, 800, 799 
## Resampling results across tuning parameters:
## 
##   maxdepth  iter  Accuracy   Kappa    
##   1          50   0.7100121  0.2403486
##   1         100   0.7220322  0.2824931
##   1         150   0.7360322  0.3346624
##   2          50   0.7529774  0.3872880
##   2         100   0.7539673  0.4019619
##   2         150   0.7559673  0.4142035
##   3          50   0.7570024  0.4112842
##   3         100   0.7550323  0.4150030
##   3         150   0.7650024  0.4408835
## 
## Tuning parameter 'nu' was held constant at a value of 0.1
## Accuracy was used to select the optimal model using the largest value.
## The final values used for the model were iter = 150, maxdepth = 3 and nu = 0.1.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{predict}\NormalTok{(caret.ada0, }\AttributeTok{newdata =}\NormalTok{ test), test}\SpecialCharTok{$}\NormalTok{taste, }\AttributeTok{positive =} \StringTok{"good"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction bad good
##       bad   37   22
##       good  47  144
##                                           
##                Accuracy : 0.724           
##                  95% CI : (0.6641, 0.7785)
##     No Information Rate : 0.664           
##     P-Value [Acc > NIR] : 0.024724        
##                                           
##                   Kappa : 0.3324          
##                                           
##  Mcnemar's Test P-Value : 0.003861        
##                                           
##             Sensitivity : 0.8675          
##             Specificity : 0.4405          
##          Pos Pred Value : 0.7539          
##          Neg Pred Value : 0.6271          
##              Prevalence : 0.6640          
##          Detection Rate : 0.5760          
##    Detection Prevalence : 0.7640          
##       Balanced Accuracy : 0.6540          
##                                           
##        'Positive' Class : good            
## 
\end{verbatim}

Se puede aumentar el número de combinaciones empleando \texttt{tuneLength} o \texttt{tuneGrid} pero la búsqueda en una rejilla completa puede incrementar considerablemente el tiempo de computación.
Por este motivo se suelen seguir distintos procedimientos de búsqueda. Por ejemplo, fijar la tasa de aprendizaje (inicialmente a un valor alto) para seleccionar primero un número de interaciones y la complejidad del árbol, y posteriormente fijar estos valores para seleccionar una nueva tasa de aprendizaje (repitiendo el proceso, si es necesario, hasta convergencia).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{caret.ada1 }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{method =} \StringTok{"ada"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ train,}
                    \AttributeTok{tuneGrid =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{iter =}  \DecValTok{150}\NormalTok{, }\AttributeTok{maxdepth =} \DecValTok{3}\NormalTok{,}
                                 \AttributeTok{nu =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{0.05}\NormalTok{, }\FloatTok{0.01}\NormalTok{, }\FloatTok{0.005}\NormalTok{)),}
                   \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{number =} \DecValTok{5}\NormalTok{))}
\NormalTok{caret.ada1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Boosted Classification Trees 
## 
## 1000 samples
##   11 predictor
##    2 classes: 'bad', 'good' 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 800, 801, 800, 800, 799 
## Resampling results across tuning parameters:
## 
##   nu     Accuracy   Kappa    
##   0.005  0.7439722  0.3723405
##   0.010  0.7439822  0.3725968
##   0.050  0.7559773  0.4116753
##   0.100  0.7619774  0.4365242
##   0.300  0.7580124  0.4405127
## 
## Tuning parameter 'iter' was held constant at a value of 150
## Tuning
##  parameter 'maxdepth' was held constant at a value of 3
## Accuracy was used to select the optimal model using the largest value.
## The final values used for the model were iter = 150, maxdepth = 3 and nu = 0.1.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{predict}\NormalTok{(caret.ada1, }\AttributeTok{newdata =}\NormalTok{ test), test}\SpecialCharTok{$}\NormalTok{taste, }\AttributeTok{positive =} \StringTok{"good"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction bad good
##       bad   40   21
##       good  44  145
##                                          
##                Accuracy : 0.74           
##                  95% CI : (0.681, 0.7932)
##     No Information Rate : 0.664          
##     P-Value [Acc > NIR] : 0.005841       
##                                          
##                   Kappa : 0.375          
##                                          
##  Mcnemar's Test P-Value : 0.006357       
##                                          
##             Sensitivity : 0.8735         
##             Specificity : 0.4762         
##          Pos Pred Value : 0.7672         
##          Neg Pred Value : 0.6557         
##              Prevalence : 0.6640         
##          Detection Rate : 0.5800         
##    Detection Prevalence : 0.7560         
##       Balanced Accuracy : 0.6748         
##                                          
##        'Positive' Class : good           
## 
\end{verbatim}

\hypertarget{ejemplo-regresiuxf3n-con-el-paquete-gbm}{%
\subsection{\texorpdfstring{Ejemplo: regresión con el paquete \texttt{gbm}}{Ejemplo: regresión con el paquete gbm}}\label{ejemplo-regresiuxf3n-con-el-paquete-gbm}}

El paquete \href{https://CRAN.R-project.org/package=gbm}{\texttt{gbm}} implementa el algoritmo SGB de \protect\hyperlink{ref-friedman2002stochastic}{Friedman} (\protect\hyperlink{ref-friedman2002stochastic}{2002}) y admite varios tipos de respuesta considerando distintas funciones de pérdida (aunque en el caso de variables dicotómicas éstas deben tomar valores en \(\{0, 1\}\)\footnote{Se puede evitar este inconveniente empleando la interfaz de \texttt{caret}.}).
La función principal es \texttt{gbm()} y se suelen considerar los siguientes argumentos:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{gbm}\NormalTok{( formula, }\AttributeTok{distribution =} \StringTok{"bernoulli"}\NormalTok{, data, }\AttributeTok{n.trees =} \DecValTok{100}\NormalTok{, }
     \AttributeTok{interaction.depth =} \DecValTok{1}\NormalTok{, }\AttributeTok{n.minobsinnode =} \DecValTok{10}\NormalTok{,}
     \AttributeTok{shrinkage =} \FloatTok{0.1}\NormalTok{, }\AttributeTok{bag.fraction =} \FloatTok{0.5}\NormalTok{, }
     \AttributeTok{cv.folds =} \DecValTok{0}\NormalTok{, }\AttributeTok{n.cores =} \ConstantTok{NULL}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\item
  \texttt{formula} y \texttt{data} (opcional): permiten especificar la respuesta y las variables predictoras de la forma habitual (típicamente \texttt{respuesta\ \textasciitilde{}\ .}; también está disponible una interfaz con matrices \texttt{gbm.fit()}).
\item
  \texttt{distribution} (opcional): texto con el nombre de la distribución (o lista con el nombre en \texttt{name} y parámetros adicionales en los demás componentes) que determina la función de pérdida.
  Si se omite se establecerá a partir del tipo de la respuesta: \texttt{"bernouilli"} (regresión logística) si es una variable dicotómica 0/1, \texttt{"multinomial"} (regresión multinomial) si es un factor (no se recomienda) y \texttt{"gaussian"} (error cuadrático) en caso contrario.
  Otras opciones que pueden ser de interés son: \texttt{"laplace"} (error absoluto), \texttt{"adaboost"} (pérdida exponencial para respuestas dicotómicas 0/1), \texttt{"huberized"} (pérdida de Huber para respuestas dicotómicas 0/1), \texttt{"poisson"} (regresión de Poisson) y \texttt{"quantile"} (regresión cuantil).
\item
  \texttt{ntrees}: iteraciones/número de árboles que se crecerán; por defecto 100 (se puede emplear la función \texttt{gbm.perf()} para seleccionar un valor ``óptimo'').
\item
  \texttt{interaction.depth}: profundidad de los árboles; por defecto 1 (modelo aditivo).
\item
  \texttt{n.minobsinnode}: número mínimo de observaciones en un nodo terminal; por defecto 10.
\item
  \texttt{shrinkage}: parámetro de regularización \(\lambda\); por defecto 0.1.
\item
  \texttt{bag.fraction}: proporción de observaciones seleccionadas al azar para crecer cada árbol; por defecto 0.5.
\item
  \texttt{cv.folds}: número grupos para validación cruzada; por defecto 0 (no se hace validación cruzada). Si se asigna un valor mayor que 1 se realizará validación cruzada y se devolverá el error en la componente \texttt{\$cv.error} (se puede emplear para seleccionar hiperparámetros).
\item
  \texttt{n.cores}: número de núcleos para el procesamiento en paralelo.
\end{itemize}

Como ejemplo consideraremos el conjunto de datos \emph{winequality.RData}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"data/winequality.RData"}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ winequality}
\NormalTok{nobs }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(df)}
\NormalTok{itrain }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(nobs, }\FloatTok{0.8} \SpecialCharTok{*}\NormalTok{ nobs)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ df[itrain, ]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ df[}\SpecialCharTok{{-}}\NormalTok{itrain, ]}

\FunctionTok{library}\NormalTok{(gbm)}
\NormalTok{gbm.fit }\OtherTok{\textless{}{-}} \FunctionTok{gbm}\NormalTok{(quality }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Distribution not specified, assuming gaussian ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbm.fit}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## gbm(formula = quality ~ ., data = train)
## A gradient boosted model with gaussian loss function.
## 100 iterations were performed.
## There were 11 predictors of which 11 had non-zero influence.
\end{verbatim}

El método \texttt{summary()} calcula las medidas de influencia de los predictores y las representa gráficamente (ver Figura \ref{fig:gbm-summary}):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(gbm.fit)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{03-bagging_boosting_files/figure-latex/gbm-summary-1} 

}

\caption{Importancia de las variables predictoras (con los valores por defecto de `gbm()`).}\label{fig:gbm-summary}
\end{figure}

\begin{verbatim}
##                                       var   rel.inf
## alcohol                           alcohol 40.907998
## volatile.acidity         volatile.acidity 13.839083
## free.sulfur.dioxide   free.sulfur.dioxide 11.488262
## fixed.acidity               fixed.acidity  7.914742
## citric.acid                   citric.acid  6.765875
## total.sulfur.dioxide total.sulfur.dioxide  4.808308
## residual.sugar             residual.sugar  4.758566
## chlorides                       chlorides  3.424537
## sulphates                       sulphates  3.086036
## density                           density  1.918442
## pH                                     pH  1.088152
\end{verbatim}

Para estudiar el efecto de un predictor se pueden generar gráficos de los efectos parciales mediante el método \texttt{plot()} (ver Figura \ref{fig:gbm-plot}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OtherTok{\textless{}{-}} \FunctionTok{plot}\NormalTok{(gbm.fit, }\AttributeTok{i =} \FunctionTok{c}\NormalTok{(}\StringTok{"alcohol"}\NormalTok{))}
\NormalTok{p2 }\OtherTok{\textless{}{-}} \FunctionTok{plot}\NormalTok{(gbm.fit, }\AttributeTok{i =} \FunctionTok{c}\NormalTok{(}\StringTok{"density"}\NormalTok{))}
\FunctionTok{grid.arrange}\NormalTok{(p1, p2, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.9\linewidth]{03-bagging_boosting_files/figure-latex/gbm-plot-1} 

}

\caption{Efecto parcíal del alcohol (panel izquierdo) y la densidad (panel derecho) sobre la respuesta (con `gbm()`).}\label{fig:gbm-plot}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot(gbm.fit, i = c("alcohol","density")) \# interacción}
\end{Highlighting}
\end{Shaded}

Finalmente podemos evaluar la precisión en la muestra de test empleando el código habitual:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(gbm.fit, }\AttributeTok{newdata =}\NormalTok{ test)}
\NormalTok{obs }\OtherTok{\textless{}{-}}\NormalTok{ test}\SpecialCharTok{$}\NormalTok{quality}

\CommentTok{\# Con el paquete caret}
\NormalTok{caret}\SpecialCharTok{::}\FunctionTok{postResample}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      RMSE  Rsquared       MAE 
## 0.7586208 0.3001401 0.6110442
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Con la función accuracy()}
\NormalTok{accuracy }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(pred, obs, }\AttributeTok{na.rm =} \ConstantTok{FALSE}\NormalTok{,}
                     \AttributeTok{tol =} \FunctionTok{sqrt}\NormalTok{(.Machine}\SpecialCharTok{$}\NormalTok{double.eps)) \{}
\NormalTok{  err }\OtherTok{\textless{}{-}}\NormalTok{ obs }\SpecialCharTok{{-}}\NormalTok{ pred     }\CommentTok{\# Errores}
  \ControlFlowTok{if}\NormalTok{(na.rm) \{}
\NormalTok{    is.a }\OtherTok{\textless{}{-}} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(err)}
\NormalTok{    err }\OtherTok{\textless{}{-}}\NormalTok{ err[is.a]}
\NormalTok{    obs }\OtherTok{\textless{}{-}}\NormalTok{ obs[is.a]}
\NormalTok{  \}}
\NormalTok{  perr }\OtherTok{\textless{}{-}} \DecValTok{100}\SpecialCharTok{*}\NormalTok{err}\SpecialCharTok{/}\FunctionTok{pmax}\NormalTok{(obs, tol)  }\CommentTok{\# Errores porcentuales}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
    \AttributeTok{me =} \FunctionTok{mean}\NormalTok{(err),           }\CommentTok{\# Error medio}
    \AttributeTok{rmse =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{(err}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)), }\CommentTok{\# Raíz del error cuadrático medio}
    \AttributeTok{mae =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(err)),     }\CommentTok{\# Error absoluto medio}
    \AttributeTok{mpe =} \FunctionTok{mean}\NormalTok{(perr),         }\CommentTok{\# Error porcentual medio}
    \AttributeTok{mape =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(perr)),   }\CommentTok{\# Error porcentual absoluto medio}
    \AttributeTok{r.squared =} \DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{sum}\NormalTok{(err}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{sum}\NormalTok{((obs }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(obs))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{  ))}
\NormalTok{\}}
\FunctionTok{accuracy}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          me        rmse         mae         mpe        mape   r.squared 
## -0.01463661  0.75862081  0.61104421 -2.00702056 10.69753668  0.29917590
\end{verbatim}

Este procedimiento también está implementado en el paquete \texttt{caret} seleccionando el método \texttt{"gbm"}, que considera como hiperparámetros:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}
\FunctionTok{modelLookup}\NormalTok{(}\StringTok{"gbm"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   model         parameter                   label forReg forClass probModel
## 1   gbm           n.trees   # Boosting Iterations   TRUE     TRUE      TRUE
## 2   gbm interaction.depth          Max Tree Depth   TRUE     TRUE      TRUE
## 3   gbm         shrinkage               Shrinkage   TRUE     TRUE      TRUE
## 4   gbm    n.minobsinnode Min. Terminal Node Size   TRUE     TRUE      TRUE
\end{verbatim}

Aunque por defecto la función \texttt{train()} solo considera nueve combinaciones de hiperparámetros. Para hacer una búsqueda más completa se podría seguir un procedimiento análogo al empleado con el método anterior:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{caret.gbm0 }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(quality }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{method =} \StringTok{"gbm"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ train,}
                   \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{number =} \DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{caret.gbm0}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Stochastic Gradient Boosting 
## 
## 1000 samples
##   11 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 800, 801, 800, 800, 799 
## Resampling results across tuning parameters:
## 
##   interaction.depth  n.trees  RMSE       Rsquared   MAE      
##   1                   50      0.7464098  0.2917796  0.5949686
##   1                  100      0.7258319  0.3171046  0.5751816
##   1                  150      0.7247246  0.3197241  0.5719404
##   2                   50      0.7198195  0.3307665  0.5712468
##   2                  100      0.7175006  0.3332903  0.5647409
##   2                  150      0.7258174  0.3222006  0.5713116
##   3                   50      0.7241661  0.3196365  0.5722590
##   3                  100      0.7272094  0.3191252  0.5754363
##   3                  150      0.7311429  0.3152905  0.5784988
## 
## Tuning parameter 'shrinkage' was held constant at a value of 0.1
## 
## Tuning parameter 'n.minobsinnode' was held constant at a value of 10
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were n.trees = 100, interaction.depth =
##  2, shrinkage = 0.1 and n.minobsinnode = 10.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{caret.gbm1 }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(quality }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{method =} \StringTok{"gbm"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ train,}
   \AttributeTok{tuneGrid =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{n.trees =}  \DecValTok{100}\NormalTok{, }\AttributeTok{interaction.depth =} \DecValTok{2}\NormalTok{, }
                        \AttributeTok{shrinkage =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{0.05}\NormalTok{, }\FloatTok{0.01}\NormalTok{, }\FloatTok{0.005}\NormalTok{),}
                        \AttributeTok{n.minobsinnode =} \DecValTok{10}\NormalTok{),}
   \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{number =} \DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{caret.gbm1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Stochastic Gradient Boosting 
## 
## 1000 samples
##   11 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 800, 800, 801, 799, 800 
## Resampling results across tuning parameters:
## 
##   shrinkage  RMSE       Rsquared   MAE      
##   0.005      0.8154916  0.2419131  0.6245818
##   0.010      0.7844257  0.2602989  0.6128582
##   0.050      0.7206972  0.3275463  0.5707273
##   0.100      0.7124838  0.3407642  0.5631748
##   0.300      0.7720844  0.2613835  0.6091765
## 
## Tuning parameter 'n.trees' was held constant at a value of 100
## Tuning
##  parameter 'interaction.depth' was held constant at a value of 2
## 
## Tuning parameter 'n.minobsinnode' was held constant at a value of 10
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were n.trees = 100, interaction.depth =
##  2, shrinkage = 0.1 and n.minobsinnode = 10.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{varImp}\NormalTok{(caret.gbm1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## gbm variable importance
## 
##                       Overall
## alcohol              100.0000
## volatile.acidity      28.4909
## free.sulfur.dioxide   24.5158
## residual.sugar        16.8406
## fixed.acidity         12.5623
## density               10.1917
## citric.acid            9.1542
## total.sulfur.dioxide   7.2659
## chlorides              4.5106
## pH                     0.1096
## sulphates              0.0000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{postResample}\NormalTok{(}\FunctionTok{predict}\NormalTok{(caret.gbm1, }\AttributeTok{newdata =}\NormalTok{ test), test}\SpecialCharTok{$}\NormalTok{quality)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      RMSE  Rsquared       MAE 
## 0.7403768 0.3329751 0.6017281
\end{verbatim}

\hypertarget{ejemplo-xgboost-con-el-paquete-caret}{%
\subsection{\texorpdfstring{Ejemplo: XGBoost con el paquete \texttt{caret}}{Ejemplo: XGBoost con el paquete caret}}\label{ejemplo-xgboost-con-el-paquete-caret}}

El método boosting implementado en el paquete \href{https://github.com/dmlc/xgboost/tree/master/R-package}{\texttt{xgboost}} es uno de los más populares hoy en día.
Esta implementación proporciona parámetros adicionales de regularización para controlar la complejidad del modelo y tratar de evitar el sobreajuste.
También incluye criterios de parada, para detener la evaluación del modelo cuando los árboles adicionales no ofrecen ninguna mejora.
Dispone de una interfaz simple \texttt{xgboost()} y otra más avanzada \texttt{xgb.train()}, que admite funciones de pérdida y evaluación personalizadas.
Normalmente es necesario un preprocesado de los datos antes de llamar a estas funciones, ya que requieren de una matriz para los predictores y de un vector para la respuesta (además en el caso de que sea dicotómica debe tomar valores en \(\{0, 1\}\)). Por tanto es necesario recodificar las variables categóricas como numéricas.
Por este motivo puede ser preferible emplear la interfaz de \texttt{caret}.

El algoritmo estándar \emph{XGBoost}, que emplea árboles como modelo base, está implementado en el método \texttt{"xgbTree"} de \texttt{caret}\footnote{Otras alternativas son: \texttt{"xgbDART"} que también emplean árboles como modelo base, pero incluye el método DART (\protect\hyperlink{ref-vinayak2015dart}{Vinayak y Gilad-Bachrach, 2015}) para evitar sobreajuste (básicamente descarta árboles al azar en la secuencia), y\texttt{"xgbLinear"} que emplea modelos lineales.}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}
\CommentTok{\# names(getModelInfo("xgb"))}
\FunctionTok{modelLookup}\NormalTok{(}\StringTok{"xgbTree"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     model        parameter                          label forReg forClass
## 1 xgbTree          nrounds          # Boosting Iterations   TRUE     TRUE
## 2 xgbTree        max_depth                 Max Tree Depth   TRUE     TRUE
## 3 xgbTree              eta                      Shrinkage   TRUE     TRUE
## 4 xgbTree            gamma         Minimum Loss Reduction   TRUE     TRUE
## 5 xgbTree colsample_bytree     Subsample Ratio of Columns   TRUE     TRUE
## 6 xgbTree min_child_weight Minimum Sum of Instance Weight   TRUE     TRUE
## 7 xgbTree        subsample           Subsample Percentage   TRUE     TRUE
##   probModel
## 1      TRUE
## 2      TRUE
## 3      TRUE
## 4      TRUE
## 5      TRUE
## 6      TRUE
## 7      TRUE
\end{verbatim}

Este método considera los siguientes hiperparámetros:

\begin{itemize}
\item
  \texttt{"nrounds"}: número de iteraciones boosting.
\item
  \texttt{"max\_depth"}: profundidad máxima del árbol; por defecto 6.
\item
  \texttt{"eta"}: parámetro de regularización \(\lambda\); por defecto 0.3.
\item
  \texttt{"gamma"}: mínima reducción de la pérdida para hacer una partición adicional en un nodo del árbol; por defecto 0.
\item
  \texttt{"colsample\_bytree"}: proporción de predictores seleccionados al azar para crecer cada árbol; por defecto 1.
\item
  \texttt{"min\_child\_weight"}: suma mínima de peso (hessiana) para hacer una partición adicional en un nodo del árbol; por defecto 1.
\item
  \texttt{"subsample"}: proporción de observaciones seleccionadas al azar en cada iteración boosting; por defecto 1.
\end{itemize}

Para más información sobre parámetros adicionales se puede consultar la ayuda de \texttt{xgboost::xgboost()} o la lista detallada disponible en la Sección \href{https://xgboost.readthedocs.io/en/latest/parameter.html}{XGBoost Parameters} del \href{https://xgboost.readthedocs.io}{Manual de XGBoost}.

Como ejemplo consideraremos el problema de clasificación empleando el conjunto de datos de calidad de vino:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"data/winetaste.RData"}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ winetaste}
\NormalTok{nobs }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(df)}
\NormalTok{itrain }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(nobs, }\FloatTok{0.8} \SpecialCharTok{*}\NormalTok{ nobs)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ df[itrain, ]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ df[}\SpecialCharTok{{-}}\NormalTok{itrain, ]}
\end{Highlighting}
\end{Shaded}

En este caso la función \texttt{train()} considera por defecto 108 combinaciones de hiperparámetros y el tiempo de computación puede ser excesivo.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{caret.xgb }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{method =} \StringTok{"xgbTree"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ train,}
                   \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{number =} \DecValTok{5}\NormalTok{))}
\NormalTok{caret.xgb}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## eXtreme Gradient Boosting 
## 
## 1000 samples
##   11 predictor
##    2 classes: 'good', 'bad' 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 799, 801, 801, 799, 800 
## Resampling results across tuning parameters:
## 
##   eta  max_depth  colsample_bytree  subsample  nrounds  Accuracy   Kappa    
##   0.3  1          0.6               0.50        50      0.7479499  0.3997718
##   0.3  1          0.6               0.50       100      0.7509649  0.4226367
##   0.3  1          0.6               0.50       150      0.7480199  0.4142399
##   0.3  1          0.6               0.75        50      0.7389498  0.3775707
##   0.3  1          0.6               0.75       100      0.7499600  0.4178857
##   0.3  1          0.6               0.75       150      0.7519900  0.4194354
##   0.3  1          0.6               1.00        50      0.7479450  0.3933223
##   0.3  1          0.6               1.00       100      0.7439499  0.3946755
##   0.3  1          0.6               1.00       150      0.7479699  0.4054549
##   0.3  1          0.8               0.50        50      0.7279446  0.3514309
##   0.3  1          0.8               0.50       100      0.7379647  0.3901818
##   0.3  1          0.8               0.50       150      0.7289797  0.3702869
##   0.3  1          0.8               0.75        50      0.7419548  0.3853122
##   0.3  1          0.8               0.75       100      0.7419798  0.3939408
##   0.3  1          0.8               0.75       150      0.7490050  0.4119554
##   0.3  1          0.8               1.00        50      0.7469399  0.3903359
##   0.3  1          0.8               1.00       100      0.7469349  0.3994462
##   0.3  1          0.8               1.00       150      0.7429499  0.3930019
##   0.3  2          0.6               0.50        50      0.7469800  0.4072389
##   0.3  2          0.6               0.50       100      0.7560152  0.4315043
##   0.3  2          0.6               0.50       150      0.7470550  0.4202096
##   0.3  2          0.6               0.75        50      0.7419347  0.3991878
##   0.3  2          0.6               0.75       100      0.7419398  0.3985245
##   0.3  2          0.6               0.75       150      0.7408999  0.4048017
##   0.3  2          0.6               1.00        50      0.7529250  0.4183744
##   0.3  2          0.6               1.00       100      0.7559601  0.4332161
##   0.3  2          0.6               1.00       150      0.7439798  0.4082169
##   0.3  2          0.8               0.50        50      0.7479801  0.4039828
##   0.3  2          0.8               0.50       100      0.7439500  0.4017708
##   0.3  2          0.8               0.50       150      0.7409099  0.4002330
##   0.3  2          0.8               0.75        50      0.7549701  0.4309398
##   0.3  2          0.8               0.75       100      0.7469550  0.4077312
##   0.3  2          0.8               0.75       150      0.7529701  0.4282530
##   0.3  2          0.8               1.00        50      0.7509800  0.4151042
##   0.3  2          0.8               1.00       100      0.7479899  0.4164189
##   0.3  2          0.8               1.00       150      0.7439498  0.4044785
##   0.3  3          0.6               0.50        50      0.7529851  0.4322174
##   0.3  3          0.6               0.50       100      0.7479900  0.4200214
##   0.3  3          0.6               0.50       150      0.7499800  0.4307546
##   0.3  3          0.6               0.75        50      0.7499550  0.4263366
##   0.3  3          0.6               0.75       100      0.7519201  0.4321688
##   0.3  3          0.6               0.75       150      0.7459449  0.4177412
##   0.3  3          0.6               1.00        50      0.7529251  0.4220849
##   0.3  3          0.6               1.00       100      0.7519400  0.4237486
##   0.3  3          0.6               1.00       150      0.7519500  0.4294623
##   0.3  3          0.8               0.50        50      0.7510299  0.4327919
##   0.3  3          0.8               0.50       100      0.7519799  0.4405268
##   0.3  3          0.8               0.50       150      0.7619652  0.4559423
##   0.3  3          0.8               0.75        50      0.7470501  0.4131934
##   0.3  3          0.8               0.75       100      0.7479849  0.4129185
##   0.3  3          0.8               0.75       150      0.7509850  0.4261251
##   0.3  3          0.8               1.00        50      0.7449099  0.4008981
##   0.3  3          0.8               1.00       100      0.7610054  0.4422136
##   0.3  3          0.8               1.00       150      0.7569803  0.4382787
##   0.4  1          0.6               0.50        50      0.7370397  0.3774680
##   0.4  1          0.6               0.50       100      0.7340546  0.3874281
##   0.4  1          0.6               0.50       150      0.7490550  0.4204110
##   0.4  1          0.6               0.75        50      0.7330097  0.3695029
##   0.4  1          0.6               0.75       100      0.7269447  0.3595653
##   0.4  1          0.6               0.75       150      0.7409999  0.3999882
##   0.4  1          0.6               1.00        50      0.7389548  0.3787453
##   0.4  1          0.6               1.00       100      0.7479499  0.4061188
##   0.4  1          0.6               1.00       150      0.7410049  0.3940049
##   0.4  1          0.8               0.50        50      0.7269246  0.3647893
##   0.4  1          0.8               0.50       100      0.7459551  0.4088011
##   0.4  1          0.8               0.50       150      0.7359947  0.3910800
##   0.4  1          0.8               0.75        50      0.7369797  0.3798786
##   0.4  1          0.8               0.75       100      0.7329997  0.3808412
##   0.4  1          0.8               0.75       150      0.7410149  0.4007794
##   0.4  1          0.8               1.00        50      0.7429449  0.3889734
##   0.4  1          0.8               1.00       100      0.7549401  0.4194777
##   0.4  1          0.8               1.00       150      0.7499600  0.4117257
##   0.4  2          0.6               0.50        50      0.7340497  0.3817464
##   0.4  2          0.6               0.50       100      0.7330547  0.3836073
##   0.4  2          0.6               0.50       150      0.7429900  0.4086515
##   0.4  2          0.6               0.75        50      0.7490100  0.4065411
##   0.4  2          0.6               0.75       100      0.7399647  0.4013642
##   0.4  2          0.6               0.75       150      0.7480149  0.4165452
##   0.4  2          0.6               1.00        50      0.7519601  0.4189103
##   0.4  2          0.6               1.00       100      0.7559751  0.4326368
##   0.4  2          0.6               1.00       150      0.7649804  0.4559090
##   0.4  2          0.8               0.50        50      0.7430148  0.4088033
##   0.4  2          0.8               0.50       100      0.7459399  0.4110881
##   0.4  2          0.8               0.50       150      0.7359897  0.3929835
##   0.4  2          0.8               0.75        50      0.7509801  0.4207733
##   0.4  2          0.8               0.75       100      0.7399848  0.3993503
##   0.4  2          0.8               0.75       150      0.7429548  0.4092104
##   0.4  2          0.8               1.00        50      0.7609753  0.4402344
##   0.4  2          0.8               1.00       100      0.7669804  0.4572722
##   0.4  2          0.8               1.00       150      0.7559651  0.4339887
##   0.4  3          0.6               0.50        50      0.7440298  0.4091740
##   0.4  3          0.6               0.50       100      0.7559752  0.4388366
##   0.4  3          0.6               0.50       150      0.7659354  0.4555764
##   0.4  3          0.6               0.75        50      0.7560301  0.4384091
##   0.4  3          0.6               0.75       100      0.7540000  0.4330182
##   0.4  3          0.6               0.75       150      0.7549501  0.4357856
##   0.4  3          0.6               1.00        50      0.7449599  0.4072659
##   0.4  3          0.6               1.00       100      0.7569501  0.4386990
##   0.4  3          0.6               1.00       150      0.7589451  0.4502683
##   0.4  3          0.8               0.50        50      0.7420546  0.4035922
##   0.4  3          0.8               0.50       100      0.7489598  0.4278516
##   0.4  3          0.8               0.50       150      0.7439448  0.4158271
##   0.4  3          0.8               0.75        50      0.7509599  0.4200445
##   0.4  3          0.8               0.75       100      0.7459798  0.4164791
##   0.4  3          0.8               0.75       150      0.7599402  0.4479586
##   0.4  3          0.8               1.00        50      0.7569851  0.4333259
##   0.4  3          0.8               1.00       100      0.7439549  0.4063617
##   0.4  3          0.8               1.00       150      0.7459649  0.4162883
## 
## Tuning parameter 'gamma' was held constant at a value of 0
## Tuning
##  parameter 'min_child_weight' was held constant at a value of 1
## Accuracy was used to select the optimal model using the largest value.
## The final values used for the model were nrounds = 100, max_depth = 2, eta
##  = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1 and subsample
##  = 1.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{caret.xgb}\SpecialCharTok{$}\NormalTok{bestTune}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    nrounds max_depth eta gamma colsample_bytree min_child_weight subsample
## 89     100         2 0.4     0              0.8                1         1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{varImp}\NormalTok{(caret.xgb)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## xgbTree variable importance
## 
##                      Overall
## alcohol              100.000
## volatile.acidity      27.693
## citric.acid           23.788
## free.sulfur.dioxide   23.673
## fixed.acidity         20.393
## residual.sugar        15.734
## density               10.956
## chlorides              8.085
## sulphates              3.598
## pH                     2.925
## total.sulfur.dioxide   0.000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{predict}\NormalTok{(caret.xgb, }\AttributeTok{newdata =}\NormalTok{ test), test}\SpecialCharTok{$}\NormalTok{taste)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction good bad
##       good  147  46
##       bad    19  38
##                                          
##                Accuracy : 0.74           
##                  95% CI : (0.681, 0.7932)
##     No Information Rate : 0.664          
##     P-Value [Acc > NIR] : 0.005841       
##                                          
##                   Kappa : 0.3671         
##                                          
##  Mcnemar's Test P-Value : 0.001260       
##                                          
##             Sensitivity : 0.8855         
##             Specificity : 0.4524         
##          Pos Pred Value : 0.7617         
##          Neg Pred Value : 0.6667         
##              Prevalence : 0.6640         
##          Detection Rate : 0.5880         
##    Detection Prevalence : 0.7720         
##       Balanced Accuracy : 0.6690         
##                                          
##        'Positive' Class : good           
## 
\end{verbatim}

Se podría seguir una estrategia de búsqueda similar a la empleada en los métodos anteriores.

\hypertarget{svm}{%
\chapter{Máquinas de soporte vectorial}\label{svm}}

Las máquinas de soporte vectorial (\emph{support vector machines}, SVM) son métodos estadísticos que Vladimir Vapnik empezó a desarrollar a mediados de 1960, inicialmente para problemas de clasificación binaria (problemas de clasificación con dos categorias), basados en la idea de separar los datos mediante hiperplanos. Actualmente existen extensiones dentro de esta metodología para clasificación con más de dos categorías, para regresión y para detección de datos atípicos. El nombre proviene de la utilización de vectores que hacen de soporte para maximizar la separación entre los datos y el hiperplano.

La popularidad de las máquinas de soporte vectorial creció a partir de los años 90 cuando los incorpora la comunidad informática. Se considera una metodología muy flexible y con buen rendimiento en un amplio abanico de situaciones, aunque por lo general no es la que consigue los mejores rendimientos. Dos referencias ya clásicas son \protect\hyperlink{ref-vapnik1998}{Vapnik} (\protect\hyperlink{ref-vapnik1998}{2000}) y \protect\hyperlink{ref-vapnik2013nature}{Vapnik} (\protect\hyperlink{ref-vapnik2013nature}{2013}).

Siguiendo a \protect\hyperlink{ref-james2021introduction}{James et~al.} (\protect\hyperlink{ref-james2021introduction}{2021}) distinguiremos en nuestra exposición entre clasificadores de máximo margen (\emph{maximal margin classifiers}), clasificadores de soporte vectorial (\emph{support vector classifiers}) y máquinas de soporte vectorial (\emph{support vector machines}).

\hypertarget{clasificadores-de-muxe1ximo-margen}{%
\section{Clasificadores de máximo margen}\label{clasificadores-de-muxe1ximo-margen}}

Los clasificadores de máximo margen (\emph{maximal margin classifiers}; también denominados \emph{hard margin classifiers}) son un método de clasificación binaria que se utiliza cuando hay una frontera lineal que separa perfectamente los datos de entrenamiento de una categoría de los de la otra. Por conveniencia, etiquetamos las dos categorías como +1/-1, es decir, los valores de la variable respuesta \(Y \in \{-1, 1\}\). Y suponemos que existe un hiperplano
\[ \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_p X_p = 0,\]
donde \(p\) es el número de variables predictoras, que tiene la propiedad de separar los datos de entrenamiento según la categoría a la que pertenecen, es decir,
\[ y_i(\beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \ldots + \beta_p x_{pi}) > 0\]
para todo \(i = 1, 2, \ldots, n\), siendo \(n\) el número de datos de entrenamiento.

Una vez tenemos el hiperplano, clasificar una nueva observación \(\mathbf{x}\) se reduce a calcular el signo de
\[m(\mathbf{x}) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_p x_p\]
Si el signo es positivo, se clasifica como perteneciente a la categoría +1, y si es negativo a la categoría -1. Además, el valor absoluto de \(m(\mathbf{x})\) nos da una idea de la distancia entre la observación y la frontera que define el hiperplano. En concreto
\[\frac{y_i}{\sqrt {\sum_{j=1}^p \beta_j^2}}(\beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \ldots + \beta_p x_{pi})\]
sería la distancia de la observación \(i\)-ésima al hiperplano.
Por supuesto, aunque clasifique los datos de entrenamiento sin error, no hay ninguna garantía de que clasifique bien nuevas observaciones, por ejemplo los datos de test. De hecho, si \(p\) es grande es fácil que haya un sobreajuste.

Realmente, si existe al menos un hiperplano que separa perfectamente los datos de entrenamiento de las dos categorías, entonces va a haber infinitos. El objetivo es seleccionar un hiperplano. Para ello, dado un hiperplano, se calculan sus distancias a todos los datos de entrenamiento y se define el \emph{margen} como la menor de esas distancias. El método \emph{maximal margin classifier} lo que hace es seleccionar, de los infinitos hiperplanos, aquel que tiene el mayor margen. Fijémonos en que siempre va a haber varias observaciones que equidistan del hiperplano de máximo margen, y cuya distancia es precisamente el margen. Esas observaciones reciben el nombre de \emph{vectores soporte} y son las que dan nombre a esta metodología.

\begin{center}\includegraphics[width=0.8\linewidth]{04-svm_files/figure-latex/unnamed-chunk-2-1} \end{center}

Matemáticamente, dadas las \(n\) observaciones de entrenamiento \(\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n\), el clasificador de máximo margen es la solución del problema de optimización
\[max_{\beta_0, \beta_1,\ldots, \beta_p} M\]
sujeto a
\[\sum_{j=1}^p \beta_j^2 = 1\]
\[ y_i(\beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \ldots + \beta_p x_{pi}) \ge M \ \ \forall i\]

Si, como estamos suponiendo en esta sección, los datos de entrenamiento son perfectamente separables mediante un hiperplano, entonces el problema anterior va a tener solución con \(M>0\), y \(M\) va a ser el margen.

Una forma equivalente (y mas conveniente) de formular el problema anterior, utilizando \(M = 1/\lVert \boldsymbol{\beta} \rVert\) con \(\boldsymbol{\beta} = (\beta_1, \beta_2, \ldots, \beta_p)\), es
\[\mbox{min}_{\beta_0, \boldsymbol{\beta}} \lVert \boldsymbol{\beta} \rVert\]
sujeto a
\[ y_i(\beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \ldots + \beta_p x_{pi}) \ge 1 \ \ \forall i\]
El problema anterior de optimización es convexo (función objetivo cuadrática con restricciones lineales).

Hay una característica de este método que es de destacar: así como en otros métodos, si se modifica cualquiera de los datos se modifica también el modelo, en este caso el modelo solo depende de los (pocos) datos que son vector soporte, y la modificación de cualquier otro dato no afecta a la construcción del modelo (siempre que, al \emph{moverse} el dato, no cambie el margen).

\hypertarget{clasificadores-de-soporte-vectorial}{%
\section{Clasificadores de soporte vectorial}\label{clasificadores-de-soporte-vectorial}}

Los clasificadores de soporte vectorial (\emph{support vector classifiers}; también denominados \emph{soft margin classifiers}) fueron introducidos en \protect\hyperlink{ref-cortes1995support}{Cortes y Vapnik} (\protect\hyperlink{ref-cortes1995support}{1995}). Son una extensión del problema anterior que se utiliza cuando se desea clasificar mediante un hiperplano pero no existe ninguno que separe perfectamente los datos de entrenamiento según su categoría. En este caso no queda más remedio que admitir errores en la clasificación de algunos datos de entrenamiento (como hemos visto que pasa con todas las metodologías), que van a estar en el lado equivocado del hiperplano. Y en lugar de hablar de un margen se habla de un margen débil (\emph{soft margin}).

Este enfoque, consistente en aceptar que algunos datos de entrenamiento van a estar mal clasificados, puede ser preferible aunque exista un hiperplano que resuelva el problema de la sección anterior, ya que los clasificadores de soporte vectorial son más robustos que los clasificadores de máximo margen.

Veamos la formulación matemática del problema:
\[\mbox{max}_{\beta_0, \beta_1,\ldots, \beta_p, \epsilon_1,\ldots, \epsilon_n} M\]
sujeto a
\[\sum_{j=1}^p \beta_j^2 = 1\]
\[ y_i(\beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \ldots + \beta_p x_{pi}) \ge M(1 - \epsilon_i) \ \ \forall i\]
\[\sum_{i=1}^n \epsilon_i \le K\]
\[\epsilon_i \ge 0 \ \ \forall i\]

Las variables \(\epsilon_i\) son las variables de holgura (\emph{slack variables}). Quizás resultase más intuitivo introducir las holguras en términos absolutos, como \(M -\epsilon_i\), pero eso daría lugar a un problema no convexo, mientras que escribiendo la restricción en términos relativos como \(M(1 - \epsilon_i)\) el problema pasa a ser convexo. Pero en esta formulación el elemento clave es la introducción del hiperparámetro \(K\), necesariamente no negativo, que se puede interpretar como la tolerancia al error. De hecho, es fácil ver que no puede haber más de \(K\) datos de entrenamiento incorrectamente clasificados, ya que si un dato está mal clasificado entonces \(\epsilon_i > 1\). En el caso extremo de utilizar \(K = 0\), estaríamos en el caso de un \emph{hard margin classifier}. La elección del valor de \(K\) también se puede interpretar como una penalización por la complejidad del modelo, y por tanto en términos del balance entre el sesgo y la varianza: valores pequeños van a dar lugar a modelos muy complejos, con mucha varianza y poco sesgo (con el consiguiente riesgo de sobreajuste); y valores grandes a modelos con mucho sesgo y poca varianza. El hiperparámetro \(K\) se puede seleccionar de modo óptimo por los procedimientos ya conocidos, tipo bootstrap o validación cruzada.

Una forma equivalente de formular el problema (cuadrático con restricciones lineales) es
\[\mbox{min}_{\beta_0, \boldsymbol{\beta}} \lVert \boldsymbol{\beta} \rVert\]
sujeto a
\[ y_i(\beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \ldots + \beta_p x_{pi}) \ge 1 - \epsilon_i \ \ \forall i\]
\[\sum_{i=1}^n \epsilon_i \le K\]
\[\epsilon_i \ge 0 \ \ \forall i\]

En la práctica, por una conveniencia de cálculo, se utiliza la siguiente formulación, también equivalente,
\[\mbox{min}_{\beta_0, \boldsymbol{\beta}} \frac{1}{2}\lVert \boldsymbol{\beta} \rVert^2 + C \sum_{i=1}^n \epsilon_i\]
sujeto a
\[ y_i(\beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \ldots + \beta_p x_{pi}) \ge 1 - \epsilon_i \ \ \forall i\]
\[\epsilon_i \ge 0 \ \ \forall i\]

Aunque el problema a resolver es el mismo, y por tanto también la solución, hay que tener cuidado con la interpretación, pues el hiperparámetro \(K\) se ha sustituido por \(C\). Este nuevo parámetro es el que nos vamos a encontrar en los ejercicios prácticos y tiene una interpretación inversa a \(K\). El parámetro \(C\) es la penalización por mala clasificación (coste que supone que un dato de entrenamiento esté mal clasificado), y por tanto el \emph{hard margin classifier} se obtiene para valores muy grandes (\(C = \infty\) se corresponde con \(K = 0\)). Esto es algo confuso, ya que no se corresponde con la interpretación habitual de \emph{penalización por complejidad}.

\begin{center}\includegraphics[width=0.9\linewidth]{04-svm_files/figure-latex/unnamed-chunk-3-1} \end{center}

En este contexto, los vectores soporte van a ser no solo los datos de entrenamiento que están (correctamente clasificados) a una distancia \(M\) del hiperplano, sino también aquellos que están incorrectamente clasificados e incluso los que están a una distancia inferior a \(M\). Como se comentó en la sección anterior, estos son los datos que definen el modelo, que es por tanto robusto a las observaciones que están lejos del hiperplano.

Aunque no vamos a entrar en detalles sobre como se obtiene la solución del problema de optimización, sí resulta interesante destacar que el clasificador de soporte vectorial
\[m(\mathbf{x}) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_p x_p\]
puede representarse como
\[m(\mathbf{x}) = \beta_0 + \sum_{i=1}^n \alpha_i \mathbf{x}^t \mathbf{x}_i\]
donde \(\mathbf{x}^t \mathbf{x}_i\) es el producto escalar entre el vector \(\mathbf{x}\) del dato a clasificar y el vector \(\mathbf{x}_i\) del dato de entrenamiento \(i\)-ésimo. Asimismo, los coeficientes \(\beta_0, \alpha_1, \ldots, \alpha_n\) se obtienen (exclusivamente) a partir de los productos escalares \(\mathbf{x}_i^t \mathbf{x}_j\) de los distintos pares de datos de entrenamiento y de las respuestas \(y_i\). Y más aún, el sumatorio anterior se puede reducir a los índices que corresponden a vectores soporte (\(i\in S\)), al ser los demás coeficientes nulos:
\[m(\mathbf{x}) = \beta_0 + \sum_{i\in S} \alpha_i \mathbf{x}^t \mathbf{x}_i\]

\hypertarget{muxe1quinas-de-soporte-vectorial}{%
\section{Máquinas de soporte vectorial}\label{muxe1quinas-de-soporte-vectorial}}

De la misma manera que en el capítulo dedicado a árboles se comentó que estos serán efectivos en la medida en la que los datos se separen adecuadamente utilizando particiones basadas en rectángulos, los dos métodos de clasificación que hemos visto hasta ahora serán efectivos si hay una frontera lineal que separe los datos de las dos categorías. En caso contrario, un clasificador de soporte vectorial resultará inadecuado. Una solución natural es sustituir el hiperplano, lineal en esencia, por otra función que dependa de las variables predictoras \(X_1,X_2, \ldots, X_n\), utilizando por ejemplo una expresión polinómica o incluso una expresión que no sea aditiva en los predictores. Pero esta solución puede resultar muy compleja computacionalmente.

En Boser \emph{et al.} (1992) se propuso sustituir, en todos los cálculos que conducen a la expresión
\[m(\mathbf{x}) = \beta_0 + \sum_{i\in S} \alpha_i \mathbf{x}^t \mathbf{x}_i\]
los productos escalares \(\mathbf{x}^t \mathbf{x}_i\), \(\mathbf{x}_i^t \mathbf{x}_j\) por funciones alternativas de los datos que reciben el nombre de funciones \emph{kernel}, obteniendo la máquina de soporte vectorial
\[m(\mathbf{x}) = \beta_0 + \sum_{i\in S} \alpha_i K(\mathbf{x}, \mathbf{x}_i)\]

Algunas de las funciones kernel más utilizadas son:

\begin{itemize}
\item
  Kernel lineal
  \[K(\mathbf{x}, \mathbf{y}) = \mathbf{x}^t \mathbf{y}\]
\item
  Kernel polinómico
  \[K(\mathbf{x}, \mathbf{y}) = (1 + \gamma \mathbf{x}^t \mathbf{y})^d\]
\item
  Kernel radial
  \[K(\mathbf{x}, \mathbf{y}) = \mbox{exp} (-\gamma \| \mathbf{x} - \mathbf{y} \|^2)\]
\item
  Tangente hiperbólica
  \[K(\mathbf{x}, \mathbf{y}) = \mbox{tanh} (1 + \gamma \mathbf{x}^t \mathbf{y})\]
\end{itemize}

Antes de construir el modelo, es recomendable centrar y reescalar los datos para evitar que los valores grandes \emph{ahoguen} al resto de los datos. Por supuesto, tiene que hacerse la misma transformación a todos los datos, incluidos los datos de test. La posibilidad de utilizar distintos kernels da mucha flexibilidad a esta metodología, pero es muy importante seleccionar adecuadamente los parámetros de la función kernel (\(\gamma,d\)) y el parámetro \(C\) para evitar sobreajustes.

\begin{center}\includegraphics[width=0.9\linewidth]{04-svm_files/figure-latex/unnamed-chunk-4-1} \end{center}

\hypertarget{clasificaciuxf3n-con-muxe1s-de-dos-categoruxedas}{%
\subsection{Clasificación con más de dos categorías}\label{clasificaciuxf3n-con-muxe1s-de-dos-categoruxedas}}

La metodología \emph{support vector machine} está específicamente diseñada para clasificar cuando hay exactamente dos categorías. En la literatura se pueden encontrar varias propuestas para extenderla al caso de más de dos categorías, aunque las dos más populares son también las más sencillas.

La primera opción consiste en construir tantos modelos como parejas de categorías hay, en un enfoque de \emph{uno contra uno}. Dada una nueva observación a clasificar, se mira en cada uno de los modelos en que categoría la clasifica. Finalmente se hace un recuento y gana la categoría con más \emph{votos}.

La alternativa es llevar a cabo un enfoque de \emph{uno contra todos}. Para cada categoría se contruye el modelo que considera esa categoría frente a todas las demás agrupadas como una sola y, para la observación a clasificar, se considera su distancia con la frontera. Se clasifica la observación como perteneciente a la categoría con mayor distancia.

\hypertarget{regresiuxf3n}{%
\subsection{Regresión}\label{regresiuxf3n}}

Aunque la metodología SVM está concebida para problemas de clasificación, ha habido varios intentos de adaptar su filosofía a problemas de regresión. En esta sección vamos a comentar muy por encima el enfoque seguido en \protect\hyperlink{ref-drucker1997support}{Drucker et~al.} (\protect\hyperlink{ref-drucker1997support}{1997}), con un fuerte enfoque en la robustez. Recordemos que, en el contexto de la clasificación, el modelo SVM va a depender de unos pocos datos: los vectores soporte. En regresión, si se utiliza RSS como criterio de error, todos los datos van a influir en el modelo y además, al estar los errores al cuadrado, los valores atípicos van a tener mucha influencia, muy superior a la que se tendría si se utilizase, por ejemplo, el valor absoluto. Una alternativa, poco intuitiva pero efectiva, es fijar los hiperparámetros \(\epsilon,c > 0\) como umbral y coste, respectivamente, y definir la función de pérdidas
\[
L_{\epsilon,c} (x) = \left\{ \begin{array}{ll}
  0 & \mbox{si } |x|< \epsilon \\
  (|x| - \epsilon)c & \mbox{en otro caso}
  \end{array}
  \right.
\]

En un problema de regresión lineal, SVM estima los parámetros del modelo
\[m(\mathbf{x}) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_p x_p\]
minimizando
\[\sum_{i=1}^n L_{\epsilon,c} (y_i - \hat y_i) + \sum_{j=1}^p \beta_j^2\]

Para hacer las cosas aún más confusas, hay autores que utilizan una formulación, equivalente, en la que el parámetro aparece en el segundo sumando como \(\lambda = 1/c\). En la práctica, es habitual fijar el valor de \(\epsilon\) y seleccionar el valor de \(c\) (equivalentemente, \(\lambda\)) por validación cruzada, por ejemplo.

El modelo puede escribirse en función de los vectores soporte, que son aquellas observaciones cuyo residuo excede el umbral \(\epsilon\):
\[m(\mathbf{x}) = \beta_0 + \sum_{i\in S} \alpha_i \mathbf{x}^t \mathbf{x}_i\]

Finalmente, utilizando una función kernel, el modelo de regresión SVM es
\[m(\mathbf{x}) = \beta_0 + \sum_{i\in S} \alpha_i K(\mathbf{x}, \mathbf{x}_i)\]

\hypertarget{ventajas-e-incovenientes}{%
\subsection{Ventajas e incovenientes}\label{ventajas-e-incovenientes}}

Ventajas:

\begin{itemize}
\item
  Son muy flexibles (pueden adaptarse a fronteras no lineales complejas), por lo que en muchos casos se obtienen buenas predicciones (en otros pueden producir malos resultados).
\item
  Al suavizar el margen, utilizando un parámetro de coste \(C\), son relativamente robustas frente a valores atípicos.
\end{itemize}

Inconvenientes:

\begin{itemize}
\item
  Los modelos ajustados son difíciles de interpretar (caja negra), habrá que recurrir a herramientas generales como las descritas en la Sección \ref{analisis-modelos}.
\item
  Pueden requerir mucho tiempo de computación cuando \(n >> p\), ya que hay que estimar (en principio) tantos parámetros como número de observaciones en los datos de entrenamiento, aunque finalmente la mayoría de ellos se anularán (en cualquier caso habría que factorizar la matriz \(K_{ij} = K(\mathbf{x}_i, \mathbf{x}_j)\) de dimensión \(n \times n\)).
\item
  Están diseñados para predictores numéricos (emplean distancias), por lo que habrá que realizar un preprocesado de las variables explicativas categóricas (para transformarlas en variables indicadoras).
\end{itemize}

\hypertarget{svm-con-el-paquete-kernlab}{%
\section{\texorpdfstring{SVM con el paquete \texttt{kernlab}}{SVM con el paquete kernlab}}\label{svm-con-el-paquete-kernlab}}

Hay varios paquetes que implementan este procedimiento (e.g.~\href{https://CRAN.R-project.org/package=e1071}{\texttt{e1071}}, \protect\hyperlink{ref-R-e1071}{Meyer et~al., 2020}; \href{https://CRAN.R-project.org/package=svmpath}{\texttt{svmpath}}, ver \protect\hyperlink{ref-hastie2004entire}{Hastie et~al., 2004}), aunque se considera que el más completo es \href{https://CRAN.R-project.org/package=kernlab}{\texttt{kernlab}} (\protect\hyperlink{ref-kernlab2004}{Karatzoglou et~al., 2004}).

La función principal es \texttt{ksvm()} y se suelen considerar los siguientes argumentos:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ksvm}\NormalTok{(formula, data, }\AttributeTok{scaled =} \ConstantTok{TRUE}\NormalTok{, type,}
  \AttributeTok{kernel =}\StringTok{"rbfdot"}\NormalTok{, }\AttributeTok{kpar =} \StringTok{"automatic"}\NormalTok{,}
  \AttributeTok{C =} \DecValTok{1}\NormalTok{, }\AttributeTok{epsilon =} \FloatTok{0.1}\NormalTok{, }\AttributeTok{prob.model =} \ConstantTok{FALSE}\NormalTok{, }
\NormalTok{  class.weights, }\AttributeTok{cross =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\item
  \texttt{formula} y \texttt{data} (opcional): permiten especificar la respuesta y las variables predictoras de la forma habitual (e.g.~\texttt{respuesta\ \textasciitilde{}\ .}; también admite matrices).
\item
  \texttt{scaled}: vector lógico indicando que predictores serán reescalados; por defecto se reescalan todas las variables no binarias (y se almacenan los valores empleados para ser usados en posteriores predicciones).
\item
  \texttt{type} (opcional): cadena de texto que permite seleccionar los distintos métodos de clasificación, de regresión o de detección de atípicos implementados (ver \texttt{?ksvm}); por defecto se establece a partir del tipo de la respuesta: \texttt{"C-svc"}, clasificación con parámetro de coste, si es un factor y \texttt{"eps-svr"}, regresión épsilon, si la respuesta es numérica.
\item
  \texttt{kernel}: función núcleo. Puede ser una función definida por el usuario o una cadena de texto que especifique una de las implementadas en el paquete (ver \texttt{?kernels}); por defecto \texttt{"rbfdot"}, kernel radial gausiano.
\item
  \texttt{kpar}: lista con los hiperparámetros del núcleo. En el caso de \texttt{"rbfdot"}, además de una lista con un único componente \texttt{"sigma"} (inversa de la ventana), puede ser \texttt{"automatic"} (valor por defecto) e internamente emplea la función \texttt{sigest()} para seleccionar un valor ``adecuado''.
\item
  \texttt{C}: (hiper)parámetro \(C\) que especifica el coste de la violación de las restricciones; por defecto 1.
\item
  \texttt{epsilon}: (hiper)parámetro \(\epsilon\) empleado en la función de pérdidas de los métodos de regresión; por defecto 0.1.
\item
  \texttt{prob.model}: si se establece a \texttt{TRUE} (por defecto es \texttt{FALSE}), se emplean los resultados de la clasificación para ajustar un modelo para estimar las probabilidades (y se podrán calcular con el método \texttt{predict()}).
\item
  \texttt{class.weights}: vector (con las clases como nombres) con los pesos de una mala clasificación en cada clase.
\item
  \texttt{cross}: número grupos para validación cruzada; por defecto 0 (no se hace validación cruzada). Si se asigna un valor mayor que 1 se realizará validación cruzada y se devolverá el error en la componente \texttt{@cross} (se puede acceder con la función \texttt{cross()}; y se puede emplear para seleccionar hiperparámetros).
\end{itemize}

Como ejemplo consideraremos el problema de clasificación con los datos de calidad de vino:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"data/winetaste.RData"}\NormalTok{)}
\CommentTok{\# Partición de los datos}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ winetaste}
\NormalTok{nobs }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(df)}
\NormalTok{itrain }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(nobs, }\FloatTok{0.8} \SpecialCharTok{*}\NormalTok{ nobs)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ df[itrain, ]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ df[}\SpecialCharTok{{-}}\NormalTok{itrain, ]}


\FunctionTok{library}\NormalTok{(kernlab)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{) }
\CommentTok{\# Selección de sigma = mean(sigest(taste \textasciitilde{} ., data = train)[{-}2]) \# depende de la semilla}
\NormalTok{svm }\OtherTok{\textless{}{-}} \FunctionTok{ksvm}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train,}
            \AttributeTok{kernel =} \StringTok{"rbfdot"}\NormalTok{, }\AttributeTok{prob.model =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{svm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Support Vector Machine object of class "ksvm" 
## 
## SV type: C-svc  (classification) 
##  parameter : cost C = 1 
## 
## Gaussian Radial Basis kernel function. 
##  Hyperparameter : sigma =  0.0751133799772488 
## 
## Number of Support Vectors : 594 
## 
## Objective Function Value : -494.1409 
## Training error : 0.198 
## Probability model included.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot(svm, data = train) produce un error \# packageVersion("kernlab") ‘0.9.29’}
\end{Highlighting}
\end{Shaded}

Podemos evaluar la precisión en la muestra de test empleando el procedimiento habitual:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(svm, }\AttributeTok{newdata =}\NormalTok{ test)}
\NormalTok{caret}\SpecialCharTok{::}\FunctionTok{confusionMatrix}\NormalTok{(pred, test}\SpecialCharTok{$}\NormalTok{taste)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction good bad
##       good  147  45
##       bad    19  39
##                                           
##                Accuracy : 0.744           
##                  95% CI : (0.6852, 0.7969)
##     No Information Rate : 0.664           
##     P-Value [Acc > NIR] : 0.003886        
##                                           
##                   Kappa : 0.3788          
##                                           
##  Mcnemar's Test P-Value : 0.001778        
##                                           
##             Sensitivity : 0.8855          
##             Specificity : 0.4643          
##          Pos Pred Value : 0.7656          
##          Neg Pred Value : 0.6724          
##              Prevalence : 0.6640          
##          Detection Rate : 0.5880          
##    Detection Prevalence : 0.7680          
##       Balanced Accuracy : 0.6749          
##                                           
##        'Positive' Class : good            
## 
\end{verbatim}

Para obtener las estimaciones de las probabilidades, habría que establecer
\texttt{type\ =\ "probabilities"} al predecir (devolverá una matriz con columnas
correspondientes a los niveles)\footnote{Otras opciones son \texttt{"votes"} y \texttt{"decision"} para obtener matrices con el número de votos o los valores de \(m(\mathbf{x})\).}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p.est }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(svm, }\AttributeTok{newdata =}\NormalTok{ test, }\AttributeTok{type =} \StringTok{"probabilities"}\NormalTok{)}
\FunctionTok{head}\NormalTok{(p.est)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           good       bad
## [1,] 0.4761934 0.5238066
## [2,] 0.7089338 0.2910662
## [3,] 0.8893454 0.1106546
## [4,] 0.8424003 0.1575997
## [5,] 0.6640875 0.3359125
## [6,] 0.3605543 0.6394457
\end{verbatim}

Este procedimiento está implementado en el método \texttt{"svmRadial"} de \texttt{caret} y considera como hiperparámetros:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}
\CommentTok{\# names(getModelInfo("svm")) \# 17 métodos}
\FunctionTok{modelLookup}\NormalTok{(}\StringTok{"svmRadial"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       model parameter label forReg forClass probModel
## 1 svmRadial     sigma Sigma   TRUE     TRUE      TRUE
## 2 svmRadial         C  Cost   TRUE     TRUE      TRUE
\end{verbatim}

En este caso la función \texttt{train()} por defecto evaluará únicamente tres valores del hiperparámetro \texttt{C\ =\ c(0.25,\ 0.5,\ 1)} y fijará el valor de \texttt{sigma}.
Alternativamente podríamos establecer la rejilla de búsqueda, por ejemplo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tuneGrid }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{sigma =} \FunctionTok{kernelf}\NormalTok{(svm)}\SpecialCharTok{@}\NormalTok{kpar}\SpecialCharTok{$}\NormalTok{sigma, }\CommentTok{\# Emplea clases S4}
                       \AttributeTok{C =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{))}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{caret.svm }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train,}
    \AttributeTok{method =} \StringTok{"svmRadial"}\NormalTok{, }\AttributeTok{preProcess =} \FunctionTok{c}\NormalTok{(}\StringTok{"center"}\NormalTok{, }\StringTok{"scale"}\NormalTok{),}
    \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{number =} \DecValTok{5}\NormalTok{),}
    \AttributeTok{tuneGrid =}\NormalTok{ tuneGrid, }\AttributeTok{prob.model =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{caret.svm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Support Vector Machines with Radial Basis Function Kernel 
## 
## 1000 samples
##   11 predictor
##    2 classes: 'good', 'bad' 
## 
## Pre-processing: centered (11), scaled (11) 
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 800, 801, 800, 800, 799 
## Resampling results across tuning parameters:
## 
##   C    Accuracy   Kappa    
##   0.5  0.7549524  0.4205204
##   1.0  0.7599324  0.4297468
##   5.0  0.7549374  0.4192217
## 
## Tuning parameter 'sigma' was held constant at a value of 0.07511338
## Accuracy was used to select the optimal model using the largest value.
## The final values used for the model were sigma = 0.07511338 and C = 1.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{varImp}\NormalTok{(caret.svm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## ROC curve variable importance
## 
##                      Importance
## alcohol                 100.000
## density                  73.616
## chlorides                60.766
## volatile.acidity         57.076
## total.sulfur.dioxide     45.500
## fixed.acidity            42.606
## pH                       34.972
## sulphates                25.546
## citric.acid               6.777
## residual.sugar            6.317
## free.sulfur.dioxide       0.000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{predict}\NormalTok{(caret.svm, }\AttributeTok{newdata =}\NormalTok{ test), test}\SpecialCharTok{$}\NormalTok{taste)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction good bad
##       good  147  45
##       bad    19  39
##                                           
##                Accuracy : 0.744           
##                  95% CI : (0.6852, 0.7969)
##     No Information Rate : 0.664           
##     P-Value [Acc > NIR] : 0.003886        
##                                           
##                   Kappa : 0.3788          
##                                           
##  Mcnemar's Test P-Value : 0.001778        
##                                           
##             Sensitivity : 0.8855          
##             Specificity : 0.4643          
##          Pos Pred Value : 0.7656          
##          Neg Pred Value : 0.6724          
##              Prevalence : 0.6640          
##          Detection Rate : 0.5880          
##    Detection Prevalence : 0.7680          
##       Balanced Accuracy : 0.6749          
##                                           
##        'Positive' Class : good            
## 
\end{verbatim}

\hypertarget{class-otros}{%
\chapter{Otros métodos de clasificación}\label{class-otros}}

En los métodos de clasificación que hemos visto en los capítulos anteriores, uno de los objetivos era estimar la probabilidad a posteriori \(P(Y = k | \mathbf{X}=\mathbf{x})\) de que la observación \(\mathbf{x}\) pertenezca a la categoría \(k\), pero en ningún caso nos preocupábamos por la distribución de las variables predictoras. En la terminología de ML estos métodos se conocen con el nombre de discriminadores (\emph{discriminative methods}). Otro ejemplo de método discriminador es la regresión logística.

En este capítulo vamos a ver métodos que reciben el nombre genérico de métodos generadores (\emph{generative methods}). Se caracterizan porque calculan las probabilidades a posteriori utilizando la distribución conjunta de \((\mathbf{X}, Y)\) y el teorema de Bayes:
\[P(Y = k | \mathbf{X}=\mathbf{x}) = \frac{P(Y = k) f_k(\mathbf{x})}{\sum_{l=1}^K P(Y = l) f_l(\mathbf{x})}\]
donde \(f_k(\mathbf{x})\) es la función de densidad del vector aleatorio \(\mathbf{X}=(X_1, X_2, \ldots, X_p)\) para una observación perteneciente a la clase \(k\), es decir, es una forma abreviada de escribir \(f(\mathbf{X}=\mathbf{x} | Y = k)\). En la jerga bayesiana a esta función se la conoce como \emph{verosimilitud} (es la función de verosimilitud sin más que considerar que la observación muestral \(\mathbf{x}\) es fija y la variable es \(k\)) y resumen la fórmula anterior como
\[posterior \propto prior \times verosimilitud\]

Una vez estimadas las probabilidades a priori \(P(Y = k)\) y las densidades (verosimilitudes) \(f_k(\mathbf{x})\), tenemos las probabilidades a posteriori. Para estimar las funciones de densidad se puede utilizar un método paramétrico o un método no paramétrico. En el primer caso, lo más habitual es modelizar la distribución del vector de variables predictoras como normales multivariantes.

A continuación vamos a ver tres casos particulares de este enfoque, siempre suponiendo normalidad.

\hypertarget{anuxe1lisis-discriminate-lineal}{%
\section{Análisis discriminate lineal}\label{anuxe1lisis-discriminate-lineal}}

El análisis lineal discrimintante (LDA) se inicia en \protect\hyperlink{ref-fisher1936use}{Fisher} (\protect\hyperlink{ref-fisher1936use}{1936}) pero es \protect\hyperlink{ref-welch1939note}{Welch} (\protect\hyperlink{ref-welch1939note}{1939}) quien lo enfoca utilizando el teorema de Bayes. Asumiendo que \(X | Y = k \sim N(\mu_k, \Sigma)\), es decir, que todas las categorías comparten la misma matriz \(\Sigma\), se obtienen las funciones discriminantes, lineales en \(\mathbf{x}\),
\[\mathbf{x}^t \Sigma^{-1} \mu_k - \frac{1}{2} \mu_k^t \Sigma^{-1} \mu_k + \mbox{log}(P(Y = k))\]

La dificultad técnica del método LDA reside en el cálculo de \(\Sigma^{-1}\). Cuando hay más variables predictoras que datos, o cuando las variables predictoras están fuertemente correlacionadas, hay un problema. Una solución pasa por aplicar análisis de componentes principales (PCA) para reducir la dimensión y tener predictores incorrelados antes de utilizar LDA. Aunque la solución anterior se utiliza mucho, hay que tener en cuenta que la reducción de la dimensión se lleva a cabo sin tener en cuenta la información de las categorías, es decir, la estructura de los datos en categorías. Una alternativa consiste en utilizar \emph{partial least squares discriminant analysis} (PLSDA, Berntsson y Wold, 1986). La idea consiste en realizar una regresión PLS siendo las categorías la respuesta, con el objetivo de reducir la dimensión a la vez que se maximiza la correlación con las respuestas.

Una generalización de LDA es el \emph{mixture discriminant analysis} (\protect\hyperlink{ref-hastie1996fisher}{Hastie y Tibshirani, 1996}) en el que, siempre con la misma matriz \(\Sigma\), se contempla la posibilidad de que dentro de cada categoría haya múltiples subcategorías que únicamente difieren en la media. Las distribuciones dentro de cada clase se agregan mediante una mixtura de las distribuciones multivariantes.

\hypertarget{ejemplo-masslda}{%
\subsection{\texorpdfstring{Ejemplo \texttt{MASS::lda}}{Ejemplo MASS::lda}}\label{ejemplo-masslda}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"data/winetaste.RData"}\NormalTok{)}
\CommentTok{\# Partición de los datos}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ winetaste}
\NormalTok{nobs }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(df)}
\NormalTok{itrain }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(nobs, }\FloatTok{0.8} \SpecialCharTok{*}\NormalTok{ nobs)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ df[itrain, ]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ df[}\SpecialCharTok{{-}}\NormalTok{itrain, ]}

\FunctionTok{library}\NormalTok{(MASS)}
\NormalTok{ld }\OtherTok{\textless{}{-}} \FunctionTok{lda}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train)}
\NormalTok{ld}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call:
## lda(taste ~ ., data = train)
## 
## Prior probabilities of groups:
##  good   bad 
## 0.662 0.338 
## 
## Group means:
##      fixed.acidity volatile.acidity citric.acid residual.sugar  chlorides
## good      6.726888        0.2616994   0.3330211       6.162009 0.04420242
## bad       7.030030        0.3075148   0.3251775       6.709024 0.05075740
##      free.sulfur.dioxide total.sulfur.dioxide   density       pH sulphates
## good            34.75831             132.7568 0.9935342 3.209668 0.4999396
## bad             35.41124             147.4615 0.9950789 3.166331 0.4763905
##        alcohol
## good 10.786959
## bad   9.845611
## 
## Coefficients of linear discriminants:
##                                LD1
## fixed.acidity        -4.577255e-02
## volatile.acidity      5.698858e+00
## citric.acid          -5.894231e-01
## residual.sugar       -2.838910e-01
## chlorides            -6.083210e+00
## free.sulfur.dioxide   1.039366e-03
## total.sulfur.dioxide -8.952115e-04
## density               5.642314e+02
## pH                   -2.103922e+00
## sulphates            -2.400004e+00
## alcohol              -1.996112e-01
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(ld)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{05-otros_metodos_files/figure-latex/unnamed-chunk-2-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ld.pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(ld, }\AttributeTok{newdata =}\NormalTok{ test)}
\NormalTok{pred }\OtherTok{\textless{}{-}}\NormalTok{ ld.pred}\SpecialCharTok{$}\NormalTok{class}
\NormalTok{caret}\SpecialCharTok{::}\FunctionTok{confusionMatrix}\NormalTok{(pred, test}\SpecialCharTok{$}\NormalTok{taste)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction good bad
##       good  146  49
##       bad    20  35
##                                           
##                Accuracy : 0.724           
##                  95% CI : (0.6641, 0.7785)
##     No Information Rate : 0.664           
##     P-Value [Acc > NIR] : 0.0247239       
##                                           
##                   Kappa : 0.3238          
##                                           
##  Mcnemar's Test P-Value : 0.0007495       
##                                           
##             Sensitivity : 0.8795          
##             Specificity : 0.4167          
##          Pos Pred Value : 0.7487          
##          Neg Pred Value : 0.6364          
##              Prevalence : 0.6640          
##          Detection Rate : 0.5840          
##    Detection Prevalence : 0.7800          
##       Balanced Accuracy : 0.6481          
##                                           
##        'Positive' Class : good            
## 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p.est }\OtherTok{\textless{}{-}}\NormalTok{ld.pred}\SpecialCharTok{$}\NormalTok{posterior}
\end{Highlighting}
\end{Shaded}

\hypertarget{anuxe1lisis-discriminante-cuadruxe1tico}{%
\section{Análisis discriminante cuadrático}\label{anuxe1lisis-discriminante-cuadruxe1tico}}

El análisis discriminante cuadrático (QDA) relaja la suposición de que todas las categorías tengan la misma estructura de covarianzas, es decir, \(X | Y = k \sim N(\mu_k, \Sigma_k)\), obteniendo como solución
\[-\frac{1}{2} (\mathbf{x} - \mu_k)^t \Sigma^{-1}_k (\mathbf{x} - \mu_k) - \frac{1}{2} \mbox{log}(|\Sigma_k|) + \mbox{log}(P(Y = k))\]

Vemos que este método da lugar a fronteras discriminantes cuadráticas.

Si el número de variables predictoras es próximo al tamaño muestral, en la prácticas QDA se vuelve impracticable, ya que el número de variables predictoras tiene que ser menor que el numero de datos en cada una de las categorías. Una recomendación básica es utilizar LDA y QDA únicamente cuando hay muchos más datos que predictores. Y al igual que en LDA, si dentro de las clases los predictores presentan mucha colinealidad el modelo va a funcionar mal.

Al ser QDA una generalización de LDA podemos pensar que siempre va a ser preferible, pero eso no es cierto, ya que QDA requiere estimar muchos más parámetros que LDA y por tanto tiene más riesgo de sobreajustar. Al ser menos flexible, LDA da lugar a modelos más simples: menos varianza pero más sesgo. LDA suele funcionar mejor que QDA cuando hay pocos datos y es por tanto muy importante reducir la varianza. Por el contrario, QDA es recomendable cuando hay muchos datos.

Una solución intermedia entre LDA y QDA es el análisis discriminante regularizado (RDA, \protect\hyperlink{ref-friedman1989regularized}{Friedman, 1989}), que utiliza el hiperparámetro \(\lambda\) para definir la matriz
\[\Sigma_{k,\lambda}' = \lambda\Sigma_k + (1 - \lambda) \Sigma
\]

También hay una versión con dos hiperparámetros, \(\lambda\) y \(\gamma\),
\[\Sigma_{k,\lambda,\gamma}' = (1 - \gamma) \Sigma_{k,\lambda}' + \gamma \frac{1}{p} \mbox{tr} (\Sigma_{k,\lambda}')I
\]

\hypertarget{ejemplo-massqda}{%
\subsection{\texorpdfstring{Ejemplo \texttt{MASS::qda}}{Ejemplo MASS::qda}}\label{ejemplo-massqda}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qd }\OtherTok{\textless{}{-}} \FunctionTok{qda}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train)}
\NormalTok{qd}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call:
## qda(taste ~ ., data = train)
## 
## Prior probabilities of groups:
##  good   bad 
## 0.662 0.338 
## 
## Group means:
##      fixed.acidity volatile.acidity citric.acid residual.sugar  chlorides
## good      6.726888        0.2616994   0.3330211       6.162009 0.04420242
## bad       7.030030        0.3075148   0.3251775       6.709024 0.05075740
##      free.sulfur.dioxide total.sulfur.dioxide   density       pH sulphates
## good            34.75831             132.7568 0.9935342 3.209668 0.4999396
## bad             35.41124             147.4615 0.9950789 3.166331 0.4763905
##        alcohol
## good 10.786959
## bad   9.845611
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qd.pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(qd, }\AttributeTok{newdata =}\NormalTok{ test)}
\NormalTok{pred }\OtherTok{\textless{}{-}}\NormalTok{ qd.pred}\SpecialCharTok{$}\NormalTok{class}
\NormalTok{caret}\SpecialCharTok{::}\FunctionTok{confusionMatrix}\NormalTok{(pred, test}\SpecialCharTok{$}\NormalTok{taste)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction good bad
##       good  147  40
##       bad    19  44
##                                           
##                Accuracy : 0.764           
##                  95% CI : (0.7064, 0.8152)
##     No Information Rate : 0.664           
##     P-Value [Acc > NIR] : 0.0003762       
##                                           
##                   Kappa : 0.4363          
##                                           
##  Mcnemar's Test P-Value : 0.0092202       
##                                           
##             Sensitivity : 0.8855          
##             Specificity : 0.5238          
##          Pos Pred Value : 0.7861          
##          Neg Pred Value : 0.6984          
##              Prevalence : 0.6640          
##          Detection Rate : 0.5880          
##    Detection Prevalence : 0.7480          
##       Balanced Accuracy : 0.7047          
##                                           
##        'Positive' Class : good            
## 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p.est }\OtherTok{\textless{}{-}}\NormalTok{ qd.pred}\SpecialCharTok{$}\NormalTok{posterior}
\end{Highlighting}
\end{Shaded}

\hypertarget{naive-bayes}{%
\section{Naive Bayes}\label{naive-bayes}}

El modelo naive Bayes simplifica los modelos anteriores asumiendo que las variables predictoras son \emph{independientes}. Esta es una suposición extremadamente fuerte y en la práctica difícilmente nos encontraremos con un problema en el que las variables sean independientes, pero a cambio se va a reducir mucho la complejidad del modelo. Esta simplicidad del modelo le va a permitir manejar un gran número de predictores, incluso con un tamaño muestral moderado, situaciones en las que puede ser imposible utilizar LDA o QDA. Otra ventaja asociada con su simplicidad es que el cálculo del modelo se va a poder hacer muy rápido incluso para tamaños muestrales muy grandes. Además, y quizás esto sea lo más sorprendente, en ocasiones su rendimiento es muy competitivo.

Asumiendo normalidad, este modelo no es más que un caso particular de QDA con matrices \(\Sigma_k\) diagonales. Cuando las variables predictoras son categóricas, lo más habitual es modelizar naive Bayes utilizando distribuciones multinomiales.

\hypertarget{ejemplo-e1071naivebayes}{%
\subsection{\texorpdfstring{Ejemplo \texttt{e1071::naiveBayes}}{Ejemplo e1071::naiveBayes}}\label{ejemplo-e1071naivebayes}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(e1071)}
\NormalTok{nb }\OtherTok{\textless{}{-}} \FunctionTok{naiveBayes}\NormalTok{(taste }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train)}
\NormalTok{nb}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Naive Bayes Classifier for Discrete Predictors
## 
## Call:
## naiveBayes.default(x = X, y = Y, laplace = laplace)
## 
## A-priori probabilities:
## Y
##  good   bad 
## 0.662 0.338 
## 
## Conditional probabilities:
##       fixed.acidity
## Y          [,1]      [,2]
##   good 6.726888 0.8175101
##   bad  7.030030 0.9164467
## 
##       volatile.acidity
## Y           [,1]       [,2]
##   good 0.2616994 0.08586935
##   bad  0.3075148 0.11015113
## 
##       citric.acid
## Y           [,1]      [,2]
##   good 0.3330211 0.1231345
##   bad  0.3251775 0.1334682
## 
##       residual.sugar
## Y          [,1]     [,2]
##   good 6.162009 4.945483
##   bad  6.709024 5.251402
## 
##       chlorides
## Y            [,1]       [,2]
##   good 0.04420242 0.02237654
##   bad  0.05075740 0.03001672
## 
##       free.sulfur.dioxide
## Y          [,1]     [,2]
##   good 34.75831 14.87336
##   bad  35.41124 19.26304
## 
##       total.sulfur.dioxide
## Y          [,1]     [,2]
##   good 132.7568 38.05871
##   bad  147.4615 47.34668
## 
##       density
## Y           [,1]       [,2]
##   good 0.9935342 0.00285949
##   bad  0.9950789 0.00256194
## 
##       pH
## Y          [,1]      [,2]
##   good 3.209668 0.1604529
##   bad  3.166331 0.1472261
## 
##       sulphates
## Y           [,1]       [,2]
##   good 0.4999396 0.11564067
##   bad  0.4763905 0.09623778
## 
##       alcohol
## Y           [,1]      [,2]
##   good 10.786959 1.2298425
##   bad   9.845611 0.8710844
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(nb, }\AttributeTok{newdata =}\NormalTok{ test)}
\NormalTok{caret}\SpecialCharTok{::}\FunctionTok{confusionMatrix}\NormalTok{(pred, test}\SpecialCharTok{$}\NormalTok{taste)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction good bad
##       good  136  47
##       bad    30  37
##                                           
##                Accuracy : 0.692           
##                  95% CI : (0.6307, 0.7486)
##     No Information Rate : 0.664           
##     P-Value [Acc > NIR] : 0.19255         
##                                           
##                   Kappa : 0.2734          
##                                           
##  Mcnemar's Test P-Value : 0.06825         
##                                           
##             Sensitivity : 0.8193          
##             Specificity : 0.4405          
##          Pos Pred Value : 0.7432          
##          Neg Pred Value : 0.5522          
##              Prevalence : 0.6640          
##          Detection Rate : 0.5440          
##    Detection Prevalence : 0.7320          
##       Balanced Accuracy : 0.6299          
##                                           
##        'Positive' Class : good            
## 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p.est }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(nb, }\AttributeTok{newdata =}\NormalTok{ test, }\AttributeTok{type =} \StringTok{"raw"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{modelos-lineales}{%
\chapter{Modelos lineales y extensiones}\label{modelos-lineales}}

En los modelo lineales se supone que la función de regresión es lineal\footnote{Algunos predictores podrían corresponderse con interacciones, \(X_i = X_j X_k\), o transformaciones (e.g.~\(X_i = X_j^2\)) de las variables explicativas originales. También se podría haber transformado la respuesta.}:
\[E( Y | \mathbf{X} ) = \beta_{0}+\beta_{1}X_{1}+\beta_{2}X_{2}+\cdots+\beta_{p}X_{p}\]
Es decir, que el efecto de las variables explicativas sobre la respuesta es muy simple, proporcional a su valor, y por tanto la interpretación de este tipo de modelos es (en principio) muy fácil.
El coeficiente \(\beta_j\) representa el incremento medio de \(Y\) al aumentar en una unidad el valor de \(X_j\), manteniendo fijos el resto de las covariables.
En este contexto las variables predictoras se denominan habitualmente variables independientes, pero en la práctica es de esperar que no haya independencia entre ellas, por lo que puede no ser muy razonable pensar que al variar una de ellas el resto va a permanecer constante.

El ajuste de este tipo de modelos en la práctica se suele realizar empleando el método de mínimos cuadrados (ordinarios), asumiendo (implícitamente o explícitamente) que la distribución condicional de la respuesta es normal, lo que se conoce como el modelo de regresión lineal múltiple (siguiente sección).

Los modelos lineales generalizados son una extensión de los modelos lineales para el caso de que la distribución condicional de la variable respuesta no sea normal (por ejemplo discreta: Bernouilli, Binomial, Poisson\ldots).
En los modelos lineales generalizados se introduce una función invertible \emph{g}, denominada función enlace (o link):
\[g\left(E(Y | \mathbf{X} )\right) = \beta_{0}+\beta_{1}X_{1}+\beta_{2}X_{2}+\cdots+\beta_{p}X_{p}\]
y su ajuste en la práctica se realiza empleando el método de máxima verosimilitud.

Ambos son modelos clásicos de la inferencia estadística y, aunque pueden ser demasiado simples en muchos casos, pueden resultar muy útiles en otros por lo que también se emplean habitualmente en AE.
Además, como veremos más adelante (en las secciones finales de este capítulo y en los siguientes), sirve como punto de partida para procedimientos más avanzados.
En este capítulo se tratarán estos métodos desde el punto de vista de AE (descrito en el Capítulo \ref{intro-AE}), es decir, con el objetivo de predecir en lugar de realizar inferencias (y preferiblemente empleando un procedimiento automático y capaz de manejar grandes volúmenes de datos).

En consecuencia, se supondrá que se dispone de unos conocimientos básicos de los métodos clásicos de regresión lineal y regresión lineal generalizada.
Para un tratamiento más completo de este tipo de métodos se puede consultar \protect\hyperlink{ref-faraway2014linear}{Faraway} (\protect\hyperlink{ref-faraway2014linear}{2016}), que incluye su aplicación en la práctica con R (también el \href{https://rubenfcasal.github.io/intror/modelos-lineales.html}{Capítulo 8} de \protect\hyperlink{ref-fernandez2019intror}{Fernández-Casal et~al., 2019}).
Además por simplicidad, en las siguientes secciones nos centraremos principalmente en el caso de modelos lineales, pero los distintos procedimientos y comentarios se extienden de forma análoga al caso de modelos generalizados (básicamente habría que sustituir la suma de cuadrados residual por el logaritmo negativo de la verosimilitud), que serán tratados en la última sección.

\hypertarget{reg-multiple}{%
\section{Regresión lineal múltiple}\label{reg-multiple}}

Como ya se comentó, el método tradicional considera el siguiente modelo:
\begin{equation} 
  Y = \beta_{0}+\beta_{1}X_{1}+\beta_{2}X_{2}+\cdots+\beta_{p}X_{p} + \varepsilon,
  \label{eq:modelo-rlm}
\end{equation}
donde \(\left( \beta_{0},\beta_{1},\ldots,\beta_{p}\right)^t\) es un vector de parámetros (desconocidos) y \(\varepsilon\) es un error aleatorio normal de media cero y varianza \(\sigma^2\).

Por tanto las hipótesis estructurales del modelo son:

\begin{itemize}
\item
  Linealidad
\item
  Homocedasticidad (varianza constante del error)
\item
  Normalidad (y homogeneidad: ausencia de valores atípicos y/o influyentes)
\item
  Independencia de los errores
\end{itemize}

Hipótesis adicional en regresión múltiple:

\begin{itemize}
\tightlist
\item
  Ninguna de las variables explicativas es combinación lineal de las demás.
\end{itemize}

En el caso de regresión múltiple es de especial interés el fenómeno de la colinealidad (o multicolinealidad) relacionado con la última de estas hipótesis (que se tratará en la Sección \ref{colinealidad}).
Además se da por hecho que el número de observaciones disponible es como mínimo el número de parámetros, \(n \geq p + 1\).

\hypertarget{ajuste-funciuxf3n-lm}{%
\subsection{\texorpdfstring{Ajuste: función \texttt{lm}}{Ajuste: función lm}}\label{ajuste-funciuxf3n-lm}}

El procedimiento habitual para ajustar un modelo de regresión lineal a un conjunto de datos es emplear mínimos cuadrados (ordinarios):

\[\mbox{min}_{\beta_{0},\beta_{1},\ldots,\beta_{p}}  \sum\limits_{i=1}^{n}\left(  y_{i} - \beta_0 - \beta_1 x_{1i} - \cdots - \beta_p x_{pi} \right)^{2}\]

En R podemos emplear la función \texttt{lm}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ajuste }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(formula, data, subset, weights, na.action)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\item
  \texttt{formula}: fórmula que especifica el modelo.
\item
  \texttt{data}: data.frame (opcional) con las variables de la formula.
\item
  \texttt{subset}: vector (opcional) que especifica un subconjunto de observaciones.
\item
  \texttt{weights}: vector (opcional) de pesos (mínimos cuadrados ponderados, WLS).
\item
  \texttt{na.action}: opción para manejar los datos faltantes; por defecto \texttt{na.omit}.
\end{itemize}

Alternativamente se puede emplear la función \texttt{biglm()} del paquete \href{https://CRAN.R-project.org/package=biglm}{\texttt{biglm}} para ajustar modelos lineales a grandes conjuntos de datos (especialmente cuando el número de observaciones es muy grande, incluyendo el caso de que los datos excedan la capacidad de memoria del equipo).
También se podría utilizar la función \texttt{rlm()} del paquete \href{https://CRAN.R-project.org/package=MASS}{\texttt{MASS}} para ajustar modelos lineales empleando un método robusto cuando hay datos atípicos.

\hypertarget{ejemplo-2}{%
\subsection{Ejemplo}\label{ejemplo-2}}

Como ejemplo consideraremos el conjunto de datos \emph{hbat.RData} que contiene observaciones de clientes de la compañía de distribución industrial HBAT (\protect\hyperlink{ref-hair1998multivariate}{Hair et~al., 1998}).
Las variables se pueden clasificar en tres grupos: las 6 primeras (categóricas) son características del comprador, las variables de la 7 a la 19 (numéricas) miden percepciones de HBAT por parte del comprador y las 5 últimas son posibles variables de interés (respuestas).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"data/hbat.RData"}\NormalTok{)}
\FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{attr}\NormalTok{(hbat, }\StringTok{"variable.labels"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             attr(hbat, "variable.labels")
## empresa                           Empresa
## tcliente                  Tipo de cliente
## tindustr                   Tipo Industria
## tamaño               Tamaño de la empresa
## region                             Región
## distrib           Sistema de distribución
## calidadp              Calidad de producto
## web      Actividades comercio electrónico
## soporte                   Soporte técnico
## quejas               Resolución de quejas
## publi                          Publicidad
## producto               Línea de productos
## imgfvent       Imagen de fuerza de ventas
## precio                   Nivel de precios
## garantia         Garantía y reclamaciones
## nprod                    Nuevos productos
## facturac            Encargo y facturación
## flexprec          Flexibilidad de precios
## velocida             Velocidad de entrega
## satisfac            Nivel de satisfacción
## precomen          Propensión a recomendar
## pcompra              Propensión a comprar
## fidelida      Porcentaje de compra a HBAT
## alianza  Consideraría alianza estratégica
\end{verbatim}

Consideraremos como respuesta la variable \emph{fidelida} y, por comodidad, únicamente las variables continuas correspondientes a las percepciones de HBAT como variables explicativas (para una introducción al tratamiento de variables predictoras categóricas ver por ejemplo la \href{https://rubenfcasal.github.io/intror/modelos-lineales.html\#regresion-con-variables-categoricas}{Sección 8.5} de \protect\hyperlink{ref-fernandez2019intror}{Fernández-Casal et~al., 2019}).

Como ya se comentó, se trata de un método clásico de Estadística y el procedimiento habitual es emplear toda la información disponible para construir el modelo y posteriormente (asumiendo que es el verdadero) utilizar métodos de inferencia para evaluar su precisión.
Sin embargo seguiremos el procedimiento habitual en AE y particionaremos los datos en una muestra de entrenamiento y en otra de test.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ hbat[, }\FunctionTok{c}\NormalTok{(}\DecValTok{7}\SpecialCharTok{:}\DecValTok{19}\NormalTok{, }\DecValTok{23}\NormalTok{)]  }\CommentTok{\# Nota: realmente no copia el objeto...}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{nobs }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(df)}
\NormalTok{itrain }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(nobs, }\FloatTok{0.8} \SpecialCharTok{*}\NormalTok{ nobs)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ df[itrain, ]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ df[}\SpecialCharTok{{-}}\NormalTok{itrain, ]}

\CommentTok{\# plot(train)}
\NormalTok{mcor }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(train)}
\NormalTok{corrplot}\SpecialCharTok{::}\FunctionTok{corrplot}\NormalTok{(mcor, }\AttributeTok{method =} \StringTok{"ellipse"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-4-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(mcor, }\AttributeTok{digits =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          calidadp    web soporte quejas publi producto imgfvent precio garantia
## calidadp     1.00 -0.088   0.051   0.05 -0.05     0.51    -0.15  -0.43     0.09
## web         -0.09  1.000  -0.009   0.14  0.53     0.03     0.79   0.20     0.08
## soporte      0.05 -0.009   1.000   0.17  0.03     0.17     0.04  -0.11     0.84
## quejas       0.05  0.144   0.172   1.00  0.27     0.53     0.23  -0.06     0.19
## publi       -0.05  0.534   0.026   0.27  1.00     0.15     0.66   0.10     0.04
## producto     0.51  0.027   0.166   0.53  0.15     1.00     0.02  -0.48     0.23
## imgfvent    -0.15  0.787   0.038   0.23  0.66     0.02     1.00   0.20     0.14
## precio      -0.43  0.196  -0.109  -0.06  0.10    -0.48     0.20   1.00    -0.10
## garantia     0.09  0.079   0.841   0.19  0.04     0.23     0.14  -0.10     1.00
## nprod        0.17 -0.049   0.017   0.06  0.05     0.13     0.03  -0.14     0.09
## facturac     0.04  0.209   0.128   0.74  0.26     0.42     0.30  -0.05     0.20
## flexprec    -0.51  0.221  -0.005   0.44  0.27    -0.36     0.29   0.45    -0.03
## velocida     0.04  0.227   0.142   0.88  0.36     0.60     0.29  -0.07     0.18
## fidelida     0.55  0.219   0.070   0.61  0.27     0.67     0.21  -0.19     0.14
##          nprod facturac flexprec velocida fidelida
## calidadp  0.17     0.04   -0.509     0.04     0.55
## web      -0.05     0.21    0.221     0.23     0.22
## soporte   0.02     0.13   -0.005     0.14     0.07
## quejas    0.06     0.74    0.444     0.88     0.61
## publi     0.05     0.26    0.266     0.36     0.27
## producto  0.13     0.42   -0.364     0.60     0.67
## imgfvent  0.03     0.30    0.285     0.29     0.21
## precio   -0.14    -0.05    0.449    -0.07    -0.19
## garantia  0.09     0.20   -0.030     0.18     0.14
## nprod     1.00     0.10    0.015     0.12     0.14
## facturac  0.10     1.00    0.428     0.77     0.50
## flexprec  0.01     0.43    1.000     0.52     0.05
## velocida  0.12     0.77    0.515     1.00     0.68
## fidelida  0.14     0.50    0.055     0.68     1.00
\end{verbatim}

En este caso observamos que aparentemente hay una relación (lineal) entre la respuesta y algunas de las variables explicativas (que en principio no parece adecuado suponer que son independientes).
Si consideramos un modelo de regresión lineal simple, el mejor ajuste se obtendría empleando \texttt{velocida} como variable explicativa:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelo }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(fidelida }\SpecialCharTok{\textasciitilde{}}\NormalTok{ velocida, train)}
\FunctionTok{summary}\NormalTok{(modelo)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = fidelida ~ velocida, data = train)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -13.8349  -4.3107   0.3677   4.3413  12.3677 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  27.5486     2.6961   10.22   <2e-16 ***
## velocida      7.9736     0.6926   11.51   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 6.403 on 158 degrees of freedom
## Multiple R-squared:  0.4562, Adjusted R-squared:  0.4528 
## F-statistic: 132.6 on 1 and 158 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(fidelida }\SpecialCharTok{\textasciitilde{}}\NormalTok{ velocida, train)}
\FunctionTok{abline}\NormalTok{(modelo)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-5-1} \end{center}

Para calcular predicciones (estimaciones de la media condicionada), también intervalos de confianza o de predicción, se puede emplear la función \texttt{predict()} (consultar la ayuda \texttt{help(predict.lm)} para ver todas las opciones disponibles).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{valores }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{6}\NormalTok{, }\AttributeTok{len =} \DecValTok{100}\NormalTok{)}
\NormalTok{newdata }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{velocida =}\NormalTok{ valores)}
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(modelo, }\AttributeTok{newdata =}\NormalTok{ newdata, }\AttributeTok{interval =} \FunctionTok{c}\NormalTok{(}\StringTok{"confidence"}\NormalTok{))}
\CommentTok{\# head(pred)}
\FunctionTok{plot}\NormalTok{(fidelida }\SpecialCharTok{\textasciitilde{}}\NormalTok{ velocida, train)}
\FunctionTok{matlines}\NormalTok{(valores, pred, }\AttributeTok{lty =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{col =} \DecValTok{1}\NormalTok{)}
\NormalTok{pred2 }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(modelo, }\AttributeTok{newdata =}\NormalTok{ newdata, }\AttributeTok{interval =} \FunctionTok{c}\NormalTok{(}\StringTok{"prediction"}\NormalTok{))}
\FunctionTok{matlines}\NormalTok{(valores, pred2[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{lty =} \DecValTok{3}\NormalTok{, }\AttributeTok{col =} \DecValTok{1}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"Ajuste"}\NormalTok{, }\StringTok{"Int. confianza"}\NormalTok{, }\StringTok{"Int. predicción"}\NormalTok{), }\AttributeTok{lty =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-6-1} \end{center}

Para la extracción de información se pueden acceder a los componentes del modelo ajustado o emplear funciones (genéricas; muchas de ellas válidas para otro tipo de modelos: rlm, glm\ldots).
Algunas de las más utilizadas son las siguientes:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.12}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.88}}@{}}
\toprule
Función & Descripción \\
\midrule
\endhead
\texttt{fitted} & valores ajustados \\
\texttt{coef} & coeficientes estimados (y errores estándar) \\
\texttt{confint} & intervalos de confianza para los coeficientes \\
\texttt{residuals} & residuos \\
\texttt{plot} & gráficos de diagnóstico \\
\texttt{termplot} & gráfico de efectos parciales \\
\texttt{anova} & calcula tablas de análisis de varianza (también permite comparar modelos) \\
\texttt{influence.measures} & calcula medidas de diagnóstico (``dejando uno fuera''; LOOCV) \\
\texttt{update} & actualiza un modelo (p.e. eliminando o añadiendo variables) \\
\bottomrule
\end{longtable}

Ejemplos (no evaluados):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelo2 }\OtherTok{\textless{}{-}} \FunctionTok{update}\NormalTok{(modelo, . }\SpecialCharTok{\textasciitilde{}}\NormalTok{ . }\SpecialCharTok{+}\NormalTok{ calidadp)}
\FunctionTok{summary}\NormalTok{(modelo2)}
\FunctionTok{confint}\NormalTok{(modelo2)}
\FunctionTok{anova}\NormalTok{(modelo2)}
\FunctionTok{anova}\NormalTok{(modelo, modelo2)}
\NormalTok{oldpar }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{termplot}\NormalTok{(modelo2, }\AttributeTok{partial.resid =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{par}\NormalTok{(oldpar)}
\end{Highlighting}
\end{Shaded}

\hypertarget{colinealidad}{%
\section{El problema de la colinealidad}\label{colinealidad}}

Si alguna de las variables explicativas no aporta información relevante sobre la respuesta puede aparecer el problema de la colinealidad.

En regresión múltiple se supone que ninguna de las variables explicativas es combinación lineal de las demás.
Si una de las variables explicativas (variables independientes) es combinación lineal de las otras, no se pueden determinar los parámetros de forma única (sistema singular).
Sin llegar a esta situación extrema, cuando algunas variables explicativas estén altamente correlacionadas entre sí, tendremos una situación de alta colinealidad.
En este caso las estimaciones de los parámetros pueden verse seriamente afectadas:

\begin{itemize}
\item
  Tendrán varianzas muy altas (serán poco eficientes).
\item
  Habrá mucha dependencia entre ellas (al modificar ligeramente el
  modelo, añadiendo o eliminando una variable o una observación,
  se producirán grandes cambios en las estimaciones de los efectos).
\end{itemize}

Consideraremos un ejemplo de regresión lineal bidimensional con datos simulados en el que las dos variables explicativas están altamente correlacionadas:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{50}
\NormalTok{rand.gen }\OtherTok{\textless{}{-}}\NormalTok{ runif }\CommentTok{\# rnorm}
\NormalTok{x1 }\OtherTok{\textless{}{-}} \FunctionTok{rand.gen}\NormalTok{(n)}
\NormalTok{rho }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FloatTok{0.99}\NormalTok{) }\CommentTok{\# coeficiente de correlación}
\NormalTok{x2 }\OtherTok{\textless{}{-}}\NormalTok{ rho}\SpecialCharTok{*}\NormalTok{x1 }\SpecialCharTok{+} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ rho}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{*}\FunctionTok{rand.gen}\NormalTok{(n)}
\NormalTok{fit.x2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(x2 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1)}
\CommentTok{\# plot(x1, x2)}
\CommentTok{\# summary(fit.x2)}

\CommentTok{\# Rejilla x{-}y para predicciones:}
\NormalTok{x1.range }\OtherTok{\textless{}{-}} \FunctionTok{range}\NormalTok{(x1)}
\NormalTok{x1.grid }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(x1.range[}\DecValTok{1}\NormalTok{], x1.range[}\DecValTok{2}\NormalTok{], }\AttributeTok{length.out =} \DecValTok{30}\NormalTok{)}
\NormalTok{x2.range }\OtherTok{\textless{}{-}} \FunctionTok{range}\NormalTok{(x2)}
\NormalTok{x2.grid }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(x2.range[}\DecValTok{1}\NormalTok{], x2.range[}\DecValTok{2}\NormalTok{], }\AttributeTok{length.out =} \DecValTok{30}\NormalTok{)}
\NormalTok{xy }\OtherTok{\textless{}{-}} \FunctionTok{expand.grid}\NormalTok{(}\AttributeTok{x1 =}\NormalTok{ x1.grid, }\AttributeTok{x2 =}\NormalTok{ x2.grid)}

\CommentTok{\# Modelo teórico:}
\NormalTok{model.teor }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x1, x2) x1}
\CommentTok{\# model.teor \textless{}{-} function(x1, x2) x1 {-} 0.5*x2}
\NormalTok{y.grid }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{mapply}\NormalTok{(model.teor, xy}\SpecialCharTok{$}\NormalTok{x1, xy}\SpecialCharTok{$}\NormalTok{x2), }\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(x1.grid))}
\NormalTok{y.mean }\OtherTok{\textless{}{-}} \FunctionTok{mapply}\NormalTok{(model.teor, x1, x2)}
\end{Highlighting}
\end{Shaded}

Tendencia teórica y valores de las variables explicativas:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(plot3D)}
\NormalTok{ylim }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{) }\CommentTok{\# range(y, y.pred)}
\FunctionTok{scatter3D}\NormalTok{(}\AttributeTok{z =}\NormalTok{ y.mean, }\AttributeTok{x =}\NormalTok{ x1, }\AttributeTok{y =}\NormalTok{ x2, }\AttributeTok{pch =} \DecValTok{16}\NormalTok{, }\AttributeTok{cex =} \DecValTok{1}\NormalTok{, }\AttributeTok{clim =}\NormalTok{ ylim, }\AttributeTok{zlim =}\NormalTok{ ylim,}
          \AttributeTok{theta =} \SpecialCharTok{{-}}\DecValTok{40}\NormalTok{, }\AttributeTok{phi =} \DecValTok{20}\NormalTok{, }\AttributeTok{ticktype =} \StringTok{"detailed"}\NormalTok{, }
          \AttributeTok{main =} \StringTok{"Modelo teórico y valores de las variables explicativas"}\NormalTok{,}
          \AttributeTok{xlab =} \StringTok{"x1"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"x2"}\NormalTok{, }\AttributeTok{zlab =} \StringTok{"y"}\NormalTok{, }\AttributeTok{sub =} \FunctionTok{sprintf}\NormalTok{(}\StringTok{"R2(x1,x2) = \%.2f"}\NormalTok{, }\FunctionTok{summary}\NormalTok{(fit.x2)}\SpecialCharTok{$}\NormalTok{r.squared),}
          \AttributeTok{surf =} \FunctionTok{list}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x1.grid, }\AttributeTok{y =}\NormalTok{ x2.grid, }\AttributeTok{z =}\NormalTok{ y.grid, }\AttributeTok{facets =} \ConstantTok{NA}\NormalTok{))}
\FunctionTok{scatter3D}\NormalTok{(}\AttributeTok{z =} \FunctionTok{rep}\NormalTok{(ylim[}\DecValTok{1}\NormalTok{], n), }\AttributeTok{x =}\NormalTok{ x1, }\AttributeTok{y =}\NormalTok{ x2, }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{colkey =} \ConstantTok{FALSE}\NormalTok{, }
           \AttributeTok{pch =} \DecValTok{16}\NormalTok{, }\AttributeTok{cex =} \DecValTok{1}\NormalTok{, }\AttributeTok{col =} \StringTok{"black"}\NormalTok{)}
\NormalTok{x2.pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(fit.x2, }\AttributeTok{newdata =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x1 =}\NormalTok{ x1.range))}
\FunctionTok{lines3D}\NormalTok{(}\AttributeTok{z =} \FunctionTok{rep}\NormalTok{(ylim[}\DecValTok{1}\NormalTok{], }\DecValTok{2}\NormalTok{), }\AttributeTok{x =}\NormalTok{ x1.range, }\AttributeTok{y =}\NormalTok{ x2.pred, }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{colkey =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{col =} \StringTok{"black"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-9-1} \end{center}

Simulación de la respuesta:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sd.err }\OtherTok{\textless{}{-}} \FloatTok{0.25}
\NormalTok{nsim }\OtherTok{\textless{}{-}} \DecValTok{10}

\ControlFlowTok{for}\NormalTok{ (isim }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nsim) \{}
  \FunctionTok{set.seed}\NormalTok{(isim)}
\NormalTok{  y }\OtherTok{\textless{}{-}}\NormalTok{ y.mean }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, sd.err)}
  
  \CommentTok{\# Ajuste lineal y superficie de predicción}
\NormalTok{  fit }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2)}
\NormalTok{  y.pred }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{predict}\NormalTok{(fit, }\AttributeTok{newdata =}\NormalTok{ xy), }\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(x1.grid)) }
  
  \CommentTok{\# Representar}
\NormalTok{  fitpoints }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(fit) }
  \FunctionTok{scatter3D}\NormalTok{(}\AttributeTok{z =}\NormalTok{ y, }\AttributeTok{x =}\NormalTok{ x1, }\AttributeTok{y =}\NormalTok{ x2, }\AttributeTok{pch =} \DecValTok{16}\NormalTok{, }\AttributeTok{cex =} \FloatTok{1.5}\NormalTok{, }\AttributeTok{clim =}\NormalTok{ ylim, }\AttributeTok{zlim =}\NormalTok{ ylim,}
            \AttributeTok{theta =} \SpecialCharTok{{-}}\DecValTok{40}\NormalTok{, }\AttributeTok{phi =} \DecValTok{20}\NormalTok{, }\AttributeTok{ticktype =} \StringTok{"detailed"}\NormalTok{, }
            \AttributeTok{main =} \StringTok{"Modelo ajustado"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"x1"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"x2"}\NormalTok{, }\AttributeTok{zlab =} \StringTok{"y"}\NormalTok{, }
            \AttributeTok{surf =} \FunctionTok{list}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x1.grid, }\AttributeTok{y =}\NormalTok{ x2.grid, }\AttributeTok{z =}\NormalTok{ y.pred, }
                        \AttributeTok{facets =} \ConstantTok{NA}\NormalTok{, }\AttributeTok{fit =}\NormalTok{ fitpoints))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sd.err }\OtherTok{\textless{}{-}} \FloatTok{0.25}
\NormalTok{oldpar }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (isim }\ControlFlowTok{in} \DecValTok{7}\SpecialCharTok{:}\DecValTok{10}\NormalTok{) \{}
  \FunctionTok{set.seed}\NormalTok{(isim)}
\NormalTok{  y }\OtherTok{\textless{}{-}}\NormalTok{ y.mean }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, sd.err)}
  
  \CommentTok{\# Ajuste lineal y superficie de predicción}
\NormalTok{  fit }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2)}
\NormalTok{  y.pred }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{predict}\NormalTok{(fit, }\AttributeTok{newdata =}\NormalTok{ xy), }\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(x1.grid)) }
  
  \CommentTok{\# Representar}
\NormalTok{  fitpoints }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(fit) }
  \FunctionTok{scatter3D}\NormalTok{(}\AttributeTok{z =}\NormalTok{ y, }\AttributeTok{x =}\NormalTok{ x1, }\AttributeTok{y =}\NormalTok{ x2, }\AttributeTok{pch =} \DecValTok{16}\NormalTok{, }\AttributeTok{cex =} \FloatTok{1.5}\NormalTok{, }\AttributeTok{clim =}\NormalTok{ ylim, }\AttributeTok{zlim =}\NormalTok{ ylim,}
            \AttributeTok{theta =} \SpecialCharTok{{-}}\DecValTok{40}\NormalTok{, }\AttributeTok{phi =} \DecValTok{20}\NormalTok{, }\AttributeTok{ticktype =} \StringTok{"detailed"}\NormalTok{, }
            \AttributeTok{main =} \StringTok{"Modelo ajustado"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"x1"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"x2"}\NormalTok{, }\AttributeTok{zlab =} \StringTok{"y"}\NormalTok{, }
            \AttributeTok{surf =} \FunctionTok{list}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x1.grid, }\AttributeTok{y =}\NormalTok{ x2.grid, }\AttributeTok{z =}\NormalTok{ y.pred, }
                        \AttributeTok{facets =} \ConstantTok{NA}\NormalTok{, }\AttributeTok{fit =}\NormalTok{ fitpoints))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{06-modelos_lineales_files/figure-latex/multicol-movie-latex-1} 

}

\caption{Ejemplo de simulaciones bajo colinelidad.}\label{fig:multicol-movie-latex}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(oldpar)}
\end{Highlighting}
\end{Shaded}

Incluso puede ocurrir que el contraste de regresión sea significativo (alto coeficiente de determinación), pero los contrastes individuales sean no significativos.

Por ejemplo, en el último ajuste obtendríamos:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y ~ x1 + x2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.45461 -0.13147  0.01428  0.16316  0.36616 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)
## (Intercept) -0.11373    0.08944  -1.272    0.210
## x1           0.87084    1.19929   0.726    0.471
## x2           0.16752    1.19337   0.140    0.889
## 
## Residual standard error: 0.2209 on 47 degrees of freedom
## Multiple R-squared:  0.6308, Adjusted R-squared:  0.6151 
## F-statistic: 40.15 on 2 and 47 DF,  p-value: 6.776e-11
\end{verbatim}

Si las variables explicativas no estuviesen correlacionadas:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x2 }\OtherTok{\textless{}{-}} \FunctionTok{rand.gen}\NormalTok{(n)}
\NormalTok{y.mean }\OtherTok{\textless{}{-}} \FunctionTok{mapply}\NormalTok{(model.teor, x1, x2)}

\ControlFlowTok{for}\NormalTok{ (isim }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nsim) \{}
  \CommentTok{\# Simular respuesta}
  \FunctionTok{set.seed}\NormalTok{(isim)}
\NormalTok{  y }\OtherTok{\textless{}{-}}\NormalTok{ y.mean }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, sd.err)}
  
  \CommentTok{\# Ajuste lineal y superficie de predicción}
\NormalTok{  fit2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2)}
\NormalTok{  y.pred }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{predict}\NormalTok{(fit2, }\AttributeTok{newdata =}\NormalTok{ xy), }\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(x1.grid)) }
  
  \CommentTok{\# Representar}
\NormalTok{  fitpoints }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(fit2) }
  \FunctionTok{scatter3D}\NormalTok{(}\AttributeTok{z =}\NormalTok{ y, }\AttributeTok{x =}\NormalTok{ x1, }\AttributeTok{y =}\NormalTok{ x2, }\AttributeTok{pch =} \DecValTok{16}\NormalTok{, }\AttributeTok{cex =} \FloatTok{1.5}\NormalTok{, }\AttributeTok{clim =}\NormalTok{ ylim, }\AttributeTok{zlim =}\NormalTok{ ylim,}
            \AttributeTok{theta =} \SpecialCharTok{{-}}\DecValTok{40}\NormalTok{, }\AttributeTok{phi =} \DecValTok{20}\NormalTok{, }\AttributeTok{ticktype =} \StringTok{"detailed"}\NormalTok{, }
            \AttributeTok{main =} \StringTok{"Modelo ajustado"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"x1"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"x2"}\NormalTok{, }\AttributeTok{zlab =} \StringTok{"y"}\NormalTok{, }
            \AttributeTok{surf =} \FunctionTok{list}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x1.grid, }\AttributeTok{y =}\NormalTok{ x2.grid, }\AttributeTok{z =}\NormalTok{ y.pred, }
                        \AttributeTok{facets =} \ConstantTok{NA}\NormalTok{, }\AttributeTok{fit =}\NormalTok{ fitpoints))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x2 }\OtherTok{\textless{}{-}} \FunctionTok{rand.gen}\NormalTok{(n)}
\NormalTok{y.mean }\OtherTok{\textless{}{-}} \FunctionTok{mapply}\NormalTok{(model.teor, x1, x2)}
\NormalTok{oldpar }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (isim }\ControlFlowTok{in} \DecValTok{7}\SpecialCharTok{:}\DecValTok{10}\NormalTok{) \{}
  \CommentTok{\# Simular respuesta}
  \FunctionTok{set.seed}\NormalTok{(isim)}
\NormalTok{  y }\OtherTok{\textless{}{-}}\NormalTok{ y.mean }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, sd.err)}
  
  \CommentTok{\# Ajuste lineal y superficie de predicción}
\NormalTok{  fit2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2)}
\NormalTok{  y.pred }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{predict}\NormalTok{(fit2, }\AttributeTok{newdata =}\NormalTok{ xy), }\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(x1.grid)) }
  
  \CommentTok{\# Representar}
\NormalTok{  fitpoints }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(fit2) }
  \FunctionTok{scatter3D}\NormalTok{(}\AttributeTok{z =}\NormalTok{ y, }\AttributeTok{x =}\NormalTok{ x1, }\AttributeTok{y =}\NormalTok{ x2, }\AttributeTok{pch =} \DecValTok{16}\NormalTok{, }\AttributeTok{cex =} \FloatTok{1.5}\NormalTok{, }\AttributeTok{clim =}\NormalTok{ ylim, }\AttributeTok{zlim =}\NormalTok{ ylim,}
            \AttributeTok{theta =} \SpecialCharTok{{-}}\DecValTok{40}\NormalTok{, }\AttributeTok{phi =} \DecValTok{20}\NormalTok{, }\AttributeTok{ticktype =} \StringTok{"detailed"}\NormalTok{, }
            \AttributeTok{main =} \StringTok{"Modelo ajustado"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"x1"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"x2"}\NormalTok{, }\AttributeTok{zlab =} \StringTok{"y"}\NormalTok{, }
            \AttributeTok{surf =} \FunctionTok{list}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x1.grid, }\AttributeTok{y =}\NormalTok{ x2.grid, }\AttributeTok{z =}\NormalTok{ y.pred, }
                        \AttributeTok{facets =} \ConstantTok{NA}\NormalTok{, }\AttributeTok{fit =}\NormalTok{ fitpoints))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{06-modelos_lineales_files/figure-latex/indep-movie-latex-1} 

}

\caption{Ejemplo de simulaciones bajo independencia.}\label{fig:indep-movie-latex}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(oldpar)}
\end{Highlighting}
\end{Shaded}

Por ejemplo, en el último ajuste obtendríamos:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(fit2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y ~ x1 + x2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.45800 -0.08645  0.00452  0.15402  0.33662 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -0.22365    0.08515  -2.627   0.0116 *  
## x1           1.04125    0.11044   9.428 2.07e-12 ***
## x2           0.22334    0.10212   2.187   0.0337 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.2105 on 47 degrees of freedom
## Multiple R-squared:  0.6648, Adjusted R-squared:  0.6505 
## F-statistic:  46.6 on 2 and 47 DF,  p-value: 7.016e-12
\end{verbatim}

En la práctica, para la detección de colinealidad, se puede emplear la función
\texttt{vif()} del paquete \href{https://CRAN.R-project.org/package=car}{\texttt{car}} para calcular los factores de inflación de varianza para las variables del modelo.
Por ejemplo, en los últimos ajustes obtendríamos:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(car)}
\FunctionTok{vif}\NormalTok{(fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       x1       x2 
## 107.0814 107.0814
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{vif}\NormalTok{(fit2) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       x1       x2 
## 1.000139 1.000139
\end{verbatim}

La idea de este estadístico es que la varianza de la estimación del efecto en
regresión simple (efecto global) es menor que en regresión múltiple (efecto parcial).
El factor de inflación de la varianza mide el incremento debido a la colinealidad.
Valores grandes, por ejemplo \textgreater{} 10, indican la posible presencia de colinealidad.

Las tolerancias, proporciones de variabilidad no explicada por las demás covariables, se pueden calcular con \texttt{1/vif(modelo)}.
Por ejemplo, los coeficientes de tolerancia de los últimos ajustes serían:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\SpecialCharTok{/}\FunctionTok{vif}\NormalTok{(fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          x1          x2 
## 0.009338689 0.009338689
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\SpecialCharTok{/}\FunctionTok{vif}\NormalTok{(fit2) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        x1        x2 
## 0.9998606 0.9998606
\end{verbatim}

Como ya se comentó en la Sección 1.4, el problema de la colinealidad se agrava al aumentar el número de dimensiones (la maldición de la dimensionalidad).
Hay que tener en cuenta también que, además de la dificultad para interpretar el efecto de los predictores, va a resultar más difícil determinar que variables son de interés para predecir la respuesta (i.e.~no son ruido). Debido a la aleatoriedad, predictores que realmente no están relacionados con la respuesta pueden ser tenidos en cuenta por el modelo con mayor facilidad, especialmente si se recurre a los contrastes tradicionales para determinar si tienen un efecto significativo.

\hypertarget{seleccion-reg-lineal}{%
\section{Selección de variables explicativas}\label{seleccion-reg-lineal}}

Cuando se dispone de un conjunto grande de posibles variables explicativas
suele ser especialmente importante determinar cuales de estas deberían ser
incluidas en el modelo de regresión. Si alguna de las variables no contiene
información relevante sobre la respuesta no se debería incluir (se simplificaría
la interpretación del modelo, aumentaría la precisión de la estimación y se
evitarían problemas como la colinealidad). Se trataría entonces de conseguir
un buen ajuste con el menor número de variables explicativas posible.

Para obtener el modelo ``óptimo'' lo ideal sería evaluar todos los modelos posibles.

\hypertarget{buxfasqueda-exhaustiva}{%
\subsection{Búsqueda exhaustiva}\label{buxfasqueda-exhaustiva}}

La función \texttt{regsubsets} del paquete \texttt{leaps} permite seleccionar los mejores modelos
fijando el número de variables explicativas.
Por defecto, evalúa todos los modelos posibles con un determinado número de
parámetros (variando desde 1 hasta por defecto un máximo de \texttt{nvmax\ =\ 8})
y selecciona el mejor (\texttt{nbest\ =\ 1}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(leaps)}
\NormalTok{regsel }\OtherTok{\textless{}{-}} \FunctionTok{regsubsets}\NormalTok{(fidelida }\SpecialCharTok{\textasciitilde{}}\NormalTok{ . , }\AttributeTok{data =}\NormalTok{ train)}
\CommentTok{\# summary(regsel)}
\CommentTok{\# names(summary(regsel))}
\end{Highlighting}
\end{Shaded}

Al representar el resultado se obtiene un gráfico con los mejores modelos ordenados
según el criterio determinado por el argumento \texttt{scale\ =\ c("bic",\ "Cp",\ "adjr2",\ "r2")}.
Por ejemplo, en este caso, empleando el coeficiente de determinación ajustado, obtendríamos:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(regsel, }\AttributeTok{scale =} \StringTok{"adjr2"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-15-1} \end{center}

En este caso, considerando que es preferible un modelo más simple que una mejora del 2\%, podríamos seleccionar como modelo final el modelo con dos predictores.
Podríamos obtener los coeficientes:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coef}\NormalTok{(regsel, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept)    calidadp    velocida 
##    3.332511    3.204201    7.700260
\end{verbatim}

pero normalmente nos interesará ajustarlo de nuevo:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lm}\NormalTok{(fidelida }\SpecialCharTok{\textasciitilde{}}\NormalTok{ velocida }\SpecialCharTok{+}\NormalTok{ calidadp, }\AttributeTok{data =}\NormalTok{ train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = fidelida ~ velocida + calidadp, data = train)
## 
## Coefficients:
## (Intercept)     velocida     calidadp  
##       3.333        7.700        3.204
\end{verbatim}

\textbf{Notas}:

\begin{itemize}
\item
  Si se emplea alguno de los criterios habituales, el mejor modelo con un determinado
  número de variables no depende del criterio empleado.
  Aunque estos criterios pueden diferir al comparar modelos con distinto número de
  variables explicativas.
\item
  Si el número de variables explicativas es grande, en lugar de emplear una
  búsqueda exhaustiva se puede emplear un criterio por pasos, mediante el argumento
  \texttt{method\ =\ c("backward",\ "forward",\ "seqrep")}, pero puede ser recomendable
  emplear el paquete \texttt{MASS} para obtener directamente el modelo final.
\end{itemize}

\hypertarget{selecciuxf3n-por-pasos}{%
\subsection{Selección por pasos}\label{selecciuxf3n-por-pasos}}

Si el número de variables es grande (no sería práctico evaluar todas las posibilidades)
se suele utilizar alguno (o varios) de los siguientes métodos:

\begin{itemize}
\item
  \emph{Selección progresiva} (forward): Se parte de una situación en la
  que no hay ninguna variable y en cada paso se incluye una aplicando
  un criterio de entrada (hasta que ninguna de las restantes lo
  verifican).
\item
  \emph{Eliminación progresiva} (backward): Se parte del modelo con todas
  las variables y en cada paso se elimina una aplicando un criterio
  de salida (hasta que ninguna de las incluidas lo verifican).
\item
  \emph{Selección paso a paso} (stepwise): El más utilizado, se combina
  un criterio de entrada y uno de salida. Normalmente se parte sin
  ninguna variable y en cada paso puede haber una inclusión y una
  exclusión (forward/backward).
\end{itemize}

La función \texttt{stepAIC} del paquete \texttt{MASS} permite seleccionar el modelo por pasos, hacia delante o hacia atrás según criterio AIC o BIC (también esta disponible una función \texttt{step} del paquete base \texttt{stats} con menos opciones).
La función \texttt{stepwise} del paquete \texttt{RcmdrMisc} es una interfaz de \texttt{stepAIC} que facilita su uso:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(MASS)}
\FunctionTok{library}\NormalTok{(RcmdrMisc)}
\NormalTok{modelo.completo }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(fidelida }\SpecialCharTok{\textasciitilde{}}\NormalTok{ . , }\AttributeTok{data =}\NormalTok{ train)}
\NormalTok{modelo }\OtherTok{\textless{}{-}} \FunctionTok{stepwise}\NormalTok{(modelo.completo, }\AttributeTok{direction =} \StringTok{"forward/backward"}\NormalTok{, }\AttributeTok{criterion =} \StringTok{"BIC"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Direction:  forward/backward
## Criterion:  BIC 
## 
## Start:  AIC=694.72
## fidelida ~ 1
## 
##            Df Sum of Sq     RSS    AIC
## + velocida  1    5435.2  6478.5 602.32
## + producto  1    5339.6  6574.2 604.67
## + quejas    1    4405.4  7508.4 625.93
## + calidadp  1    3664.7  8249.1 640.98
## + facturac  1    2962.6  8951.2 654.05
## + publi     1     866.5 11047.3 687.71
## + web       1     572.1 11341.6 691.92
## + imgfvent  1     516.4 11397.4 692.70
## + precio    1     433.4 11480.4 693.87
## <none>                  11913.8 694.72
## + garantia  1     248.7 11665.1 696.42
## + nprod     1     234.1 11679.6 696.62
## + soporte   1      59.0 11854.7 699.00
## + flexprec  1      35.9 11877.9 699.31
## 
## Step:  AIC=602.32
## fidelida ~ velocida
## 
##            Df Sum of Sq     RSS    AIC
## + calidadp  1    3288.7  3189.9 494.04
## + flexprec  1    1395.7  5082.9 568.58
## + producto  1    1312.1  5166.5 571.19
## + precio    1     254.7  6223.8 600.98
## <none>                   6478.5 602.32
## + web       1      54.4  6424.2 606.05
## + nprod     1      45.1  6433.4 606.28
## + quejas    1      13.5  6465.1 607.06
## + facturac  1       9.6  6468.9 607.16
## + publi     1       8.4  6470.1 607.19
## + soporte   1       7.9  6470.6 607.20
## + garantia  1       4.8  6473.7 607.28
## + imgfvent  1       2.4  6476.1 607.34
## - velocida  1    5435.2 11913.8 694.72
## 
## Step:  AIC=494.04
## fidelida ~ velocida + calidadp
## 
##            Df Sum of Sq    RSS    AIC
## + web       1     175.4 3014.5 490.06
## + imgfvent  1     125.6 3064.3 492.68
## <none>                  3189.9 494.04
## + precio    1      95.3 3094.6 494.26
## + publi     1      48.1 3141.8 496.68
## + soporte   1      29.4 3160.5 497.63
## + facturac  1      15.3 3174.6 498.34
## + nprod     1       9.7 3180.2 498.63
## + garantia  1       6.2 3183.7 498.80
## + quejas    1       5.2 3184.7 498.85
## + flexprec  1       4.8 3185.0 498.87
## + producto  1       3.6 3186.3 498.93
## - calidadp  1    3288.7 6478.5 602.32
## - velocida  1    5059.2 8249.1 640.98
## 
## Step:  AIC=490.06
## fidelida ~ velocida + calidadp + web
## 
##            Df Sum of Sq    RSS    AIC
## <none>                  3014.5 490.06
## + precio    1      53.8 2960.7 492.26
## + soporte   1      24.2 2990.3 493.85
## + facturac  1      21.9 2992.6 493.97
## - web       1     175.4 3189.9 494.04
## + quejas    1      14.7 2999.8 494.36
## + flexprec  1      10.6 3004.0 494.58
## + producto  1      10.3 3004.2 494.59
## + garantia  1       9.7 3004.8 494.62
## + nprod     1       5.3 3009.3 494.86
## + imgfvent  1       2.5 3012.1 495.01
## + publi     1       0.2 3014.3 495.13
## - calidadp  1    3409.7 6424.2 606.05
## - velocida  1    4370.9 7385.4 628.36
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(modelo)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = fidelida ~ velocida + calidadp + web, data = train)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -12.1533  -1.8588   0.1145   3.0086   7.7625 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  -1.2205     3.0258  -0.403  0.68724    
## velocida      7.3582     0.4893  15.040  < 2e-16 ***
## calidadp      3.2794     0.2469  13.283  < 2e-16 ***
## web           1.4005     0.4649   3.012  0.00302 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 4.396 on 156 degrees of freedom
## Multiple R-squared:  0.747,  Adjusted R-squared:  0.7421 
## F-statistic: 153.5 on 3 and 156 DF,  p-value: < 2.2e-16
\end{verbatim}

Los métodos disponibles son \texttt{"backward/forward"}, \texttt{"forward/backward"}, \texttt{"backward"} y \texttt{"forward"}.

Cuando el número de variables explicativas es muy grande (o si el tamaño de la muestra es pequeño en comparación) pueden aparecer problemas al emplear los métodos anteriores (incluso pueden no ser aplicables).
Una alternativa son los métodos de regularización (ridge regression, lasso; Sección \ref{shrinkage}) o los de reducción de la dimensión (regresión con componentes principales o mínimos cuadrados parciales; Sección \ref{pca-pls}).

Por otra parte en los modelos anteriores no se consideraron interacciones entre predictores (para detalles sobre como incluir interacciones en modelos lineales ver por ejemplo la \href{https://rubenfcasal.github.io/intror/modelos-lineales.html\#interacciones}{Sección 8.6} de \protect\hyperlink{ref-fernandez2019intror}{Fernández-Casal et~al., 2019}).
Por ejemplo podríamos considerar como modelo completo \texttt{respuesta\ \textasciitilde{}\ .*.}, que incluiría los efectos principales y las interacciones de orden 2 de todos los predictores.

En la práctica se suele comenzar con modelos aditivos y posteriormente se estudian posibles interacciones siguiendo un proceso interactivo (aunque también, por ejemplo, se podría considerar un nuevo modelo completo a partir de las variables seleccionadas en el modelo aditivo, incluyendo todas las posibles interacciones de orden 2, y posteriormente aplicar alguno de los métodos de selección anteriores).
Como ya vimos en capítulos anteriores, en AE interesan algoritmos que puedan detectar e incorporar automáticamente efectos de interacción (en el siguiente capítulo veremos extensiones en este sentido).

\hypertarget{analisis-reg-multiple}{%
\section{Análisis e interpretación del modelo}\label{analisis-reg-multiple}}

Al margen de la colinealidad, si no se verifican las otras hipótesis estructurales del modelo (Sección \ref{reg-multiple}), las conclusiones obtenidas pueden no ser fiables, o incluso totalmente erróneas:

\begin{itemize}
\item
  La falta de linealidad ``invalida'' las conclusiones obtenidas
  (cuidado con las extrapolaciones).
\item
  La falta de normalidad tiene poca influencia si el
  número de datos es suficientemente grande (TCL). En caso contrario
  la estimación de la varianza, los intervalos de confianza y los
  contrastes podrían verse afectados.
\item
  Si no hay igualdad de varianzas los estimadores de los
  parámetros no son eficientes pero sí insesgados. Las varianzas, los
  intervalos de confianza y contrastes podrían verse afectados.
\item
  La dependencia entre observaciones puede tener un efecto mucho
  más grave.
\end{itemize}

Con la función \texttt{plot} se pueden generar gráficos de interés para la diagnosis del modelo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{oldpar }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(modelo)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-19-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(oldpar)}
\end{Highlighting}
\end{Shaded}

Por defecto se muestran cuatro gráficos (ver \texttt{help(plot.lm)} para más detalles).
El primero (residuos frente a predicciones) permite detectar falta de
linealidad o heterocedasticidad (o el efecto de un factor omitido: mala
especificación del modelo), lo ideal sería no observar ningún patrón.

El segundo gráfico (gráfico QQ), permite diagnosticar la normalidad,
los puntos del deberían estar cerca de la diagonal.

El tercer gráfico de dispersión-nivel permite detectar heterocedasticidad (la pendiente debería ser nula) y ayudar a seleccionar una transformación para corregirla (también se podría emplear la función \texttt{boxcox()} del paquete \texttt{MASS}).

El último gráfico permite detectar valores atípicos o influyentes. Representa los residuos estandarizados en función del valor de influencia (a priori) o leverage (\(hii\) que depende de los valores de las variables explicativas, debería ser \(< 2(p+1)/2\)) y señala las observaciones atípicas (residuos fuera de {[}-2,2{]}) e influyentes a posteriori (estadístico de Cook \textgreater0.5 y \textgreater1).

Si las conclusiones obtenidas dependen en gran medida de una
observación (normalmente atípica), esta se denomina influyente (a
posteriori) y debe ser examinada con cuidado por el experimentador.
Se puede volver a ajustar el modelo eliminando las observaciones influyentes\footnote{Normalmente se sigue un proceso iterativo, eliminando la más influyente cada vez, por ejemplo con \texttt{which.max(cooks.distance(modelo))} y \texttt{update()}.},
pero puede ser recomendable emplear regresión lineal robusta,
por ejemplo mediante la función \texttt{rlm()} del paquete \texttt{MASS}.

En regresión lineal múltiple, en lugar de generar gráficos de dispersión simple
(p.e. gráficos de dispersión matriciales) para analizar los efectos de las variables explicativas y
detectar posibles problemas (falta de linealidad\ldots),
se pueden generar gráficos parciales de residuos, por ejemplo con el comando:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{termplot}\NormalTok{(modelo, }\AttributeTok{partial.resid =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Aunque puede ser preferible emplear las funciones \texttt{crPlots} ó \texttt{avPlots} del paquete \texttt{car}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(car)}
\FunctionTok{crPlots}\NormalTok{(modelo)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-21-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# avPlots(modelo)}
\end{Highlighting}
\end{Shaded}

Estas funciones permitirían además detectar puntos atípicos o influyentes
(mediante los argumentos \texttt{id.method} e \texttt{id.n}).

Para obtener medidas de diagnosis o resúmenes numéricos de interés se pueden emplear
las siguientes funciones (ver \texttt{help(influence.measures)} para un listado más completo):

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.10}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.90}}@{}}
\toprule
Función & Descripción \\
\midrule
\endhead
rstandard & residuos estandarizados (también eliminados) \\
rstudent & residuos estudentizados \\
cooks.distance & valores del estadístico de Cook \\
influence & valores de influencia, cambios en coeficientes y varianza residual al eliminar cada dato (LOOCV). \\
\bottomrule
\end{longtable}

Hay muchas herramientas adicionales disponibles en otros paquetes.
Por ejemplo, como ya se comentó, se puede emplear la función
\texttt{vif()} del paquete \texttt{car} para calcular los factores de inflación de varianza,
aunque puede ser preferible emplear otras medidas como el \emph{índice de condicionamiento},
implementado en el paquete \href{https://CRAN.R-project.org/package=mctest}{\texttt{mctest}}.
La librería \href{https://CRAN.R-project.org/package=lmtest}{\texttt{lmtest}} proporciona herramientas adicionales para la diagnosis de modelos lineales,
por ejemplo el test de Breusch-Pagan (para contrastar homocedasticidad) en la función \texttt{bptest()}
o el de Durbin-Watson (para detectar si hay correlación en serie) en \texttt{dwtest()}.

Posibles soluciones cuando no se satisfacen los supuestos básicos:

\begin{itemize}
\item
  Como ya se comentó, pueden llevarse a cabo transformaciones de los datos para tratar de
  corregir la falta de linealidad, heterocedasticidad y/o normalidad
  (normalmente estas últimas ``suelen ocurrir en la misma escala'').
  Otra alternativa sería tratar de emplear modelos lineales generalizados.
\item
  Si no se logra corregir la heterocedasticidad puede ser adecuado
  utilizar mínimos cuadrados ponderados (habría que modelar la varianza).
\item
  Si hay dependencia se puede tratar de modelarla y utilizar mínimos
  cuadrados generalizados.
\item
  Si no se logra corregir la falta de linealidad se puede pensar en
  utilizar modelos más flexibles (capítulo siguiente y anteriores).
\end{itemize}

\hypertarget{evaluaciuxf3n-de-la-precisiuxf3n}{%
\section{Evaluación de la precisión}\label{evaluaciuxf3n-de-la-precisiuxf3n}}

Para evaluar la precisión de las predicciones podríamos utilizar el coeficiente de determinación ajustado:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(modelo)}\SpecialCharTok{$}\NormalTok{adj.r.squared}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7421059
\end{verbatim}

que estimaría la proporción de variabilidad explicada en una nueva muestra.
Sin embargo, hay que tener en cuenta que su validez dependería de la de las hipótesis estructurales (especialmente de la linealidad, homocedasticidad e independencia), ya que se obtiene a partir de estimaciones de las varianzas residual y total:

\[R_{ajus}^{2} = 1 - \frac{\hat{S}_{R}^{2}}{\hat{S}_{Y}^{2}} 
= 1 - \left( \frac{n-1}{n-p-1} \right) (1-R^{2})\]

siendo \(\hat{S}_{R}^{2}=\sum_{i=1}^{n}(y_{i}-\hat{y}_{i})^{2}/(n - p - 1)\).
Algo similar ocurriría con otras medidas de bondad de ajuste, como por ejemplo BIC o AIC.

Alternativamente, por si no es razonable asumir estas hipótesis, se pueden emplear el procedimiento tradicional en AE (o alguno de los otros descritos en la Sección \ref{const-eval}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{obs }\OtherTok{\textless{}{-}}\NormalTok{ test}\SpecialCharTok{$}\NormalTok{fidelida}
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(modelo, }\AttributeTok{newdata =}\NormalTok{ test)}

\FunctionTok{plot}\NormalTok{(pred, obs, }\AttributeTok{main =} \StringTok{"Observado frente a predicciones"}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{"Predicción"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Observado"}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{a =} \DecValTok{0}\NormalTok{, }\AttributeTok{b =} \DecValTok{1}\NormalTok{)}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(obs }\SpecialCharTok{\textasciitilde{}}\NormalTok{ pred)}
\CommentTok{\# summary(res)}
\FunctionTok{abline}\NormalTok{(res, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-23-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{accuracy }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(pred, obs, }\AttributeTok{na.rm =} \ConstantTok{FALSE}\NormalTok{, }
                     \AttributeTok{tol =} \FunctionTok{sqrt}\NormalTok{(.Machine}\SpecialCharTok{$}\NormalTok{double.eps)) \{}
\NormalTok{  err }\OtherTok{\textless{}{-}}\NormalTok{ obs }\SpecialCharTok{{-}}\NormalTok{ pred     }\CommentTok{\# Errores}
  \ControlFlowTok{if}\NormalTok{(na.rm) \{}
\NormalTok{    is.a }\OtherTok{\textless{}{-}} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(err)}
\NormalTok{    err }\OtherTok{\textless{}{-}}\NormalTok{ err[is.a]}
\NormalTok{    obs }\OtherTok{\textless{}{-}}\NormalTok{ obs[is.a]}
\NormalTok{  \}  }
\NormalTok{  perr }\OtherTok{\textless{}{-}} \DecValTok{100}\SpecialCharTok{*}\NormalTok{err}\SpecialCharTok{/}\FunctionTok{pmax}\NormalTok{(obs, tol)  }\CommentTok{\# Errores porcentuales}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
    \AttributeTok{me =} \FunctionTok{mean}\NormalTok{(err),           }\CommentTok{\# Error medio}
    \AttributeTok{rmse =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{(err}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)), }\CommentTok{\# Raíz del error cuadrático medio }
    \AttributeTok{mae =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(err)),     }\CommentTok{\# Error absoluto medio}
    \AttributeTok{mpe =} \FunctionTok{mean}\NormalTok{(perr),         }\CommentTok{\# Error porcentual medio}
    \AttributeTok{mape =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(perr)),   }\CommentTok{\# Error porcentual absoluto medio}
    \AttributeTok{r.squared =} \DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{sum}\NormalTok{(err}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{sum}\NormalTok{((obs }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(obs))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\CommentTok{\# Pseudo R{-}cuadrado}
\NormalTok{  ))}
\NormalTok{\}}
\FunctionTok{accuracy}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         me       rmse        mae        mpe       mape  r.squared 
##  0.4032996  4.1995208  3.3013714 -0.1410512  5.9553699  0.8271449
\end{verbatim}

De igual forma, los métodos de selección de variables descritos en la Sección \ref{seleccion-reg-lineal} dependen (en mayor o menor medida) de la validez de las hipótesis estructurales.
Por este motivo se podría pensar también en emplear alguno de los procedimientos descritos en la Sección \ref{const-eval} para evaluar la precisión de los distintos modelos.
Por ejemplo adaptando adecuadamente el algoritmo de validación cruzada empleado en la Sección \ref{cv}.
Sin embargo, el procedimiento de selección debería realizarse también en cada uno de los conjuntos de entrenamiento utilizados en la validación.
Esto puede hacerse fácilmente empleando el paquete \texttt{caret}.

Por ejemplo, el método de selección por pasos hacia atrás, empleando la función \texttt{stepAIC} del paquete \texttt{MASS}, está implementado en el método \texttt{"lmStepAIC"}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}
\CommentTok{\# names(getModelInfo("lm")) \# 15 métodos}
\CommentTok{\# names(getModelInfo("leap")) \# 3 métodos}
\FunctionTok{modelLookup}\NormalTok{(}\StringTok{"lmStepAIC"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       model parameter     label forReg forClass probModel
## 1 lmStepAIC parameter parameter   TRUE    FALSE     FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{caret.lmStepAIC }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(fidelida }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{method =} \StringTok{"lmStepAIC"}\NormalTok{,}
                   \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{number =} \DecValTok{5}\NormalTok{),}
                   \AttributeTok{trace =} \DecValTok{0}\NormalTok{) }\CommentTok{\# Opción de MASS::stepAIC para no imprimir output...}
\NormalTok{caret.lmStepAIC}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Linear Regression with Stepwise Selection 
## 
## 160 samples
##  13 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 128, 127, 128, 128, 129 
## Resampling results:
## 
##   RMSE      Rsquared   MAE     
##   4.748814  0.7052369  3.615072
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{caret.lmStepAIC}\SpecialCharTok{$}\NormalTok{finalModel}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = .outcome ~ calidadp + web + precio + flexprec + 
##     velocida, data = dat)
## 
## Coefficients:
## (Intercept)     calidadp          web       precio     flexprec     velocida  
##     -3.8487       3.2198       1.2449       0.5979      -0.7551       8.1166
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(caret.lmStepAIC, }\AttributeTok{newdata =}\NormalTok{ test)}
\FunctionTok{accuracy}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         me       rmse        mae        mpe       mape  r.squared 
##  0.3735687  4.1900738  3.3732868 -0.1928986  6.0990996  0.8279217
\end{verbatim}

También está implementados métodos de selección basados en el paquete \texttt{leaps}, considerando el número máximo de predictores \texttt{nvmax} como hiperparámetro y empleando búsqueda: hacia atrás (\texttt{"leapBackward"}), hacia adelante (\texttt{"leapForward"}) y por pasos (\texttt{"leapSeq"}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{modelLookup}\NormalTok{(}\StringTok{"leapSeq"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     model parameter                        label forReg forClass probModel
## 1 leapSeq     nvmax Maximum Number of Predictors   TRUE    FALSE     FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{caret.leapSeq }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(fidelida }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{method =} \StringTok{"leapSeq"}\NormalTok{,}
                   \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{number =} \DecValTok{10}\NormalTok{),}
                   \AttributeTok{tuneGrid =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{nvmax =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{6}\NormalTok{))}
\NormalTok{caret.leapSeq}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Linear Regression with Stepwise Selection 
## 
## 160 samples
##  13 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 143, 144, 144, 143, 144, 145, ... 
## Resampling results across tuning parameters:
## 
##   nvmax  RMSE      Rsquared   MAE     
##   1      6.811476  0.3880874  5.514825
##   2      6.082191  0.5061883  4.874637
##   3      6.023200  0.5124853  4.809341
##   4      4.339067  0.7594275  3.362703
##   5      4.538799  0.7390205  3.461429
##   6      4.604788  0.7356875  3.585628
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was nvmax = 4.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# summary(caret.leapSeq$finalModel)}
\FunctionTok{with}\NormalTok{(caret.leapSeq, }\FunctionTok{coef}\NormalTok{(finalModel, bestTune}\SpecialCharTok{$}\NormalTok{nvmax))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept)    calidadp         web      precio    velocida 
##  -5.3610807   3.4712306   1.2471721   0.4190875   7.4382584
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(caret.leapSeq, }\AttributeTok{newdata =}\NormalTok{ test)}
\FunctionTok{accuracy}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         me       rmse        mae        mpe       mape  r.squared 
##  0.2886512  4.1741220  3.2946370 -0.3413883  5.9590279  0.8292294
\end{verbatim}

Además, en el caso de ajustes de modelos de este tipo, puede resultar de interés realizar un preprocesado de los datos para eliminar predictores correlados o con varianza próxima a cero,
estableciendo por ejemplo \texttt{preProc\ =\ c("nzv",\ "corr")} en la llamada a la función \texttt{train()}.

\hypertarget{shrinkage}{%
\section{Métodos de regularización}\label{shrinkage}}

Como ya se comentó, el procedimiento habitual para ajustar un modelo de regresión lineal es emplear mínimos cuadrados, es decir, utilizar como criterio de error la suma de cuadrados residual
\[\mbox{RSS} = \sum\limits_{i=1}^{n}\left(  y_{i} - \beta_0 - \boldsymbol{\beta}^t \mathbf{x}_{i} \right)^{2}\]

Si el modelo lineal es razonablemente adecuado, utilizar \(\mbox{RSS}\) va a dar lugar a estimaciones con poco sesgo, y si además \(n\gg p\), entonces el modelo también va a tener poca varianza (bajo las hipótesis estructurales, la estimación es insesgada y además de varianza mínima entre todas las técnicas insesgadas).
Las dificultades surgen cuando \(p\) es grande o cuando hay correlaciones altas entre las variables predictoras: tener muchas variables dificulta la interpretación del modelo, y si además hay problemas de colinealidad o se incumple \(n\gg p\), entonces la estimación del modelo va a tener muchas varianza y el modelo estará sobreajustado.
La solución pasa por forzar a que el modelo tenga menos complejidad para así reducir su varianza.
Una forma de conseguirlo es mediante la regularización (\emph{regularization} o \emph{shrinkage}) de la estimación de los parámetros \(\beta_1, \beta_2,\ldots, \beta_p\) que consiste en considerar todas las variables predictoras pero forzando a que algunos de los parámetros se estimen mediante valores muy próximos a cero, o directamente con ceros.
Esta técnica va a provocar un pequeño aumento en el sesgo pero a cambio una notable reducción en la varianza y una interpretación más sencilla del modelo resultante.

Hay dos formas básicas de lograr esta simplificación de los parámetros (con la consiguiente simplificación del modelo), utilizando una penalización cuadrática (norma \(L_2\)) o en valor absoluto (norma \(L_1\)):

\begin{itemize}
\item
  \emph{Ridge regression} (\protect\hyperlink{ref-hothorn2006unbiased}{Hothorn et~al., 2006})
  \[\mbox{min}_{\beta_0, \boldsymbol{\beta}} \mbox{RSS} + \lambda\sum_{j=1}^{p}\beta_{j}^{2}\]

  Equivalentemente,
  \[\mbox{min}_{\beta_0, \boldsymbol{\beta}} \mbox{RSS}\]
  sujeto a
  \[\sum_{j=1}^{p}\beta_{j}^{2} \le s\]
\item
  \emph{Lasso} (\emph{least absolute shrinkage and selection operator}, \protect\hyperlink{ref-tibshirani1996regression}{Tibshirani, 1996})
  \[\mbox{min}_{\beta_0, \boldsymbol{\beta}} RSS + \lambda\sum_{j=1}^{p}|\beta_{j}|\]

  Equivalentemente,
  \[\mbox{min}_{\beta_0, \boldsymbol{\beta}} \mbox{RSS}\]
  sujeto a
  \[\sum_{j=1}^{p}|\beta_{j}| \le s\]
\end{itemize}

Una formulación unificada consiste en considerar el problema
\[\mbox{min}_{\beta_0, \boldsymbol{\beta}} RSS + \lambda\sum_{j=1}^{p}|\beta_{j}|^d\]

Si \(d=0\), la penalización consiste en el número de variables utilizadas, por tanto se corresponde con el problema de selección de variables; \(d=1\) se corresponde con \emph{lasso} y \(d=2\) con \emph{ridge}.

La ventaja de utilizar \emph{lasso} es que va a forzar a que algunos parámetros sean cero, con lo cual también se realiza una selección de las variables más influyentes.
Por el contrario, \emph{ridge regression} va a incluir todas las variables predictoras en el modelo final, si bien es cierto que algunas con parámetros muy próximos a cero: de este modo va a reducir el riesgo del sobreajuste, pero no resuelve el problema de la interpretabilidad.
Otra posible ventaja de utilizar \emph{lasso} es que cuando hay variables predictoras correlacionadas tiene tendencia a seleccionar una y anular las demás (esto también se puede ver como un inconveniente, ya que pequeños cambios en los datos pueden dar lugar a distintos modelos), mientras que \emph{ridge} tiende a darles igual peso.

Dos generalizaciones de \emph{lasso} son \emph{least angle regression} (LARS, \protect\hyperlink{ref-efron2004least}{Efron et~al., 2004}) y \emph{elastic net} (\protect\hyperlink{ref-zou2005regularization}{Zou y Hastie, 2005}).
\emph{Elastic net} combina las ventajas de \emph{ridge} y \emph{lasso}, minimizando
\[\mbox{min}_{\beta_0, \boldsymbol{\beta}} \ \mbox{RSS} + \lambda \left( \frac{1 - \alpha}{2}\sum_{j=1}^{p}\beta_{j}^{2} + \alpha \sum_{j=1}^{p}|\beta_{j}| \right)\]
con \(0 \leq \alpha \leq 1\).

Es muy importante estandarizar (centrar y reescalar) las variables predictoras antes de realizar estas técnicas.
Fijémonos en que, así como \(\mbox{RSS}\) es insensible a los cambios de escala, la penalización es muy sensible.
Previa estandarización, el término independiente \(\beta_0\) (que no interviene en la penalización) tiene una interpretación muy directa, ya que
\[\widehat \beta_0 = \bar y =\sum_{i=1}^n \frac{y_i}{n}\]

Los dos métodos de regularización comentados dependen del hiperparámetro \(\lambda\) (equivalentemente, \(s\)).
Es muy importante seleccionar adecuadamente el valor del hiperparámetro, por ejemplo utilizando \emph{validación cruzada}.
Hay algoritmos muy eficientes que permiten el ajuste, tanto de \emph{ridge regression} como de \emph{lasso} de forma conjunta (simultánea) para todos los valores de \(\lambda\).

\hypertarget{implementaciuxf3n-en-r}{%
\subsection{Implementación en R}\label{implementaciuxf3n-en-r}}

Hay varios paquetes que implementan estos métodos: \texttt{h2o}, \texttt{elasticnet}, \texttt{penalized}, \texttt{lasso2}, \texttt{biglasso}, etc., pero el paquete \href{https://glmnet.stanford.edu}{\texttt{glmnet}} utiliza una de las más eficientes.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(glmnet)}
\end{Highlighting}
\end{Shaded}

El paquete \texttt{glmnet} no emplea formulación de modelos, hay que establecer la respuesta \texttt{y} y la matriz numérica \texttt{x} correspondiente a las variables explicativas.
Por tanto no se pueden incluir directamente predictores categóricos, habrá que codificarlos empleando variables auxiliares numéricas.
Se puede emplear la función \texttt{model.matrix()}(o \texttt{Matrix::sparse.model.matrix()} si el conjunto de datos es muy grande) para construir la matriz de diseño \texttt{x} a partir de una fórmula (alternativamente se pueden emplear la herramientas implementadas en el paquete \texttt{caret}). Además, esta función tampoco admite datos faltantes.

La función principal es:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{glmnet}\NormalTok{(x, y, family, }\AttributeTok{alpha =} \DecValTok{1}\NormalTok{, }\AttributeTok{lambda =} \ConstantTok{NULL}\NormalTok{, ...)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\item
  \texttt{family}: familia del modelo lineal generalizado (ver Sección \ref{reg-glm}); por defecto \texttt{"gaussian"} (modelo lineal con ajuste cuadrático), también admite \texttt{"binomial"}, \texttt{"poisson"}, \texttt{"multinomial"}, \texttt{"cox"} o \texttt{"mgaussian"} (modelo lineal con respuesta multivariante).
\item
  \texttt{alpha}: parámetro \(\alpha\) de elasticnet \(0 \leq \alpha \leq 1\). Por defecto \texttt{alpha\ =\ 1} penalización \emph{lasso} (\texttt{alpha\ =\ 0} para \emph{ridge regression}).
\item
  \texttt{lambda}: secuencia (opcional) de valores de \(\lambda\); si no se especifica se establece una secuencia por defecto (en base a los argumentos adicionales \texttt{nlambda} y \texttt{lambda.min.ratio}). Se devolverán los ajustes para todos los valores de esta secuencia (también se podrán obtener posteriormente para otros valores).
\end{itemize}

Entre los métodos genéricos disponibles del objeto resultante, \texttt{coef()} y \texttt{predict()} permiten obtener los coeficientes y las predicciones para un valor concreto de \(\lambda\), que se debe especificar mediante el argumento \texttt{s\ =\ valor} (``For historical reasons we use the symbol `s' rather than `lambda'\,'').

Aunque para seleccionar el un valor ``óptimo'' del hiperparámetro \(\lambda\) (mediante validación cruzada) se puede emplear:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cv.glmnet}\NormalTok{(x, y, family, alpha, lambda, }\AttributeTok{type.measure =} \StringTok{"default"}\NormalTok{, }\AttributeTok{nfolds =} \DecValTok{10}\NormalTok{, ...)}
\end{Highlighting}
\end{Shaded}

Esta función también devuelve los ajustes con toda la muestra de entrenamiento (en la componente \texttt{\$glmnet.fit}) y se puede emplear el resultado directamente para predecir o obtener los coeficientes del modelo.
Por defecto seleccionando \(\lambda\) mediante la regla de ``un error estándar'' de \protect\hyperlink{ref-breiman1984classification}{Breiman et~al.} (\protect\hyperlink{ref-breiman1984classification}{1984}) (componente \texttt{\$lambda.1se}), aunque también calcula el valor óptimo (componente \texttt{\$lambda.min}; que se puede seleccionar con estableciendo \texttt{s\ =\ "lambda.min"}).

Para más detalles consultar la vignette del paquete \href{https://glmnet.stanford.edu/articles/glmnet.html}{An Introduction to glmnet}.

Continuaremos con el ejemplo de los datos de clientes de la compañía de distribución industrial HBAT (en este caso todos los predictores son numéricos y no hay datos faltantes):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(train[, }\SpecialCharTok{{-}}\DecValTok{14}\NormalTok{])}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ train}\SpecialCharTok{$}\NormalTok{fidelida}
\end{Highlighting}
\end{Shaded}

\hypertarget{ejemplo-ridge-regression}{%
\subsection{Ejemplo: Ridge Regression}\label{ejemplo-ridge-regression}}

Ajustamos los modelos de regresión ridge (con la secuencia de valores de \(\lambda\) por defecto) con la función \texttt{glmnet()} con \texttt{alpha=0} (ridge penalty):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit.ridge }\OtherTok{\textless{}{-}} \FunctionTok{glmnet}\NormalTok{(x, y, }\AttributeTok{alpha =} \DecValTok{0}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(fit.ridge, }\AttributeTok{xvar =} \StringTok{"lambda"}\NormalTok{, }\AttributeTok{label =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-30-1} \end{center}

Podemos obtener el modelo o predicciones para un valor concreto de \(\lambda\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coef}\NormalTok{(fit.ridge, }\AttributeTok{s =} \DecValTok{2}\NormalTok{) }\CommentTok{\# lambda = 2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 14 x 1 sparse Matrix of class "dgCMatrix"
##                      s1
## (Intercept)  3.56806743
## calidadp     2.41027431
## web          0.94414628
## soporte     -0.22183509
## quejas       1.08417665
## publi        0.20121976
## producto     1.41018809
## imgfvent     0.21140360
## precio       0.26171759
## garantia     0.07110803
## nprod        0.04859325
## facturac     0.22695054
## flexprec     0.37732748
## velocida     3.11101217
\end{verbatim}

Para seleccionar el parámetro de penalización por validación cruzada empleamos \texttt{cv.glmnet()}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{cv.ridge }\OtherTok{\textless{}{-}} \FunctionTok{cv.glmnet}\NormalTok{(x, y, }\AttributeTok{alpha =} \DecValTok{0}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(cv.ridge)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-32-1} \end{center}

En este caso el parámetro óptimo (según la regla de un error estándar) sería:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cv.ridge}\SpecialCharTok{$}\NormalTok{lambda}\FloatTok{.1}\NormalTok{se}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.413705
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# cv.ridge$lambda.min}
\end{Highlighting}
\end{Shaded}

y el correspondiente modelo contiene todas las variables explicativas:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coef}\NormalTok{(cv.ridge) }\CommentTok{\# s = "lambda.1se"}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 14 x 1 sparse Matrix of class "dgCMatrix"
##                      s1
## (Intercept)  8.38314273
## calidadp     2.06713538
## web          0.84771656
## soporte     -0.17674892
## quejas       1.08099022
## publi        0.25926570
## producto     1.34198207
## imgfvent     0.21510001
## precio       0.15194226
## garantia     0.05417865
## nprod        0.08252518
## facturac     0.45964418
## flexprec     0.24646749
## velocida     2.70697234
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# coef(cv.ridge, s = "lambda.min")}
\end{Highlighting}
\end{Shaded}

Finalmente evaluamos la precisión en la muestra de test:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{newx }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(test[, }\SpecialCharTok{{-}}\DecValTok{14}\NormalTok{])}
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(cv.ridge, }\AttributeTok{newx =}\NormalTok{ newx) }\CommentTok{\# s = "lambda.1se"}
\FunctionTok{accuracy}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         me       rmse        mae        mpe       mape  r.squared 
## 0.74752331 5.04159165 4.08299692 0.03577857 7.26473444 0.75087456
\end{verbatim}

\hypertarget{ejemplo-lasso}{%
\subsection{Ejemplo: Lasso}\label{ejemplo-lasso}}

También podríamos ajustar modelos lasso con la opción por defecto de \texttt{glmnet()} (\texttt{alpha\ =\ 1}, lasso penalty).
Pero en este caso lo haremos al mismo tiempo que seleccionamos el parámetro de penalización por validación cruzada:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{cv.lasso }\OtherTok{\textless{}{-}} \FunctionTok{cv.glmnet}\NormalTok{(x,y)}
\FunctionTok{plot}\NormalTok{(cv.lasso)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-36-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(cv.lasso}\SpecialCharTok{$}\NormalTok{glmnet.fit, }\AttributeTok{xvar =} \StringTok{"lambda"}\NormalTok{, }\AttributeTok{label =} \ConstantTok{TRUE}\NormalTok{)    }
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =} \FunctionTok{log}\NormalTok{(cv.lasso}\SpecialCharTok{$}\NormalTok{lambda}\FloatTok{.1}\NormalTok{se), }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =} \FunctionTok{log}\NormalTok{(cv.lasso}\SpecialCharTok{$}\NormalTok{lambda.min), }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-36-2} \end{center}

El modelo resultante (oneSE rule) solo contiene 4 variables explicativas:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coef}\NormalTok{(cv.lasso) }\CommentTok{\# s = "lambda.1se"}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 14 x 1 sparse Matrix of class "dgCMatrix"
##                     s1
## (Intercept) 12.0485398
## calidadp     2.4673862
## web          0.3498592
## soporte      .        
## quejas       .        
## publi        .        
## producto     0.3227830
## imgfvent     .        
## precio       .        
## garantia     .        
## nprod        .        
## facturac     .        
## flexprec     .        
## velocida     6.1011015
\end{verbatim}

Por tanto este método también podría ser empleando para la selección de variables (puede hacerse automáticamente estableciendo \texttt{relax\ =\ TRUE}, ajustará los modelos sin regularización).

Finalmente evaluamos también la precisión en la muestra de test:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(cv.lasso, }\AttributeTok{newx =}\NormalTok{ newx)}
\FunctionTok{accuracy}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         me       rmse        mae        mpe       mape  r.squared 
##  0.4895391  4.8572144  3.8870383 -0.4192005  6.9713208  0.7687630
\end{verbatim}

\hypertarget{ejemplo-elastic-net}{%
\subsection{Ejemplo: Elastic Net}\label{ejemplo-elastic-net}}

Podemos ajustar modelos elastic net para un valor concreto de \texttt{alpha} empleando la función \texttt{glmnet()}, pero las opciones del paquete no incluyen la selección de este hiperparámetro.
Aunque se podría implementar fácilmente (como se muestra en \texttt{help(cv.glmnet)}), resulta mucho más cómodo emplear el método \texttt{"glmnet"} de \texttt{caret}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}
\FunctionTok{modelLookup}\NormalTok{(}\StringTok{"glmnet"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    model parameter                    label forReg forClass probModel
## 1 glmnet     alpha        Mixing Percentage   TRUE     TRUE      TRUE
## 2 glmnet    lambda Regularization Parameter   TRUE     TRUE      TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\CommentTok{\# Se podría emplear train(fidelida \textasciitilde{} ., data = train, ...)}
\NormalTok{caret.glmnet }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(x, y, }\AttributeTok{method =} \StringTok{"glmnet"}\NormalTok{,}
    \AttributeTok{preProc =} \FunctionTok{c}\NormalTok{(}\StringTok{"zv"}\NormalTok{, }\StringTok{"center"}\NormalTok{, }\StringTok{"scale"}\NormalTok{),}
    \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{number =} \DecValTok{5}\NormalTok{),}
    \AttributeTok{tuneLength =} \DecValTok{5}\NormalTok{)}


\NormalTok{caret.glmnet}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## glmnet 
## 
## 160 samples
##  13 predictor
## 
## Pre-processing: centered (13), scaled (13) 
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 129, 129, 127, 127, 128 
## Resampling results across tuning parameters:
## 
##   alpha  lambda       RMSE      Rsquared   MAE     
##   0.100  0.005410604  4.581364  0.7148069  3.414825
##   0.100  0.025113801  4.576940  0.7153275  3.408862
##   0.100  0.116567945  4.545239  0.7187940  3.361951
##   0.100  0.541060495  4.474562  0.7284099  3.295198
##   0.100  2.511380465  4.704071  0.7187452  3.594686
##   0.325  0.005410604  4.573738  0.7157479  3.408931
##   0.325  0.025113801  4.564560  0.7167890  3.397543
##   0.325  0.116567945  4.500834  0.7241961  3.326005
##   0.325  0.541060495  4.438653  0.7349191  3.306102
##   0.325  2.511380465  4.881621  0.7184709  3.757854
##   0.550  0.005410604  4.573800  0.7157344  3.411370
##   0.550  0.025113801  4.552473  0.7182118  3.386635
##   0.550  0.116567945  4.462650  0.7291272  3.299872
##   0.550  0.541060495  4.459588  0.7344030  3.358370
##   0.550  2.511380465  5.140746  0.7128471  3.964142
##   0.775  0.005410604  4.570751  0.7161237  3.409145
##   0.775  0.025113801  4.542225  0.7194584  3.378410
##   0.775  0.116567945  4.430677  0.7334438  3.277212
##   0.775  0.541060495  4.495356  0.7323161  3.413533
##   0.775  2.511380465  5.410928  0.7138082  4.213179
##   1.000  0.005410604  4.569043  0.7162973  3.407715
##   1.000  0.025113801  4.532524  0.7206448  3.371146
##   1.000  0.116567945  4.420602  0.7349329  3.279275
##   1.000  0.541060495  4.525359  0.7308248  3.449277
##   1.000  2.511380465  5.730967  0.7102963  4.473639
## 
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were alpha = 1 and lambda = 0.1165679.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(caret.glmnet, }\AttributeTok{highlight =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-39-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(caret.glmnet, }\AttributeTok{newdata =}\NormalTok{ test)}
\FunctionTok{accuracy}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          me        rmse         mae         mpe        mape   r.squared 
##  0.49843131  4.28230542  3.43805154 -0.02851825  6.15711129  0.82026278
\end{verbatim}

\hypertarget{pca-pls}{%
\section{Métodos de reducción de la dimensión}\label{pca-pls}}

Otra alternativa, para tratar de reducir la varianza de los modelos lineales, es transformar los predictores considerando \(k < p\) combinaciones lineales:
\[Z_j = a_{1j}X_{1} + a_{2j}X_{2} + \ldots + a_{pj}X_{p}\]
con \(j = 1, \ldots, k\), denominadas componentes (o variables latentes),
y posteriormente ajustar un modelo de regresión lineal empleándolas como nuevos predictores:
\[Y = \alpha_0 + \alpha_1 Z_1 + \ldots + \alpha_k Z_k + \varepsilon\]

Adicionalmente, si se seleccionan los coeficientes \(a_{ji}\) (denominados \emph{cargas} o \emph{pesos}) de forma que
\[\sum_{i=1}^p a_{ij}a_{il} = 0, \text{ si } j \neq l,\]
las componentes serán ortogonales y se evitarán posibles problemas de colinealidad.
De esta forma se reduce la dimensión del problema, pasando de \(p + 1\) a \(k + 1\) coeficientes a estimar, lo cual en principio reducirá la varianza, especialmente si \(p\) es grande en comparación con \(n\).
Por otra parte, también podríamos expresar el modelo final en función de los predictores originales, con coeficientes:
\[\beta_i = \sum_{j=1}^k \alpha_j a_{ij}\]
Es decir, se ajusta un modelo lineal con restricciones, lo que en principio incrementará el sesgo (si \(k = p\) sería equivalente a ajustar un modelo lineal sin restricciones).
Además, podríamos interpretar los coeficientes \(\alpha_j\) como los efectos de las componentes del modo tradicional, pero resultaría más complicado interpretar los efectos de los predictores originales.

También hay que tener en cuenta que al considerar combinaciones lineales, si las hipótesis estructurales de linealidad, homocedasticidad, normalidad o independencia no son asumibles en el modelo original, es de esperar que tampoco lo sean en el modelo transformado (se podrían emplear las herramientas descritas en la Sección \ref{analisis-reg-multiple} para su análisis).

Hay una gran variedad de algoritmos para obtener estas componentes, en esta sección consideraremos las dos aproximaciones más utilizadas: componentes principales y mínimos cuadrados parciales.
También hay numerosos paquetes de R que implementan métodos de este tipo (\href{https://mevik.net/work/software/pls.html}{\texttt{pls}}, \href{https://github.com/fbertran/plsRglm}{\texttt{plsRglm}}\ldots), incluyendo \texttt{caret}.

\hypertarget{regresiuxf3n-por-componentes-principales-pcr}{%
\subsection{Regresión por componentes principales (PCR)}\label{regresiuxf3n-por-componentes-principales-pcr}}

Una de las aproximaciones tradicionales, cuando se detecta la presencia de colinealidad, consiste en aplicar el método de componentes principales a los predictores.
El análisis de componentes principales (\emph{principal component analysis}, PCA) es un método muy utilizado de aprendizaje no supervisado, que permite reducir el número de dimensiones tratando de recoger la mayor parte de la variabilidad de los datos originales (en este caso de los predictores; para más detalles sobre PCA ver por ejemplo el Capítulo 10 de \protect\hyperlink{ref-james2021introduction}{James et~al., 2021}).

Al aplicar PCA a los predictores \(X_1, \ldots, X_p\) se obtienen componentes ordenados según la variabilidad explicada de forma descendente.
El primer componente es el que recoge el mayor porcentaje de la variabilidad total (se corresponde con la dirección de mayor variación de las observaciones).
Las siguientes componentes se seleccionan entre las direcciones ortogonales a las anteriores y de forma que recojan la mayor parte de la variabilidad restante.
Además estas componentes son normalizadas, de forma que:
\[\sum_{i=1}^p a_{ij}^2 = 1\]
(se busca una transformación lineal ortonormal).
En la práctica esto puede llevarse a cabo fácilmente a partir de la descomposición espectral de la matriz de covarianzas muestrales, aunque normalmente se estandarizan previamente los datos (i.e., se emplea la matriz de correlaciones).
Por tanto, si se pretende emplear estas componentes para ajustar un modelo de regresión, habrá que conservar los parámetros de estas transformaciones para poder aplicarlas a nuevas observaciones.

Normalmente se seleccionan las primeras \(k\) componentes de forma que expliquen la mayor parte de la variabilidad de los datos (los predictores en este caso).
En PCR {[}\emph{principal component regression}; \protect\hyperlink{ref-massy1965principal}{Massy} (\protect\hyperlink{ref-massy1965principal}{1965}){]} se confía en que estas componentes recojan también la mayor parte de la información sobre la respuesta, pero podría no ser el caso.

Como ejemplo continuaremos con los datos de clientes de la compañía de distribución industrial HBAT.
Aunque podríamos emplear las funciones \texttt{printcomp()} y \texttt{lm()} del paquete base, emplearemos por comodidad la función \texttt{pcr()} del paquete \href{https://mevik.net/work/software/pls.html}{\texttt{pls}} (ya que incorpora validación cruzada para seleccionar el número de componentes y facilita el cálculo de nuevas predicciones).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(pls)}
\CommentTok{\# pcr(formula, ncomp, data, scale = FALSE, center = TRUE, }
\CommentTok{\#     validation = c("none", "CV", "LOO"), segments = 10)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{pcreg }\OtherTok{\textless{}{-}} \FunctionTok{pcr}\NormalTok{(fidelida }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{scale =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{validation =} \StringTok{"CV"}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(pcreg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Data:    X dimension: 160 13 
##  Y dimension: 160 1
## Fit method: svdpc
## Number of components considered: 13
## 
## VALIDATION: RMSEP
## Cross-validated using 10 random segments.
##        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps
## CV           8.683    6.892    5.960    5.695    5.448    5.525    4.901
## adjCV        8.683    6.888    5.954    5.630    5.440    5.517    4.846
##        7 comps  8 comps  9 comps  10 comps  11 comps  12 comps  13 comps
## CV       4.930    4.880    4.550     4.575     4.555     4.579     4.573
## adjCV    4.916    4.862    4.535     4.560     4.539     4.561     4.554
## 
## TRAINING: % variance explained
##           1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps
## X           29.40    50.38    63.09    75.38    82.93    87.33    91.02
## fidelida    37.89    53.76    58.84    61.79    61.96    70.56    70.97
##           8 comps  9 comps  10 comps  11 comps  12 comps  13 comps
## X           94.14    96.39     97.86     99.00     99.93    100.00
## fidelida    72.13    75.12     75.12     75.78     76.00     76.14
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# validationplot(pcreg, legend = "topright") }
\NormalTok{rmsep.cv }\OtherTok{\textless{}{-}} \FunctionTok{RMSEP}\NormalTok{(pcreg)}
\FunctionTok{plot}\NormalTok{(rmsep.cv, }\AttributeTok{legend =} \StringTok{"topright"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-40-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ncomp.op }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(rmsep.cv, comps[}\FunctionTok{which.min}\NormalTok{(val[}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, ])]) }\CommentTok{\# mínimo adjCV RMSEP}
\end{Highlighting}
\end{Shaded}

Empleando el criterio de menor error de validación cruzada se seleccionaría un número elevado de componentes, el mínimo se alcanzaría con 9 componentes (bastante próximo a ajustar un modelo lineal con todos los predictores).

Los coeficientes de los predictores originales con el modelo seleccionado serían:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coef}\NormalTok{(pcreg, }\AttributeTok{ncomp =} \DecValTok{9}\NormalTok{, }\AttributeTok{intercept =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## , , 9 comps
## 
##                fidelida
## (Intercept) -5.33432555
## calidadp     4.53450998
## web          1.36586619
## soporte     -0.08892573
## quejas       2.21875583
## publi        0.16238769
## producto     1.77457778
## imgfvent    -0.20518565
## precio       0.83775389
## garantia    -0.32313633
## nprod        0.07569817
## facturac    -0.45633670
## flexprec     0.72941138
## velocida     2.27911181
\end{verbatim}

Finalmente evaluamos su precisión:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{ (pcreg , test, }\AttributeTok{ncomp =} \DecValTok{9}\NormalTok{)}
\FunctionTok{accuracy}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         me       rmse        mae        mpe       mape  r.squared 
## 0.54240746 4.39581553 3.46755308 0.08093351 6.15004687 0.81060798
\end{verbatim}

Empleando el método \texttt{"pcr"} de \texttt{caret}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}
\FunctionTok{modelLookup}\NormalTok{(}\StringTok{"pcr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   model parameter       label forReg forClass probModel
## 1   pcr     ncomp #Components   TRUE    FALSE     FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{caret.pcr }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(fidelida }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{method =} \StringTok{"pcr"}\NormalTok{,}
                   \AttributeTok{preProcess =} \FunctionTok{c}\NormalTok{(}\StringTok{"zv"}\NormalTok{, }\StringTok{"center"}\NormalTok{, }\StringTok{"scale"}\NormalTok{),}
                   \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{number =} \DecValTok{10}\NormalTok{),}
                   \AttributeTok{tuneGrid =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{ncomp =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{))}
\CommentTok{\# También se podía haber incluido \textasciigrave{}selectionFunction = "oneSE"\textasciigrave{} en \textasciigrave{}trControl()\textasciigrave{}}
\NormalTok{caret.pcr}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Principal Component Analysis 
## 
## 160 samples
##  13 predictor
## 
## Pre-processing: centered (13), scaled (13) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 145, 143, 144, 143, 145, 144, ... 
## Resampling results across tuning parameters:
## 
##   ncomp  RMSE      Rsquared   MAE     
##    1     6.844663  0.3889234  5.680556
##    2     5.894889  0.5446242  4.795170
##    3     5.604429  0.5837430  4.588714
##    4     5.403949  0.6077034  4.374244
##    5     5.476941  0.5984578  4.392604
##    6     4.806541  0.6891701  3.772401
##    7     4.830222  0.6886805  3.780234
##    8     4.825438  0.6895724  3.736469
##    9     4.511374  0.7295536  3.371115
##   10     4.551134  0.7260848  3.405876
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was ncomp = 9.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(caret.pcr, }\AttributeTok{highlight =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-43-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(caret.pcr, }\AttributeTok{newdata =}\NormalTok{ test)}
\FunctionTok{accuracy}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         me       rmse        mae        mpe       mape  r.squared 
## 0.54240746 4.39581553 3.46755308 0.08093351 6.15004687 0.81060798
\end{verbatim}

Al incluir más componentes se aumenta la proporción de variabilidad explicada de los predictores,
pero esto no está relacionado con su utilidad para explicar la respuesta.
No va a haber problemas de colinealidad aunque incluyamos muchas componentes, pero se tendrán que estimar más coeficientes y va a disminuir su precisión.
Sería más razonable obtener las componentes principales y después aplicar un método de selección.
Por ejemplo podemos combinar el método de preprocesado \texttt{"pca"} de \texttt{caret} con un método de selección de variables\footnote{Esta forma de proceder se podría emplear con otros modelos que puedan tener problemas de colinealidad, como los lineales generalizados.}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{caret.pcrsel }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(fidelida }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{method =} \StringTok{"leapSeq"}\NormalTok{,}
                   \AttributeTok{preProcess =} \FunctionTok{c}\NormalTok{(}\StringTok{"zv"}\NormalTok{, }\StringTok{"center"}\NormalTok{, }\StringTok{"scale"}\NormalTok{, }\StringTok{"pca"}\NormalTok{),     }
                   \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{number =} \DecValTok{10}\NormalTok{),}
                   \AttributeTok{tuneGrid =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{nvmax =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{))}
\NormalTok{caret.pcrsel}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Linear Regression with Stepwise Selection 
## 
## 160 samples
##  13 predictor
## 
## Pre-processing: centered (13), scaled (13), principal component
##  signal extraction (13) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 145, 143, 144, 143, 145, 144, ... 
## Resampling results across tuning parameters:
## 
##   nvmax  RMSE      Rsquared   MAE     
##    1     6.844663  0.3889234  5.680556
##    2     5.894889  0.5446242  4.795170
##    3     5.626635  0.5780222  4.614693
##    4     4.965728  0.6639455  4.041916
##    5     4.829841  0.6864472  3.782061
##    6     4.666785  0.7085316  3.558379
##    7     4.545961  0.7276881  3.437428
##    8     4.642381  0.7140237  3.518435
##    9     4.511374  0.7295536  3.371115
##   10     4.511374  0.7295536  3.371115
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was nvmax = 9.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(caret.pcrsel, }\AttributeTok{highlight =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-44-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{with}\NormalTok{(caret.pcrsel, }\FunctionTok{coef}\NormalTok{(finalModel, bestTune}\SpecialCharTok{$}\NormalTok{nvmax))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept)         PC1         PC2         PC3         PC4         PC5 
##  58.0375000   2.7256200  -2.0882164   1.5167199  -1.1761229  -0.3588877 
##         PC6         PC7         PC8         PC9 
##  -3.3571851   0.8032460  -1.4655909   2.7670125
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(caret.pcrsel, }\AttributeTok{newdata =}\NormalTok{ test)}
\FunctionTok{accuracy}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         me       rmse        mae        mpe       mape  r.squared 
## 0.54240746 4.39581553 3.46755308 0.08093351 6.15004687 0.81060798
\end{verbatim}

\hypertarget{regresiuxf3n-por-muxednimos-cuadrados-parciales-plsr}{%
\subsection{Regresión por mínimos cuadrados parciales (PLSR)}\label{regresiuxf3n-por-muxednimos-cuadrados-parciales-plsr}}

Como ya se comentó, en PCR las componentes se determinan con el objetivo de explicar la variabilidad de los predictores, ignorando por completo la respuesta.
Por el contrario, en PLSR {[}\emph{partial least squares regression}; \protect\hyperlink{ref-wold1983multivariate}{Wold et~al.} (\protect\hyperlink{ref-wold1983multivariate}{1983}){]} se construyen las componentes \(Z_1, \ldots, Z_k\) teniendo en cuenta desde un principio el objetivo final de predecir linealmente la respuesta.

Hay varios procedimientos para seleccionar los pesos \(a_{ij}\), pero la idea es asignar mayor peso a los predictores que están más correlacionados con la respuesta (o con los correspondientes residuos al ir obteniendo nuevos componentes), considerando siempre direcciones ortogonales (ver por ejemplo la Sección 6.3.2 de \protect\hyperlink{ref-james2021introduction}{James et~al., 2021}).

Continuando con el ejemplo anterior, emplearemos en primer lugar la función \texttt{plsr()} del paquete \texttt{pls} (este paquete implementa distintas proyecciones, ver \texttt{help(pls.options)}, o \protect\hyperlink{ref-Mevik2007pls}{Mevik y Wehrens, 2007}):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plsr(formula, ncomp, data, scale = FALSE, center = TRUE, }
\CommentTok{\#      validation = c("none", "CV", "LOO"), segments = 10)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{plsreg }\OtherTok{\textless{}{-}} \FunctionTok{plsr}\NormalTok{(fidelida }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{scale =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{validation =} \StringTok{"CV"}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(plsreg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Data:    X dimension: 160 13 
##  Y dimension: 160 1
## Fit method: kernelpls
## Number of components considered: 13
## 
## VALIDATION: RMSEP
## Cross-validated using 10 random segments.
##        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps
## CV           8.683    5.439    4.952    4.684    4.588    4.560    4.576
## adjCV        8.683    5.433    4.945    4.670    4.571    4.542    4.558
##        7 comps  8 comps  9 comps  10 comps  11 comps  12 comps  13 comps
## CV       4.572    4.572    4.580     4.563     4.584     4.574     4.573
## adjCV    4.555    4.554    4.562     4.545     4.564     4.555     4.554
## 
## TRAINING: % variance explained
##           1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps
## X           27.32    44.59    56.70    66.70    70.29    79.07    86.27
## fidelida    62.09    69.84    73.96    75.43    75.89    75.96    76.00
##           8 comps  9 comps  10 comps  11 comps  12 comps  13 comps
## X           90.98    93.83     95.23     97.59     98.53    100.00
## fidelida    76.03    76.04     76.09     76.12     76.14     76.14
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# validationplot(plsreg, legend = "topright")}
\NormalTok{rmsep.cv }\OtherTok{\textless{}{-}} \FunctionTok{RMSEP}\NormalTok{(plsreg)}
\FunctionTok{plot}\NormalTok{(rmsep.cv, }\AttributeTok{legend =} \StringTok{"topright"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-45-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ncomp.op }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(rmsep.cv, comps[}\FunctionTok{which.min}\NormalTok{(val[}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, ])]) }\CommentTok{\# mínimo adjCV RMSEP}
\end{Highlighting}
\end{Shaded}

En este caso el mínimo se alcanza con 5 componentes pero 4 sería un valor razonable.
Podríamos obtener los coeficientes de los predictores del modelo seleccionado:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coef}\NormalTok{(pcreg, }\AttributeTok{ncomp =} \DecValTok{4}\NormalTok{, }\AttributeTok{intercept =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## , , 4 comps
## 
##               fidelida
## (Intercept) 20.7676017
## calidadp     1.3800150
## web          0.4380180
## soporte     -0.4201579
## quejas       1.4368692
## publi        0.7988489
## producto     2.0103817
## imgfvent     0.4806218
## precio      -1.2171454
## garantia    -0.2287305
## nprod        0.5953945
## facturac     1.3296997
## flexprec    -0.3569203
## velocida     1.5624947
\end{verbatim}

y evaluar su precisión:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(plsreg , test, }\AttributeTok{ncomp =} \DecValTok{4}\NormalTok{)}
\FunctionTok{accuracy}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        me      rmse       mae       mpe      mape r.squared 
## 0.5331010 4.4027291 3.4983343 0.0461853 6.2529706 0.8100118
\end{verbatim}

También se puede emplear el método \texttt{"pls"} de \texttt{caret}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{modelLookup}\NormalTok{(}\StringTok{"pls"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   model parameter       label forReg forClass probModel
## 1   pls     ncomp #Components   TRUE     TRUE      TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{caret.pls }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(fidelida }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{method =} \StringTok{"pls"}\NormalTok{,}
                   \AttributeTok{preProcess =} \FunctionTok{c}\NormalTok{(}\StringTok{"zv"}\NormalTok{, }\StringTok{"center"}\NormalTok{, }\StringTok{"scale"}\NormalTok{),}
                   \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{number =} \DecValTok{10}\NormalTok{),}
                   \AttributeTok{tuneGrid =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{ncomp =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{))}
\NormalTok{caret.pls}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Partial Least Squares 
## 
## 160 samples
##  13 predictor
## 
## Pre-processing: centered (13), scaled (13) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 145, 143, 144, 143, 145, 144, ... 
## Resampling results across tuning parameters:
## 
##   ncomp  RMSE      Rsquared   MAE     
##    1     5.385375  0.6130430  4.301648
##    2     4.902373  0.6765146  3.882695
##    3     4.630757  0.7151341  3.472635
##    4     4.516718  0.7278875  3.356058
##    5     4.480285  0.7320425  3.391015
##    6     4.490064  0.7314898  3.376068
##    7     4.478319  0.7323472  3.365828
##    8     4.490064  0.7312432  3.384096
##    9     4.492672  0.7308291  3.379606
##   10     4.483548  0.7316750  3.368064
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was ncomp = 7.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(caret.pls, }\AttributeTok{highlight =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-48-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Podía ser preferible incluir \textasciigrave{}trControl(selectionFunction = "oneSE")\textasciigrave{}}

\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(caret.pls, }\AttributeTok{newdata =}\NormalTok{ test)}
\FunctionTok{accuracy}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         me       rmse        mae        mpe       mape  r.squared 
## 0.52838223 4.32029848 3.46711182 0.08674838 6.18085646 0.81705933
\end{verbatim}

Como comentario final, en la práctica se suelen obtener resultados muy similares empleando PCR, PLSR o \emph{ridge regression}.

\hypertarget{reg-glm}{%
\section{Modelos lineales generalizados}\label{reg-glm}}

Como ya se comentó, los modelos lineales generalizados son una extensión de los modelos lineales para el caso de que la distribución condicional de la variable respuesta no sea normal, introduciendo una función de enlace (o link) \(g\) de forma que
\[g\left(E(Y | \mathbf{X} )\right) = \beta_{0}+\beta_{1}X_{1}+\beta_{2}X_{2}+\cdots+\beta_{p}X_{p}\]
y su ajuste en la práctica se realiza empleando el método de máxima verosimilitud (habrá que especificar también una familia de distribuciones para la respuesta).

La función link debe ser invertible, de forma que se pueda volver a transformar el modelo ajustado (en la escala lineal de las puntuaciones) a la escala original.
Por ejemplo, como se comentó al final de la Sección \ref{notacion}, para modelar una variable indicadora, con distribución de Bernouilli (caso particular de la Binomial) donde \(E(Y | \mathbf{X} ) = p(\mathbf{X})\) es la probabilidad de éxito, podemos considerar la función logit
\[\operatorname{logit}(p(\mathbf{X}))=\log\left( \frac{p(\mathbf{X})}{1-p(\mathbf{X})} \right) = \beta_{0}+\beta_{1}X_{1}+\beta_{2}X_{2}+\cdots+\beta_{p}X_{p}\]
(que proyecta el intervalo \([0, 1]\) en \(\mathbb{R}\)), siendo su inversa la función logística
\[p(\mathbf{X}) = \frac{e^{\beta_{0}+\beta_{1}X_{1}+\beta_{2}X_{2}+\cdots+\beta_{p}X_{p}}}{1 + e^{\beta_{0}+\beta_{1}X_{1}+\beta_{2}X_{2}+\cdots+\beta_{p}X_{p}}}\]
Esto da lugar al modelo de regresión logística (múltiple), que será el que utilizaremos como ejemplo en esta sección.
Para un tratamiento más completo de los métodos de regresión lineal generalizada se recomienda consultar \protect\hyperlink{ref-faraway2014linear}{Faraway} (\protect\hyperlink{ref-faraway2014linear}{2016}).

\hypertarget{ajuste-funciuxf3n-glm}{%
\subsection{\texorpdfstring{Ajuste: función \texttt{glm}}{Ajuste: función glm}}\label{ajuste-funciuxf3n-glm}}

Para el ajuste (estimación de los parámetros) de un modelo lineal generalizado a un conjunto de datos (por máxima verosimilitud) se emplea la función \texttt{glm()} (la mayoría de los principales parámetros coinciden con los de la función \texttt{lm()}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ajuste }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(formula, }\AttributeTok{family =}\NormalTok{ gaussian, data, weights, subset, na.action, ...)}
\end{Highlighting}
\end{Shaded}

El parámetro \texttt{family} especifica la distribución y opcionalmente la función de enlace.
Por ejemplo:

\begin{itemize}
\item
  \texttt{gaussian(link\ =\ "identity")}, \texttt{gaussian(link\ =\ "log")}
\item
  \texttt{binomial(link\ =\ "logit")}, \texttt{binomial(link\ =\ "probit")}
\item
  \texttt{poisson(link\ =\ "log")}
\item
  \texttt{Gamma(link\ =\ "inverse")}
\end{itemize}

Para cada distribución se toma por defecto una función de enlace (el denominado \emph{enlace canónico}, mostrada en primer lugar en la lista anterior; ver \texttt{help(family)} para más detalles).
Por ejemplo, en el caso del modelo logístico bastará con establecer \texttt{family\ =\ binomial}.

También se podría emplear la función \texttt{bigglm()} del paquete \href{https://CRAN.R-project.org/package=biglm}{\texttt{biglm}} para ajustar modelos lineales generalizados a grandes conjuntos de datos, aunque en este caso los requerimientos computacionales pueden ser mayores.

Como ya se comentó, muchas de las herramientas y funciones genéricas disponibles para los modelos lineales son válidas también para este tipo de modelos: \texttt{summary}, \texttt{coef}, \texttt{confint}, \texttt{predict}, \texttt{anova}\ldots{}

\hypertarget{ejemplo-regresiuxf3n-loguxedstica}{%
\subsection{Ejemplo: Regresión logística}\label{ejemplo-regresiuxf3n-loguxedstica}}

Como ejemplo continuaremos con los datos de clientes de la compañía de distribución industrial HBAT, pero consideraremos como respuesta la variable \emph{alianza} y como predictores las percepciones de HBAT (al igual que en las secciones anteriores consideraremos únicamente variables explicativas continuas, sin interacciones, por comodidad).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load("data/hbat.RData")}
\CommentTok{\# as.data.frame(attr(hbat, "variable.labels"))}
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ hbat[, }\FunctionTok{c}\NormalTok{(}\DecValTok{7}\SpecialCharTok{:}\DecValTok{19}\NormalTok{, }\DecValTok{24}\NormalTok{)]  }
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{nobs }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(df)}
\NormalTok{itrain }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(nobs, }\FloatTok{0.8} \SpecialCharTok{*}\NormalTok{ nobs)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ df[itrain, ]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ df[}\SpecialCharTok{{-}}\NormalTok{itrain, ]}

\FunctionTok{plot}\NormalTok{(train, }\AttributeTok{pch =} \FunctionTok{as.numeric}\NormalTok{(train}\SpecialCharTok{$}\NormalTok{alianza), }\AttributeTok{col =} \FunctionTok{as.numeric}\NormalTok{(train}\SpecialCharTok{$}\NormalTok{alianza))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=1\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-50-1} \end{center}

Como ya se comentó, estableciendo \texttt{family\ =\ binomial} en la llamada a \texttt{glm()} se ajusta un modelo de regresión logística (por defecto \texttt{link\ =\ "logit"}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelo }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(alianza }\SpecialCharTok{\textasciitilde{}}\NormalTok{ velocida }\SpecialCharTok{+}\NormalTok{ calidadp, }\AttributeTok{family =}\NormalTok{ binomial, }\AttributeTok{data =}\NormalTok{ train)}
\NormalTok{modelo}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:  glm(formula = alianza ~ velocida + calidadp, family = binomial, 
##     data = train)
## 
## Coefficients:
## (Intercept)     velocida     calidadp  
##    -12.5218       1.6475       0.7207  
## 
## Degrees of Freedom: 159 Total (i.e. Null);  157 Residual
## Null Deviance:       218.2 
## Residual Deviance: 160.5     AIC: 166.5
\end{verbatim}

La razón de ventajas (OR) permite cuantificar el efecto de las variables explicativas en la respuesta (incremento proporcional en la razón entre la probabilidad de éxito y la de fracaso, al aumentar una unidad la variable manteniendo las demás fijas):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{exp}\NormalTok{(}\FunctionTok{coef}\NormalTok{(modelo))  }\CommentTok{\# Razones de ventajas ("odds ratios")}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  (Intercept)     velocida     calidadp 
## 3.646214e-06 5.194162e+00 2.055887e+00
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{exp}\NormalTok{(}\FunctionTok{confint}\NormalTok{(modelo))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                    2.5 %       97.5 %
## (Intercept) 4.465945e-08 1.593277e-04
## velocida    2.766629e+00 1.068554e+01
## calidadp    1.557441e+00 2.789897e+00
\end{verbatim}

Para obtener un resumen más completo del ajuste también se utiliza \texttt{summary()}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(modelo)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = alianza ~ velocida + calidadp, family = binomial, 
##     data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.8273  -0.7622  -0.2998   0.7837   1.8375  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -12.5218     2.0758  -6.032 1.62e-09 ***
## velocida      1.6475     0.3426   4.809 1.52e-06 ***
## calidadp      0.7207     0.1479   4.872 1.11e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 218.19  on 159  degrees of freedom
## Residual deviance: 160.55  on 157  degrees of freedom
## AIC: 166.55
## 
## Number of Fisher Scoring iterations: 5
\end{verbatim}

La desvianza (deviance) es una medida de la bondad del ajuste de un modelo lineal generalizado (sería equivalente a la suma de cuadrados residual de un modelo lineal; valores más altos indican peor ajuste).
La \emph{Null deviance} se correspondería con un modelo solo con la constante y la \emph{Residual deviance} con el modelo ajustado.
En este caso hay una reducción de 57.65 con una pérdida de 2 grados de libertad (una reducción significativa).

Para contrastar globalmente el efecto de las covariables también podemos emplear:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelo.null }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(alianza }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, binomial, train)}
\FunctionTok{anova}\NormalTok{(modelo.null, modelo, }\AttributeTok{test =} \StringTok{"Chi"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Deviance Table
## 
## Model 1: alianza ~ 1
## Model 2: alianza ~ velocida + calidadp
##   Resid. Df Resid. Dev Df Deviance  Pr(>Chi)    
## 1       159     218.19                          
## 2       157     160.55  2   57.646 3.036e-13 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\hypertarget{selecciuxf3n-de-variables-explicativas}{%
\subsection{Selección de variables explicativas}\label{selecciuxf3n-de-variables-explicativas}}

El objetivo sería conseguir un buen ajuste con el menor número de variables explicativas posible.
Al igual que en el caso del modelo de regresión lineal múltiple, se podría seguir un proceso interactivo, eliminando o añadiendo variables con la función \texttt{update()}, aunque también están disponibles métodos automáticos de selección de variables.

Para obtener el modelo ``óptimo'' lo ideal sería evaluar todos los modelos posibles.
En este caso no se puede emplear la función \texttt{regsubsets} del paquete \texttt{leaps} (sólo para modelos lineales),
pero por ejemplo el paquete
\href{https://cran.r-project.org/web/packages/bestglm/vignettes/bestglm.pdf}{\texttt{bestglm}}
proporciona una herramienta equivalente (\texttt{bestglm()}).

En este caso también se podría emplear la función \texttt{stepwise} del paquete \texttt{RcmdrMisc} (interfaz de \texttt{stepAIC} del paquete \texttt{MASS}), para seleccionar el modelo por pasos según criterio AIC o BIC:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# library(RcmdrMisc)}
\NormalTok{modelo.completo }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(alianza }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{family =}\NormalTok{ binomial, }\AttributeTok{data =}\NormalTok{ train)}

\NormalTok{modelo }\OtherTok{\textless{}{-}} \FunctionTok{stepwise}\NormalTok{(modelo.completo, }\AttributeTok{direction=}\StringTok{\textquotesingle{}forward/backward\textquotesingle{}}\NormalTok{, }\AttributeTok{criterion=}\StringTok{\textquotesingle{}BIC\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Direction:  forward/backward
## Criterion:  BIC 
## 
## Start:  AIC=223.27
## alianza ~ 1
## 
##            Df Deviance    AIC
## + velocida  1   189.38 199.53
## + calidadp  1   192.15 202.30
## + facturac  1   193.45 203.60
## + producto  1   196.91 207.06
## + quejas    1   198.10 208.25
## + imgfvent  1   198.80 208.95
## + web       1   204.40 214.55
## + publi     1   209.28 219.43
## + precio    1   211.97 222.12
## + garantia  1   212.37 222.52
## <none>          218.19 223.27
## + nprod     1   213.97 224.12
## + soporte   1   216.50 226.65
## + flexprec  1   216.99 227.14
## 
## Step:  AIC=199.53
## alianza ~ velocida
## 
##            Df Deviance    AIC
## + calidadp  1   160.55 175.77
## + imgfvent  1   178.43 193.65
## + web       1   181.52 196.74
## + precio    1   183.38 198.61
## <none>          189.38 199.53
## + flexprec  1   185.47 200.69
## + producto  1   185.54 200.77
## + nprod     1   186.92 202.14
## + facturac  1   186.93 202.15
## + garantia  1   187.02 202.25
## + publi     1   187.44 202.67
## + soporte   1   189.06 204.29
## + quejas    1   189.27 204.50
## - velocida  1   218.19 223.27
## 
## Step:  AIC=175.77
## alianza ~ velocida + calidadp
## 
##            Df Deviance    AIC
## + imgfvent  1   137.05 157.35
## + web       1   145.63 165.93
## <none>          160.55 175.77
## + publi     1   156.03 176.33
## + facturac  1   157.35 177.66
## + flexprec  1   157.44 177.74
## + producto  1   157.75 178.06
## + garantia  1   158.97 179.27
## + nprod     1   160.18 180.47
## + quejas    1   160.20 180.50
## + soporte   1   160.37 180.67
## + precio    1   160.37 180.67
## - calidadp  1   189.38 199.53
## - velocida  1   192.15 202.30
## 
## Step:  AIC=157.35
## alianza ~ velocida + calidadp + imgfvent
## 
##            Df Deviance    AIC
## <none>          137.05 157.35
## + precio    1   134.97 160.35
## + flexprec  1   135.39 160.77
## + publi     1   135.65 161.03
## + producto  1   135.72 161.09
## + facturac  1   135.81 161.19
## + garantia  1   136.31 161.69
## + nprod     1   136.63 162.00
## + soporte   1   136.79 162.16
## + quejas    1   136.96 162.33
## + web       1   137.03 162.40
## - velocida  1   160.34 175.57
## - imgfvent  1   160.55 175.77
## - calidadp  1   178.43 193.65
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(modelo)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = alianza ~ velocida + calidadp + imgfvent, family = binomial, 
##     data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.6527  -0.6822  -0.1482   0.7631   2.0561  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -20.5164     3.4593  -5.931 3.02e-09 ***
## velocida      1.6631     0.3981   4.177 2.95e-05 ***
## calidadp      1.0469     0.2014   5.197 2.02e-07 ***
## imgfvent      1.0085     0.2398   4.205 2.61e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 218.19  on 159  degrees of freedom
## Residual deviance: 137.05  on 156  degrees of freedom
## AIC: 145.05
## 
## Number of Fisher Scoring iterations: 5
\end{verbatim}

\hypertarget{analisis-glm}{%
\subsection{Análisis e interpretación del modelo}\label{analisis-glm}}

Las hipótesis estructurales del modelo son similares al caso de regresión lineal (aunque algunas como la linealidad se suponen en la escala transformada) y si no se verifican los resultados pueden no ser fiables o totalmente erróneos.

Con la función \texttt{plot} se pueden generar gráficos de interés para la diagnosis del modelo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{oldpar }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{( }\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(modelo)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-56-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(oldpar)}
\end{Highlighting}
\end{Shaded}

Aunque su interpretación difiere un poco de la de los modelos lineales\ldots{}

Se pueden generar gráficos parciales de residuos (p.e. \texttt{crPlots()} del paquete \texttt{car}):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# library(car)}
\FunctionTok{crPlots}\NormalTok{(modelo)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{06-modelos_lineales_files/figure-latex/unnamed-chunk-57-1} \end{center}

Se pueden emplear las mismas funciones vistas en los modelos lineales para obtener medidas de diagnosis de interés (Sección \ref{analisis-reg-multiple}). Por ejemplo:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{residuals}\NormalTok{(model, }\AttributeTok{type =} \StringTok{"deviance"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

proporcionará los residuos \emph{deviance}.

Por supuesto también pueden aparecer problemas de colinealidad, y podemos emplear las mismas herramientas para detectarla:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# library(car)}
\FunctionTok{vif}\NormalTok{(modelo)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## velocida calidadp imgfvent 
## 1.193557 1.656649 1.451237
\end{verbatim}

Si no se satisfacen los supuestos básicos también se pueden intentar distintas alternativas (en este caso se pueden cambiar además la función de enlace y la familia de distribuciones, que puede incluir parámetros para modelar dispersión).
Por ejemplo, para tratar de corregir la falta de linealidad se pueden considerar ajustes polinómicos o emplear métodos no paramétricos, como la función \texttt{gam()} del paquete \texttt{mgcv}.

\hypertarget{evaluaciuxf3n-de-la-precisiuxf3n-1}{%
\subsection{Evaluación de la precisión}\label{evaluaciuxf3n-de-la-precisiuxf3n-1}}

Como ya se mostró en la Sección \ref{eval-class}, podemos obtener las estimaciones de la probabilidad de la segunda categoría empleando \texttt{predict()} con \texttt{type\ =\ "response"}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p.est }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(modelo, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{, }\AttributeTok{newdata =}\NormalTok{ test)}
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(p.est }\SpecialCharTok{\textgreater{}} \FloatTok{0.5}\NormalTok{, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"No"}\NormalTok{, }\StringTok{"Si"}\NormalTok{)) }\CommentTok{\# levels = c(\textquotesingle{}FALSE\textquotesingle{}, \textquotesingle{}TRUE\textquotesingle{})}
\end{Highlighting}
\end{Shaded}

y las medidas de precisión de la predicción (además de los criterios AIC o BIC tradicionales):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{caret}\SpecialCharTok{::}\FunctionTok{confusionMatrix}\NormalTok{(pred, test}\SpecialCharTok{$}\NormalTok{alianza, }\AttributeTok{positive =} \StringTok{"Si"}\NormalTok{, }\AttributeTok{mode =} \StringTok{"everything"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction No Si
##         No 19  5
##         Si  3 13
##                                           
##                Accuracy : 0.8             
##                  95% CI : (0.6435, 0.9095)
##     No Information Rate : 0.55            
##     P-Value [Acc > NIR] : 0.0008833       
##                                           
##                   Kappa : 0.5918          
##                                           
##  Mcnemar's Test P-Value : 0.7236736       
##                                           
##             Sensitivity : 0.7222          
##             Specificity : 0.8636          
##          Pos Pred Value : 0.8125          
##          Neg Pred Value : 0.7917          
##               Precision : 0.8125          
##                  Recall : 0.7222          
##                      F1 : 0.7647          
##              Prevalence : 0.4500          
##          Detection Rate : 0.3250          
##    Detection Prevalence : 0.4000          
##       Balanced Accuracy : 0.7929          
##                                           
##        'Positive' Class : Si              
## 
\end{verbatim}

También podemos emplear \texttt{caret}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# library(caret)}
\FunctionTok{names}\NormalTok{(}\FunctionTok{getModelInfo}\NormalTok{(}\StringTok{"glm"}\NormalTok{)) }\CommentTok{\# 11 métodos}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "bayesglm"       "glm.nb"         "glm"            "glmboost"      
##  [5] "glmnet_h2o"     "glmnet"         "glmStepAIC"     "plsRglm"       
##  [9] "vglmAdjCat"     "vglmContRatio"  "vglmCumulative"
\end{verbatim}

\hypertarget{extensiones}{%
\subsection{Extensiones}\label{extensiones}}

Se pueden imponer restricciones a las estimaciones de los parámetros de modo análogo al caso de modelos lineales (secciones \ref{shrinkage} y \ref{pca-pls}).
Por ejemplo, en los métodos de regularización (\emph{ridge}, \emph{lasso} o \emph{elastic net}; Sección \ref{shrinkage}) bastaría con cambiar en la función de pérdidas la suma residual de cuadrados por el logaritmo negativo de la función de verosimilitud.

\begin{exercise}
\protect\hypertarget{exr:glmnet}{}{\label{exr:glmnet} }
Emplear el paquete \texttt{glmnet} para ajustar modelos logísticos con penalización \emph{ridge} y \emph{lasso} a la muestra de entrenamiento de los datos de clientes de la compañía de distribución industrial HBAT, considerando como respuesta la variable \emph{alianza} y seleccionando un valor ``óptimo'' del hiperparámetro \(\lambda\).
Ajustar también un modelo con penalización \emph{elastic net} empleando \texttt{caret} (seleccionando los valores óptimos de los hiperparámetros).
\end{exercise}

El método PCR (Sección \ref{pca-pls}) se extendería de forma inmediata al caso de modelos generalizados, simplemente cambiando el modelo ajustado.
También están disponibles métodos PLSR para modelos generalizados.

\begin{exercise}
\protect\hypertarget{exr:glm-reduccion}{}{\label{exr:glm-reduccion} }
Emplear el paquete \texttt{caret} para ajustar modelos logísticos con reducción de la dimensión a los datos de clientes de la compañía de distribución industrial HBAT. Comparar el modelo obtenido con preprocesado \texttt{"pca"} y el método \texttt{"glmStepAIC"}, con el obtenido empleando el método \texttt{"plsRglm"}.
\end{exercise}

\hypertarget{reg-np}{%
\chapter{Regresión no paramétrica}\label{reg-np}}

Se trata de métodos que no suponen ninguna forma concreta de la media condicional (i.e.~no se hacen suposiciones paramétricas sobre el efecto de las variables explicativas):
\[Y=m\left( X_1, \ldots,  X_p \right) + \varepsilon\]
siendo \(m\) una función ``cualquiera'' (se asume que es una función ``suave'' de los predictores).

La idea detrás de la mayoría de estos métodos es ajustar localmente un modelo de regresión (este capítulo se podría haber titulado ``modelos locales'').
Suponiendo que disponemos de ``suficiente'' información en un entorno de la posición de predicción (el número de observaciones debe ser relativamente grande), podríamos pensar en predecir la respuesta a partir de lo que ocurre en las observaciones cercanas.

Nos centraremos principalmente en el caso de regresión, pero la mayoría de estos métodos se pueden extender para el caso de clasificación (por ejemplo considerando una función de enlace y realizando el ajuste localmente por máxima verosimilitud).

Los métodos de regresión basados en: árboles de decisión, bosques aleatorios, bagging, boosting y máquinas de soporte vectorial, vistos en capítulos anteriores, entrarían también dentro de esta clasificación.

\hypertarget{reg-local}{%
\section{Regresión local}\label{reg-local}}

En este tipo de métodos se incluirían: vecinos más próximos, regresión tipo núcleo y loess (o lowess).
También se podrían incluir los \emph{splines de regresión} (\emph{regression splines}), pero se tratarán en la siguiente sección, ya que también se pueden ver como una extensión de un modelo lineal global.

Con muchos de estos procedimientos no se obtiene una expresión cerrada del modelo ajustado y (en principio) es necesario disponer de la muestra de entrenamiento para calcular predicciones, por lo que en AE también se denominan \emph{métodos basados en memoria}.

\hypertarget{reg-knn}{%
\subsection{Vecinos más próximos}\label{reg-knn}}

Uno de los métodos más conocidos de regresión local es el denominado \emph{k-vecinos más cercanos} (\emph{k-nearest neighbors}; KNN), que ya se empleó como ejemplo en la Sección \ref{dimen-curse} (la maldición de la dimensionalidad).
Se trata de un método muy simple, pero que en la práctica puede ser efectivo en muchas ocasiones.
Se basa en la idea de que localmente la media condicional (la predicción óptima) es constante.
Concretamente, dados un entero \(k\) (hiperparámetro) y un conjunto de entrenamiento \(\mathcal{T}\), para obtener la predicción correspondiente a un vector de valores de las variables explicativas \(\mathbf{x}\), el método de regresión KNN promedia las observaciones en un vecindario \(\mathcal{N}_k(\mathbf{x}, \mathcal{T})\) formado por las \(k\) observaciones más cercanas a \(\mathbf{x}\):
\[\hat{Y}(\mathbf{x}) = \hat{m}(\mathbf{x}) = \frac{1}{k} \sum_{i \in \mathcal{N}_k(\mathbf{x}, \mathcal{T})} Y_i\]
Se puede emplear la misma idea en el caso de clasificación, las frecuencias relativas en el vecindario serían las estimaciones de las probabilidades de las clases (lo que sería equivalente a considerar las variables indicadoras de las categorías) y normalmente la predicción sería la moda (la clase más probable).

Para seleccionar el vecindario es necesario especificar una distancia, por ejemplo:
\[d(\mathbf{x}_0, \mathbf{x}_i) = \left( \sum_{j=1}^p \left| x_{j0} - x_{ji}  \right|^d  \right)^{\frac{1}{d}}\]
Normalmente se considera la distancia euclídea (\(d=2\)) o la de Manhatan (\(d=1\)) si los predictores son muméricos (también habría distancias diseñadas para predictores categóricos).
En cualquier caso la recomendación es estandarizar previamente los predictores para que no influya su escala en el cálculo de las distancias.

Como ya se mostró en al final del Capítulo \ref{intro-AE}, este método está implementado en la función \texttt{knnreg()} (Sección \ref{dimen-curse}) y en el método \texttt{"knn"} del paquete \texttt{caret} (Sección \ref{caret}).

Como ejemplo adicional emplearemos el conjunto de datos \texttt{MASS::mcycle} que contiene mediciones de la aceleración de la cabeza en una simulación de un accidente de motocicleta, utilizado para probar cascos protectores (considerando el conjunto de datos completo como si fuese la muestra de entrenamiento).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(mcycle, }\AttributeTok{package =} \StringTok{"MASS"}\NormalTok{)}

\FunctionTok{library}\NormalTok{(caret)}

\CommentTok{\# Ajuste de los modelos}
\NormalTok{fit1 }\OtherTok{\textless{}{-}} \FunctionTok{knnreg}\NormalTok{(accel }\SpecialCharTok{\textasciitilde{}}\NormalTok{ times, }\AttributeTok{data =}\NormalTok{ mcycle, }\AttributeTok{k =} \DecValTok{5}\NormalTok{) }\CommentTok{\# 5 observaciones más cercanas (5\% de los datos)}
\NormalTok{fit2 }\OtherTok{\textless{}{-}} \FunctionTok{knnreg}\NormalTok{(accel }\SpecialCharTok{\textasciitilde{}}\NormalTok{ times, }\AttributeTok{data =}\NormalTok{ mcycle, }\AttributeTok{k =} \DecValTok{10}\NormalTok{)}
\NormalTok{fit3 }\OtherTok{\textless{}{-}} \FunctionTok{knnreg}\NormalTok{(accel }\SpecialCharTok{\textasciitilde{}}\NormalTok{ times, }\AttributeTok{data =}\NormalTok{ mcycle, }\AttributeTok{k =} \DecValTok{20}\NormalTok{)}

\FunctionTok{plot}\NormalTok{(accel }\SpecialCharTok{\textasciitilde{}}\NormalTok{ times, }\AttributeTok{data =}\NormalTok{ mcycle, }\AttributeTok{col =} \StringTok{\textquotesingle{}darkgray\textquotesingle{}}\NormalTok{) }
\NormalTok{newx }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{1}\NormalTok{ , }\DecValTok{60}\NormalTok{, }\AttributeTok{len =} \DecValTok{200}\NormalTok{)}
\NormalTok{newdata }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{times =}\NormalTok{ newx)}
\FunctionTok{lines}\NormalTok{(newx, }\FunctionTok{predict}\NormalTok{(fit1, newdata), }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(newx, }\FunctionTok{predict}\NormalTok{(fit2, newdata), }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(newx, }\FunctionTok{predict}\NormalTok{(fit3, newdata))}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }\AttributeTok{legend =} \FunctionTok{c}\NormalTok{(}\StringTok{"5{-}NN"}\NormalTok{, }\StringTok{"10{-}NN"}\NormalTok{, }\StringTok{"20{-}NN"}\NormalTok{), }
       \AttributeTok{lty =} \FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{lwd =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!htb]

{\centering \includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/np-knnfit-1} 

}

\caption{Predicciones con el método KNN y distintos vecindarios}\label{fig:np-knnfit}
\end{figure}

El hiperparámetro \(k\) (número de vecinos más cercanos) determina la complejidad del modelo, de forma que valores más pequeños de \(k\) se corresponden con modelos más complejos (en el caso extremo \(k = 1\) se interpolarían las observaciones).
Este parámetro se puede seleccionar empleando alguno de los métodos descritos en la Sección \ref{cv} (por ejemplo mediante validación con \emph{k} grupos como se mostró en la Sección \ref{caret}).

\hypertarget{reg-locpol}{%
\subsection{Regresión polinómica local}\label{reg-locpol}}

En el caso univariante, para cada \(x_0\) se ajusta un polinomio de grado \(d\):
\[\beta_0+\beta_{1}\left(x - x_0\right) + \cdots 
+ \beta_{d}\left( x-x_0\right)^{d}\]
por mínimos cuadrados ponderados, con pesos
\[w_{i} = K_h(x - x_0) = \frac{1}{h}K\left(\frac{x-x_0}{h}\right)\]
donde \(K\) es una función núcleo (normalmente una densidad simétrica en torno al cero) y \(h>0\) es un parámetro de suavizado, llamado ventana, que regula el tamaño del entorno que se usa para llevar a cabo el ajuste
(esta ventana también se puede suponer local, \(h \equiv h(x_0)\); por ejemplo el método KNN se puede considerar un caso particular, con \(d=0\) y \(K\) la densidad de una \(\mathcal{U}(-1, 1)\)).
A partir de este ajuste\footnote{Se puede pensar que se están estimando los coeficientes de un desarrollo de Taylor de \(m(x_0)\).}:

\begin{itemize}
\item
  La estimación en \(x_0\) es \(\hat{m}_{h}(x_0)=\hat{\beta}_0\).
\item
  Podemos obtener también estimaciones de las derivadas:
  \(\widehat{m_{h}^{(r)}}(x_0) = r!\hat{\beta}_{r}\).
\end{itemize}

Por tanto, la estimación polinómica local de grado \(d\), \(\hat{m}_{h}(x)=\hat{\beta}_0\), se obtiene al minimizar:
\[\min_{\beta_0 ,\beta_1, \ldots, \beta_d} \sum_{i=1}^{n}\left\{ Y_{i} - \beta_0 
- \beta_1(x - X_i) - \ldots -\beta_d(x - X_i)^d \right\}^{2} K_{h}(x - X_i)\]

Explícitamente:
\[\hat{m}_{h}(x) = \mathbf{e}_{1}^{t} \left(
X_{x}^{t} {W}_{x} 
X_{x} \right)^{-1} X_{x}^{t} 
{W}_{x}\mathbf{Y} \equiv {s}_{x}^{t}\mathbf{Y}\]
donde \(\mathbf{e}_{1} = \left( 1, \cdots, 0\right)^{t}\), \(X_{x}\)
es la matriz con \((1,x - X_i, \ldots, (x - X_i)^d)\) en la fila \(i\),
\(W_{x} = \mathtt{diag} \left( K_{h}(x_{1} - x), \ldots, K_{h}(x_{n} - x) \right)\)
es la matriz de pesos, e \(\mathbf{Y} = \left( Y_1, \cdots, Y_n\right)^{t}\) es el vector de observaciones de la respuesta.

Se puede pensar que se obtiene aplicando un suavizado polinómico a
\((X_i, Y_i)\):
\[\hat{\mathbf{Y}} = S\mathbf{Y}\]
siendo \(S\) la matriz de suavizado con \(\mathbf{s}_{X_{i}}^{t}\) en la fila \(i\) (este tipo de métodos también se denominan \emph{suavizadores lineales}).

Habitualmente se considera:

\begin{itemize}
\item
  \(d=0\): Estimador Nadaraya-Watson.
\item
  \(d=1\): Estimador lineal local.
\end{itemize}

Desde el punto de vista asintótico ambos estimadores tienen un comportamiento similar\footnote{Asintóticamente el estimador lineal local tiene un sesgo menor que el de Nadaraya-Watson (pero del mismo orden) y la misma varianza (e.g. \protect\hyperlink{ref-fan1996}{Fan y Gijbels} (\protect\hyperlink{ref-fan1996}{1996})).}, pero en la práctica suele ser preferible el estimador lineal local, sobre todo porque se ve menos afectado por el denominado efecto frontera (Sección \ref{dimen-curse}).

Aunque el paquete base de \texttt{R} incluye herramientas para la estimación tipo núcleo de la regresión (\texttt{ksmooth()}, \texttt{loess()}), recomiendan el uso del paquete \texttt{KernSmooth} (\protect\hyperlink{ref-R-KernSmooth}{Wand, 2021}).

La ventana \(h\) es el (hiper)parámetro de mayor importancia en la predicción y para seleccionarlo se suelen emplear métodos de validación cruzada (Sección \ref{cv}) o tipo plug-in (reemplazando las funciones desconocidas que aparecen en la expresión de la ventana asintóticamente óptima por estimaciones; e.g.~función \texttt{dpill()} del paquete \texttt{KernSmooth}).
Por ejemplo, usando el criterio de validación cruzada dejando uno fuera (LOOCV) se trataría de minimizar:
\[CV(h)=\frac{1}{n}\sum_{i=1}^n(y_i-\hat{m}_{-i}(x_i))^2\]
siendo \(\hat{m}_{-i}(x_i)\) la predicción obtenida eliminando la observación \(i\)-ésima.
Al igual que en el caso de regresión lineal, este error también se puede obtener a partir del ajuste con todos los datos:
\[CV(h)=\frac{1}{n}\sum_{i=1}^n\left(\frac{y_i-\hat{m}(x_i)}{1 - S_{ii}}\right)^2\]
siendo \(S_{ii}\) el elemento \(i\)-ésimo de la diagonal de la matriz de suavizado (esto en general es cierto para cualquier suavizador lineal).

Alternativamente se podría emplear \emph{validación cruzada generalizada} (\protect\hyperlink{ref-craven1978smoothing}{Craven y Wahba, 1978}):
\[GCV(h)=\frac{1}{n}\sum_{i=1}^n\left(\frac{y_i-\hat{m}(x_i)}{1 - \frac{1}{n}tr(S)}\right)^2\]
(sustituyendo \(S_{ii}\) por su promedio).
Además, la traza de la matriz de suavizado \(tr(S)\) es lo que se conoce como el \emph{número efectivo de parámetros} (\(n - tr(S)\) sería una aproximación de los grados de libertad del error).

Continuando con el ejemplo del conjunto de datos \texttt{MASS::mcycle} emplearemos la función \texttt{locpoly()} del paquete \texttt{KernSmooth} para obtener estimaciones lineales locales\footnote{La función \texttt{KernSmooth::locpoly()} también admite la estimación de derivadas.} con una venta seleccionada mediante un método plug-in:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# data(mcycle, package = "MASS")}
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ mcycle}\SpecialCharTok{$}\NormalTok{times}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ mcycle}\SpecialCharTok{$}\NormalTok{accel  }

\FunctionTok{library}\NormalTok{(KernSmooth)}
\NormalTok{h }\OtherTok{\textless{}{-}} \FunctionTok{dpill}\NormalTok{(x, y) }\CommentTok{\# Método plug{-}in de Ruppert, Sheather y Wand (1995)}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{locpoly}\NormalTok{(x, y, }\AttributeTok{bandwidth =}\NormalTok{ h) }\CommentTok{\# Estimación lineal local}
\FunctionTok{plot}\NormalTok{(x, y, }\AttributeTok{col =} \StringTok{\textquotesingle{}darkgray\textquotesingle{}}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(fit)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-2-1} \end{center}

Hay que tener en cuenta que el paquete \texttt{KernSmooth} no implementa los métodos
\texttt{predict()} y \texttt{residuals()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{approx}\NormalTok{(fit, }\AttributeTok{xout =}\NormalTok{ x)}\SpecialCharTok{$}\NormalTok{y }\CommentTok{\# pred \textless{}{-} predict(fit)}
\NormalTok{resid }\OtherTok{\textless{}{-}}\NormalTok{ y }\SpecialCharTok{{-}}\NormalTok{ pred }\CommentTok{\# resid \textless{}{-} residuals(fit)}
\end{Highlighting}
\end{Shaded}

Tampoco calcula medidas de bondad de ajuste, aunque podríamos calcular medidas de la precisión de las predicciones de la forma habitual (en este caso de la muestra de entrenamiento):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{accuracy }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(pred, obs, }\AttributeTok{na.rm =} \ConstantTok{FALSE}\NormalTok{, }
                     \AttributeTok{tol =} \FunctionTok{sqrt}\NormalTok{(.Machine}\SpecialCharTok{$}\NormalTok{double.eps)) \{}
\NormalTok{  err }\OtherTok{\textless{}{-}}\NormalTok{ obs }\SpecialCharTok{{-}}\NormalTok{ pred     }\CommentTok{\# Errores}
  \ControlFlowTok{if}\NormalTok{(na.rm) \{}
\NormalTok{    is.a }\OtherTok{\textless{}{-}} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(err)}
\NormalTok{    err }\OtherTok{\textless{}{-}}\NormalTok{ err[is.a]}
\NormalTok{    obs }\OtherTok{\textless{}{-}}\NormalTok{ obs[is.a]}
\NormalTok{  \}  }
\NormalTok{  perr }\OtherTok{\textless{}{-}} \DecValTok{100}\SpecialCharTok{*}\NormalTok{err}\SpecialCharTok{/}\FunctionTok{pmax}\NormalTok{(obs, tol)  }\CommentTok{\# Errores porcentuales}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
    \AttributeTok{me =} \FunctionTok{mean}\NormalTok{(err),           }\CommentTok{\# Error medio}
    \AttributeTok{rmse =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{(err}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)), }\CommentTok{\# Raíz del error cuadrático medio }
    \AttributeTok{mae =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(err)),     }\CommentTok{\# Error absoluto medio}
    \AttributeTok{mpe =} \FunctionTok{mean}\NormalTok{(perr),         }\CommentTok{\# Error porcentual medio}
    \AttributeTok{mape =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(perr)),   }\CommentTok{\# Error porcentual absoluto medio}
    \AttributeTok{r.squared =} \DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{sum}\NormalTok{(err}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{sum}\NormalTok{((obs }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(obs))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\CommentTok{\# Pseudo R{-}cuadrado}
\NormalTok{  ))}
\NormalTok{\}}
\FunctionTok{accuracy}\NormalTok{(pred, y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            me          rmse           mae           mpe          mape 
## -2.712378e-01  2.140005e+01  1.565921e+01 -2.460832e+10  7.559223e+10 
##     r.squared 
##  8.023864e-01
\end{verbatim}

El caso multivariante es análogo, aunque habría que considerar una matriz de ventanas simétrica \(H\). También hay extensiones para el caso de predictores categóricos (nominales o ordinales) y para el caso de distribuciones de la respuesta distintas de la normal (máxima verosimilitud local).

Otros paquetes de R incluyen más funcionalidades (\texttt{sm}, \texttt{locfit}, \href{https://rubenfcasal.github.io/npsp}{\texttt{npsp}}\ldots), pero hoy en día el paquete \href{https://github.com/JeffreyRacine/R-Package-np}{\texttt{np}} es el que se podría considerar más completo.

\hypertarget{regresiuxf3n-polinuxf3mica-local-robusta}{%
\subsection{Regresión polinómica local robusta}\label{regresiuxf3n-polinuxf3mica-local-robusta}}

También hay versiones robustas del ajuste polinómico local tipo núcleo.
Estos métodos surgieron en el caso bivariante (\(p=1\)), por lo que también se denominan \emph{suavizado de diagramas de dispersión} (\emph{scatterplot smoothing}; e.g.~función \texttt{lowess()}, \emph{locally weighted scatterplot smoothing}, del paquete base).
Posteriormente se extendieron al caso multivariante (e.g.~función \texttt{loess()}).

Son métodos muy empleados en análisis descriptivo (no supervisado) y normalmente se emplean ventanas locales tipo vecinos más cercanos (por ejemplo a través de un parámetro \texttt{spam} que determina la proporción de observaciones empleadas en el ajuste).

Como ejemplo emplearemos la función \texttt{loess()} con ajuste robusto (habrá que establecer \texttt{family\ =\ "symmetric"} para emplear M-estimadores, por defecto con 4 iteraciones, en lugar de mínimos cuadrados ponderados), seleccionando previamente \texttt{spam} por validación cruzada (LOOCV) pero empleando como criterio de error la mediana de los errores en valor absoluto (\emph{median absolute deviation}, MAD)\footnote{En este caso habría dependencia entre las observaciones y los criterios habituales como validación cruzada tenderán a seleccionar ventanas pequeñas, i.e.~a infrasuavizar.}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cv.loess }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(formula, datos, span, ...) \{}
\NormalTok{  n }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(datos)}
\NormalTok{  cv.pred }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(n)}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{n) \{}
\NormalTok{    modelo }\OtherTok{\textless{}{-}} \FunctionTok{loess}\NormalTok{(formula, datos[}\SpecialCharTok{{-}}\NormalTok{i, ], }\AttributeTok{span =}\NormalTok{ span, }
                    \AttributeTok{control =} \FunctionTok{loess.control}\NormalTok{(}\AttributeTok{surface =} \StringTok{"direct"}\NormalTok{), ...)}
    \CommentTok{\# control = loess.control(surface = "direct") permite extrapolaciones}
\NormalTok{    cv.pred[i] }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(modelo, }\AttributeTok{newdata =}\NormalTok{ datos[i, ])}
\NormalTok{  \}}
  \FunctionTok{return}\NormalTok{(cv.pred)}
\NormalTok{\}}

\NormalTok{ventanas }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\AttributeTok{len =} \DecValTok{10}\NormalTok{)}
\NormalTok{np }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(ventanas)}
\NormalTok{cv.error }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(np)}
\ControlFlowTok{for}\NormalTok{(p }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{np)\{}
\NormalTok{  cv.pred }\OtherTok{\textless{}{-}} \FunctionTok{cv.loess}\NormalTok{(accel }\SpecialCharTok{\textasciitilde{}}\NormalTok{ times, mcycle, ventanas[p], }\AttributeTok{family =} \StringTok{"symmetric"}\NormalTok{)}
  \CommentTok{\# cv.error[p] \textless{}{-} mean((cv.pred {-} mcycle$accel)\^{}2)}
\NormalTok{  cv.error[p] }\OtherTok{\textless{}{-}} \FunctionTok{median}\NormalTok{(}\FunctionTok{abs}\NormalTok{(cv.pred }\SpecialCharTok{{-}}\NormalTok{ mcycle}\SpecialCharTok{$}\NormalTok{accel))}
\NormalTok{\}}

\FunctionTok{plot}\NormalTok{(ventanas, cv.error)}
\NormalTok{imin }\OtherTok{\textless{}{-}} \FunctionTok{which.min}\NormalTok{(cv.error)}
\NormalTok{span.cv }\OtherTok{\textless{}{-}}\NormalTok{ ventanas[imin]}
\FunctionTok{points}\NormalTok{(span.cv, cv.error[imin], }\AttributeTok{pch =} \DecValTok{16}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-5-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Ajuste con todos los datos}
\FunctionTok{plot}\NormalTok{(accel }\SpecialCharTok{\textasciitilde{}}\NormalTok{ times, }\AttributeTok{data =}\NormalTok{ mcycle, }\AttributeTok{col =} \StringTok{\textquotesingle{}darkgray\textquotesingle{}}\NormalTok{)}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{loess}\NormalTok{(accel }\SpecialCharTok{\textasciitilde{}}\NormalTok{ times, mcycle, }\AttributeTok{span =}\NormalTok{ span.cv, }\AttributeTok{family =} \StringTok{"symmetric"}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(mcycle}\SpecialCharTok{$}\NormalTok{times, }\FunctionTok{predict}\NormalTok{(fit))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-5-2} \end{center}

\hypertarget{splines}{%
\section{Splines}\label{splines}}

Otra alternativa consiste en trocear los datos en intervalos, fijando unos puntos de corte \(z_i\) (denominados nudos; \emph{knots}), con \(i = 1, \ldots, k\), y ajustar un polinomio en cada segmento (lo que se conoce como regresión segmentada, \emph{piecewise regression}).

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-6-1} \end{center}

De esta forma sin embargo habrá discontinuidades en los puntos de corte, pero podrían añadirse restricciones adicionales de continuidad (o incluso de diferenciabilidad) para evitarlo (e.g.~paquete \href{https://CRAN.R-project.org/package=segmented}{\texttt{segmented}}).

\hypertarget{reg-splines}{%
\subsection{Regression splines}\label{reg-splines}}

Cuando en cada intervalo se ajustan polinomios de orden \(d\) y se incluyen restricciones de forma que las derivadas sean continuas hasta el orden \(d-1\) se obtienen los denominados splines de regresión (\emph{regression splines}).

Puede verse que este tipo de ajustes equivalen a transformar la variable predictora \(X\), considerando por ejemplo la \emph{base de potencias truncadas} (\emph{truncated power basis}):
\[1, x, \ldots, x^d, (x-z_1)_+^d,\ldots,(x-z_k)_+^d\]
siendo \((x - z)_+ = \max(0, x - z)\), y posteriormente realizar un ajuste lineal:
\[m(x) = \beta_0 + \beta_1 b_1(x) +  \beta_2 b_2(x) + \ldots  + \beta_{k+d} b_{k+d}(x)\]

Típicamente se seleccionan polinomios de grado \(d=3\), lo que se conoce como splines cúbicos, y nodos equiespaciados.
Además, se podrían emplear otras bases equivalentes. Por ejemplo, para evitar posibles problemas computacionales con la base anterior, se suele emplear la denominada base \(B\)-spline (\protect\hyperlink{ref-de1978practical}{De Boor y De Boor, 1978}), implementada en la función \texttt{bs()} del paquete \texttt{splines}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nknots }\OtherTok{\textless{}{-}} \DecValTok{9} \CommentTok{\# nodos internos; 10 intervalos}
\NormalTok{knots }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(x), }\FunctionTok{max}\NormalTok{(x), }\AttributeTok{len =}\NormalTok{ nknots }\SpecialCharTok{+} \DecValTok{2}\NormalTok{)[}\SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, nknots }\SpecialCharTok{+} \DecValTok{2}\NormalTok{)]}
\CommentTok{\# knots \textless{}{-} quantile(x, 1:nknots/(nknots + 1)) \# bs(x, df = nknots + degree + intercept)}

\FunctionTok{library}\NormalTok{(splines)}
\NormalTok{fit1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{bs}\NormalTok{(x, }\AttributeTok{knots =}\NormalTok{ knots, }\AttributeTok{degree =} \DecValTok{1}\NormalTok{))}
\NormalTok{fit2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{bs}\NormalTok{(x, }\AttributeTok{knots =}\NormalTok{ knots, }\AttributeTok{degree =} \DecValTok{2}\NormalTok{))}
\NormalTok{fit3 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{bs}\NormalTok{(x, }\AttributeTok{knots =}\NormalTok{ knots)) }\CommentTok{\# degree = 3}

\FunctionTok{plot}\NormalTok{(x, y, }\AttributeTok{col =} \StringTok{\textquotesingle{}darkgray\textquotesingle{}}\NormalTok{)}
\NormalTok{newx }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(x), }\FunctionTok{max}\NormalTok{(x), }\AttributeTok{len =} \DecValTok{200}\NormalTok{)}
\NormalTok{newdata }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x =}\NormalTok{ newx)}
\FunctionTok{lines}\NormalTok{(newx, }\FunctionTok{predict}\NormalTok{(fit1, newdata), }\AttributeTok{lty =} \DecValTok{3}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(newx, }\FunctionTok{predict}\NormalTok{(fit2, newdata), }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(newx, }\FunctionTok{predict}\NormalTok{(fit3, newdata))}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =}\NormalTok{ knots, }\AttributeTok{lty =} \DecValTok{3}\NormalTok{, }\AttributeTok{col =} \StringTok{\textquotesingle{}darkgray\textquotesingle{}}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }\AttributeTok{legend =} \FunctionTok{c}\NormalTok{(}\StringTok{"d=1 (df=11)"}\NormalTok{, }\StringTok{"d=2 (df=12)"}\NormalTok{, }\StringTok{"d=3 (df=13)"}\NormalTok{), }
       \AttributeTok{lty =} \FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-7-1} \end{center}

El grado del polinomio, pero sobre todo el número de nodos, determinarán la flexibilidad del modelo.
Se podrían considerar el número de parámetros en el ajuste lineal, los grados de libertad, como medida de la complejidad (en la función \texttt{bs()} se puede especificar \texttt{df} en lugar de \texttt{knots}, y estos se generarán a partir de los cuantiles de \texttt{x}).

Como ya se comentó, al aumentar el grado del modelo polinómico se incrementa la variabilidad de las predicciones, especialmente en la frontera.
Para tratar de evitar este problema se suelen emplear los \emph{splines naturales}, que son splines de regresión con restricciones adicionales de forma que el ajuste sea lineal en los intervalos extremos (lo que en general produce estimaciones más estables en la frontera y mejores extrapolaciones).
Estas restricciones reducen la complejidad (los grados de libertad del modelo), y al igual que en el caso de considerar únicamente las restricciones de continuidad y diferenciabilidad, resultan equivalentes a considerar una nueva base en un ajuste sin restricciones.
Por ejemplo, se puede emplear la función \texttt{splines::ns()} para ajustar un spline natural (cúbico por defecto):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(x, y, }\AttributeTok{col =} \StringTok{\textquotesingle{}darkgray\textquotesingle{}}\NormalTok{)}
\NormalTok{fit4 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{ns}\NormalTok{(x, }\AttributeTok{knots =}\NormalTok{ knots))}
\FunctionTok{lines}\NormalTok{(newx, }\FunctionTok{predict}\NormalTok{(fit4, newdata))}
\FunctionTok{lines}\NormalTok{(newx, }\FunctionTok{predict}\NormalTok{(fit3, newdata), }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =}\NormalTok{ knots, }\AttributeTok{lty =} \DecValTok{3}\NormalTok{, }\AttributeTok{col =} \StringTok{\textquotesingle{}darkgray\textquotesingle{}}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }\AttributeTok{legend =} \FunctionTok{c}\NormalTok{(}\StringTok{"ns (d=3, df=11)"}\NormalTok{, }\StringTok{"bs (d=3, df=13)"}\NormalTok{), }\AttributeTok{lty =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-8-1} \end{center}

La dificultad está en la selección de los nodos \(z_i\). Si se consideran equiespaciados (o se emplea otro criterio como los cuantiles), se podría seleccionar su número (equivalentemente los grados de libertad) empleando algún método de validación cruzada.
Sin embargo, sería preferible considerar más nodos donde aparentemente hay más variaciones en la función de regresión y menos donde es más estable, esta es la idea de la regresión spline adaptativa descrita en la Sección \ref{mars}.
Otra alternativa son los splines penalizados, descritos al final de esta sección.

\hypertarget{smoothing-splines}{%
\subsection{Smoothing splines}\label{smoothing-splines}}

Los splines de suavizado (\emph{smoothing splines}) se obtienen como la función \(s(x)\) suave (dos veces diferenciable) que minimiza la suma de cuadrados residual más una penalización que mide su rugosidad:
\[\sum_{i=1}^{n} (y_i - s(x_i))^2  + \lambda \int s^{\prime\prime}(x)^2 dx\]
siendo \(0 \leq \lambda < \infty\) el (hiper)parámetro de suavizado.

Puede verse que la solución a este problema, en el caso univariante, es un spline natural cúbico con nodos en \(x_1, \ldots, x_n\) y restricciones en los coeficientes determinadas por el valor de \(\lambda\) (es una versión regularizada de un spline natural cúbico).
Por ejemplo si \(\lambda = 0\) se interpolarán las observaciones y cuando \(\lambda \rightarrow \infty\) el ajuste tenderá a una recta (con segunda derivada nula).
En el caso multivariante \(p> 1\) la solución da lugar a los denominados \emph{thin plate splines}\footnote{Están relacionados con las funciones radiales. También hay versiones con un número reducido de nodos denominados \emph{low-rank thin plate regression splines} empleados en el paquete \texttt{mgcv}.}.

Al igual que en el caso de la regresión polinómica local (Sección \ref{reg-locpol}), estos métodos son suavizadores lineales:
\[\hat{\mathbf{Y}} = S_{\lambda}\mathbf{Y}\]
y para seleccionar el parámetro de suavizado \(\lambda\) podemos emplear los criterios de validación cruzada (dejando uno fuera), minimizando:
\[CV(\lambda)=\frac{1}{n}\sum_{i=1}^n\left(\frac{y_i-\hat{s}_{\lambda}(x_i)}{1 - \{ S_{\lambda}\}_{ii}}\right)^2\]
siendo \(\{ S_{\lambda}\}_{ii}\) el elemento \(i\)-ésimo de la diagonal de la matriz de suavizado,
o validación cruzada generalizada (GCV), minimizando:
\[GCV(\lambda)=\frac{1}{n}\sum_{i=1}^n\left(\frac{y_i-\hat{s}_{\lambda}(x_i)}{1 - \frac{1}{n}tr(S_{\lambda})}\right)^2\]

Análogamente, el número efectivo de parámetros o grados de libertad\footnote{Esto también permitiría generalizar los criterios AIC o BIC.} \(df_{\lambda}=tr(S_{\lambda})\) sería una medida de la complejidad del modelo equivalente a \(\lambda\) (muchas implementaciones permiten seleccionar la complejidad empleando \(df\)).

Este método de suavizado está implementado en la función \texttt{smooth.spline()} del paquete base y por defecto emplea GCV para seleccionar el parámetro de suavizado (aunque también admite CV y se puede especificar \texttt{lambda} o \texttt{df})\footnote{Además de predicciones, el correspondiente método \texttt{predict()} también permite obtener estimaciones de las derivadas.}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sspline.gcv }\OtherTok{\textless{}{-}} \FunctionTok{smooth.spline}\NormalTok{(x, y)}
\NormalTok{sspline.cv }\OtherTok{\textless{}{-}} \FunctionTok{smooth.spline}\NormalTok{(x, y, }\AttributeTok{cv =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(x, y, }\AttributeTok{col =} \StringTok{\textquotesingle{}darkgray\textquotesingle{}}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(sspline.gcv)}
\FunctionTok{lines}\NormalTok{(sspline.cv, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-9-1} \end{center}

Cuando el número de observaciones es muy grande, y por tanto el número de nodos, pueden aparecer problemas computacionales al emplear estos métodos.

\hypertarget{splines-penalizados}{%
\subsection{Splines penalizados}\label{splines-penalizados}}

Los splines penalizados (\emph{penalized splines}) combinan las dos aproximaciones anteriores.
Incluyen una penalización (que depende de la base considerada) y el número de nodos puede ser mucho menor que el número de observaciones (son un tipo de \emph{low-rank smoothers}). De esta forma se obtienen modelos spline con mejores propiedades, con un menor efecto frontera y en los que se evitan problemas en la selección de los nodos.
Unos de los más empleados son los \(P\)-splines (\protect\hyperlink{ref-eilers1996flexible}{Eilers y Marx, 1996}) que emplean una base \(B\)-spline con una penalización simple (basada en los cuadrados de diferencias de coeficientes consecutivos \((\beta_{i+1} - \beta_i)^2\)).

Además, un modelo spline penalizado se puede representar como un modelo lineal mixto, lo que permite emplear herramientas desarrolladas para este tipo de modelos (por ejemplo la implementadas en el paquete \texttt{nlme}, del que depende \texttt{mgcv}, que por defecto emplea splines penalizados).
Para más detalles ver por ejemplo las secciones 5.2 y 5.3 de \protect\hyperlink{ref-wood2017generalized}{Wood} (\protect\hyperlink{ref-wood2017generalized}{2017}).

\hypertarget{modelos-aditivos}{%
\section{Modelos aditivos}\label{modelos-aditivos}}

Se supone que:
\[Y= \beta_{0} + f_1(X_1) + f_2(X_2) + \ldots + f_p(X_p)  + \varepsilon\]
con \(f_{i},\) \(i=1,...,p,\) funciones cualesquiera.
De esta forma se consigue mucha mayor flexibilidad que con los modelos lineales pero manteniendo la interpretabilidad de los efectos de los predictores.
Adicionalmente se puede considerar una función de enlace, obteniéndose los denominados \emph{modelos aditivos generalizados} (GAM). Para más detalles sobre este tipo modelos ver por ejemplo \protect\hyperlink{ref-hastie1990generalized}{Hastie y Tibshirani} (\protect\hyperlink{ref-hastie1990generalized}{1990}) o \protect\hyperlink{ref-wood2017generalized}{Wood} (\protect\hyperlink{ref-wood2017generalized}{2017}).

Los modelos lineales (generalizados) serían un caso particular considerando \(f_{i}(x) = \beta_{i}x\).
Además, se podrían considerar cualquiera de los métodos de suavizado descritos anteriormente para construir las componentes no paramétricas (por ejemplo si se emplean splines naturales de regresión el ajuste se reduciría al de un modelo lineal).
Se podrían considerar distintas aproximaciones para el modelado de cada componente (modelos semiparamétricos) y realizar el ajuste mediante \emph{backfitting} (se ajusta cada componente de forma iterativa, empleando los residuos obtenidos al mantener las demás fijas).
Si en las componentes no paramétricas se emplea únicamente splines de regresión (con o sin penalización), se puede reformular el modelo como un GLM (regularizado si hay penalización) y ajustarlo fácilmente adaptando herramientas disponibles (\emph{penalized re-weighted iterative least squares}, PIRLS).

De entre todos los paquetes de R que implementan estos modelos destacan:

\begin{itemize}
\item
  \texttt{gam}: Admite splines de suavizado (univariantes, \texttt{s()}) y regresión polinómica local (multivariante, \texttt{lo()}), pero no dispone de un método para la selección automática de los parámetros de suavizado (se podría emplear un criterio por pasos para la selección de componentes).
  Sigue la referencia \protect\hyperlink{ref-hastie1990generalized}{Hastie y Tibshirani} (\protect\hyperlink{ref-hastie1990generalized}{1990}).
\item
  \texttt{mgcv}: Admite una gran variedad de splines de regresión y splines penalizados (\texttt{s()}; por defecto emplea thin plate regression splines penalizados multivariantes), con la opción de selección automática de los parámetros de suavizado mediante distintos criterios.
  Además de que se podría emplear un método por pasos, permite la selección de componentes mediante regularización.
  Al ser más completo que el anterior sería el recomendado en la mayoría de los casos (ver \texttt{?mgcv::mgcv.package} para una introducción al paquete).
  Sigue la referencia \protect\hyperlink{ref-wood2017generalized}{Wood} (\protect\hyperlink{ref-wood2017generalized}{2017}).
\end{itemize}

\hypertarget{ajuste-funciuxf3n-gam}{%
\subsection{\texorpdfstring{Ajuste: función \texttt{gam}}{Ajuste: función gam}}\label{ajuste-funciuxf3n-gam}}

La función \texttt{gam()} del paquete \texttt{mgcv} permite ajustar modelos aditivos generalizados empleando suavizado mediante splines:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(mgcv)}
\NormalTok{ajuste }\OtherTok{\textless{}{-}} \FunctionTok{gam}\NormalTok{(formula, }\AttributeTok{family =}\NormalTok{ gaussian, data, }\AttributeTok{method =} \StringTok{"GCV.Cp"}\NormalTok{, }\AttributeTok{select =} \ConstantTok{FALSE}\NormalTok{, ...)}
\end{Highlighting}
\end{Shaded}

(también dispone de la función \texttt{bam()} para el ajuste de estos modelos a grandes conjuntos de datos y de la función \texttt{gamm()} para el ajuste de modelos aditivos generalizados mixtos). El modelo se establece a partir de la \texttt{formula} empleando \texttt{s()} para especificar las componentes ``suaves'' (ver \texttt{help(s)} y Sección \ref{mgcv-diagnosis}).

Algunas posibilidades de uso son las que siguen:

\begin{itemize}
\item
  Modelo lineal:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ajuste }\OtherTok{\textless{}{-}} \FunctionTok{gam}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2 }\SpecialCharTok{+}\NormalTok{ x3)}
\end{Highlighting}
\end{Shaded}
\item
  Modelo (semiparamétrico) aditivo con efectos no paramétricos para \texttt{x1} y \texttt{x2}, y un efecto lineal para \texttt{x3}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ajuste }\OtherTok{\textless{}{-}} \FunctionTok{gam}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(x1) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(x2) }\SpecialCharTok{+}\NormalTok{ x3)}
\end{Highlighting}
\end{Shaded}
\item
  Modelo no aditivo (con interacción):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ajuste }\OtherTok{\textless{}{-}} \FunctionTok{gam}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(x1, x2))}
\end{Highlighting}
\end{Shaded}
\item
  Modelo (semiparamétrico) con distintas combinaciones :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ajuste }\OtherTok{\textless{}{-}} \FunctionTok{gam}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(x1, x2) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(x3) }\SpecialCharTok{+}\NormalTok{ x4)}
\end{Highlighting}
\end{Shaded}
\end{itemize}

\hypertarget{ejemplo-3}{%
\subsection{Ejemplo}\label{ejemplo-3}}

En esta sección utilizaremos como ejemplo el conjunto de datos \texttt{Prestige} de la librería \texttt{carData}.
Se tratará de explicar \texttt{prestige} (puntuación de ocupaciones obtenidas a partir de una encuesta) a partir de \texttt{income} (media de ingresos en la ocupación) y \texttt{education} (media de los años de educación).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(Prestige, }\AttributeTok{package =} \StringTok{"carData"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(mgcv)}
\NormalTok{modelo }\OtherTok{\textless{}{-}} \FunctionTok{gam}\NormalTok{(prestige }\SpecialCharTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(income) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(education), }\AttributeTok{data =}\NormalTok{ Prestige)}
\FunctionTok{summary}\NormalTok{(modelo)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## prestige ~ s(income) + s(education)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  46.8333     0.6889   67.98   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Approximate significance of smooth terms:
##                edf Ref.df     F p-value    
## s(income)    3.118  3.877 14.61  <2e-16 ***
## s(education) 3.177  3.952 38.78  <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## R-sq.(adj) =  0.836   Deviance explained = 84.7%
## GCV = 52.143  Scale est. = 48.414    n = 102
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# coef(modelo) \# El resultado es un modelo lineal en transformaciones de los predictores}
\end{Highlighting}
\end{Shaded}

En este caso el método \texttt{plot()} representa los efectos (parciales) estimados de cada predictor:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{par.old }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(modelo, }\AttributeTok{shade =} \ConstantTok{TRUE}\NormalTok{) }\CommentTok{\# }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-16-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(par.old)}
\end{Highlighting}
\end{Shaded}

En general se representa cada componente no paramétrica (salvo que se especifique \texttt{all.terms\ =\ TRUE}), incluyendo gráficos de contorno para el caso de componentes bivariantes (correspondientes a interacciones entre predictores).

Se dispone también de un método \texttt{predict()} para calcular las predicciones de la forma habitual (por defecto devuelve las correspondientes a las observaciones \texttt{modelo\$fitted.values} y para nuevos datos hay que emplear el argumento \texttt{newdata}).

\hypertarget{superficies-de-predicciuxf3n}{%
\subsection{Superficies de predicción}\label{superficies-de-predicciuxf3n}}

En el caso bivariante, para representar las estimaciones (la superficie de predicción) obtenidas con el modelo se pueden utilizar las funciones \texttt{persp()} o versiones mejoradas como \texttt{plot3D::persp3D}.
Estas funciones requieren que los valores de entrada estén dispuestos en una rejilla bidimensional.
Para generar esta rejilla se puede emplear la función \texttt{expand.grid(x,y)} que crea todas las combinaciones de los puntos dados en \texttt{x} e \texttt{y}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{inc }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(Prestige, }\FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(income), }\FunctionTok{max}\NormalTok{(income), }\AttributeTok{len =} \DecValTok{25}\NormalTok{))}
\NormalTok{ed }\OtherTok{\textless{}{-}} \FunctionTok{with}\NormalTok{(Prestige, }\FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(education), }\FunctionTok{max}\NormalTok{(education), }\AttributeTok{len =} \DecValTok{25}\NormalTok{))}
\NormalTok{newdata }\OtherTok{\textless{}{-}} \FunctionTok{expand.grid}\NormalTok{(}\AttributeTok{income =}\NormalTok{ inc, }\AttributeTok{education =}\NormalTok{ ed)}
\CommentTok{\# Representamos la rejilla}
\FunctionTok{plot}\NormalTok{(income }\SpecialCharTok{\textasciitilde{}}\NormalTok{ education, Prestige, }\AttributeTok{pch =} \DecValTok{16}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =}\NormalTok{ inc, }\AttributeTok{v =}\NormalTok{ ed, }\AttributeTok{col =} \StringTok{"grey"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-17-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Se calculan las predicciones}
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(modelo, newdata)}
\CommentTok{\# Se representan}
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(pred, }\AttributeTok{nrow =} \DecValTok{25}\NormalTok{)}
\CommentTok{\# persp(inc, ed, pred, theta = {-}40, phi = 30)}
\NormalTok{plot3D}\SpecialCharTok{::}\FunctionTok{persp3D}\NormalTok{(inc, ed, pred, }\AttributeTok{theta =} \SpecialCharTok{{-}}\DecValTok{40}\NormalTok{, }\AttributeTok{phi =} \DecValTok{30}\NormalTok{, }\AttributeTok{ticktype =} \StringTok{"detailed"}\NormalTok{,}
                \AttributeTok{xlab =} \StringTok{"Income"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Education"}\NormalTok{, }\AttributeTok{zlab =} \StringTok{"Prestige"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-17-2} \end{center}

Alternativamente se podrían emplear las funciones \texttt{contour()}, \texttt{filled.contour()}, \texttt{plot3D::image2D} o similares:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# contour(inc, ed, pred, xlab = "Income", ylab = "Education")}
\FunctionTok{filled.contour}\NormalTok{(inc, ed, pred, }\AttributeTok{xlab =} \StringTok{"Income"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Education"}\NormalTok{, }\AttributeTok{key.title =} \FunctionTok{title}\NormalTok{(}\StringTok{"Prestige"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-18-1} \end{center}

Puede ser más cómodo emplear el paquete \href{https://modelr.tidyverse.org}{\texttt{modelr}} (emplea gráficos \texttt{ggplot2}) para trabajar con modelos y predicciones.

\hypertarget{comparaciuxf3n-y-selecciuxf3n-de-modelos}{%
\subsection{Comparación y selección de modelos}\label{comparaciuxf3n-y-selecciuxf3n-de-modelos}}

Además de las medidas de bondad de ajuste como el coeficiente de determinación ajustado, también se puede emplear la función \texttt{anova} para la comparación de modelos (y seleccionar las componentes por pasos de forma interactiva).
Por ejemplo, viendo el gráfico de los efectos se podría pensar que el efecto de \texttt{education} podría ser lineal:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot(modelo)}
\NormalTok{modelo0 }\OtherTok{\textless{}{-}} \FunctionTok{gam}\NormalTok{(prestige }\SpecialCharTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(income) }\SpecialCharTok{+}\NormalTok{ education, }\AttributeTok{data =}\NormalTok{ Prestige)}
\FunctionTok{summary}\NormalTok{(modelo0)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## prestige ~ s(income) + education
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   4.2240     3.7323   1.132    0.261    
## education     3.9681     0.3412  11.630   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Approximate significance of smooth terms:
##            edf Ref.df    F p-value    
## s(income) 3.58  4.441 13.6  <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## R-sq.(adj) =  0.825   Deviance explained = 83.3%
## GCV = 54.798  Scale est. = 51.8      n = 102
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(modelo0, modelo, }\AttributeTok{test=}\StringTok{"F"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Deviance Table
## 
## Model 1: prestige ~ s(income) + education
## Model 2: prestige ~ s(income) + s(education)
##   Resid. Df Resid. Dev     Df Deviance      F Pr(>F)  
## 1    95.559     4994.6                                
## 2    93.171     4585.0 2.3886   409.58 3.5418 0.0257 *
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

En este caso aceptaríamos que el modelo original es significativamente mejor.

Alternativamente, podríamos pensar que hay interacción:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelo2 }\OtherTok{\textless{}{-}} \FunctionTok{gam}\NormalTok{(prestige }\SpecialCharTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(income, education), }\AttributeTok{data =}\NormalTok{ Prestige)}
\FunctionTok{summary}\NormalTok{(modelo2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## prestige ~ s(income, education)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  46.8333     0.7138   65.61   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Approximate significance of smooth terms:
##                      edf Ref.df     F p-value    
## s(income,education) 4.94  6.303 75.41  <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## R-sq.(adj) =  0.824   Deviance explained = 83.3%
## GCV = 55.188  Scale est. = 51.974    n = 102
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot(modelo2, se = FALSE)}
\CommentTok{\# plot(modelo2, scheme = 2)}
\end{Highlighting}
\end{Shaded}

En este caso el coeficiente de determinación ajustado es menor y ya no tendría sentido realizar el contraste.

Ademas se pueden seleccionar componentes del modelo (mediante regularización) empleando el parámetro \texttt{select\ =\ TRUE}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{example}\NormalTok{(gam.selection)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## gm.slc> ## an example of automatic model selection via null space penalization
## gm.slc> library(mgcv)
## 
## gm.slc> set.seed(3);n<-200
## 
## gm.slc> dat <- gamSim(1,n=n,scale=.15,dist="poisson") ## simulate data
## Gu & Wahba 4 term additive model
## 
## gm.slc> dat$x4 <- runif(n, 0, 1);dat$x5 <- runif(n, 0, 1) ## spurious
## 
## gm.slc> b<-gam(y~s(x0)+s(x1)+s(x2)+s(x3)+s(x4)+s(x5),data=dat,
## gm.slc+          family=poisson,select=TRUE,method="REML")
## 
## gm.slc> summary(b)
## 
## Family: poisson 
## Link function: log 
## 
## Formula:
## y ~ s(x0) + s(x1) + s(x2) + s(x3) + s(x4) + s(x5)
## 
## Parametric coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  1.21758    0.04082   29.83   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Approximate significance of smooth terms:
##             edf Ref.df  Chi.sq p-value    
## s(x0) 1.7655088      9   5.264  0.0392 *  
## s(x1) 1.9271040      9  65.356  <2e-16 ***
## s(x2) 6.1351414      9 156.204  <2e-16 ***
## s(x3) 0.0002849      9   0.000  0.4181    
## s(x4) 0.0003044      9   0.000  0.9703    
## s(x5) 0.1756926      9   0.195  0.3018    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## R-sq.(adj) =  0.545   Deviance explained = 51.6%
## -REML = 430.78  Scale est. = 1         n = 200
## 
## gm.slc> plot(b,pages=1)
\end{verbatim}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-22-1} \end{center}

\hypertarget{mgcv-diagnosis}{%
\subsection{Diagnosis del modelo}\label{mgcv-diagnosis}}

La función \texttt{gam.check()} realiza una diagnosis del modelo:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{gam.check}\NormalTok{(modelo)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-23-1} \end{center}

\begin{verbatim}
## 
## Method: GCV   Optimizer: magic
## Smoothing parameter selection converged after 4 iterations.
## The RMS GCV score gradient at convergence was 9.783945e-05 .
## The Hessian was positive definite.
## Model rank =  19 / 19 
## 
## Basis dimension (k) checking results. Low p-value (k-index<1) may
## indicate that k is too low, especially if edf is close to k'.
## 
##                k'  edf k-index p-value
## s(income)    9.00 3.12    0.98    0.42
## s(education) 9.00 3.18    1.03    0.54
\end{verbatim}

Lo ideal sería observar normalidad en los dos gráficos de la izquierda, falta de patrón en el superior derecho, y ajuste a una recta en el inferior derecho. En este caso parece que el modelo se comporta adecuadamente.
Como se deduce del resultado anterior, podría ser recomendable modificar la dimensión \texttt{k} de la base utilizada construir la componente no paramétrica, este valor se puede interpretar como el grado máximo de libertad permitido en ese componente, aunque normalmente no influye demasiado en el resultado (puede influir en el tiempo de computación).

También se podría chequear concurvidad (\emph{concurvity}; generalización de la colinealidad) entre las componentes del modelo:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{concurvity}\NormalTok{(modelo)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                  para s(income) s(education)
## worst    3.107241e-23 0.5931528    0.5931528
## observed 3.107241e-23 0.4065402    0.4398639
## estimate 3.107241e-23 0.3613674    0.4052251
\end{verbatim}

Esta función devuelve tres medidas por componente, que tratan de medir la proporción de variación de esa componente que está contenida en el resto (similares al complementario de la tolerancia; un valor próximo a 1 indicaría que puede haber problemas de concurvidad).

\hypertarget{gam-en-caret}{%
\subsection{\texorpdfstring{GAM en \texttt{caret}}{GAM en caret}}\label{gam-en-caret}}

El soporte de GAM en \texttt{caret} es como poco deficiente\ldots{}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}
\FunctionTok{names}\NormalTok{(}\FunctionTok{getModelInfo}\NormalTok{(}\StringTok{"gam"}\NormalTok{)) }\CommentTok{\# 4 métodos}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "gam"       "gamboost"  "gamLoess"  "gamSpline"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{modelLookup}\NormalTok{(}\StringTok{"gam"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   model parameter             label forReg forClass probModel
## 1   gam    select Feature Selection   TRUE     TRUE      TRUE
## 2   gam    method            Method   TRUE     TRUE      TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{modelLookup}\NormalTok{(}\StringTok{"gamLoess"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      model parameter  label forReg forClass probModel
## 1 gamLoess      span   Span   TRUE     TRUE      TRUE
## 2 gamLoess    degree Degree   TRUE     TRUE      TRUE
\end{verbatim}

\hypertarget{ejercicios}{%
\subsection{Ejercicios}\label{ejercicios}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Continuando con los datos de \texttt{MASS:mcycle}, emplear \texttt{mgcv::gam()} para ajustar un spline penalizado para predecir \texttt{accel} a partir de \texttt{times} con las opciones por defecto y representar el ajuste obtenido. Comparar el ajuste con el obtenido empleando un spline penalizado adaptativo (\texttt{bs="ad"}; ver \texttt{?adaptive.smooth}).
\item
  Empleando el conjunto de datos \texttt{airquality}, crear una muestra de entrenamiento y otra de test, buscar un modelo aditivo que resulte adecuado para explicar \texttt{sqrt(Ozone)} a partir de \texttt{Temp}, \texttt{Wind} y \texttt{Solar.R}.
  Es preferible suponer que hay una interacción entre \texttt{Temp} y \texttt{Wind}?
\end{enumerate}

\hypertarget{mars}{%
\section{Regresión spline adaptativa multivariante}\label{mars}}

La regresión spline adaptativa multivariante, en inglés \emph{multivariate adaptive regression splines} {[}MARS; \protect\hyperlink{ref-friedman1991multivariate}{Friedman} (\protect\hyperlink{ref-friedman1991multivariate}{1991}){]}, es un procedimiento adaptativo para problemas de regresión que puede verse como una generalización tanto de la regresión lineal por pasos (\emph{stepwise linear regression}) como de los árboles de decisión CART.

El modelo MARS es un spline multivariante lineal:\\
\[m(\mathbf{x}) = \beta_0 + \sum_{m=1}^M \beta_m h_m(\mathbf{x})\]
(es un modelo lineal en transformaciones \(h_m(\mathbf{x})\) de los predictores originales), donde las bases \(h_m(\mathbf{x})\) se construyen de forma adaptativa empleando funciones \emph{bisagra} (\emph{hinge functions})
\[ h(x) = (x)_+ = \left\{ \begin{array}{ll}
  x & \mbox{si } x > 0 \\
  0 & \mbox{si } x \leq 0
  \end{array}
  \right.\]
y considerando como posibles nodos los valores observados de los predictores
(en el caso univariante se emplean las bases de potencias truncadas con \(d=1\) descritas en la Sección \ref{reg-splines}, pero incluyendo también su versión simetrizada).

Vamos a empezar explicando el modelo MARS aditivo (sin interacciones), que funciona de forma muy parecida a los árboles de decisión CART, y después lo extenderemos al caso con interacciones.
Asumimos que todas las variables predictoras son numéricas. El proceso de construcción del modelo es un proceso iterativo \emph{hacia delante} (forward) que empieza con el modelo
\[\hat m(\mathbf{x}) = \hat \beta_0 \]
donde \(\hat \beta_0\) es la media de todas las respuestas, para a continuación considerar todos los puntos de corte (\emph{knots}) posibles \(x_{ji}\) con \(i = 1, 2, \ldots, n\), \(j = 1, 2, \ldots, p\), es decir, todas las observaciones de todas las variables predictoras de la muestra de entrenamiento.
Para cada punto de corte \(x_{ji}\) (combinación de variable y observación) se consideran dos bases:
\[ \begin{aligned}
h_1(\mathbf{x}) = h(x_j - x_{ji}) \\
h_2(\mathbf{x}) = h(x_{ji} - x_j)
\end{aligned}\]
y se construye el nuevo modelo
\[\hat m(\mathbf{x}) = \hat \beta_0 + \hat \beta_1 h_1(\mathbf{x}) + \hat \beta_2 h_2(\mathbf{x})\]
La estimación de los parámetros \(\beta_0, \beta_1, \beta_2\) se realiza de la forma estándar en regresión lineal, minimizando \(\mbox{RSS}\). De este modo se construyen muchos modelos alternativos y entre ellos se selecciona aquel que tenga un menor error de entrenamiento. En la siguiente iteración se conservan \(h_1(\mathbf{x})\) y \(h_2(\mathbf{x})\) y se añade una pareja de términos nuevos siguiendo el mismo procedimiento. Y así sucesivamente, añadiendo de cada vez dos nuevos términos. Este procedimiento va creando un modelo lineal segmentado (piecewise) donde cada nuevo término modeliza una porción aislada de los datos originales.

El \emph{tamaño} de cada modelo es el número términos (funciones \(h_m\)) que este incorpora. El proceso iterativo se para cuando se alcanza un modelo de tamaño \(M\), que se consigue después de incorporar \(M/2\) cortes. Este modelo depende de \(M+1\) parámetros \(\beta_m\) con \(m=0,1,\ldots,M\). El objetivo es alcanzar un modelo lo suficientemente grande para que sobreajuste los datos, para a continuación proceder a su poda en un proceso de eliminación de variables hacia atrás (\emph{backward deletion}) en el que se van eliminando las variables de una en una (no por parejas, como en la construcción). En cada paso de poda se elimina el término que produce el menor incremento en el error. Así, para cada tamaño \(\lambda = 0,1,\ldots, M\) se obtiene el mejor modelo estimado \(\hat{m}_{\lambda}\).

La selección \emph{óptima} del valor del hiperparámetro \(\lambda\) puede realizarse por los procedimientos habituales tipo validación cruzada. Una alternativa mucho más rápida es utilizar validación cruzada generalizada (GCV) que es una aproximación de la validación cruzada \emph{leave-one-out} mediante la fórmula
\[\mbox{GCV} (\lambda) = \frac{\mbox{RSS}}{(1-M(\lambda)/n)^2}\]
donde \(M(\lambda)\) es el número de parámetros \emph{efectivos} del modelo, que depende del número de términos más el número de puntos de corte utilizados penalizado por un factor (2 en el caso aditivo que estamos explicando, 3 cuando hay interacciones).

Hemos explicado una caso particular de MARS: el modelo aditivo. El modelo general sólo se diferencia del caso aditivo en que se permiten interacciones, es decir, multiplicaciones entre las variables \(h_m(\mathbf{x})\).
Para ello, en cada iteración durante la fase de construcción del modelo, además de considerar todos los puntos de corte, también se consideran todas las combinaciones con los términos incorporados previamente al modelo, denominados términos padre.
De este modo, si resulta seleccionado un término padre \(h_l(\mathbf{x})\) (incluyendo \(h_0(\mathbf{x}) = 1\)) y un punto de corte \(x_{ji}\), después de analizar todas las posibilidades, al modelo anterior se le agrega
\[\hat \beta_{m+1} h_l(\mathbf{x}) h(x_j - x_{ji}) + \hat \beta_{m+2} h_l(\mathbf{x}) h(x_{ji} - x_j)\]
Recordando que en cada caso se vuelven a estimar todos los parámetros \(\beta_i\).

Al igual que \(\lambda\), también el grado de interacción máxima permitida se considera un hiperparámetro del problema, aunque lo habitual es trabajar con grado 1 (modelo aditivo) o interacción de grado 2. Una restricción adicional que se impone al modelo es que en cada producto no puede aparecer más de una vez la misma variable \(X_j\).

Aunque el procedimiento de construcción del modelo realiza búsquedas exhaustivas y en consecuencia puede parecer computacionalmente intratable, en la práctica se realiza de forma razonablemente rápida, al igual que ocurría en CART.
Una de las principales ventajas de MARS es que realiza una selección automática de las variables predictoras.
Aunque inicialmente pueda haber muchos predictores, y este método es adecuado para problemas de alta dimensión, en el modelo final van a aparecer muchos menos (pueden aparecer más de una vez).
Además, si se utiliza un modelo aditivo su interpretación es directa, e incluso permitiendo interacciones de grado 2 el modelo puede ser interpretado.
Otra ventaja es que no es necesario realizar un prepocesado de los datos, ni filtrando variables ni transformando los datos.
Que haya predictores con correlaciones altas no va a afectar a la construcción del modelo (normalmente seleccionará el primero), aunque sí puede dificultar su interpretación.
Aunque hemos supuesto al principio de la explicación que los predictores son numéricos, se pueden incorporar variables predictoras cualitativas siguiendo los procedimientos estándar.
Por último, se puede realizar una cuantificación de la importancia de las variables de forma similar a como se hace en CART.

En conclusión, MARS utiliza splines lineales con una selección automática de los puntos de corte mediante un algoritmo avaricioso similar al empleado en los árboles CART, tratando de añadir más puntos de corte donde aparentemente hay más variaciones en la función de regresión y menos puntos donde esta es más estable.

\hypertarget{mars-con-el-paquete-earth}{%
\subsection{\texorpdfstring{MARS con el paquete \texttt{earth}}{MARS con el paquete earth}}\label{mars-con-el-paquete-earth}}

Actualmente el paquete de referencia para MARS es \href{http://www.milbo.users.sonic.net/earth}{\texttt{earth}} (\emph{Enhanced Adaptive Regression Through Hinges})\footnote{Desarrollado a partir de la función \texttt{mda::mars()} de T. Hastie y R. Tibshirani. Utiliza este nombre porque MARS está registrado para un uso comercial por \href{https://www.salford-systems.com}{Salford Systems}.}.

La función principal es \texttt{earth()} y se suelen considerar los siguientes argumentos:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{earth}\NormalTok{(formula, data, }\AttributeTok{glm =} \ConstantTok{NULL}\NormalTok{, }\AttributeTok{degree =} \DecValTok{1}\NormalTok{, ...) }
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\item
  \texttt{formula} y \texttt{data} (opcional): permiten especificar la respuesta y las variables predictoras de la forma habitual (e.g.~\texttt{respuesta\ \textasciitilde{}\ .}; también admite matrices). Admite respuestas multidimensionales (ajustará un modelo para cada componente) y categóricas (las convierte en multivariantes), también predictores categóricos, aunque no permite datos faltantes.
\item
  \texttt{glm}: lista con los parámetros del ajuste GLM (e.g.~\texttt{glm\ =\ list(family\ =\ binomial)}).
\item
  \texttt{degree}: grado máximo de interacción; por defecto 1 (modelo aditivo).
\end{itemize}

Otros parámetros que pueden ser de interés (afectan a la complejidad del modelo en el crecimiento, a la selección del modelo final o al tiempo de computación; para más detalles ver \texttt{help(earth)}):

\begin{itemize}
\item
  \texttt{nk}: número máximo de términos en el crecimiento del modelo (dimensión \(M\) de la base); por defecto \texttt{min(200,\ max(20,\ 2\ *\ ncol(x)))\ +\ 1} (puede ser demasiado pequeña si muchos de los predictores influyen en la respuesta).
\item
  \texttt{thresh}: umbral de parada en el crecimiento (se interpretaría como \texttt{cp} en los árboles CART); por defecto 0.001 (si se establece a 0 la única condición de parada será alcanzar el valor máximo de términos \texttt{nk}).
\item
  \texttt{fast.k}: número máximo de términos padre considerados en cada paso durante el crecimiento; por defecto 20, si se establece a 0 no habrá limitación.
\item
  \texttt{linpreds}: índice de variables que se considerarán con efecto lineal.
\item
  \texttt{nprune}: número máximo de términos (incluida la intersección) en el modelo final (después de la poda); por defecto no hay límite (se podrían incluir todos los creados durante el crecimiento).
\item
  \texttt{pmethod}: método empleado para la poda; por defecto \texttt{"backward"}. Otras opciones son: \texttt{"forward"}, \texttt{"seqrep"}, \texttt{"exhaustive"} (emplea los métodos de selección implementados en paquete \texttt{leaps}), \texttt{"cv"} (validación cruzada, empleando \texttt{nflod}) y \texttt{"none"} para no realizar poda.
\item
  \texttt{nfold}: número de grupos de validación cruzada; por defecto 0 (no se hace validación cruzada).
\item
  \texttt{varmod.method}: permite seleccionar un método para estimar las varianzas y por ejemplo poder realizar contrastes o construir intervalos de confianza (para más detalles ver \texttt{?varmod} o la vignette ``Variance models in earth'').
\end{itemize}

Utilizaremos como ejemplo inicial los datos de \texttt{MASS:mcycle}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# data(mcycle, package = "MASS")}
\FunctionTok{library}\NormalTok{(earth)}
\NormalTok{mars }\OtherTok{\textless{}{-}} \FunctionTok{earth}\NormalTok{(accel }\SpecialCharTok{\textasciitilde{}}\NormalTok{ times, }\AttributeTok{data =}\NormalTok{ mcycle)}
\CommentTok{\# mars}
\FunctionTok{summary}\NormalTok{(mars)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call: earth(formula=accel~times, data=mcycle)
## 
##               coefficients
## (Intercept)     -90.992956
## h(19.4-times)     8.072585
## h(times-19.4)     9.249999
## h(times-31.2)   -10.236495
## 
## Selected 4 of 6 terms, and 1 of 1 predictors
## Termination condition: RSq changed by less than 0.001 at 6 terms
## Importance: times
## Number of terms at each degree of interaction: 1 3 (additive model)
## GCV 1119.813    RSS 133670.3    GRSq 0.5240328    RSq 0.5663192
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(mars)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-27-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(accel }\SpecialCharTok{\textasciitilde{}}\NormalTok{ times, }\AttributeTok{data =}\NormalTok{ mcycle, }\AttributeTok{col =} \StringTok{\textquotesingle{}darkgray\textquotesingle{}}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(mcycle}\SpecialCharTok{$}\NormalTok{times, }\FunctionTok{predict}\NormalTok{(mars))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-27-2} \end{center}

Como con las opciones por defecto el ajuste no es muy bueno (aunque podría ser suficiente), podríamos forzar la complejidad del modelo en el crecimiento (\texttt{minspan\ =\ 1} permite que todas las observaciones sean potenciales nodos):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mars2 }\OtherTok{\textless{}{-}} \FunctionTok{earth}\NormalTok{(accel }\SpecialCharTok{\textasciitilde{}}\NormalTok{ times, }\AttributeTok{data =}\NormalTok{ mcycle, }\AttributeTok{minspan =} \DecValTok{1}\NormalTok{, }\AttributeTok{thresh =} \DecValTok{0}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(mars2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call: earth(formula=accel~times, data=mcycle, minspan=1, thresh=0)
## 
##               coefficients
## (Intercept)      -6.274366
## h(times-14.6)   -25.333056
## h(times-19.2)    32.979264
## h(times-25.4)   153.699248
## h(times-25.6)  -145.747392
## h(times-32)     -30.041076
## h(times-35.2)    13.723887
## 
## Selected 7 of 12 terms, and 1 of 1 predictors
## Termination condition: Reached nk 21
## Importance: times
## Number of terms at each degree of interaction: 1 6 (additive model)
## GCV 623.5209    RSS 67509.03    GRSq 0.7349776    RSq 0.7809732
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(accel }\SpecialCharTok{\textasciitilde{}}\NormalTok{ times, }\AttributeTok{data =}\NormalTok{ mcycle, }\AttributeTok{col =} \StringTok{\textquotesingle{}darkgray\textquotesingle{}}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(mcycle}\SpecialCharTok{$}\NormalTok{times, }\FunctionTok{predict}\NormalTok{(mars2))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-28-1} \end{center}

Como siguiente ejemplo consideramos los datos de \texttt{carData::Prestige}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# data(Prestige, package = "carData")}
\NormalTok{mars }\OtherTok{\textless{}{-}} \FunctionTok{earth}\NormalTok{(prestige }\SpecialCharTok{\textasciitilde{}}\NormalTok{ education }\SpecialCharTok{+}\NormalTok{ income }\SpecialCharTok{+}\NormalTok{ women, }\AttributeTok{data =}\NormalTok{ Prestige,}
              \AttributeTok{degree =} \DecValTok{2}\NormalTok{, }\AttributeTok{nk =} \DecValTok{40}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(mars)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call: earth(formula=prestige~education+income+women, data=Prestige, degree=2,
##             nk=40)
## 
##                                coefficients
## (Intercept)                      19.9845240
## h(education-9.93)                 5.7683265
## h(income-3161)                    0.0085297
## h(income-5795)                   -0.0080222
## h(women-33.57)                    0.2154367
## h(income-5299) * h(women-4.14)   -0.0005163
## h(income-5795) * h(women-4.28)    0.0005409
## 
## Selected 7 of 31 terms, and 3 of 3 predictors
## Termination condition: Reached nk 40
## Importance: education, income, women
## Number of terms at each degree of interaction: 1 4 2
## GCV 53.08737    RSS 3849.355    GRSq 0.8224057    RSq 0.8712393
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(mars)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-29-1} \end{center}

Para representar los efectos de las variables importa las herramientas del paquete \texttt{plotmo} (del mismo autor; válido también para la mayoría de los modelos tratados en este libro, incluyendo \texttt{mgcv::gam()}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotmo}\NormalTok{(mars)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  plotmo grid:    education income women
##                      10.54   5930  13.6
\end{verbatim}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-30-1} \end{center}

Podríamos obtener la importancia de las variables:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{varimp }\OtherTok{\textless{}{-}} \FunctionTok{evimp}\NormalTok{(mars)}
\NormalTok{varimp}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           nsubsets   gcv    rss
## education        6 100.0  100.0
## income           5  36.0   40.3
## women            3  16.3   22.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(varimp)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-31-1} \end{center}

Siempre podríamos considerar este modelo de partida para seleccionar componentes de un modelo GAM más flexible:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# library(mgcv)}
\NormalTok{gam }\OtherTok{\textless{}{-}} \FunctionTok{gam}\NormalTok{(prestige }\SpecialCharTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(education) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(income) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(women), }\AttributeTok{data =}\NormalTok{ Prestige, }\AttributeTok{select =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(gam)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## prestige ~ s(education) + s(income) + s(women)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  46.8333     0.6461   72.49   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Approximate significance of smooth terms:
##                edf Ref.df     F p-value    
## s(education) 2.349      9 9.926 < 2e-16 ***
## s(income)    6.289      9 7.420 < 2e-16 ***
## s(women)     1.964      9 1.309 0.00149 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## R-sq.(adj) =  0.856   Deviance explained = 87.1%
## GCV = 48.046  Scale est. = 42.58     n = 102
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gam2 }\OtherTok{\textless{}{-}} \FunctionTok{gam}\NormalTok{(prestige }\SpecialCharTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(education) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(income, women), }\AttributeTok{data =}\NormalTok{ Prestige)}
\FunctionTok{summary}\NormalTok{(gam2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## prestige ~ s(education) + s(income, women)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   46.833      0.679   68.97   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Approximate significance of smooth terms:
##                   edf Ref.df     F p-value    
## s(education)    2.802  3.489 25.09  <2e-16 ***
## s(income,women) 4.895  6.286 10.03  <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## R-sq.(adj) =  0.841   Deviance explained = 85.3%
## GCV = 51.416  Scale est. = 47.032    n = 102
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(gam, gam2, }\AttributeTok{test =} \StringTok{"F"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Deviance Table
## 
## Model 1: prestige ~ s(education) + s(income) + s(women)
## Model 2: prestige ~ s(education) + s(income, women)
##   Resid. Df Resid. Dev      Df Deviance      F  Pr(>F)   
## 1    88.325     3849.1                                   
## 2    91.225     4388.3 -2.9001  -539.16 4.3661 0.00705 **
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotmo}\NormalTok{(gam2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  plotmo grid:    education income women
##                      10.54   5930  13.6
\end{verbatim}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-32-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(gam2, }\AttributeTok{scheme =} \DecValTok{2}\NormalTok{, }\AttributeTok{select =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-32-2} \end{center}

Pregunta: ¿Observas algo extraño en el contraste ANOVA anterior?

\hypertarget{mars-con-el-paquete-caret}{%
\subsection{\texorpdfstring{MARS con el paquete \texttt{caret}}{MARS con el paquete caret}}\label{mars-con-el-paquete-caret}}

Emplearemos como ejemplo el conjunto de datos \texttt{earth::Ozone1}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# data(ozone1, package = "earth")}
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ ozone1  }
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{nobs }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(df)}
\NormalTok{itrain }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(nobs, }\FloatTok{0.8} \SpecialCharTok{*}\NormalTok{ nobs)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ df[itrain, ]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ df[}\SpecialCharTok{{-}}\NormalTok{itrain, ]}
\end{Highlighting}
\end{Shaded}

\texttt{caret} implementa varios métodos basados en \texttt{earth}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}
\CommentTok{\# names(getModelInfo("[Ee]arth")) \# 4 métodos}
\FunctionTok{modelLookup}\NormalTok{(}\StringTok{"earth"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   model parameter          label forReg forClass probModel
## 1 earth    nprune         #Terms   TRUE     TRUE      TRUE
## 2 earth    degree Product Degree   TRUE     TRUE      TRUE
\end{verbatim}

Consideramos una rejilla de búsqueda personalizada:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tuneGrid }\OtherTok{\textless{}{-}} \FunctionTok{expand.grid}\NormalTok{(}\AttributeTok{degree =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{, }
                       \AttributeTok{nprune =} \FunctionTok{floor}\NormalTok{(}\FunctionTok{seq}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{20}\NormalTok{, }\AttributeTok{len =} \DecValTok{10}\NormalTok{)))}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{caret.mars }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(O3 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{method =} \StringTok{"earth"}\NormalTok{,}
    \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{number =} \DecValTok{10}\NormalTok{),}
    \AttributeTok{tuneGrid =}\NormalTok{ tuneGrid)}
\NormalTok{caret.mars}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Multivariate Adaptive Regression Spline 
## 
## 264 samples
##   9 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 238, 238, 238, 236, 237, 239, ... 
## Resampling results across tuning parameters:
## 
##   degree  nprune  RMSE      Rsquared   MAE     
##   1        2      4.842924  0.6366661  3.803870
##   1        4      4.558953  0.6834467  3.488040
##   1        6      4.345781  0.7142046  3.413213
##   1        8      4.256592  0.7295113  3.220256
##   1       10      4.158604  0.7436812  3.181941
##   1       12      4.128416  0.7509562  3.142176
##   1       14      4.069714  0.7600561  3.061458
##   1       16      4.058769  0.7609245  3.058843
##   1       18      4.058769  0.7609245  3.058843
##   1       20      4.058769  0.7609245  3.058843
##   2        2      4.842924  0.6366661  3.803870
##   2        4      4.652783  0.6725979  3.540031
##   2        6      4.462122  0.7039134  3.394627
##   2        8      4.188539  0.7358147  3.209399
##   2       10      3.953353  0.7658754  2.988747
##   2       12      4.028546  0.7587781  3.040408
##   2       14      4.084860  0.7514781  3.076990
##   2       16      4.091340  0.7510666  3.081559
##   2       18      4.091340  0.7510666  3.081559
##   2       20      4.091340  0.7510666  3.081559
## 
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were nprune = 10 and degree = 2.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(caret.mars, }\AttributeTok{highlight =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-35-1} \end{center}

Podemos analizar el modelo final con las herramientas de \texttt{earth}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(caret.mars}\SpecialCharTok{$}\NormalTok{finalModel)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call: earth(x=matrix[264,9], y=c(4,13,16,3,6,2...), keepxy=TRUE, degree=2,
##             nprune=10)
## 
##                             coefficients
## (Intercept)                   11.6481994
## h(dpg-15)                     -0.0743900
## h(ibt-110)                     0.1224848
## h(17-vis)                     -0.3363332
## h(vis-17)                     -0.0110360
## h(101-doy)                    -0.1041604
## h(doy-101)                    -0.0236813
## h(wind-3) * h(1046-ibh)       -0.0023406
## h(humidity-52) * h(15-dpg)    -0.0047940
## h(60-humidity) * h(ibt-110)   -0.0027632
## 
## Selected 10 of 21 terms, and 7 of 9 predictors (nprune=10)
## Termination condition: Reached nk 21
## Importance: humidity, ibt, dpg, doy, wind, ibh, vis, temp-unused, ...
## Number of terms at each degree of interaction: 1 6 3
## GCV 13.84161    RSS 3032.585    GRSq 0.7846289    RSq 0.8199031
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plotmo(caret.mars$finalModel, caption = \textquotesingle{}ozone$O3 (caret "earth" method)\textquotesingle{})}
\FunctionTok{plotmo}\NormalTok{(caret.mars}\SpecialCharTok{$}\NormalTok{finalModel, }\AttributeTok{degree2 =} \DecValTok{0}\NormalTok{, }\AttributeTok{caption =} \StringTok{\textquotesingle{}ozone$O3 (efectos principales)\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  plotmo grid:    vh wind humidity temp    ibh dpg   ibt vis   doy
##                5770    5     64.5   62 2046.5  24 169.5 100 213.5
\end{verbatim}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-36-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotmo}\NormalTok{(caret.mars}\SpecialCharTok{$}\NormalTok{finalModel, }\AttributeTok{degree1 =} \DecValTok{0}\NormalTok{, }\AttributeTok{caption =} \StringTok{\textquotesingle{}ozone$O3 (interacciones)\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-36-2} \end{center}

Finalmente medimos la precisión con el procedimiento habitual:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(caret.mars, }\AttributeTok{newdata =}\NormalTok{ test)}
\FunctionTok{accuracy}\NormalTok{(pred, test}\SpecialCharTok{$}\NormalTok{O3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          me        rmse         mae         mpe        mape   r.squared 
##   0.4817913   4.0952444   3.0764376 -14.1288949  41.2602037   0.7408061
\end{verbatim}

\hypertarget{projection-pursuit}{%
\section{Projection pursuit}\label{projection-pursuit}}

\emph{Projection pursuit} (\protect\hyperlink{ref-friedman1974projection}{Friedman y Tukey, 1974}) es una técnica de análisis exploratorio de datos multivariantes que busca proyecciones lineales de los datos en espacios de dimensión baja, siguiendo una idea originalmente propuesta en (\protect\hyperlink{ref-kruskal1969toward}{Kruskal, 1969}).
Inicialmente se presentó como una técnica gráfica y por ese motivo buscaba proyecciones de dimensión 1 o 2 (proyecciones en rectas o planos), resultando que las direcciones interesantes son aquellas con distribución no normal.
La motivación es que cuando se realizan transformaciones lineales lo habitual es que el resultado tenga la apariencia de una distribución normal (por el teorema central del límite), lo cual oculta las singularidades de los datos originales.
Se supone que los datos son una trasformación lineal de componentes no gaussianas (variables latentes) y la idea es deshacer esta transformación mediante la optimización de una función objetivo, que en este contexto recibe el nombre de \emph{projection index}.
Aunque con orígenes distintos, \emph{projection pursuit} es muy similar a \emph{independent component analysis} (Comon, 1994), una técnica de reducción de la dimensión que, en lugar de buscar como es habitual componentes incorreladas (ortogonales), busca componentes independientes y con distribución no normal (ver por ejemplo la documentación del paquete \href{https://CRAN.R-project.org/package=fastICA}{\texttt{fastICA}}).

Hay extensiones de \emph{projection pursuit} para regresión, clasificación, estimación de la función de densidad, etc.

\hypertarget{ppr}{%
\subsection{\texorpdfstring{Regresión por \emph{projection pursuit}}{Regresión por projection pursuit}}\label{ppr}}

En el método original de \emph{projection pursuit regression} {[}PPR; \protect\hyperlink{ref-friedman1981projection}{Friedman y Stuetzle} (\protect\hyperlink{ref-friedman1981projection}{1981}){]} se considera el siguiente modelo semiparamétrico
\[m(\mathbf{x}) = \sum_{m=1}^M g_m (\alpha_{1m}x_1 + \alpha_{2m}x_2 + \ldots + \alpha_{pm}x_p)\]
siendo \(\boldsymbol{\alpha}_m = (\alpha_{1m}, \alpha_{2m}, \ldots, \alpha_{pm})\) vectores de parámetros (desconocidos) de módulo unitario y \(g_m\) funciones suaves (desconocidas), denominadas funciones \emph{ridge}.

Con esta aproximación se obtiene un modelo muy general que evita los problemas de la maldición de la dimensionalidad.
De hecho se trata de un \emph{aproximador universal}, con \(M\) suficientemente grande y eligiendo adecuadamente las componentes se podría aproximar cualquier función continua.
Sin embargo el modelo resultante puede ser muy difícil de interpretar, salvo el caso de \(M=1\) que se corresponde con el denominado \emph{single index model} empleado habitualmente en Econometría, pero que solo es algo más general que el modelo de regresión lineal múltiple.

El ajuste se este tipo de modelos es en principio un problema muy complejo.
Hay que estimar las funciones univariantes \(g_m\) (utilizando un método de suavizado) y los parámetros \(\alpha_{im}\), utilizando como criterio de error \(\mbox{RSS}\).
En la práctica se resuelve utilizando un proceso iterativo en el que se van fijando sucesivamente los valores de los parámetros y las funciones \emph{ridge} (si son estimadas empleando un método que también proporcione estimaciones de su derivada, las actualizaciones de los parámetros se pueden obtener por mínimos cuadrados ponderados).

También se han desarrollado extensiones del método original para el caso de respuesta multivariante:
\[m_i(\mathbf{x}) = \beta_{i0} + \sum_{m=1}^M \beta_{im} g_m (\alpha_{1m}x_1 + \alpha_{2m}x_2 + \ldots + \alpha_{pm}x_p)\]
reescalando las funciones \emph{rigde} de forma que tengan media cero y varianza unidad sobre las proyecciones de las observaciones.

Este procedimiento de regresión está muy relacionado con las redes de neuronas artificiales que se tratarán en el siguiente capítulo y que han sido de mayor objeto de estudio y desarrollo en los último años.

\hypertarget{implementaciuxf3n-en-r-1}{%
\subsection{Implementación en R}\label{implementaciuxf3n-en-r-1}}

El método PPR (con respuesta multivariante) está implementado en la función \texttt{ppr()} del paquete base de R\footnote{Basada en la función \texttt{ppreg()} de S-PLUS e implementado en R por B.D. Ripley inicialmente para el paquete \texttt{MASS}.}, y es empleada por el método \texttt{"ppr"} de \texttt{caret}.
Esta función:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ppr}\NormalTok{(formula, data, nterms, }\AttributeTok{max.terms =}\NormalTok{ nterms, }\AttributeTok{optlevel =} \DecValTok{2}\NormalTok{,}
    \AttributeTok{sm.method =} \FunctionTok{c}\NormalTok{(}\StringTok{"supsmu"}\NormalTok{, }\StringTok{"spline"}\NormalTok{, }\StringTok{"gcvspline"}\NormalTok{),}
    \AttributeTok{bass =} \DecValTok{0}\NormalTok{, }\AttributeTok{span =} \DecValTok{0}\NormalTok{, }\AttributeTok{df =} \DecValTok{5}\NormalTok{, }\AttributeTok{gcvpen =} \DecValTok{1}\NormalTok{, ...)}
\end{Highlighting}
\end{Shaded}

va añadiendo términos \emph{ridge} hasta un máximo de \texttt{max.terms} y posteriormente emplea un método hacia atrás para seleccionar \texttt{nterms} (el argumento \texttt{optlevel} controla como se vuelven a reajustar los términos en cada iteración).
Por defecto emplea el \emph{super suavizador} de Friedman (función \texttt{supsmu()}, con parámetros \texttt{bass} y \texttt{spam}), aunque también admite splines (función \texttt{smooth.spline()}, fijando los grados de libertad con \texttt{df} o seleccionándolos mediante GCV).
Para más detalles ver \texttt{help(ppr)}.

Continuaremos con el ejemplo del conjunto de datos \texttt{earth::Ozone1}. En primer lugar ajustamos un modelo PPR con dos términos (incrementando el suavizado por defecto de \texttt{supsmu()} siguiendo la recomendación de \protect\hyperlink{ref-Venables2002Modern}{Venables y Ripley, 2002}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ppreg }\OtherTok{\textless{}{-}} \FunctionTok{ppr}\NormalTok{(O3 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{nterms =} \DecValTok{2}\NormalTok{, }\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{bass =} \DecValTok{2}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(ppreg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call:
## ppr(formula = O3 ~ ., data = train, nterms = 2, bass = 2)
## 
## Goodness of fit:
##  2 terms 
## 4033.668 
## 
## Projection direction vectors ('alpha'):
##          term 1       term 2      
## vh       -0.016617786  0.047417127
## wind     -0.317867945 -0.544266150
## humidity  0.238454606 -0.786483702
## temp      0.892051760 -0.012563393
## ibh      -0.001707214 -0.001794245
## dpg       0.033476907  0.285956216
## ibt       0.205536326  0.026984921
## vis      -0.026255153 -0.014173612
## doy      -0.044819013 -0.010405236
## 
## Coefficients of ridge terms ('beta'):
##   term 1   term 2 
## 6.790447 1.531222
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{oldpar }\OtherTok{\textless{}{-}} \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(ppreg)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-39-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(oldpar)}
\end{Highlighting}
\end{Shaded}

Evaluamos las predicciones en la muestra de test:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(ppreg, }\AttributeTok{newdata =}\NormalTok{ test)}
\NormalTok{obs }\OtherTok{\textless{}{-}}\NormalTok{ test}\SpecialCharTok{$}\NormalTok{O3}
\FunctionTok{plot}\NormalTok{(pred, obs, }\AttributeTok{main =} \StringTok{"Observado frente a predicciones"}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{"Predicción"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Observado"}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{a =} \DecValTok{0}\NormalTok{, }\AttributeTok{b =} \DecValTok{1}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\FunctionTok{lm}\NormalTok{(obs }\SpecialCharTok{\textasciitilde{}}\NormalTok{ pred), }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-40-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{accuracy}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         me       rmse        mae        mpe       mape  r.squared 
##  0.4819794  3.2330060  2.5941476 -6.1203121 34.8728543  0.8384607
\end{verbatim}

Empleando el método \texttt{"ppr"} de \texttt{caret} para seleccionar el número de términos:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}
\FunctionTok{modelLookup}\NormalTok{(}\StringTok{"ppr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   model parameter   label forReg forClass probModel
## 1   ppr    nterms # Terms   TRUE    FALSE     FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{caret.ppr }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(O3 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{method =} \StringTok{"ppr"}\NormalTok{, }\CommentTok{\# bass = 2,}
    \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{number =} \DecValTok{10}\NormalTok{))}
\NormalTok{caret.ppr}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Projection Pursuit Regression 
## 
## 264 samples
##   9 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 238, 238, 238, 236, 237, 239, ... 
## Resampling results across tuning parameters:
## 
##   nterms  RMSE      Rsquared   MAE     
##   1       4.366022  0.7069042  3.306658
##   2       4.479282  0.6914678  3.454853
##   3       4.624943  0.6644089  3.568929
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was nterms = 1.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(caret.ppr, }\AttributeTok{highlight =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-41-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(caret.ppr}\SpecialCharTok{$}\NormalTok{finalModel)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call:
## ppr(x = as.matrix(x), y = y, nterms = param$nterms)
## 
## Goodness of fit:
##  1 terms 
## 4436.727 
## 
## Projection direction vectors ('alpha'):
##           vh         wind     humidity         temp          ibh          dpg 
## -0.016091543 -0.167891347  0.351773894  0.907301452 -0.001828865  0.026901492 
##          ibt          vis          doy 
##  0.148021198 -0.026470384 -0.035703896 
## 
## Coefficients of ridge terms ('beta'):
##   term 1 
## 6.853971
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(caret.ppr}\SpecialCharTok{$}\NormalTok{finalModel)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-41-2} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# varImp(caret.ppr) \# emplea una medida genérica de importancia}
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(caret.ppr, }\AttributeTok{newdata =}\NormalTok{ test)}
\FunctionTok{accuracy}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          me        rmse         mae         mpe        mape   r.squared 
##   0.3135877   3.3652891   2.7061615 -10.7532705  33.8333646   0.8249710
\end{verbatim}

Para ajustar un modelo \emph{single index} también se podría emplear la función \texttt{npindex()} del paquete \href{https://github.com/JeffreyRacine/R-Package-np}{\texttt{np}} (que implementa el método de \protect\hyperlink{ref-ichimura1993}{Ichimura, 1993}, considerando un estimador local constante), aunque en este caso ni el tiempo de computación ni el resultado es satisfactorio:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(np)}
\CommentTok{\# bw \textless{}{-} npindexbw(O3 \textasciitilde{} ., data = train)}
\CommentTok{\# Error in terms.formula(formula): \textquotesingle{}.\textquotesingle{} in formula and no \textquotesingle{}data\textquotesingle{} argument}
\CommentTok{\# formula \textless{}{-} reformulate(setdiff(colnames(train), "O3"), response="O3")}

\NormalTok{bw }\OtherTok{\textless{}{-}} \FunctionTok{npindexbw}\NormalTok{(O3 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ vh }\SpecialCharTok{+}\NormalTok{ wind }\SpecialCharTok{+}\NormalTok{ humidity }\SpecialCharTok{+}\NormalTok{ temp }\SpecialCharTok{+}\NormalTok{ ibh }\SpecialCharTok{+}\NormalTok{ dpg }\SpecialCharTok{+}\NormalTok{ ibt }\SpecialCharTok{+}\NormalTok{ vis }\SpecialCharTok{+}\NormalTok{ doy,}
                \AttributeTok{data =}\NormalTok{ train, }\AttributeTok{optim.method =} \StringTok{"BFGS"}\NormalTok{, }\AttributeTok{nmulti =} \DecValTok{1}\NormalTok{) }\CommentTok{\# Por defecto nmulti = 5}
\CommentTok{\# Nota: por defecto imprime caracteres inválidos para compilar en LaTeX}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(bw)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Single Index Model
## Regression data (264 observations, 9 variable(s)):
## 
##       vh     wind humidity     temp       ibh      dpg      ibt        vis
## Beta:  1 4.338446 6.146688 10.44244 0.0926648 3.464211 5.017786 -0.5646063
##             doy
## Beta: -1.048745
## Bandwidth:  16.54751
## Optimisation Method:  BFGS
## Regression Type: Local-Constant
## Bandwidth Selection Method: Ichimura
## Formula: O3 ~ vh + wind + humidity + temp + ibh + dpg + ibt + vis + doy
## Bandwidth Type: Fixed
## Objective Function Value: 18.87884 (achieved on multistart 1)
## 
## Continuous Kernel Type: Second-Order Gaussian
## No. Continuous Explanatory Vars.: 1
## Estimation Time: 6.76 seconds
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sindex }\OtherTok{\textless{}{-}} \FunctionTok{npindex}\NormalTok{(}\AttributeTok{bws =}\NormalTok{ bw, }\AttributeTok{gradients =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(sindex)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Single Index Model
## Regression Data: 264 training points, in 9 variable(s)
## 
##       vh     wind humidity     temp       ibh      dpg      ibt        vis
## Beta:  1 4.338446 6.146688 10.44244 0.0926648 3.464211 5.017786 -0.5646063
##             doy
## Beta: -1.048745
## Bandwidth: 16.54751
## Kernel Regression Estimator: Local-Constant
## 
## Residual standard error: 3.520037
## R-squared: 0.806475
## 
## Continuous Kernel Type: Second-Order Gaussian
## No. Continuous Explanatory Vars.: 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(bw)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{07-regresion_np_files/figure-latex/unnamed-chunk-43-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(sindex, }\AttributeTok{newdata =}\NormalTok{ test)}
\FunctionTok{accuracy}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          me        rmse         mae         mpe        mape   r.squared 
##   0.1712457   4.3725067   3.1789199 -10.2320531  35.2010284   0.7045213
\end{verbatim}

\hypertarget{neural-nets}{%
\chapter{Redes neuronales}\label{neural-nets}}

Las redes neuronales (\protect\hyperlink{ref-mcculloch1943logical}{McCulloch y Pitts, 1943}), también conocidas como redes de neuronas artificiales (\emph{artificial neural network}; ANN), son una metodología de aprendizaje supervisado que destaca porque da lugar a modelos con un número muy elevado de parámetros, adecuada para abordar problemas con estructuras subyacentes muy complejas, pero de muy difícil interpretación.
Con la aparición de los métodos SVM y boosting, ANN perdió popularidad, pero en los últimos años ha vuelto a ganarla, también gracias al aumento de las capacidades de computación.
El diseño y el entrenamiento de una ANN suele requerir de más tiempo y experimentación que otros algoritmos de AE/ML. Además el gran número de hiperparámetros lo convierte en un problema de optimización complicado.
En este capítulo se va a hacer una breve introducción a estos métodos, para poder emplearlos con solvencia en la práctica sería muy recomendable profundizar más en esta metodología (por ejemplo se podría consultar \protect\hyperlink{ref-chollet2018deep}{Chollet y Allaire, 2018}, para un tratamiento más detallado).

En los métodos de aprendizaje supervisado se realizan una o varias transformaciones del espacio de las variables predictoras buscando una representación \emph{óptima} de los datos, para así poder conseguir una buena predicción. Los modelos que realizan una o dos transformaciones reciben el nombre de modelos superficiales (\emph{shallow models}). Por el contrario, cuando se realizan muchas transformaciones se habla de aprendizaje profundo (\emph{deep learning}). No nos debemos dejar engañar por la publicidad: que un aprendizaje sea profundo no significa que sea mejor que el superficial. Aunque es verdad que ahora mismo la metodología que está de moda son las redes neuronales profundas (\emph{deep neural networks}), hay que ser muy consciente de que dependiendo del contexto será más conveniente un tipo de modelos u otro. Se trata de una metodología adecuada para problemas muy complejos y no tanto para problemas con pocas observaciones o pocos predictores. Hay que tener en cuenta que no existe ninguna metodología que sea \emph{transversalmente} la mejor {[}lo que se conoce como el teorema \emph{no free lunch}; \protect\hyperlink{ref-wolpert1997no}{Wolpert y Macready} (\protect\hyperlink{ref-wolpert1997no}{1997}){]}.

Una red neuronal básica va a realizar dos transformaciones de los datos, y por tanto es un modelo con tres capas: una capa de entrada (\emph{input layer}) consistente en las variables originales \(\mathbf{X} = (X_1,X_2,\ldots, X_p)\), otra capa oculta (\emph{hidden layer}) con \(M\) nodos, y la capa de salida (\emph{output layer}) con la predicción (o predicciones) final \(m(\mathbf{X})\).

\begin{center}\includegraphics[width=0.8\linewidth]{08-redes_neuronales_files/figure-latex/unnamed-chunk-2-1} \end{center}

Para que las redes neuronales tengan un rendimiento aceptable se requiere disponer de tamaños muestrales grandes, debido a que son modelos hiperparametrizados (y por tanto de difícil interpretación). Son modelos muy demandantes computacionalmente y solo desde fechas recientes es viable utilizarlos con un número elevado de capas (\emph{deep neural networks}).

Son modelos muy sensibles a las escala de los predictores y requieren un preprocesado en el que se homogeneicen sus escalas.

Una de las fortalezas de las redes neuronales es que sus modelos son muy robustos frente a predictores irrelevantes. Esto la convierte en una metodología muy interesante cuando se dispone de datos de dimensión muy alta. Otros métodos requieren un preprocesado muy costoso, pero las redes neuronales lo realizan de forma automática en las capas intermedias, que de forma sucesiva se van centrado en aspectos relevantes de los datos. Y una de sus debilidades es que conforme aumentan las capas se hace más difícil la interpretación del modelo, hasta convertirse en una auténtica caja negra.

Hay distintas formas de construir redes neuronales. La básica recibe el nombre de \emph{feedforward} (o también \emph{multilayer perceptron}). Otras formas, con sus campos de aplicación principales, son:

\begin{itemize}
\item
  \emph{Convolutional neural networks} para reconocimiento de imagen y vídeo.
\item
  \emph{Recurrent neural networks} para reconocimiento de voz.
\item
  \emph{Long short-term memory neural networks} para traducción automática.
\end{itemize}

\hypertarget{single-hidden-layer-feedforward-network}{%
\section{Single-hidden-layer feedforward network}\label{single-hidden-layer-feedforward-network}}

La red neuronal más simple es la \emph{single-hidden-layer feedforward network}, también conocida como \emph{single layer perceptron}. Se trata de una red \emph{feedforward} con una única capa oculta que consta de \(M\) variables ocultas \(h_m\) (los nodos que conforman la capa, también llamados unidades ocultas). Cada variable \(h_m\) es una combinación lineal de las variables predictoras, con parámetros \(\omega_{jm}\) (los parámetros \(\omega_{0m}\) reciben el nombre de parámetros \emph{sesgo})
\[\omega_{0m} + \omega_{1m} x_1 + \omega_{2m} x_2 + \ldots + \omega_{pm} x_p\]
transformada por una función no lineal, denominada \emph{función de activación}, típicamente la función logística (denominada función sigmoidal, \emph{sigmoid function}, en este contexto)
\[\phi(u) = \frac{1}{1 + e^{-u}} = \frac{e^u}{1 + e^u}\]
(la idea es que cada neurona ``aprende'' un resultado binario).
De este modo tenemos que
\[h_{m}(\mathbf{x}) = \phi\left( \omega_{0m} + \omega_{1m} x_1 + \omega_{2m} x_2 + \ldots + \omega_{pm} x_p \right)\]

El modelo final es una combinación lineal de las variables ocultas
\[m(\mathbf{x}) = \gamma_0 + \gamma_1 h_1 + \gamma_2 h_2 + \ldots + \gamma_M h_M\]
aunque también se puede considerar una función de activación en el nodo final para adaptar la predicción a distintos tipos de respuestas (en regresión sería normalmente la identidad) y distintas funciones de activación en los nodos intermedios (ver por ejemplo \href{https://en.wikipedia.org/wiki/Activation_function}{Wikipedia: Activation function} para un listado de distintas funciones de activación).

Por tanto, el modelo \(m\) es un modelo de regresión no lineal en dos etapas con \(M(p + 1) + M + 1\) parámetros (también llamados \emph{pesos}). Por ejemplo, con 200 variables predictoras y 10 variables ocultas, hay nada menos que 2021 parámetros. Como podemos comprobar, incluso con el modelo más sencillo y una cantidad moderada de variables predictoras y ocultas, el número de parámetros a estimar es muy grande. Por eso decimos que estos modelos están hiperparametrizados.

La estimación de los parámetros (el aprendizaje) se realiza minimizando una función de pérdidas, típicamente \(\mbox{RSS}\). La solución exacta de este problema de optimización suele ser imposible en la práctica (es un problema no convexo), por lo que se resuelve mediante un algoritmo heurístico de descenso de gradientes (que utiliza las derivadas de las funciones de activación), llamado en este contexto \emph{backpropagation} (\protect\hyperlink{ref-werbos1974new}{Werbos, 1974}), que va a converger a un óptimo local, pero difícilmente al óptimo global. Por este motivo, el modelo resultante va a ser muy sensible a la solución inicial, que generalmente se selecciona de forma aleatoria con valores próximos a cero (si se empezase dando a los parámetros valores nulos, el algoritmo no se movería). El algoritmo va cogiendo los datos de entrenamiento por lotes (de 32, 64\ldots) llamados \emph{batch}, y recibe el nombre de \emph{epoch} cada vez que el algoritmo completa el procesado de todos los datos; por tanto, el número de \emph{epochs} es el número de veces que el algoritmo procesa la totalidad de los datos.

Una forma de mitigar la inestabilidad de la estimación del modelo es generando muchos modelos (que se consiguen con soluciones iniciales diferentes) y promediando las predicciones; una alternativa es utilizar \emph{bagging}. El algoritmo depende de un parámetro en cada iteración, que representa el ratio de aprendizaje (\emph{learning rate}). Por razones matemáticas, se selecciona una sucesión que converja a cero.

Otro problema inherente a la heurística de tipo gradiente es que se ve afectada negativamente por la correlación entre las variables predictoras. Cuando hay correlaciones muy altas, es usual preprocesar los datos, o bien eliminando variables predictoras o bien utilizando PCA.

Naturalmente, al ser las redes neuronales unos modelos con tantos parámetros tienen una gran tendencia al sobreajuste. Una forma de mitigar este problema es implementar la misma idea que se utiliza en la regresión \emph{ridge} de penalizar los parámetros y que en este contexto recibe el nombre de reducción de los pesos (\emph{weight decay})
\[\mbox{min}_{\boldsymbol{\omega}, \boldsymbol{\gamma}}\ \mbox{RSS} + 
\lambda \left(\sum_{m=1}^m \sum_{j=0}^p \omega_{jm}^2 + \sum_{m=0}^M \gamma_m^2
\right)\]

En esta modelización del problema, hay dos hiperparámetros cuyos valores deben ser seleccionados: el parámetro regularizador \(\lambda\) (con frecuencia un número entre 0 y 0.1) y el número de nodos \(M\). Es frecuente seleccionar \(M\) a mano (un valor alto, entre 5 y 100) y \(\lambda\) por validación cruzada, confiando en que el proceso de regularización forzará a que muchos pesos (parámetros) sean próximos a cero. Además, al depender la penalización de una suma de pesos es imprescindible que sean comparables, es decir, hay que reescalar las variables predictoras antes de empezar a construir el modelo.

La extensión natural de este modelo es utilizar más de una capa de nodos (variables ocultas). En cada capa, los nodos están \emph{conectados} con los nodos de la capa precedente.

Observemos que el modelo \emph{single-hidden-layer feedforward network} tiene la misma forma que el de la \emph{projection pursuit regression} (Sección \ref{ppr}), sin más que considerar \(\alpha_m = \omega_m/\| \omega_m \|\), con \(\omega_m = (\omega_{1m}, \omega_{2m}, \ldots, \omega_{pm})\), y
\[g_m (\alpha_{1m}x_1 + \alpha_{2m}x_2 + \ldots + \alpha_{pm}x_p) = 
\gamma_m \phi(\omega_{0m} + \omega_{1m} x_1 + \omega_{2m} x_2 + \ldots + \omega_{pm} x_p)\]
Sin embargo, hay que destacar una diferencia muy importante: en una red neuronal, el analista fija la función \(\phi\) (lo más habitual es utilizar la función logística), mientras que las funciones \emph{ridge} \(g_m\) se consideran como funciones no paramétricas desconocidas que hay que estimar.

\hypertarget{clasificaciuxf3n-con-ann}{%
\section{Clasificación con ANN}\label{clasificaciuxf3n-con-ann}}

En un problema de clasificación con dos categorías, si se emplea una variable binaria para codificar la respuesta, bastará con considerar una función logística como función de activación en el nodo final (de esta forma se estará estimando la probabilidad de éxito).
En el caso general, en lugar de construir un único modelo \(m(\mathbf{x})\), se construyen tantos como categorías, aunque habrá que seleccionar una función de activación adecuada en los nodos finales.

Por ejemplo, en el caso de una \emph{single-hidden-layer feedforward network}, para cada categoría \(i\), se construye el modelo \(T_i\) como ya se explicó antes
\[T_i(\mathbf{x}) = \gamma_{0i} + \gamma_{1i} h_1 + \gamma_{2i} h_2 + \ldots + \gamma_{Mi} h_M \]
y a continuación se transforman los resultados de los \(k\) modelos para obtener estimaciones válidas de las probabilidades
\[m_i(\mathbf{x}) = \tilde{\phi}_i (T_1(\mathbf{x}), T_2(\mathbf{x}),\ldots, T_k(\mathbf{x})) \]
donde \(\tilde{\phi}_i\) es la función \emph{softmax}
\[\tilde{\phi}_i (u_1,u_2,\ldots,u_k) = \frac{e^{u_i}}{\sum_{j=1}^k e^{u_j}}\]

Como criterio de error se suele utilizar la \emph{entropía} aunque se podrían considerar otros.
Desde este punto de vista la regresión logística (multinomial) sería un caso particular.

\hypertarget{implementaciuxf3n-en-r-2}{%
\section{Implementación en R}\label{implementaciuxf3n-en-r-2}}

Hay numerosos paquetes que implementan métodos de este tipo, aunque por simplicidad consideraremos el paquete \texttt{nnet} que implementa redes neuronales \emph{feed fordward} con una única capa oculta y está incluido en el paquete base de R.
Para el caso de redes más complejas se puede utilizar por ejemplo el paquete \href{https://CRAN.R-project.org/package=neuralnet}{\texttt{neuralnet}}, pero en el caso de grandes volúmenes de datos o aprendizaje profundo la recomendación sería emplear paquetes computacionalmente más eficientes (con computación en paralelo empleando CPUs o GPUs) como \href{https://keras.rstudio.com}{\texttt{keras}}, \href{https://github.com/h2oai/h2o-3}{\texttt{h2o}} o \href{https://spark.rstudio.com/}{\texttt{sparlyr}}, entre otros.

La función principal \texttt{nnet()} se suele emplear con los siguientes argumentos:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{nnet}\NormalTok{(formula, data, size, Wts, }\AttributeTok{linout =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{skip =} \ConstantTok{FALSE}\NormalTok{, }
     \AttributeTok{rang =} \FloatTok{0.7}\NormalTok{, }\AttributeTok{decay =} \DecValTok{0}\NormalTok{, }\AttributeTok{maxit =} \DecValTok{100}\NormalTok{, ...)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\item
  \texttt{formula} y \texttt{data} (opcional): permiten especificar la respuesta y las variables predictoras de la forma habitual (e.g.~\texttt{respuesta\ \textasciitilde{}\ .}; también implementa una interfaz con matrices \texttt{x} e \texttt{y}). Admite respuestas multidimensionales (ajustará un modelo para cada componente) y categóricas (las convierte en multivariantes si tienen más de dos categorías y emplea \emph{softmax} en los nodos finales).
  Teniendo en cuenta que por defecto los pesos iniciales se asignan al azar (\texttt{Wts\ \textless{}-\ runif(nwts,\ -rang,\ rang)}) la recomendación sería reescalar los predictores en el intervalo \([0, 1]\), sobre todo si se emplea regularización (\texttt{decay\ \textgreater{}\ 0}).
\item
  \texttt{size}: número de nodos en la capa oculta.
\item
  \texttt{linout}: permite seleccionar la identidad como función de activación en los nodos finales; por defecto \texttt{FALSE} y empleará la función logística o \emph{softmax} en el caso de factores con múltiples niveles (si se emplea la interfaz de fórmula, con matrices habrá que establecer \texttt{softmax\ =\ TRUE}).
\item
  \texttt{skip}: permite añadir pesos adicionales entre la capa de entrada y la de salida (saltándose la capa oculta); por defecto \texttt{FALSE}.
\item
  \texttt{decay}: parámetro \(\lambda\) de regularización de los pesos (\emph{weight decay}); por defecto 0. Para emplear este parámetro los predictores deberían estar en la misma escala.
\item
  \texttt{maxit}: número máximo de iteraciones; por defecto 100.
\end{itemize}

Como ejemplo consideraremos el conjunto de datos \texttt{earth::Ozone1} empleado en el capítulo anterior:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(ozone1, }\AttributeTok{package =} \StringTok{"earth"}\NormalTok{)}
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ ozone1}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{nobs }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(df)}
\NormalTok{itrain }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(nobs, }\FloatTok{0.8} \SpecialCharTok{*}\NormalTok{ nobs)}
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ df[itrain, ]}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ df[}\SpecialCharTok{{-}}\NormalTok{itrain, ]}
\end{Highlighting}
\end{Shaded}

En este caso emplearemos el método \texttt{"nnet"} de \texttt{caret} para preprocesar los datos y seleccionar el número de nodos en la capa oculta y el parámetro de regularización.
Como emplea las opciones por defecto de \texttt{nnet()} (diseñadas para clasificación),
estableceremos \texttt{linout\ =\ TRUE} (la alternativa sería transformar la respuesta a rango 1) y aumentaremos el número de iteraciones (aunque seguramente sigue siendo demasiado pequeño).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}
\CommentTok{\# Buscar "Neural Network": 10 métodos}
\CommentTok{\# getModelInfo("nnet")}
\FunctionTok{modelLookup}\NormalTok{(}\StringTok{"nnet"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   model parameter         label forReg forClass probModel
## 1  nnet      size #Hidden Units   TRUE     TRUE      TRUE
## 2  nnet     decay  Weight Decay   TRUE     TRUE      TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tuneGrid }\OtherTok{\textless{}{-}} \FunctionTok{expand.grid}\NormalTok{(}\AttributeTok{size =} \DecValTok{2}\SpecialCharTok{*}\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{, }\AttributeTok{decay =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.001}\NormalTok{, }\FloatTok{0.01}\NormalTok{))}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{caret.nnet }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(O3 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{method =} \StringTok{"nnet"}\NormalTok{,}
             \AttributeTok{preProc =} \FunctionTok{c}\NormalTok{(}\StringTok{"range"}\NormalTok{), }\CommentTok{\# Reescalado en [0,1]}
             \AttributeTok{tuneGrid =}\NormalTok{ tuneGrid,}
             \AttributeTok{trControl =} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{number =} \DecValTok{10}\NormalTok{), }
             \AttributeTok{linout =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{maxit =} \DecValTok{200}\NormalTok{, }\AttributeTok{trace =} \ConstantTok{FALSE}\NormalTok{)}

\FunctionTok{ggplot}\NormalTok{(caret.nnet, }\AttributeTok{highlight =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{08-redes_neuronales_files/figure-latex/unnamed-chunk-5-1} \end{center}

Analizamos el modelo resultante:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(caret.nnet}\SpecialCharTok{$}\NormalTok{finalModel)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## a 9-4-1 network with 45 weights
## options were - linear output units  decay=0.01
##  b->h1 i1->h1 i2->h1 i3->h1 i4->h1 i5->h1 i6->h1 i7->h1 i8->h1 i9->h1 
##  -8.66   3.74  -5.50 -18.11 -12.83   6.49  14.39  -4.53  14.48  -1.96 
##  b->h2 i1->h2 i2->h2 i3->h2 i4->h2 i5->h2 i6->h2 i7->h2 i8->h2 i9->h2 
##  -2.98   1.78   0.00   1.58   1.96  -0.60   0.63   2.46   2.36 -19.69 
##  b->h3 i1->h3 i2->h3 i3->h3 i4->h3 i5->h3 i6->h3 i7->h3 i8->h3 i9->h3 
##  25.23 -50.14   9.74  -3.66  -5.61   4.21 -11.17  39.34 -20.18   0.37 
##  b->h4 i1->h4 i2->h4 i3->h4 i4->h4 i5->h4 i6->h4 i7->h4 i8->h4 i9->h4 
##  -3.90   4.94  -1.08   1.50   1.52  -0.54   0.14  -1.27   0.98  -1.54 
##   b->o  h1->o  h2->o  h3->o  h4->o 
##  -5.32   4.19 -14.03   7.50  38.75
\end{verbatim}

Podemos representarlo gráficamente empleando el paquete \texttt{NeuralNetTools}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(NeuralNetTools)}
\FunctionTok{plotnet}\NormalTok{(caret.nnet}\SpecialCharTok{$}\NormalTok{finalModel)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{08-redes_neuronales_files/figure-latex/unnamed-chunk-7-1} \end{center}

Por último evaluamos las predicciones en la muestra de test:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(caret.nnet, }\AttributeTok{newdata =}\NormalTok{ test)}
\NormalTok{obs }\OtherTok{\textless{}{-}}\NormalTok{ test}\SpecialCharTok{$}\NormalTok{O3}

\FunctionTok{plot}\NormalTok{(pred, obs, }\AttributeTok{main =} \StringTok{"Observado frente a predicciones"}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{"Predicción"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Observado"}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{a =} \DecValTok{0}\NormalTok{, }\AttributeTok{b =} \DecValTok{1}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\FunctionTok{lm}\NormalTok{(obs }\SpecialCharTok{\textasciitilde{}}\NormalTok{ pred), }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.8\linewidth]{08-redes_neuronales_files/figure-latex/unnamed-chunk-8-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{accuracy }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(pred, obs, }\AttributeTok{na.rm =} \ConstantTok{FALSE}\NormalTok{,}
                     \AttributeTok{tol =} \FunctionTok{sqrt}\NormalTok{(.Machine}\SpecialCharTok{$}\NormalTok{double.eps)) \{}
\NormalTok{  err }\OtherTok{\textless{}{-}}\NormalTok{ obs }\SpecialCharTok{{-}}\NormalTok{ pred     }\CommentTok{\# Errores}
  \ControlFlowTok{if}\NormalTok{(na.rm) \{}
\NormalTok{    is.a }\OtherTok{\textless{}{-}} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(err)}
\NormalTok{    err }\OtherTok{\textless{}{-}}\NormalTok{ err[is.a]}
\NormalTok{    obs }\OtherTok{\textless{}{-}}\NormalTok{ obs[is.a]}
\NormalTok{  \}}
\NormalTok{  perr }\OtherTok{\textless{}{-}} \DecValTok{100}\SpecialCharTok{*}\NormalTok{err}\SpecialCharTok{/}\FunctionTok{pmax}\NormalTok{(obs, tol)  }\CommentTok{\# Errores porcentuales}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
    \AttributeTok{me =} \FunctionTok{mean}\NormalTok{(err),           }\CommentTok{\# Error medio}
    \AttributeTok{rmse =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{(err}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)), }\CommentTok{\# Raíz del error cuadrático medio}
    \AttributeTok{mae =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(err)),     }\CommentTok{\# Error absoluto medio}
    \AttributeTok{mpe =} \FunctionTok{mean}\NormalTok{(perr),         }\CommentTok{\# Error porcentual medio}
    \AttributeTok{mape =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(perr)),   }\CommentTok{\# Error porcentual absoluto medio}
    \AttributeTok{r.squared =} \DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{sum}\NormalTok{(err}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{sum}\NormalTok{((obs }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(obs))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\CommentTok{\# Pseudo R{-}cuadrado}
\NormalTok{  ))}
\NormalTok{\}}

\FunctionTok{accuracy}\NormalTok{(pred, obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         me       rmse        mae        mpe       mape  r.squared 
##  0.3321276  3.0242169  2.4466958 -7.4095987 32.8000107  0.8586515
\end{verbatim}

\hypertarget{referencias}{%
\chapter*{Referencias}\label{referencias}}
\addcontentsline{toc}{chapter}{Referencias}

\textbf{Bibliografía básica}

James, G., Witten, D., Hastie, T. y Tibshirani, R. (2021). \emph{\href{https://www.statlearning.com}{An Introduction to Statistical Learning: with Aplications in R, Segunda Edición}}. Springer.

Kuhn, M. y Johnson, K. (2013). \emph{\href{http://appliedpredictivemodeling.com}{Applied predictive modeling}}. Springer.

Williams, G. (2011). \emph{Data Mining with Rattle and R}. Springer.

\hypertarget{bibliografuxeda-completa}{%
\section*{Bibliografía completa}\label{bibliografuxeda-completa}}
\addcontentsline{toc}{section}{Bibliografía completa}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\hypertarget{ref-agor2019feature}{}%
Agor, J., y Özaltın, O. Y. (2019). Feature selection for classification models via bilevel optimization. \emph{Computers and Operations Research}, \emph{106}, 156-168. \url{https://doi.org/10.1016/j.cor.2018.05.005}

\leavevmode\hypertarget{ref-becker2021mlr3}{}%
Becker, M., Binder, M., Bischl, B., Lang, M., Pfisterer, F., Reich, N. G., Richter, J., Schratz, P., Sonabend, R., y Pulatov, D. (2021). \emph{mlr3 book}. \url{https://mlr3book.mlr-org.com}

\leavevmode\hypertarget{ref-bellman1961adaptive}{}%
Bellman, R. (1961). \emph{Adaptive Control Processes: a guided tour}. Princeton University Press.

\leavevmode\hypertarget{ref-breiman1996bagging}{}%
Breiman, L. (1996). Bagging predictors. \emph{Machine Learning}, \emph{24}(2), 123-140. \url{https://doi.org/10.1007/bf00058655}

\leavevmode\hypertarget{ref-breiman2001random}{}%
Breiman, L. (2001a). Random forests. \emph{Machine Learning}, \emph{45}(1), 5-32.

\leavevmode\hypertarget{ref-breiman2001statistical}{}%
Breiman, L. (2001b). Statistical modeling: The two cultures (with comments and a rejoinder by the author). \emph{Statistical Science}, \emph{16}(3), 199-231. \url{https://doi.org/10.1214/ss/1009213726}

\leavevmode\hypertarget{ref-breiman1984classification}{}%
Breiman, L., Friedman, J. H., Stone, C. J., y Olshen, R. A. (1984). \emph{Classification and Regression Trees}. Taylor; Francis.

\leavevmode\hypertarget{ref-chen2016xgboost}{}%
Chen, T., y Guestrin, C. (2016). Xgboost: A scalable tree boosting system. \emph{Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining}, 785-794. \url{https://doi.org/10.1145/2939672.2939785}

\leavevmode\hypertarget{ref-chollet2018deep}{}%
Chollet, F., y Allaire, J. J. (2018). \emph{Deep Learning with R}. Manning Publications.

\leavevmode\hypertarget{ref-cortes1995support}{}%
Cortes, C., y Vapnik, V. (1995). Support-vector networks. \emph{Machine Learning}, \emph{20}(3), 273-297. \url{https://doi.org/10.1007/bf00994018}

\leavevmode\hypertarget{ref-cortez2009modeling}{}%
Cortez, P., Cerdeira, A., Almeida, F., Matos, T., y Reis, J. (2009). Modeling wine preferences by data mining from physicochemical properties. \emph{Decision Support Systems}, \emph{47}(4), 547-553. \url{https://doi.org/10.1016/j.dss.2009.05.016}

\leavevmode\hypertarget{ref-craven1978smoothing}{}%
Craven, P., y Wahba, G. (1978). Smoothing noisy data with spline functions. \emph{Numerische Mathematik}, \emph{31}(4), 377-403. \url{https://doi.org/10.1007/bf01404567}

\leavevmode\hypertarget{ref-culp2006ada}{}%
Culp, M., Johnson, K., y Michailidis, G. (2006). ada: An R Package for Stochastic Boosting. \emph{Journal of Statistical Software}, \emph{17}(2), 1-27. \url{https://doi.org/10.18637/jss.v017.i02}

\leavevmode\hypertarget{ref-de1978practical}{}%
De Boor, C., y De Boor, C. (1978). \emph{A practical guide to splines} (Vol. 27). springer-verlag New York. \url{https://doi.org/10.1007/978-1-4612-6333-3}

\leavevmode\hypertarget{ref-dietterich2000experimental}{}%
Dietterich, T. G. (2000). An experimental comparison of three methods for constructing ensembles of decision trees: Bagging, boosting, and randomization. \emph{Machine Learning}, \emph{40}(2), 139-157.

\leavevmode\hypertarget{ref-drucker1997support}{}%
Drucker, H., Burges, C. J., Kaufman, L., Smola, A., y Vapnik, V. (1997). Support Vector Regression Machines. \emph{Advances in Neural Information Processing Systems}, \emph{9}, 155-161.

\leavevmode\hypertarget{ref-dunson2018statistics}{}%
Dunson, D. B. (2018). Statistics in the big data era: Failures of the machine. \emph{Statistics and Probability Letters}, \emph{136}, 4-9. \url{https://doi.org/10.1016/j.spl.2018.02.028}

\leavevmode\hypertarget{ref-efron2004least}{}%
Efron, B., Hastie, T., Johnstone, I., y Tibshirani, R. (2004). Least angle regression. \emph{The Annals of Statistics}, \emph{32}(2), 407-499. \url{https://doi.org/10.1214/009053604000000067}

\leavevmode\hypertarget{ref-eilers1996flexible}{}%
Eilers, P. H., y Marx, B. D. (1996). Flexible smoothing with B-splines and penalties. \emph{Statistical Science}, \emph{11}(2), 89-121. \url{https://doi.org/10.1214/ss/1038425655}

\leavevmode\hypertarget{ref-fan1996}{}%
Fan, J., y Gijbels, I. (1996). \emph{Local Polynomial Modelling and Its Applications}. Chapman; Hall.

\leavevmode\hypertarget{ref-faraway2014linear}{}%
Faraway, J. J. (2016). \emph{Linear Models with R} (Second). CRC Press.

\leavevmode\hypertarget{ref-fernandez2020simbook}{}%
Fernández-Casal, R., y Cao, R. (2020). \emph{Simulación Estadística}. \url{https://rubenfcasal.github.io/simbook}

\leavevmode\hypertarget{ref-fernandez2019intror}{}%
Fernández-Casal, R., Roca-Pardiñas, J., y Costa, J. (2019). \emph{Introducción al Análisis de Datos con R}. \url{https://rubenfcasal.github.io/intror}

\leavevmode\hypertarget{ref-fisher1936use}{}%
Fisher, R. A. (1936). The use of multiple measurements in taxonomic problems. \emph{Annals of eugenics}, \emph{7}(2), 179-188. \url{https://doi.org/10.1111/j.1469-1809.1936.tb02137.x}

\leavevmode\hypertarget{ref-freund1996schapire}{}%
Freund, Y., y Schapire, R. E. (1996). Schapire R: Experiments with a new boosting algorithm. \emph{in: Thirteenth International Conference on ML}.

\leavevmode\hypertarget{ref-friedman1989regularized}{}%
Friedman, J. H. (1989). Regularized discriminant analysis. \emph{Journal of the American statistical association}, \emph{84}(405), 165-175. \url{https://doi.org/10.1080/01621459.1989.10478752}

\leavevmode\hypertarget{ref-friedman1991multivariate}{}%
Friedman, J. H. (1991). {Multivariate Adaptive Regression Splines}. \emph{The Annals of Statistics}, \emph{19}(1), 1-67. \url{https://doi.org/10.1214/aos/1176347963}

\leavevmode\hypertarget{ref-friedman2001greedy}{}%
Friedman, J. H. (2001). Greedy function approximation: a gradient boosting machine. \emph{The Annals of Statistics}, 1189-1232. \url{https://doi.org/10.1214/aos/1013203451}

\leavevmode\hypertarget{ref-friedman2002stochastic}{}%
Friedman, J. H. (2002). Stochastic gradient boosting. \emph{Computational Statistics \& data analysis}, \emph{38}(4), 367-378. \url{https://doi.org/10.1016/S0167-9473(01)00065-2}

\leavevmode\hypertarget{ref-friedman2008predictive}{}%
Friedman, J. H., y Popescu, B. E. (2008). Predictive learning via rule ensembles. \emph{The Annals of Applied Statistics}, \emph{2}(3), 916-954. \url{https://doi.org/10.1214/07-aoas148}

\leavevmode\hypertarget{ref-friedman1981projection}{}%
Friedman, J. H., y Stuetzle, W. (1981). Projection pursuit regression. \emph{Journal of the American statistical Association}, \emph{76}(376), 817-823. \url{https://doi.org/10.1080/01621459.1981.10477729}

\leavevmode\hypertarget{ref-friedman1974projection}{}%
Friedman, J. H., y Tukey, J. W. (1974). A projection pursuit algorithm for exploratory data analysis. \emph{IEEE Transactions on computers}, \emph{100}(9), 881-890. \url{https://doi.org/10.1109/t-c.1974.224051}

\leavevmode\hypertarget{ref-friedman2000additive}{}%
Friedman, J., Hastie, T., y Tibshirani, R. (2000). Additive logistic regression: a statistical view of boosting (with discussion and a rejoinder by the authors). \emph{The Annals of Statistics}, \emph{28}(2), 337-407. \url{https://doi.org/10.1214/aos/1016218223}

\leavevmode\hypertarget{ref-goldstein2015peeking}{}%
Goldstein, A., Kapelner, A., Bleich, J., y Pitkin, E. (2015). Peeking Inside the Black Box: Visualizing Statistical Learning With Plots of Individual Conditional Expectation. \emph{Journal of Computational and Graphical Statistics}, \emph{24}(1), 44-65. \url{https://doi.org/10.1080/10618600.2014.907095}

\leavevmode\hypertarget{ref-greenwell2020dblp}{}%
Greenwell, B. M. (2017). {pdp: An R Package for Constructing Partial Dependence Plots}. \emph{{The R Journal}}, \emph{9}(1), 421-436. \url{https://doi.org/10.32614/RJ-2017-016}

\leavevmode\hypertarget{ref-hair1998multivariate}{}%
Hair, J. F., Anderson, R. E., Tatham, R. L., y Black, W. (1998). \emph{Multivariate Data Analysis}. Prentice Hall.

\leavevmode\hypertarget{ref-hastie2004entire}{}%
Hastie, T., Rosset, S., Tibshirani, R., y Zhu, J. (2004). The entire regularization path for the support vector machine. \emph{Journal of Machine Learning Research}, \emph{5}(Oct), 1391-1415.

\leavevmode\hypertarget{ref-hastie1990generalized}{}%
Hastie, T., y Tibshirani, R. (1990). \emph{Generalized Additive Models}. Chapman; Hall. \url{https://doi.org/10.1201/9780203753781}

\leavevmode\hypertarget{ref-hastie1996fisher}{}%
Hastie, T., y Tibshirani, R. (1996). Discriminant Analysis by Gaussian Mixtures. \emph{Journal of the Royal Statistical Society. Series B (Methodological)}, \emph{58}(1), 155-176. \url{https://doi.org/10.1111/j.2517-6161.1996.tb02073.x}

\leavevmode\hypertarget{ref-hothorn2006unbiased}{}%
Hothorn, T., Hornik, K., y Zeileis, A. (2006). Unbiased recursive partitioning: A conditional inference framework. \emph{Journal of Computational and Graphical Statistics}, \emph{15}(3), 651-674. \url{https://doi.org/10.1198/106186006x133933}

\leavevmode\hypertarget{ref-ichimura1993}{}%
Ichimura, H. (1993). Semiparametric least squares (SLS) and weighted SLS estimation of single-index models. \emph{Journal of Econometrics}, \emph{58}(1), 71-120. \url{https://doi.org/10.1016/0304-4076(93)90114-K}

\leavevmode\hypertarget{ref-james2021introduction}{}%
James, G., Witten, D., Hastie, T., y Tibshirani, R. (2021). \emph{An Introduction to Statistical Learning: With Applications in R, Second Edition}. Springer. \url{https://www.statlearning.com}

\leavevmode\hypertarget{ref-kernlab2004}{}%
Karatzoglou, A., Smola, A., Hornik, K., y Zeileis, A. (2004). kernlab - An S4 Package for Kernel Methods in R. \emph{Journal of Statistical Software, Articles}, \emph{11}(9), 1-20. \url{https://doi.org/10.18637/jss.v011.i09}

\leavevmode\hypertarget{ref-kass1980exploratory}{}%
Kass, G. V. (1980). An exploratory technique for investigating large quantities of categorical data. \emph{Journal of the Royal Statistical Society: Series C (Applied Statistics)}, \emph{29}(2), 119-127. \url{https://doi.org/10.2307/2986296}

\leavevmode\hypertarget{ref-kearns_cryptographic_1994}{}%
Kearns, M., y Valiant, L. (1994). Cryptographic limitations on learning {Boolean} formulae and finite automata. \emph{Journal of the ACM}, \emph{41}(1), 67-95. \url{https://doi.org/10.1145/174644.174647}

\leavevmode\hypertarget{ref-kruskal1969toward}{}%
Kruskal, J. B. (1969). Toward a practical method which helps uncover the structure of a set of multivariate observations by finding the linear transformation which optimizes a new {«index of condensation»}. \emph{Statistical Computation}, 427-440. \url{https://doi.org/10.1016/b978-0-12-498150-8.50024-0}

\leavevmode\hypertarget{ref-kuhn2008building}{}%
Kuhn, M. (2008). Building Predictive Models in R Using the caret Package. \emph{Journal of Statistical Software}, \emph{28}(5), 1-26. \url{https://doi.org/10.18637/jss.v028.i05}

\leavevmode\hypertarget{ref-kuhn2020tidymodels}{}%
Kuhn, M., y Wickham, H. (2020). Tidymodels: a collection of packages for modeling and machine learning using tidyverse principles. \emph{Boston, MA, USA.{[}(accessed on 10 December 2020){]}}.

\leavevmode\hypertarget{ref-kvaalseth1985cautionary}{}%
Kvålseth, T. O. (1985). Cautionary note about R 2. \emph{The American Statistician}, \emph{39}(4), 279-285. \url{https://doi.org/10.1080/00031305.1985.10479448}

\leavevmode\hypertarget{ref-lauro1996computational}{}%
Lauro, C. (1996). Computational statistics or statistical computing, is that the question? \emph{Computational Statistics \& Data Analysis}, \emph{23}(1), 191-193. \url{https://doi.org/10.1016/0167-9473(96)88920-1}

\leavevmode\hypertarget{ref-liaw2002classification}{}%
Liaw, A., y Wiener, M. (2002). Classification and Regression by {randomForest}. \emph{R News}, \emph{2}(3), 18-22. \url{https://www.r-project.org/doc/Rnews/Rnews_2002-3.pdf}

\leavevmode\hypertarget{ref-loh2002regression}{}%
Loh, W.-Y. (2002). Regression tress with unbiased variable selection and interaction detection. \emph{Statistica Sinica}, 361-386.

\leavevmode\hypertarget{ref-massy1965principal}{}%
Massy, W. F. (1965). Principal components regression in exploratory statistical research. \emph{Journal of the American Statistical Association}, \emph{60}(309), 234-256. \url{https://doi.org/10.1080/01621459.1965.10480787}

\leavevmode\hypertarget{ref-mcculloch1943logical}{}%
McCulloch, W. S., y Pitts, W. (1943). A logical calculus of the ideas immanent in nervous activity. \emph{The bulletin of mathematical biophysics}, \emph{5}(4), 115-133. \url{https://doi.org/10.1007/bf02459570}

\leavevmode\hypertarget{ref-Mevik2007pls}{}%
Mevik, B.-H., y Wehrens, R. (2007). The pls Package: Principal Component and Partial Least Squares Regression in R. \emph{Journal of Statistical Software, Articles}, \emph{18}(2), 1-23. \url{https://doi.org/10.18637/jss.v018.i02}

\leavevmode\hypertarget{ref-R-e1071}{}%
Meyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., y Leisch, F. (2020). \emph{e1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien}. \url{https://CRAN.R-project.org/package=e1071}

\leavevmode\hypertarget{ref-molnar2020interpretable}{}%
Molnar, C. (2020). \emph{Interpretable Machine Learning}. Lulu.com. \url{https://christophm.github.io/interpretable-ml-book}

\leavevmode\hypertarget{ref-quinlan1993c4}{}%
Quinlan, J. R. (1993). \emph{C4.5: Programs for Machine Learning}. Elsevier Science.

\leavevmode\hypertarget{ref-quinlan1992learning}{}%
Quinlan, J. R., y others. (1992). Learning with continuous classes. \emph{5th Australian joint conference on artificial intelligence}, \emph{92}, 343-348.

\leavevmode\hypertarget{ref-shannon1948mathematical}{}%
Shannon, C. E. (1948). A mathematical theory of communication. \emph{The Bell System Technical Journal}, \emph{27}(3), 379-423. \url{https://doi.org/10.2307/410457}

\leavevmode\hypertarget{ref-spinoza1667ethics}{}%
Spinoza, B. (1677). \emph{Ethics}.

\leavevmode\hypertarget{ref-strumbelj2010efficient}{}%
Strumbelj, E., y Kononenko, I. (2010). An efficient explanation of individual classifications using game theory. \emph{The Journal of Machine Learning Research}, \emph{11}, 1-18.

\leavevmode\hypertarget{ref-tibshirani1996regression}{}%
Tibshirani, R. (1996). Regression shrinkage and selection via the lasso. \emph{Journal of the Royal Statistical Society: Series B (Methodological)}, \emph{58}(1), 267-288. \url{https://doi.org/10.1111/j.2517-6161.1996.tb02080.x}

\leavevmode\hypertarget{ref-valiant1984theory}{}%
Valiant, L. G. (1984). A Theory of the Learnable. \emph{Communications of the ACM}, \emph{27}(11), 1134-1142. \url{https://doi.org/10.1145/800057.808710}

\leavevmode\hypertarget{ref-vapnik1998}{}%
Vapnik, V. (2000). \emph{Statistical Learning Theory}. Willey.

\leavevmode\hypertarget{ref-vapnik2013nature}{}%
Vapnik, V. (2013). \emph{The Nature of Statistical Learning Theory}. Springer.

\leavevmode\hypertarget{ref-Venables2002Modern}{}%
Venables, W. N., y Ripley, B. D. (2002). \emph{Modern Applied Statistics with S}. Springer New York. \url{https://doi.org/10.1007/978-0-387-21706-2}

\leavevmode\hypertarget{ref-vinayak2015dart}{}%
Vinayak, R. K., y Gilad-Bachrach, R. (2015). Dart: Dropouts meet multiple additive regression trees. \emph{Artificial Intelligence and Statistics}, 489-497.

\leavevmode\hypertarget{ref-R-KernSmooth}{}%
Wand, M. (2021). \emph{KernSmooth: Functions for Kernel Smoothing Supporting Wand \& Jones (1995)}. \url{https://CRAN.R-project.org/package=KernSmooth}

\leavevmode\hypertarget{ref-welch1939note}{}%
Welch, B. L. (1939). Note on Discriminant Functions. \emph{Biometrika}, \emph{31}(1/2), 218-220. \url{https://doi.org/10.2307/2334985}

\leavevmode\hypertarget{ref-werbos1974new}{}%
Werbos, P. (1974). New tools for prediction and analysis in the behavioral sciences. \emph{Ph. D. dissertation, Harvard University}.

\leavevmode\hypertarget{ref-wold1983multivariate}{}%
Wold, S., Martens, H., y Wold, H. (1983). The multivariate calibration problem in chemistry solved by the PLS method. En \emph{Matrix pencils} (pp. 286-293). Springer. \url{https://doi.org/10.1007/bfb0062108}

\leavevmode\hypertarget{ref-wolpert1997no}{}%
Wolpert, D. H., y Macready, W. G. (1997). No free lunch theorems for optimization. \emph{IEEE Transactions on Evolutionary Computation}, \emph{1}(1), 67-82. \url{https://doi.org/10.1109/4235.585893}

\leavevmode\hypertarget{ref-wood2017generalized}{}%
Wood, S. N. (2017). \emph{Generalized Additive Models: An Introduction with R, Second Edition}. CRC Press.

\leavevmode\hypertarget{ref-zou2005regularization}{}%
Zou, H., y Hastie, T. (2005). Regularization and Variable Selection via the Elastic Net. \emph{Journal of the Royal Statistical Society, Series B (Statistical Methodology)}, \emph{67}(2), 301-320. \url{https://doi.org/10.1111/j.1467-9868.2005.00503.x}

\end{CSLReferences}

\end{document}
