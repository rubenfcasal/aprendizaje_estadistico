<!DOCTYPE html>
<html lang="es" xml:lang="es">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.3 Construcción y evaluación de los modelos | Métodos predictivos de aprendizaje estadístico</title>
  <meta name="description" content="1.3 Construcción y evaluación de los modelos | Métodos predictivos de aprendizaje estadístico con R." />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="1.3 Construcción y evaluación de los modelos | Métodos predictivos de aprendizaje estadístico" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="1.3 Construcción y evaluación de los modelos | Métodos predictivos de aprendizaje estadístico con R." />
  <meta name="github-repo" content="rubenfcasal/book_mpae" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.3 Construcción y evaluación de los modelos | Métodos predictivos de aprendizaje estadístico" />
  
  <meta name="twitter:description" content="1.3 Construcción y evaluación de los modelos | Métodos predictivos de aprendizaje estadístico con R." />
  

<meta name="author" content="Rubén Fernández Casal (ruben.fcasal@udc.es)" />
<meta name="author" content="Julián Costa Bouzas (julian.costa@udc.es)" />
<meta name="author" content="Manuel Oviedo de la Fuente (manuel.oviedo@udc.es)" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="métodos-de-aprendizaje-estadístico.html"/>
<link rel="next" href="dimen-curse.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.6.2/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.30/datatables.js"></script>
<link href="libs/dt-core-1.13.4/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.13.4/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.13.4/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Métodos predictivos de aprendizaje estadístico</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Bienvenida</a></li>
<li class="chapter" data-level="" data-path="prólogo.html"><a href="prólogo.html"><i class="fa fa-check"></i>Prólogo</a>
<ul>
<li class="chapter" data-level="" data-path="el-lenguaje-de-programación-r.html"><a href="el-lenguaje-de-programación-r.html"><i class="fa fa-check"></i>El lenguaje de programación R</a></li>
<li class="chapter" data-level="" data-path="organización.html"><a href="organización.html"><i class="fa fa-check"></i>Organización</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro-AE.html"><a href="intro-AE.html"><i class="fa fa-check"></i><b>1</b> Introducción al aprendizaje estadístico</a>
<ul>
<li class="chapter" data-level="1.1" data-path="aprendizaje-estadístico-vs.-aprendizaje-automático.html"><a href="aprendizaje-estadístico-vs.-aprendizaje-automático.html"><i class="fa fa-check"></i><b>1.1</b> Aprendizaje estadístico vs. aprendizaje automático</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="aprendizaje-estadístico-vs.-aprendizaje-automático.html"><a href="aprendizaje-estadístico-vs.-aprendizaje-automático.html#las-dos-culturas"><i class="fa fa-check"></i><b>1.1.1</b> Las dos culturas</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="métodos-de-aprendizaje-estadístico.html"><a href="métodos-de-aprendizaje-estadístico.html"><i class="fa fa-check"></i><b>1.2</b> Métodos de aprendizaje estadístico</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="métodos-de-aprendizaje-estadístico.html"><a href="métodos-de-aprendizaje-estadístico.html#notacion"><i class="fa fa-check"></i><b>1.2.1</b> Notación y terminología</a></li>
<li class="chapter" data-level="1.2.2" data-path="métodos-de-aprendizaje-estadístico.html"><a href="métodos-de-aprendizaje-estadístico.html#metodos-pkgs"><i class="fa fa-check"></i><b>1.2.2</b> Métodos (de aprendizaje supervisado) y paquetes de R</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="const-eval.html"><a href="const-eval.html"><i class="fa fa-check"></i><b>1.3</b> Construcción y evaluación de los modelos</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="const-eval.html"><a href="const-eval.html#bias-variance"><i class="fa fa-check"></i><b>1.3.1</b> Equilibrio entre sesgo y varianza: infraajuste y sobreajuste</a></li>
<li class="chapter" data-level="1.3.2" data-path="const-eval.html"><a href="const-eval.html#entrenamiento-test"><i class="fa fa-check"></i><b>1.3.2</b> Datos de entrenamiento y datos de test</a></li>
<li class="chapter" data-level="1.3.3" data-path="const-eval.html"><a href="const-eval.html#cv"><i class="fa fa-check"></i><b>1.3.3</b> Selección de hiperparámetros mediante validación cruzada</a></li>
<li class="chapter" data-level="1.3.4" data-path="const-eval.html"><a href="const-eval.html#eval-reg"><i class="fa fa-check"></i><b>1.3.4</b> Evaluación de un método de regresión</a></li>
<li class="chapter" data-level="1.3.5" data-path="const-eval.html"><a href="const-eval.html#eval-class"><i class="fa fa-check"></i><b>1.3.5</b> Evaluación de un método de clasificación</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="dimen-curse.html"><a href="dimen-curse.html"><i class="fa fa-check"></i><b>1.4</b> La maldición de la dimensionalidad</a></li>
<li class="chapter" data-level="1.5" data-path="analisis-modelos.html"><a href="analisis-modelos.html"><i class="fa fa-check"></i><b>1.5</b> Análisis e interpretación de los modelos</a></li>
<li class="chapter" data-level="1.6" data-path="caret.html"><a href="caret.html"><i class="fa fa-check"></i><b>1.6</b> Introducción al paquete <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="clasicos.html"><a href="clasicos.html"><i class="fa fa-check"></i><b>2</b> Métodos clásicos de estadística</a>
<ul>
<li class="chapter" data-level="2.1" data-path="rlm.html"><a href="rlm.html"><i class="fa fa-check"></i><b>2.1</b> Regresión lineal múltiple</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="rlm.html"><a href="rlm.html#colinealidad"><i class="fa fa-check"></i><b>2.1.1</b> El problema de la colinealidad</a></li>
<li class="chapter" data-level="2.1.2" data-path="rlm.html"><a href="rlm.html#seleccion-rlm"><i class="fa fa-check"></i><b>2.1.2</b> Selección de variables explicativas</a></li>
<li class="chapter" data-level="2.1.3" data-path="rlm.html"><a href="rlm.html#analisis-rlm"><i class="fa fa-check"></i><b>2.1.3</b> Análisis e interpretación del modelo</a></li>
<li class="chapter" data-level="2.1.4" data-path="rlm.html"><a href="rlm.html#eval-rlm"><i class="fa fa-check"></i><b>2.1.4</b> Evaluación de la precisión</a></li>
<li class="chapter" data-level="2.1.5" data-path="rlm.html"><a href="rlm.html#selec-ae-rlm"><i class="fa fa-check"></i><b>2.1.5</b> Selección del modelo mediante remuestreo</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="reg-glm.html"><a href="reg-glm.html"><i class="fa fa-check"></i><b>2.2</b> Modelos lineales generalizados</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="reg-glm.html"><a href="reg-glm.html#seleccion-glm"><i class="fa fa-check"></i><b>2.2.1</b> Selección de variables explicativas</a></li>
<li class="chapter" data-level="2.2.2" data-path="reg-glm.html"><a href="reg-glm.html#analisis-glm"><i class="fa fa-check"></i><b>2.2.2</b> Análisis e interpretación del modelo</a></li>
<li class="chapter" data-level="2.2.3" data-path="reg-glm.html"><a href="reg-glm.html#glm-bfan"><i class="fa fa-check"></i><b>2.2.3</b> Evaluación de la precisión</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="generadores.html"><a href="generadores.html"><i class="fa fa-check"></i><b>2.3</b> Otros métodos de clasificación</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="generadores.html"><a href="generadores.html#clas-lda"><i class="fa fa-check"></i><b>2.3.1</b> Análisis discriminante lineal</a></li>
<li class="chapter" data-level="2.3.2" data-path="generadores.html"><a href="generadores.html#clas-qda"><i class="fa fa-check"></i><b>2.3.2</b> Análisis discriminante cuadrático</a></li>
<li class="chapter" data-level="2.3.3" data-path="generadores.html"><a href="generadores.html#bayes"><i class="fa fa-check"></i><b>2.3.3</b> Bayes naíf</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="trees.html"><a href="trees.html"><i class="fa fa-check"></i><b>3</b> Árboles de decisión</a>
<ul>
<li class="chapter" data-level="3.1" data-path="árboles-de-regresión-cart.html"><a href="árboles-de-regresión-cart.html"><i class="fa fa-check"></i><b>3.1</b> Árboles de regresión CART</a></li>
<li class="chapter" data-level="3.2" data-path="árboles-de-clasificación-cart.html"><a href="árboles-de-clasificación-cart.html"><i class="fa fa-check"></i><b>3.2</b> Árboles de clasificación CART</a></li>
<li class="chapter" data-level="3.3" data-path="tree-rpart.html"><a href="tree-rpart.html"><i class="fa fa-check"></i><b>3.3</b> CART con el paquete <code>rpart</code></a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="tree-rpart.html"><a href="tree-rpart.html#reg-rpart"><i class="fa fa-check"></i><b>3.3.1</b> Ejemplo: regresión</a></li>
<li class="chapter" data-level="3.3.2" data-path="tree-rpart.html"><a href="tree-rpart.html#class-rpart"><i class="fa fa-check"></i><b>3.3.2</b> Ejemplo: modelo de clasificación</a></li>
<li class="chapter" data-level="3.3.3" data-path="tree-rpart.html"><a href="tree-rpart.html#interfaz-de-caret"><i class="fa fa-check"></i><b>3.3.3</b> Interfaz de <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="alternativas-a-los-árboles-cart.html"><a href="alternativas-a-los-árboles-cart.html"><i class="fa fa-check"></i><b>3.4</b> Alternativas a los árboles CART</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bagging-boosting.html"><a href="bagging-boosting.html"><i class="fa fa-check"></i><b>4</b> Bagging y boosting</a>
<ul>
<li class="chapter" data-level="4.1" data-path="bagging.html"><a href="bagging.html"><i class="fa fa-check"></i><b>4.1</b> Bagging</a></li>
<li class="chapter" data-level="4.2" data-path="rf.html"><a href="rf.html"><i class="fa fa-check"></i><b>4.2</b> Bosques aleatorios</a></li>
<li class="chapter" data-level="4.3" data-path="bagging-rf-r.html"><a href="bagging-rf-r.html"><i class="fa fa-check"></i><b>4.3</b> Bagging y bosques aleatorios en R</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="bagging-rf-r.html"><a href="bagging-rf-r.html#ejemplo-clasificación-con-bagging"><i class="fa fa-check"></i><b>4.3.1</b> Ejemplo: clasificación con bagging</a></li>
<li class="chapter" data-level="4.3.2" data-path="bagging-rf-r.html"><a href="bagging-rf-r.html#ejemplo-clasif-rf"><i class="fa fa-check"></i><b>4.3.2</b> Ejemplo: clasificación con bosques aleatorios</a></li>
<li class="chapter" data-level="4.3.3" data-path="bagging-rf-r.html"><a href="bagging-rf-r.html#ejemplo-bosques-aleatorios-con-caret"><i class="fa fa-check"></i><b>4.3.3</b> Ejemplo: bosques aleatorios con <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="boosting.html"><a href="boosting.html"><i class="fa fa-check"></i><b>4.4</b> Boosting</a></li>
<li class="chapter" data-level="4.5" data-path="boosting-r.html"><a href="boosting-r.html"><i class="fa fa-check"></i><b>4.5</b> Boosting en R</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="boosting-r.html"><a href="boosting-r.html#ejemplo-clasificación-con-el-paquete-ada"><i class="fa fa-check"></i><b>4.5.1</b> Ejemplo: clasificación con el paquete <code>ada</code></a></li>
<li class="chapter" data-level="4.5.2" data-path="boosting-r.html"><a href="boosting-r.html#ejemplo-regresión-con-el-paquete-gbm"><i class="fa fa-check"></i><b>4.5.2</b> Ejemplo: regresión con el paquete <code>gbm</code></a></li>
<li class="chapter" data-level="4.5.3" data-path="boosting-r.html"><a href="boosting-r.html#xgb-caret"><i class="fa fa-check"></i><b>4.5.3</b> Ejemplo: XGBoost con el paquete <code>caret</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="svm.html"><a href="svm.html"><i class="fa fa-check"></i><b>5</b> Máquinas de soporte vectorial</a>
<ul>
<li class="chapter" data-level="5.1" data-path="clasificadores-de-máximo-margen.html"><a href="clasificadores-de-máximo-margen.html"><i class="fa fa-check"></i><b>5.1</b> Clasificadores de máximo margen</a></li>
<li class="chapter" data-level="5.2" data-path="clasificadores-de-soporte-vectorial.html"><a href="clasificadores-de-soporte-vectorial.html"><i class="fa fa-check"></i><b>5.2</b> Clasificadores de soporte vectorial</a></li>
<li class="chapter" data-level="5.3" data-path="máquinas-de-soporte-vectorial.html"><a href="máquinas-de-soporte-vectorial.html"><i class="fa fa-check"></i><b>5.3</b> Máquinas de soporte vectorial</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="máquinas-de-soporte-vectorial.html"><a href="máquinas-de-soporte-vectorial.html#regresión-con-svm"><i class="fa fa-check"></i><b>5.3.1</b> Regresión con SVM</a></li>
<li class="chapter" data-level="5.3.2" data-path="máquinas-de-soporte-vectorial.html"><a href="máquinas-de-soporte-vectorial.html#ventajas-e-incovenientes"><i class="fa fa-check"></i><b>5.3.2</b> Ventajas e incovenientes</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="svm-kernlab.html"><a href="svm-kernlab.html"><i class="fa fa-check"></i><b>5.4</b> SVM en R</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ext-glm.html"><a href="ext-glm.html"><i class="fa fa-check"></i><b>6</b> Extensiones de los modelos lineales (generalizados)</a>
<ul>
<li class="chapter" data-level="6.1" data-path="shrinkage.html"><a href="shrinkage.html"><i class="fa fa-check"></i><b>6.1</b> Métodos de regularización</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="shrinkage.html"><a href="shrinkage.html#implementación-en-r"><i class="fa fa-check"></i><b>6.1.1</b> Implementación en R</a></li>
<li class="chapter" data-level="6.1.2" data-path="shrinkage.html"><a href="shrinkage.html#ejemplo-ridge-regression"><i class="fa fa-check"></i><b>6.1.2</b> Ejemplo: <em>ridge regression</em></a></li>
<li class="chapter" data-level="6.1.3" data-path="shrinkage.html"><a href="shrinkage.html#ejemplo-lasso"><i class="fa fa-check"></i><b>6.1.3</b> Ejemplo: LASSO</a></li>
<li class="chapter" data-level="6.1.4" data-path="shrinkage.html"><a href="shrinkage.html#ejemplo-elastic-net"><i class="fa fa-check"></i><b>6.1.4</b> Ejemplo: <em>elastic net</em></a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="pca-pls.html"><a href="pca-pls.html"><i class="fa fa-check"></i><b>6.2</b> Métodos de reducción de la dimensión</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="pca-pls.html"><a href="pca-pls.html#regresión-por-componentes-principales-pcr"><i class="fa fa-check"></i><b>6.2.1</b> Regresión por componentes principales (PCR)</a></li>
<li class="chapter" data-level="6.2.2" data-path="pca-pls.html"><a href="pca-pls.html#regresión-por-mínimos-cuadrados-parciales-plsr"><i class="fa fa-check"></i><b>6.2.2</b> Regresión por mínimos cuadrados parciales (PLSR)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="reg-np.html"><a href="reg-np.html"><i class="fa fa-check"></i><b>7</b> Regresión no paramétrica</a>
<ul>
<li class="chapter" data-level="7.1" data-path="reg-local.html"><a href="reg-local.html"><i class="fa fa-check"></i><b>7.1</b> Regresión local</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="reg-local.html"><a href="reg-local.html#reg-knn"><i class="fa fa-check"></i><b>7.1.1</b> Vecinos más próximos</a></li>
<li class="chapter" data-level="7.1.2" data-path="reg-local.html"><a href="reg-local.html#reg-locpol"><i class="fa fa-check"></i><b>7.1.2</b> Regresión polinómica local</a></li>
<li class="chapter" data-level="7.1.3" data-path="reg-local.html"><a href="reg-local.html#regresión-polinómica-local-robusta"><i class="fa fa-check"></i><b>7.1.3</b> Regresión polinómica local robusta</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>7.2</b> Splines</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="splines.html"><a href="splines.html#reg-splines"><i class="fa fa-check"></i><b>7.2.1</b> Splines de regresión</a></li>
<li class="chapter" data-level="7.2.2" data-path="splines.html"><a href="splines.html#splines-de-suavizado"><i class="fa fa-check"></i><b>7.2.2</b> Splines de suavizado</a></li>
<li class="chapter" data-level="7.2.3" data-path="splines.html"><a href="splines.html#splines-penalizados"><i class="fa fa-check"></i><b>7.2.3</b> Splines penalizados</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="reg-gam.html"><a href="reg-gam.html"><i class="fa fa-check"></i><b>7.3</b> Modelos aditivos</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="reg-gam.html"><a href="reg-gam.html#superficies-de-predicción"><i class="fa fa-check"></i><b>7.3.1</b> Superficies de predicción</a></li>
<li class="chapter" data-level="7.3.2" data-path="reg-gam.html"><a href="reg-gam.html#anova-gam"><i class="fa fa-check"></i><b>7.3.2</b> Comparación y selección de modelos</a></li>
<li class="chapter" data-level="7.3.3" data-path="reg-gam.html"><a href="reg-gam.html#mgcv-diagnosis"><i class="fa fa-check"></i><b>7.3.3</b> Diagnosis del modelo</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="mars.html"><a href="mars.html"><i class="fa fa-check"></i><b>7.4</b> Regresión spline adaptativa multivariante</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="mars.html"><a href="mars.html#mars-con-el-paquete-earth"><i class="fa fa-check"></i><b>7.4.1</b> MARS con el paquete <code>earth</code></a></li>
<li class="chapter" data-level="7.4.2" data-path="mars.html"><a href="mars.html#mars-con-el-paquete-caret"><i class="fa fa-check"></i><b>7.4.2</b> MARS con el paquete <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="pursuit.html"><a href="pursuit.html"><i class="fa fa-check"></i><b>7.5</b> Projection pursuit</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="pursuit.html"><a href="pursuit.html#ppr"><i class="fa fa-check"></i><b>7.5.1</b> Regresión por projection pursuit</a></li>
<li class="chapter" data-level="7.5.2" data-path="pursuit.html"><a href="pursuit.html#implementación-en-r-1"><i class="fa fa-check"></i><b>7.5.2</b> Implementación en R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="neural-nets.html"><a href="neural-nets.html"><i class="fa fa-check"></i><b>8</b> Redes neuronales</a>
<ul>
<li class="chapter" data-level="8.1" data-path="single-hidden-layer-feedforward-network.html"><a href="single-hidden-layer-feedforward-network.html"><i class="fa fa-check"></i><b>8.1</b> Single-hidden-layer feedforward network</a></li>
<li class="chapter" data-level="8.2" data-path="clasificación-con-ann.html"><a href="clasificación-con-ann.html"><i class="fa fa-check"></i><b>8.2</b> Clasificación con ANN</a></li>
<li class="chapter" data-level="8.3" data-path="implementación-en-r-2.html"><a href="implementación-en-r-2.html"><i class="fa fa-check"></i><b>8.3</b> Implementación en R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliografía.html"><a href="bibliografía.html"><i class="fa fa-check"></i>Bibliografía</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Métodos predictivos de aprendizaje estadístico</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="const-eval" class="section level2 hasAnchor" number="1.3">
<h2><span class="header-section-number">1.3</span> Construcción y evaluación de los modelos<a href="const-eval.html#const-eval" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En inferencia estadística clásica el procedimiento habitual es emplear toda la información disponible para construir un modelo válido (que refleje de la forma más fiel posible lo que ocurre en la población) y, asumiendo que el modelo es el verdadero (lo que en general sería falso), utilizar resultados teóricos para evaluar su precisión. Por ejemplo, en el caso de regresión lineal múltiple, el coeficiente de determinación ajustado es una medida de la precisión del modelo para predecir nuevas observaciones (no se debe emplear el coeficiente de determinación sin ajustar; aunque, en cualquier caso, su validez depende de la de las suposiciones estructurales del modelo).</p>
<p>Alternativamente, en estadística computacional es habitual emplear técnicas de remuestreo para evaluar la precisión (entrenando también el modelo con todos los datos disponibles), principalmente validación cruzada (<em>leave-one-out</em>, <em>k-fold</em>), <em>jackknife</em> o bootstrap.</p>
<p>Por otra parte, como ya se comentó, algunos de los modelos empleados en AE son muy flexibles (están hiperparametrizados) y pueden aparecer problemas si se permite que se ajusten demasiado bien a las observaciones (podrían llegar a interpolar los datos). En estos casos habrá que controlar el procedimiento de aprendizaje, típicamente a través de parámetros relacionados con la complejidad del modelo (ver siguiente sección).</p>
<p>En AE se distingue entre parámetros estructurales, los que van a ser estimados al ajustar el modelo a los datos (en el entrenamiento), e hiperparámetros (<em>tuning parameters</em> o parámetros de ajuste), que imponen restricciones al aprendizaje del modelo (por ejemplo, determinando el número de parámetros estructurales). Si los hiperparámetros seleccionados producen un modelo demasiado complejo, aparecerán problemas de sobreajuste (<em>overfitting</em>), y en caso contrario, de infraajuste (<em>undefitting</em>).</p>
<p>Hay que tener en cuenta también que al aumentar la complejidad disminuye la interpretabilidad de los modelos. Se trata, por tanto, de conseguir buenas predicciones (habrá que evaluar la capacidad predictiva) con el modelo más sencillo posible.</p>
<!-- Sección <a href="const-eval.html#bias-variance">1.3.1</a> -->
<div id="bias-variance" class="section level3 hasAnchor" number="1.3.1">
<h3><span class="header-section-number">1.3.1</span> Equilibrio entre sesgo y varianza: infraajuste y sobreajuste<a href="const-eval.html#bias-variance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La idea es que queremos aprender más allá de los datos empleados en el entrenamiento (en estadística diríamos que queremos hacer inferencia sobre nuevas observaciones). Como ya se comentó, en AE hay que tener especial cuidado con el sobreajuste. Este problema ocurre cuando el modelo se ajusta demasiado bien a los datos de entrenamiento, pero falla cuando se utiliza en un nuevo conjunto de datos (nunca antes visto).</p>
<p>Como ejemplo ilustrativo emplearemos regresión polinómica, considerando el grado del polinomio como un hiperparámetro que determina la complejidad del modelo. En primer lugar simulamos una muestra y ajustamos modelos polinómicos con distintos grados de complejidad.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="const-eval.html#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulación datos</span></span>
<span id="cb4-2"><a href="const-eval.html#cb4-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb4-3"><a href="const-eval.html#cb4-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">length =</span> n)</span>
<span id="cb4-4"><a href="const-eval.html#cb4-4" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">+</span> <span class="dv">4</span><span class="sc">*</span>(<span class="dv">5</span><span class="sc">*</span>x <span class="sc">-</span> <span class="dv">1</span>)<span class="sc">*</span>(<span class="dv">4</span><span class="sc">*</span>x <span class="sc">-</span> <span class="dv">2</span>)<span class="sc">*</span>(x <span class="sc">-</span> <span class="fl">0.8</span>)<span class="sc">^</span><span class="dv">2</span> <span class="co"># grado 4</span></span>
<span id="cb4-5"><a href="const-eval.html#cb4-5" aria-hidden="true" tabindex="-1"></a>sd <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb4-6"><a href="const-eval.html#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb4-7"><a href="const-eval.html#cb4-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> mu <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, sd)</span>
<span id="cb4-8"><a href="const-eval.html#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, y) </span>
<span id="cb4-9"><a href="const-eval.html#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, mu, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb4-10"><a href="const-eval.html#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajuste de los modelos</span></span>
<span id="cb4-11"><a href="const-eval.html#cb4-11" aria-hidden="true" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb4-12"><a href="const-eval.html#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, <span class="fu">fitted</span>(fit1))</span>
<span id="cb4-13"><a href="const-eval.html#cb4-13" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="fu">poly</span>(x, <span class="dv">4</span>))</span>
<span id="cb4-14"><a href="const-eval.html#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, <span class="fu">fitted</span>(fit2), <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb4-15"><a href="const-eval.html#cb4-15" aria-hidden="true" tabindex="-1"></a>fit3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="fu">poly</span>(x, <span class="dv">20</span>)) </span>
<span id="cb4-16"><a href="const-eval.html#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, <span class="fu">fitted</span>(fit3), <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb4-17"><a href="const-eval.html#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>), <span class="at">lwd =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>),</span>
<span id="cb4-18"><a href="const-eval.html#cb4-18" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;Verdadero&quot;</span>, <span class="st">&quot;Ajuste con grado 1&quot;</span>,</span>
<span id="cb4-19"><a href="const-eval.html#cb4-19" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;Ajuste con grado 4&quot;</span>, <span class="st">&quot;Ajuste con grado 20&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:polyfit"></span>
<img src="01-introduccion_files/figure-html/polyfit-1.png" alt="Muestra (simulada) y ajustes polinómicos con distinta complejidad." width="75%" />
<p class="caption">
Figura 1.3: Muestra (simulada) y ajustes polinómicos con distinta complejidad.
</p>
</div>
<!-- 
# NOTA: poly(x, degree, raw = FALSE) puede tener un problema de desbordamiento
# si degree > 25
-->
<p>Como se observa en la Figura <a href="const-eval.html#fig:polyfit">1.3</a>, al aumentar la complejidad del modelo se consigue un mejor ajuste a los datos observados (usados para el entrenamiento), a costa de un incremento en la variabilidad de las predicciones, lo que puede producir un mal comportamiento del modelo al ser empleado en un conjunto de datos distinto del observado.</p>
<p>Si calculamos medidas de bondad de ajuste, como el error cuadrático medio (<em>mean squared error</em>, MSE) o el coeficiente de determinación (<span class="math inline">\(R^2\)</span>), se obtienen mejores resultados al aumentar la complejidad. Como se trata de modelos lineales, podríamos obtener también el coeficiente de determinación ajustado (<span class="math inline">\(R^2_{adj}\)</span>), que sería preferible (en principio, ya que dependería de la validez de las hipótesis estructurales del modelo) para medir la precisión al emplear los modelos en un nuevo conjunto de datos (ver Tabla <a href="const-eval.html#tab:gof-polyfit">1.1</a>).</p>
<!-- 
Nota:  
No distinguimos en la notación entre el valor teórico (MSE) y la estimación habitual en la práctica (*averaged squared error*, ASE), además de que se podrían tener en cuenta los grados de libertad.
-->
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="const-eval.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sapply</span>(<span class="fu">list</span>(<span class="at">fit1 =</span> fit1, <span class="at">fit2 =</span> fit2, <span class="at">fit3 =</span> fit3),</span>
<span id="cb5-2"><a href="const-eval.html#cb5-2" aria-hidden="true" tabindex="-1"></a>       <span class="cf">function</span>(x) <span class="fu">with</span>(<span class="fu">summary</span>(x),</span>
<span id="cb5-3"><a href="const-eval.html#cb5-3" aria-hidden="true" tabindex="-1"></a>          <span class="fu">c</span>(<span class="at">MSE =</span> <span class="fu">mean</span>(residuals<span class="sc">^</span><span class="dv">2</span>), <span class="at">R2 =</span> r.squared, <span class="at">R2adj =</span> adj.r.squared)))</span></code></pre></div>
<table>
<caption><span id="tab:gof-polyfit">Tabla 1.1: </span>Medidas de bondad de ajuste de los modelos polinómicos (obtenidas a partir de la muestra de entrenamiento).</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right"><span class="math inline">\(MSE\)</span></th>
<th align="right"><span class="math inline">\(R^2\)</span></th>
<th align="right"><span class="math inline">\(R^2_{adj}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>fit1</code></td>
<td align="right">1.22</td>
<td align="right">0.20</td>
<td align="right">0.17</td>
</tr>
<tr class="even">
<td align="left"><code>fit2</code></td>
<td align="right">0.19</td>
<td align="right">0.87</td>
<td align="right">0.85</td>
</tr>
<tr class="odd">
<td align="left"><code>fit3</code></td>
<td align="right">0.07</td>
<td align="right">0.95</td>
<td align="right">0.84</td>
</tr>
</tbody>
</table>
<p>Por ejemplo, si generamos nuevas respuestas de este proceso, la precisión del modelo más complejo empeorará considerablemente (ver Figura <a href="const-eval.html#fig:polyfit2">1.4</a>):</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="const-eval.html#cb6-1" aria-hidden="true" tabindex="-1"></a>y.new <span class="ot">&lt;-</span> mu <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, sd)</span>
<span id="cb6-2"><a href="const-eval.html#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, y) </span>
<span id="cb6-3"><a href="const-eval.html#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x, y.new, <span class="at">pch =</span> <span class="dv">2</span>)</span>
<span id="cb6-4"><a href="const-eval.html#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, mu, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb6-5"><a href="const-eval.html#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, <span class="fu">fitted</span>(fit1))</span>
<span id="cb6-6"><a href="const-eval.html#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, <span class="fu">fitted</span>(fit2), <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb6-7"><a href="const-eval.html#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, <span class="fu">fitted</span>(fit3), <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb6-8"><a href="const-eval.html#cb6-8" aria-hidden="true" tabindex="-1"></a>leyenda <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Verdadero&quot;</span>, <span class="st">&quot;Muestra&quot;</span>, <span class="st">&quot;Ajuste con grado 1&quot;</span>,</span>
<span id="cb6-9"><a href="const-eval.html#cb6-9" aria-hidden="true" tabindex="-1"></a>       <span class="st">&quot;Ajuste con grado 4&quot;</span>, <span class="st">&quot;Ajuste con grado 20&quot;</span>, <span class="st">&quot;Nuevas observaciones&quot;</span>)</span>
<span id="cb6-10"><a href="const-eval.html#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend =</span> leyenda, <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="cn">NA</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="cn">NA</span>),</span>
<span id="cb6-11"><a href="const-eval.html#cb6-11" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="cn">NA</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="cn">NA</span>), <span class="at">pch =</span> <span class="fu">c</span>(<span class="cn">NA</span>, <span class="dv">1</span>, <span class="cn">NA</span>, <span class="cn">NA</span>, <span class="cn">NA</span>, <span class="dv">2</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:polyfit2"></span>
<img src="01-introduccion_files/figure-html/polyfit2-1.png" alt="Muestra con ajustes polinómicos con distinta complejidad y nuevas observaciones." width="75%" />
<p class="caption">
Figura 1.4: Muestra con ajustes polinómicos con distinta complejidad y nuevas observaciones.
</p>
</div>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="const-eval.html#cb7-1" aria-hidden="true" tabindex="-1"></a>MSEP <span class="ot">&lt;-</span> <span class="fu">sapply</span>(<span class="fu">list</span>(<span class="at">fit1 =</span> fit1, <span class="at">fit2 =</span> fit2, <span class="at">fit3 =</span> fit3), </span>
<span id="cb7-2"><a href="const-eval.html#cb7-2" aria-hidden="true" tabindex="-1"></a>               <span class="cf">function</span>(x) <span class="fu">mean</span>((y.new <span class="sc">-</span> <span class="fu">fitted</span>(x))<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb7-3"><a href="const-eval.html#cb7-3" aria-hidden="true" tabindex="-1"></a>MSEP</span></code></pre></div>
<pre><code>##    fit1    fit2    fit3 
## 1.49832 0.17112 0.26211</code></pre>
<!-- lines(x, y.new, type = "b", pch = 2, lty = 4, col = "blue") -->
<p>Como ejemplo adicional, para evitar el efecto de la aleatoriedad de la muestra, en el siguiente código se simulan 100 muestras del proceso anterior a las que se les ajustan modelos polinómicos variando el grado desde 1 hasta 20. Posteriormente se evalúa la precisión, en la muestra empleada en el ajuste y en un nuevo conjunto de datos procedente de la misma población.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="const-eval.html#cb9-1" aria-hidden="true" tabindex="-1"></a>nsim <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb9-2"><a href="const-eval.html#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb9-3"><a href="const-eval.html#cb9-3" aria-hidden="true" tabindex="-1"></a>grado.max <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb9-4"><a href="const-eval.html#cb9-4" aria-hidden="true" tabindex="-1"></a>grados <span class="ot">&lt;-</span> <span class="fu">seq_len</span>(grado.max) </span>
<span id="cb9-5"><a href="const-eval.html#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulación, ajustes y errores cuadráticos</span></span>
<span id="cb9-6"><a href="const-eval.html#cb9-6" aria-hidden="true" tabindex="-1"></a>mse <span class="ot">&lt;-</span> mse.new <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="at">nrow =</span> grado.max, <span class="at">ncol =</span> nsim) </span>
<span id="cb9-7"><a href="const-eval.html#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="fu">seq_len</span>(nsim)) {</span>
<span id="cb9-8"><a href="const-eval.html#cb9-8" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> mu <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, sd)</span>
<span id="cb9-9"><a href="const-eval.html#cb9-9" aria-hidden="true" tabindex="-1"></a>  y.new <span class="ot">&lt;-</span> mu <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, sd)</span>
<span id="cb9-10"><a href="const-eval.html#cb9-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (grado <span class="cf">in</span> grados) { <span class="co"># grado &lt;- 1</span></span>
<span id="cb9-11"><a href="const-eval.html#cb9-11" aria-hidden="true" tabindex="-1"></a>    fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="fu">poly</span>(x, grado))</span>
<span id="cb9-12"><a href="const-eval.html#cb9-12" aria-hidden="true" tabindex="-1"></a>    mse[grado, i] <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">residuals</span>(fit)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb9-13"><a href="const-eval.html#cb9-13" aria-hidden="true" tabindex="-1"></a>    mse.new[grado, i] <span class="ot">&lt;-</span> <span class="fu">mean</span>((y.new <span class="sc">-</span> <span class="fu">fitted</span>(fit))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb9-14"><a href="const-eval.html#cb9-14" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb9-15"><a href="const-eval.html#cb9-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-16"><a href="const-eval.html#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Representación errores simulaciones</span></span>
<span id="cb9-17"><a href="const-eval.html#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="fu">matplot</span>(grados, mse, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, <span class="at">col =</span> <span class="st">&quot;lightgray&quot;</span>, <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">2</span>),</span>
<span id="cb9-18"><a href="const-eval.html#cb9-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;Grado del polinomio (complejidad)&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Error cuadrático medio&quot;</span>)</span>
<span id="cb9-19"><a href="const-eval.html#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(grados, mse.new, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;lightgray&quot;</span>) </span>
<span id="cb9-20"><a href="const-eval.html#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Errores globales</span></span>
<span id="cb9-21"><a href="const-eval.html#cb9-21" aria-hidden="true" tabindex="-1"></a>precision <span class="ot">&lt;-</span> <span class="fu">rowMeans</span>(mse)</span>
<span id="cb9-22"><a href="const-eval.html#cb9-22" aria-hidden="true" tabindex="-1"></a>precision.new <span class="ot">&lt;-</span> <span class="fu">rowMeans</span>(mse.new)</span>
<span id="cb9-23"><a href="const-eval.html#cb9-23" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(grados, precision, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb9-24"><a href="const-eval.html#cb9-24" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(grados, precision.new, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb9-25"><a href="const-eval.html#cb9-25" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> sd<span class="sc">^</span><span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">3</span>);<span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">4</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb9-26"><a href="const-eval.html#cb9-26" aria-hidden="true" tabindex="-1"></a>leyenda <span class="ot">&lt;-</span>  <span class="fu">c</span>(<span class="st">&quot;Muestras&quot;</span>, <span class="st">&quot;Nuevas observaciones&quot;</span>)</span>
<span id="cb9-27"><a href="const-eval.html#cb9-27" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend =</span> leyenda, <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:polyfitsim"></span>
<img src="01-introduccion_files/figure-html/polyfitsim-1.png" alt="Precisiones (errores cuadráticos medios) de ajustes polinómicos variando la complejidad, en las muestras empleadas en el ajuste y en nuevas observaciones (simulados)." width="75%" />
<p class="caption">
Figura 1.5: Precisiones (errores cuadráticos medios) de ajustes polinómicos variando la complejidad, en las muestras empleadas en el ajuste y en nuevas observaciones (simulados).
</p>
</div>
<p>Como se puede observar en la Figura <a href="const-eval.html#fig:polyfitsim">1.5</a>, los errores de entrenamiento disminuyen a medida que aumenta la complejidad del modelo. Sin embargo, los errores de predicción en nuevas observaciones inicialmente disminuyen, hasta alcanzar un mínimo marcado por la línea de puntos vertical, que se corresponde con el modelo de grado 4, y posteriormente aumentan (la línea de puntos horizontal es la varianza del proceso; el error cuadrático medio de predicción asintótico). La línea vertical representa el equilibrio entre el sesgo y la varianza. Considerando un valor de complejidad a la izquierda de esa línea tendríamos infraajuste (mayor sesgo y menor varianza), y a la derecha, sobreajuste (menor sesgo y mayor varianza).</p>
<p>Desde un punto de vista más formal, considerando el modelo <a href="métodos-de-aprendizaje-estadístico.html#eq:modelogeneral">(1.1)</a> y una función de pérdidas cuadrática, el predictor óptimo (desconocido) sería la media condicional <span class="math inline">\(m(\mathbf{x}) = E\left( \left. Y\right\vert \mathbf{X}=\mathbf{x} \right)\)</span><a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>. Por tanto, los predictores serían realmente estimaciones de la función de regresión, <span class="math inline">\(\hat Y(\mathbf{x}) = \hat m(\mathbf{x})\)</span>, y podemos expresar la media del error cuadrático de predicción en términos del sesgo y la varianza: <span class="math display">\[
\begin{aligned}
E \left( Y(\mathbf{x}_0) - \hat Y(\mathbf{x}_0) \right)^2 &amp; = E \left( m(\mathbf{x}_0) + \varepsilon - \hat m(\mathbf{x}_0) \right)^2 = E \left( m(\mathbf{x}_0) - \hat m(\mathbf{x}_0) \right)^2 + \sigma^2 \\
&amp; = E^2 \left( m(\mathbf{x}_0) - \hat m(\mathbf{x}_0) \right) + Var\left( \hat m(\mathbf{x}_0) \right) + \sigma^2 \\
&amp; = \text{sesgo}^2 + \text{varianza} + \text{error irreducible}
\end{aligned}
\]</span> donde <span class="math inline">\(\mathbf{x}_0\)</span> hace referencia al vector de valores de las variables explicativas de una nueva observación (no empleada en la construcción del predictor).</p>
<p>En general, al aumentar la complejidad disminuye el sesgo y aumenta la varianza (y viceversa). Esto es lo que se conoce como el dilema o compromiso entre el sesgo y la varianza (<em>bias-variance tradeoff</em>). La recomendación sería por tanto seleccionar los hiperparámetros (el modelo final) tratando de que haya un equilibrio entre el sesgo y la varianza (ver Figura <a href="const-eval.html#fig:biasvar">1.6</a>).</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:biasvar"></span>
<img src="images/Bias-variance_tradeoff.png" alt="Equilibrio entre sesgo y varianza (Fuente: Wikimedia Commons)." width="80%" />
<p class="caption">
Figura 1.6: Equilibrio entre sesgo y varianza (Fuente: <a href="https://commons.wikimedia.org/wiki/File:Bias_and_variance_contributing_to_total_error.svg">Wikimedia Commons</a>).
</p>
</div>
<!-- Sección <a href="const-eval.html#entrenamiento-test">1.3.2</a> -->
</div>
<div id="entrenamiento-test" class="section level3 hasAnchor" number="1.3.2">
<h3><span class="header-section-number">1.3.2</span> Datos de entrenamiento y datos de test<a href="const-eval.html#entrenamiento-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Como se mostró en la sección anterior, hay que tener mucho cuidado si se pretende evaluar la precisión de las predicciones empleando la muestra de entrenamiento. Si el número de observaciones no es muy grande, se puede entrenar el modelo con todos los datos y emplear técnicas de remuestreo para evaluar la precisión (típicamente validación cruzada o bootstrap). Aunque habría que asegurarse de que el procedimiento de remuestreo empleado es adecuado (por ejemplo, la presencia de dependencia requeriría de métodos más sofisticados).</p>
<p>Sin embargo, si el número de observaciones es grande, se suele emplear el procedimiento tradicional en ML, que consiste en particionar la base de datos en 2 (o incluso en 3) conjuntos (disjuntos):</p>
<ul>
<li><p>Conjunto de datos de entrenamiento (o aprendizaje) para construir los modelos.</p></li>
<li><p>Conjunto de datos de test para evaluar el rendimiento de los modelos (los errores observados en esta muestra servirán para aproximar lo que ocurriría con nuevas observaciones).</p></li>
</ul>
<p>Típicamente se selecciona al azar el 80 % de los datos como muestra de entrenamiento y el 20 % restante como muestra de test, aunque esto dependería del número de datos (los resultados serán aleatorios y su variabilidad dependerá principalmente del tamaño de las muestras). En R se puede realizar el particionamiento de los datos empleando la función <a href="https://rdrr.io/r/base/sample.html"><code>sample()</code></a> del paquete base (otra alternativa sería emplear la función <a href="https://rdrr.io/pkg/caret/man/createDataPartition.html"><code>createDataPartition()</code></a> del paquete <code>caret</code>, como se describe en la Sección <a href="caret.html#caret">1.6</a>).</p>
<p>Como ejemplo consideraremos el conjunto de datos <a href="https://rdrr.io/pkg/MASS/man/Boston.html"><code>Boston</code></a> del paquete <code>MASS</code> <span class="citation">(<a href="#ref-R-MASS" role="doc-biblioref">Ripley, 2023</a>)</span> que contiene, entre otros datos, la valoración de las viviendas (<code>medv</code>, mediana de los valores de las viviendas ocupadas, en miles de dólares) y el porcentaje de población con “menor estatus” (<code>lstat</code>) en los suburbios de Boston. Podemos construir las muestras de entrenamiento (80 %) y de test (20 %) con el siguiente código:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="const-eval.html#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Boston, <span class="at">package =</span> <span class="st">&quot;MASS&quot;</span>)</span>
<span id="cb10-2"><a href="const-eval.html#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb10-3"><a href="const-eval.html#cb10-3" aria-hidden="true" tabindex="-1"></a>nobs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(Boston)</span>
<span id="cb10-4"><a href="const-eval.html#cb10-4" aria-hidden="true" tabindex="-1"></a>itrain <span class="ot">&lt;-</span> <span class="fu">sample</span>(nobs, <span class="fl">0.8</span> <span class="sc">*</span> nobs)</span>
<span id="cb10-5"><a href="const-eval.html#cb10-5" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> Boston[itrain, ]</span>
<span id="cb10-6"><a href="const-eval.html#cb10-6" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> Boston[<span class="sc">-</span>itrain, ]</span></code></pre></div>
<p>Los datos de test deberían utilizarse únicamente para evaluar los modelos finales, no se deberían emplear para seleccionar hiperparámetros. Para seleccionarlos se podría volver a particionar los datos de entrenamiento, es decir, dividir la muestra en tres subconjuntos: datos de entrenamiento, de validación y de test (por ejemplo considerando un 70 %, 15 % y 15 % de las observaciones, respectivamente). Para cada combinación de hiperparámetros se ajustaría el correspondiente modelo con los datos de entrenamiento, se emplearían los de validación para evaluarlos y posteriormente seleccionar los valores “óptimos”. Por último, se emplean los datos de test para evaluar el rendimiento del modelo seleccionado. No obstante, lo más habitual es seleccionar los hiperparámetros empleando validación cruzada (u otro tipo de remuestreo) en la muestra de entrenamiento, en lugar de considerar una muestra adicional de validación. En la siguiente sección se tratará esta última aproximación. En la Sección <a href="bagging.html#bagging">4.1</a> (Bagging) se describirá cómo usar remuestreo para evaluar la precisión de las predicciones y su aplicación para la selección de hiperparámetros.</p>
<!-- Sección <a href="const-eval.html#cv">1.3.3</a> -->
</div>
<div id="cv" class="section level3 hasAnchor" number="1.3.3">
<h3><span class="header-section-number">1.3.3</span> Selección de hiperparámetros mediante validación cruzada<a href="const-eval.html#cv" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Como se mencionó anteriormente, una herramienta para evaluar la calidad predictiva de un modelo es la <em>validación cruzada</em> (CV, <em>cross-validation</em>), que permite cuantificar el error de predicción utilizando una única muestra de datos. En su versión más simple, validación cruzada dejando uno fuera (<em>leave-one-out cross-validation</em>, LOOCV), para cada observación de la muestra se realiza un ajuste empleando el resto de las observaciones, y se mide el error de predicción en esa observación (único dato no utilizado en el ajuste del modelo). Finalmente, combinando todos los errores individuales se pueden obtener medidas globales del error de predicción (o aproximar otras características de su distribución).</p>
<p>El método de LOOCV requeriría, en principio (ver comentarios más adelante), el ajuste de un modelo para cada observación, por lo que pueden aparecer problemas computacionales si el conjunto de datos es grande. En este caso se suelen emplear grupos de observaciones en lugar de observaciones individuales. Si se particiona el conjunto de datos en <em>k</em> grupos, típicamente 10 o 5 grupos, se denomina <em>k-fold cross-validation</em> (LOOCV sería un caso particular considerando un número de grupos igual al número de observaciones)<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a>. Hay muchas variaciones de este método, entre ellas particionar repetidamente de forma aleatoria los datos en un conjunto de entrenamiento y otro de validación (de esta forma, algunas observaciones podrían aparecer repetidas varias veces y otras ninguna en las muestras de validación).</p>
<p>Continuando con el ejemplo anterior, supongamos que queremos emplear regresión polinómica para explicar la valoración de las viviendas a partir del “estatus” de los residentes (ver Figura <a href="const-eval.html#fig:boston-mass">1.7</a>). Al igual que se hizo en la Sección <a href="const-eval.html#bias-variance">1.3.1</a>, consideraremos el grado del polinomio como un hiperparámetro.</p>

<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="const-eval.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(medv <span class="sc">~</span> lstat, <span class="at">data =</span> train)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:boston-mass"></span>
<img src="01-introduccion_files/figure-html/boston-mass-1.png" alt="Gráfico de dispersión de las valoraciones de las viviendas (medv) frente al porcentaje de población con “menor estatus” (lstat)." width="75%" />
<p class="caption">
Figura 1.7: Gráfico de dispersión de las valoraciones de las viviendas (<code>medv</code>) frente al porcentaje de población con “menor estatus” (<code>lstat</code>).
</p>
</div>
<p>Podríamos emplear la siguiente función que devuelve para cada observación (fila) de una muestra de entrenamiento, el error de predicción en esa observación ajustando un modelo lineal con todas las demás observaciones:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="const-eval.html#cb12-1" aria-hidden="true" tabindex="-1"></a>cv.lm0 <span class="ot">&lt;-</span> <span class="cf">function</span>(formula, datos) {</span>
<span id="cb12-2"><a href="const-eval.html#cb12-2" aria-hidden="true" tabindex="-1"></a>    respuesta <span class="ot">&lt;-</span> <span class="fu">as.character</span>(formula)[<span class="dv">2</span>] <span class="co"># extraer nombre variable respuesta</span></span>
<span id="cb12-3"><a href="const-eval.html#cb12-3" aria-hidden="true" tabindex="-1"></a>    n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(datos)</span>
<span id="cb12-4"><a href="const-eval.html#cb12-4" aria-hidden="true" tabindex="-1"></a>    cv.res <span class="ot">&lt;-</span> <span class="fu">numeric</span>(n)</span>
<span id="cb12-5"><a href="const-eval.html#cb12-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n) {</span>
<span id="cb12-6"><a href="const-eval.html#cb12-6" aria-hidden="true" tabindex="-1"></a>        modelo <span class="ot">&lt;-</span> <span class="fu">lm</span>(formula, datos[<span class="sc">-</span>i, ])</span>
<span id="cb12-7"><a href="const-eval.html#cb12-7" aria-hidden="true" tabindex="-1"></a>        cv.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelo, <span class="at">newdata =</span> datos[i, ])</span>
<span id="cb12-8"><a href="const-eval.html#cb12-8" aria-hidden="true" tabindex="-1"></a>        cv.res[i] <span class="ot">&lt;-</span> cv.pred <span class="sc">-</span> datos[i, respuesta]</span>
<span id="cb12-9"><a href="const-eval.html#cb12-9" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb12-10"><a href="const-eval.html#cb12-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(cv.res)</span>
<span id="cb12-11"><a href="const-eval.html#cb12-11" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>La función anterior no es muy eficiente, pero se podría modificar fácilmente para otros métodos de regresión<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a>. En el caso de regresión lineal múltiple (y de otros predictores lineales), se pueden obtener fácilmente las predicciones eliminando una de las observaciones a partir del ajuste con todos los datos. Por ejemplo, en lugar de la anterior, sería preferible emplear la siguiente función (consultar la ayuda de <a href="https://rdrr.io/r/stats/influence.measures.html"><code>rstandard()</code></a>):</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="const-eval.html#cb13-1" aria-hidden="true" tabindex="-1"></a>cv.lm <span class="ot">&lt;-</span> <span class="cf">function</span>(formula, datos) {</span>
<span id="cb13-2"><a href="const-eval.html#cb13-2" aria-hidden="true" tabindex="-1"></a>    modelo <span class="ot">&lt;-</span> <span class="fu">lm</span>(formula, datos)</span>
<span id="cb13-3"><a href="const-eval.html#cb13-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">rstandard</span>(modelo, <span class="at">type =</span> <span class="st">&quot;predictive&quot;</span>))</span>
<span id="cb13-4"><a href="const-eval.html#cb13-4" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Empleando esta función, podemos calcular una medida del error de predicción de validación cruzada (en este caso el error cuadrático medio) para cada valor del hiperparámetro (grado del ajuste polinómico) y seleccionar el que lo minimiza (ver Figura <a href="const-eval.html#fig:cv-mse">1.8</a>).</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="const-eval.html#cb14-1" aria-hidden="true" tabindex="-1"></a>grado.max <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb14-2"><a href="const-eval.html#cb14-2" aria-hidden="true" tabindex="-1"></a>grados <span class="ot">&lt;-</span> <span class="fu">seq_len</span>(grado.max) </span>
<span id="cb14-3"><a href="const-eval.html#cb14-3" aria-hidden="true" tabindex="-1"></a>cv.mse <span class="ot">&lt;-</span> cv.mse.sd <span class="ot">&lt;-</span> <span class="fu">numeric</span>(grado.max)</span>
<span id="cb14-4"><a href="const-eval.html#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(grado <span class="cf">in</span> grados){</span>
<span id="cb14-5"><a href="const-eval.html#cb14-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Tiempo de computación elevado!</span></span>
<span id="cb14-6"><a href="const-eval.html#cb14-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># cv.res &lt;- cv.lm0(medv ~ poly(lstat, grado), train) </span></span>
<span id="cb14-7"><a href="const-eval.html#cb14-7" aria-hidden="true" tabindex="-1"></a>  cv.res <span class="ot">&lt;-</span> <span class="fu">cv.lm</span>(medv <span class="sc">~</span> <span class="fu">poly</span>(lstat, grado), train)</span>
<span id="cb14-8"><a href="const-eval.html#cb14-8" aria-hidden="true" tabindex="-1"></a>  se <span class="ot">&lt;-</span> cv.res<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb14-9"><a href="const-eval.html#cb14-9" aria-hidden="true" tabindex="-1"></a>  cv.mse[grado] <span class="ot">&lt;-</span> <span class="fu">mean</span>(se)</span>
<span id="cb14-10"><a href="const-eval.html#cb14-10" aria-hidden="true" tabindex="-1"></a>  cv.mse.sd[grado] <span class="ot">&lt;-</span> <span class="fu">sd</span>(se)<span class="sc">/</span><span class="fu">sqrt</span>(<span class="fu">length</span>(se))</span>
<span id="cb14-11"><a href="const-eval.html#cb14-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb14-12"><a href="const-eval.html#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(grados, cv.mse, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">45</span>), <span class="at">xlab =</span> <span class="st">&quot;Grado del polinomio&quot;</span>)</span>
<span id="cb14-13"><a href="const-eval.html#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Valor óptimo</span></span>
<span id="cb14-14"><a href="const-eval.html#cb14-14" aria-hidden="true" tabindex="-1"></a>imin.mse <span class="ot">&lt;-</span> <span class="fu">which.min</span>(cv.mse)</span>
<span id="cb14-15"><a href="const-eval.html#cb14-15" aria-hidden="true" tabindex="-1"></a>grado.min <span class="ot">&lt;-</span> grados[imin.mse]</span>
<span id="cb14-16"><a href="const-eval.html#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(grado.min, cv.mse[imin.mse], <span class="at">pch =</span> <span class="dv">16</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cv-mse"></span>
<img src="01-introduccion_files/figure-html/cv-mse-1.png" alt="Error cuadrático medio de validación cruzada dependiendo del grado del polinomio (complejidad)  y valor seleccionado con el criterio de un error estándar (punto sólido)." width="75%" />
<p class="caption">
Figura 1.8: Error cuadrático medio de validación cruzada dependiendo del grado del polinomio (complejidad) y valor seleccionado con el criterio de un error estándar (punto sólido).
</p>
</div>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="const-eval.html#cb15-1" aria-hidden="true" tabindex="-1"></a>grado.min</span></code></pre></div>
<pre><code>## [1] 5</code></pre>
<p>En lugar de emplear los valores óptimos de los hiperparámetros, <span class="citation">Breiman et al. (<a href="#ref-breiman1984classification" role="doc-biblioref">1984</a>)</span> propusieron la regla de “un error estándar” para seleccionar la complejidad del modelo. La idea es que estamos trabajando con estimaciones de la precisión y pueden presentar variabilidad (si cambiamos la muestra o cambiamos la partición, los resultados seguramente cambiarán), por lo que la sugerencia es seleccionar el modelo más simple<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a> dentro de un error estándar de la precisión del modelo correspondiente al valor óptimo (se consideraría que no hay diferencias significativas en la precisión; además, se mitigaría el efecto de la variabilidad debida a aleatoriedad, incluyendo la inducida por la elección de la semilla; ver figuras <a href="const-eval.html#fig:cv-onese">1.9</a> y <a href="const-eval.html#fig:boston-final">1.10</a>).</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="const-eval.html#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(grados, cv.mse, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">45</span>),</span>
<span id="cb17-2"><a href="const-eval.html#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;Grado del polinomio&quot;</span>)</span>
<span id="cb17-3"><a href="const-eval.html#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(grados, cv.mse <span class="sc">-</span> cv.mse.sd, grados, cv.mse <span class="sc">+</span> cv.mse.sd)</span>
<span id="cb17-4"><a href="const-eval.html#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Límite superior &quot;oneSE rule&quot; </span></span>
<span id="cb17-5"><a href="const-eval.html#cb17-5" aria-hidden="true" tabindex="-1"></a>upper.cv.mse <span class="ot">&lt;-</span> cv.mse[imin.mse] <span class="sc">+</span> cv.mse.sd[imin.mse]</span>
<span id="cb17-6"><a href="const-eval.html#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> upper.cv.mse, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb17-7"><a href="const-eval.html#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Complejidad mínima por debajo del límite</span></span>
<span id="cb17-8"><a href="const-eval.html#cb17-8" aria-hidden="true" tabindex="-1"></a>imin<span class="fl">.1</span>se <span class="ot">&lt;-</span> <span class="fu">min</span>(<span class="fu">which</span>(cv.mse <span class="sc">&lt;=</span> upper.cv.mse))</span>
<span id="cb17-9"><a href="const-eval.html#cb17-9" aria-hidden="true" tabindex="-1"></a>grado<span class="fl">.1</span>se <span class="ot">&lt;-</span> grados[imin<span class="fl">.1</span>se]</span>
<span id="cb17-10"><a href="const-eval.html#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(grado<span class="fl">.1</span>se, cv.mse[imin<span class="fl">.1</span>se], <span class="at">pch =</span> <span class="dv">16</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cv-onese"></span>
<img src="01-introduccion_files/figure-html/cv-onese-1.png" alt="Error cuadrático medio de validación cruzada dependiendo del grado del polinomio (complejidad) y valor seleccionado con el criterio de un error estándar (punto sólido)." width="75%" />
<p class="caption">
Figura 1.9: Error cuadrático medio de validación cruzada dependiendo del grado del polinomio (complejidad) y valor seleccionado con el criterio de un error estándar (punto sólido).
</p>
</div>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="const-eval.html#cb18-1" aria-hidden="true" tabindex="-1"></a>grado<span class="fl">.1</span>se</span></code></pre></div>
<pre><code>## [1] 2</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="const-eval.html#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(medv <span class="sc">~</span> lstat, <span class="at">data =</span> train)</span>
<span id="cb20-2"><a href="const-eval.html#cb20-2" aria-hidden="true" tabindex="-1"></a>fit.min <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> <span class="fu">poly</span>(lstat, grado.min), train)</span>
<span id="cb20-3"><a href="const-eval.html#cb20-3" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.1</span>se <span class="ot">&lt;-</span> <span class="fu">lm</span>(medv <span class="sc">~</span> <span class="fu">poly</span>(lstat, grado<span class="fl">.1</span>se), train)</span>
<span id="cb20-4"><a href="const-eval.html#cb20-4" aria-hidden="true" tabindex="-1"></a>newdata <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">lstat =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">40</span>, <span class="at">len =</span> <span class="dv">100</span>))</span>
<span id="cb20-5"><a href="const-eval.html#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(newdata<span class="sc">$</span>lstat, <span class="fu">predict</span>(fit.min, <span class="at">newdata =</span> newdata))</span>
<span id="cb20-6"><a href="const-eval.html#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(newdata<span class="sc">$</span>lstat, <span class="fu">predict</span>(fit<span class="fl">.1</span>se, <span class="at">newdata =</span> newdata), <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb20-7"><a href="const-eval.html#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="fu">paste</span>(<span class="st">&quot;Grado óptimo:&quot;</span>, grado.min), </span>
<span id="cb20-8"><a href="const-eval.html#cb20-8" aria-hidden="true" tabindex="-1"></a>       <span class="fu">paste</span>(<span class="st">&quot;oneSE rule:&quot;</span>, grado<span class="fl">.1</span>se)), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:boston-final"></span>
<img src="01-introduccion_files/figure-html/boston-final-1.png" alt="Ajuste de los modelos finales, empleando el valor óptimo (línea continua) y el criterio de un error estándar (línea discontinua) para seleccionar el grado del polinomio mediante validación cruzada." width="75%" />
<p class="caption">
Figura 1.10: Ajuste de los modelos finales, empleando el valor óptimo (línea continua) y el criterio de un error estándar (línea discontinua) para seleccionar el grado del polinomio mediante validación cruzada.
</p>
</div>
<p>Es importante destacar que la selección aleatoria puede no ser muy adecuada en el caso de dependencia, por ejemplo, para series de tiempo. En este caso se suele emplear el denominado <em>rolling forecasting</em>, considerando las observaciones finales como conjunto de validación, y para predecir en cada una de ellas se ajusta el modelo considerando únicamente observaciones anteriores <span class="citation">(para más detalles, ver por ejemplo la <a href="https://otexts.com/fpp3/tscv.html" role="doc-biblioref">Sección 5.10</a> de <a href="#ref-hyndman2021forecasting" role="doc-biblioref">Hyndman y Athanasopoulos, 2021</a>)</span>.</p>
</div>
<div id="eval-reg" class="section level3 hasAnchor" number="1.3.4">
<h3><span class="header-section-number">1.3.4</span> Evaluación de un método de regresión<a href="const-eval.html#eval-reg" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para estudiar la precisión de las predicciones de un método de regresión se evalúa el modelo en el conjunto de datos de test y se comparan las predicciones frente a los valores reales. Los resultados servirán como medidas globales de la calidad de las predicciones con nuevas observaciones.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="const-eval.html#cb21-1" aria-hidden="true" tabindex="-1"></a>obs <span class="ot">&lt;-</span> test<span class="sc">$</span>medv</span>
<span id="cb21-2"><a href="const-eval.html#cb21-2" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit.min, <span class="at">newdata =</span> test)</span></code></pre></div>
<p>Si generamos un gráfico de dispersión de observaciones frente a predicciones<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a>, los puntos deberían estar en torno a la recta <span class="math inline">\(y=x\)</span> (ver Figura <a href="const-eval.html#fig:obs-pred-plot">1.11</a>).</p>
<!-- 
Volver a intentar incluir latex en leyenda con referencia externa:
(ref:obs-pred) Gráfico de dispersión de observaciones frente a predicciones, incluyendo la recta $x=y$ (línea continua) y el ajuste lineal (línea discontinua). 
-->
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="const-eval.html#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(pred, obs, <span class="at">xlab =</span> <span class="st">&quot;Predicción&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Observado&quot;</span>)</span>
<span id="cb22-2"><a href="const-eval.html#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> <span class="dv">0</span>, <span class="at">b =</span> <span class="dv">1</span>)</span>
<span id="cb22-3"><a href="const-eval.html#cb22-3" aria-hidden="true" tabindex="-1"></a>res <span class="ot">&lt;-</span> <span class="fu">lm</span>(obs <span class="sc">~</span> pred)</span>
<span id="cb22-4"><a href="const-eval.html#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># summary(res)</span></span>
<span id="cb22-5"><a href="const-eval.html#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(res, <span class="at">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:obs-pred-plot"></span>
<img src="01-introduccion_files/figure-html/obs-pred-plot-1.png" alt="Gráfico de dispersión de observaciones frente a predicciones (incluyendo la identidad, línea continua, y el ajuste lineal, línea discontinua)." width="75%" />
<p class="caption">
Figura 1.11: Gráfico de dispersión de observaciones frente a predicciones (incluyendo la identidad, línea continua, y el ajuste lineal, línea discontinua).
</p>
</div>
<p>Este gráfico está implementado en la función <a href="https://rubenfcasal.github.io/mpae/reference/pred.plot.html"><code>pred.plot()</code></a> del paquete <a href="https://rubenfcasal.github.io/mpae"><code>mpae</code></a> (aunque por defecto añade el suavizado robusto <code>lowess(pred, obs)</code>).</p>
<p>También es habitual calcular distintas medidas de error. Por ejemplo, podríamos emplear la función <code>postResample()</code> del paquete <code>caret</code>:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="const-eval.html#cb23-1" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">postResample</span>(pred, obs)</span></code></pre></div>
<pre><code>##     RMSE Rsquared      MAE 
##  4.85267  0.62596  3.66718</code></pre>
<p>La función anterior, además de las medidas de error habituales (que dependen en su mayoría de la escala de la variable respuesta), calcula un <em>pseudo R-cuadrado</em>. En este paquete (y en muchos otros, como <code>tidymodels</code> o <code>rattle</code>) se emplea uno de los más utilizados, el cuadrado del coeficiente de correlación entre las predicciones y los valores observados (que se corresponde con la línea discontinua en la Figura <a href="const-eval.html#fig:obs-pred-plot">1.11</a>). Su valor se suele interpretar como el del coeficiente de determinación en regresión lineal (aunque únicamente es una medida de correlación), y sería deseable que su valor fuese próximo a 1. Hay otras alternativas <span class="citation">(ver <a href="#ref-kvaalseth1985cautionary" role="doc-biblioref">Kvålseth, 1985</a>)</span>, pero la idea es que deberían medir la proporción de variabilidad de la respuesta (en nuevas observaciones) explicada por el modelo, algo que en general no es cierto con el anterior<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a>. La recomendación sería utilizar: <span class="math display">\[\tilde R^2 = 1 - \frac{\sum_{i=1}^n(y_i - \hat y_i)^2}{\sum_{i=1}^n(y_i - \bar y)^2}\]</span> (que sería una medida equivalente al coeficiente de determinación ajustado en regresión múltiple, pero sin depender de hipótesis estructurales del modelo), implementado junto con otras medidas en la siguiente función (incluida en el paquete <a href="https://rubenfcasal.github.io/mpae"><code>mpae</code></a>):</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="const-eval.html#cb25-1" aria-hidden="true" tabindex="-1"></a>accuracy <span class="ot">&lt;-</span> <span class="cf">function</span>(pred, obs, <span class="at">na.rm =</span> <span class="cn">FALSE</span>, </span>
<span id="cb25-2"><a href="const-eval.html#cb25-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">tol =</span> <span class="fu">sqrt</span>(.Machine<span class="sc">$</span>double.eps)) {</span>
<span id="cb25-3"><a href="const-eval.html#cb25-3" aria-hidden="true" tabindex="-1"></a>  err <span class="ot">&lt;-</span> obs <span class="sc">-</span> pred     <span class="co"># Errores</span></span>
<span id="cb25-4"><a href="const-eval.html#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(na.rm) {</span>
<span id="cb25-5"><a href="const-eval.html#cb25-5" aria-hidden="true" tabindex="-1"></a>    is.a <span class="ot">&lt;-</span> <span class="sc">!</span><span class="fu">is.na</span>(err)</span>
<span id="cb25-6"><a href="const-eval.html#cb25-6" aria-hidden="true" tabindex="-1"></a>    err <span class="ot">&lt;-</span> err[is.a]</span>
<span id="cb25-7"><a href="const-eval.html#cb25-7" aria-hidden="true" tabindex="-1"></a>    obs <span class="ot">&lt;-</span> obs[is.a]</span>
<span id="cb25-8"><a href="const-eval.html#cb25-8" aria-hidden="true" tabindex="-1"></a>  }  </span>
<span id="cb25-9"><a href="const-eval.html#cb25-9" aria-hidden="true" tabindex="-1"></a>  perr <span class="ot">&lt;-</span> <span class="dv">100</span><span class="sc">*</span>err<span class="sc">/</span><span class="fu">pmax</span>(obs, tol)  <span class="co"># Errores porcentuales</span></span>
<span id="cb25-10"><a href="const-eval.html#cb25-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">c</span>(</span>
<span id="cb25-11"><a href="const-eval.html#cb25-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">me =</span> <span class="fu">mean</span>(err),           <span class="co"># Error medio</span></span>
<span id="cb25-12"><a href="const-eval.html#cb25-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">rmse =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(err<span class="sc">^</span><span class="dv">2</span>)), <span class="co"># Raíz del error cuadrático medio </span></span>
<span id="cb25-13"><a href="const-eval.html#cb25-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">mae =</span> <span class="fu">mean</span>(<span class="fu">abs</span>(err)),     <span class="co"># Error absoluto medio</span></span>
<span id="cb25-14"><a href="const-eval.html#cb25-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">mpe =</span> <span class="fu">mean</span>(perr),         <span class="co"># Error porcentual medio</span></span>
<span id="cb25-15"><a href="const-eval.html#cb25-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">mape =</span> <span class="fu">mean</span>(<span class="fu">abs</span>(perr)),   <span class="co"># Error porcentual absoluto medio</span></span>
<span id="cb25-16"><a href="const-eval.html#cb25-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">r.squared =</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">sum</span>(err<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span><span class="fu">sum</span>((obs <span class="sc">-</span> <span class="fu">mean</span>(obs))<span class="sc">^</span><span class="dv">2</span>) <span class="co"># Pseudo R-cuadrado</span></span>
<span id="cb25-17"><a href="const-eval.html#cb25-17" aria-hidden="true" tabindex="-1"></a>  ))</span>
<span id="cb25-18"><a href="const-eval.html#cb25-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb25-19"><a href="const-eval.html#cb25-19" aria-hidden="true" tabindex="-1"></a>accu.min <span class="ot">&lt;-</span> <span class="fu">accuracy</span>(pred, obs)</span>
<span id="cb25-20"><a href="const-eval.html#cb25-20" aria-hidden="true" tabindex="-1"></a>accu.min</span></code></pre></div>
<pre><code>##        me      rmse       mae       mpe      mape r.squared 
##  -0.67313   4.85267   3.66718  -8.23225  19.70974   0.60867</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="const-eval.html#cb27-1" aria-hidden="true" tabindex="-1"></a>accu<span class="fl">.1</span>se <span class="ot">&lt;-</span> <span class="fu">accuracy</span>(<span class="fu">predict</span>(fit<span class="fl">.1</span>se, <span class="at">newdata =</span> test), obs)</span>
<span id="cb27-2"><a href="const-eval.html#cb27-2" aria-hidden="true" tabindex="-1"></a>accu<span class="fl">.1</span>se</span></code></pre></div>
<pre><code>##        me      rmse       mae       mpe      mape r.squared 
##  -0.92363   5.27974   4.12521  -9.00298  21.65124   0.53676</code></pre>
<p>En este caso concreto (con la semilla establecida anteriormente), estimaríamos que el ajuste polinómico con el grado óptimo (seleccionado al minimizar el error cuadrático medio de validación cruzada) explicaría un 60.9 % de la variabilidad de la respuesta en nuevas observaciones (un 7.2 % más que el modelo seleccionado con el criterio de un error estándar de Breiman).</p>
<div class="exercise">
<p><span id="exr:train-validate-test" class="exercise"><strong>Ejercicio 1.1  </strong></span>Considerando de nuevo el ejemplo anterior, particiona la muestra en datos de entrenamiento (70 %), de validación (15 %) y de test (15 %), para entrenar los modelos polinómicos, seleccionar el grado óptimo (el hiperparámetro) y evaluar las predicciones del modelo final, respectivamente.</p>
<p>Podría ser de utilidad el siguiente código (basado en la aproximación de <code>rattle</code>), que particiona los datos suponiendo que están almacenados en el data.frame <code>df</code>:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="const-eval.html#cb29-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> Boston</span>
<span id="cb29-2"><a href="const-eval.html#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb29-3"><a href="const-eval.html#cb29-3" aria-hidden="true" tabindex="-1"></a>nobs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(df)</span>
<span id="cb29-4"><a href="const-eval.html#cb29-4" aria-hidden="true" tabindex="-1"></a>itrain <span class="ot">&lt;-</span> <span class="fu">sample</span>(nobs, <span class="fl">0.7</span> <span class="sc">*</span> nobs)</span>
<span id="cb29-5"><a href="const-eval.html#cb29-5" aria-hidden="true" tabindex="-1"></a>inotrain <span class="ot">&lt;-</span> <span class="fu">setdiff</span>(<span class="fu">seq_len</span>(nobs), itrain)</span>
<span id="cb29-6"><a href="const-eval.html#cb29-6" aria-hidden="true" tabindex="-1"></a>ivalidate <span class="ot">&lt;-</span> <span class="fu">sample</span>(inotrain, <span class="fl">0.15</span> <span class="sc">*</span> nobs)</span>
<span id="cb29-7"><a href="const-eval.html#cb29-7" aria-hidden="true" tabindex="-1"></a>itest <span class="ot">&lt;-</span> <span class="fu">setdiff</span>(inotrain, ivalidate)</span>
<span id="cb29-8"><a href="const-eval.html#cb29-8" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> df[itrain, ]</span>
<span id="cb29-9"><a href="const-eval.html#cb29-9" aria-hidden="true" tabindex="-1"></a>validate <span class="ot">&lt;-</span> df[ivalidate, ]</span>
<span id="cb29-10"><a href="const-eval.html#cb29-10" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> df[itest, ]</span></code></pre></div>
<p>Alternativamente podríamos emplear la función <code>split()</code>, creando un factor que divida aleatoriamente los datos en tres grupos<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a>:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="const-eval.html#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb30-2"><a href="const-eval.html#cb30-2" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="at">train =</span> <span class="fl">0.7</span>, <span class="at">validate =</span> <span class="fl">0.15</span>, <span class="at">test =</span> <span class="fl">0.15</span>)</span>
<span id="cb30-3"><a href="const-eval.html#cb30-3" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">sample</span>( <span class="fu">rep</span>(<span class="fu">factor</span>(<span class="fu">seq_along</span>(p), <span class="at">labels =</span> <span class="fu">names</span>(p)),</span>
<span id="cb30-4"><a href="const-eval.html#cb30-4" aria-hidden="true" tabindex="-1"></a>                 <span class="at">times =</span> <span class="fu">nrow</span>(df)<span class="sc">*</span>p<span class="sc">/</span><span class="fu">sum</span>(p)) )</span>
<span id="cb30-5"><a href="const-eval.html#cb30-5" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">suppressWarnings</span>(<span class="fu">split</span>(df, f))</span>
<span id="cb30-6"><a href="const-eval.html#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(samples, <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## List of 3
##  $ train   :&#39;data.frame&#39;:    356 obs. of  14 variables:
##  $ validate:&#39;data.frame&#39;:    75 obs. of  14 variables:
##  $ test    :&#39;data.frame&#39;:    75 obs. of  14 variables:</code></pre>
</div>
</div>
<div id="eval-class" class="section level3 hasAnchor" number="1.3.5">
<h3><span class="header-section-number">1.3.5</span> Evaluación de un método de clasificación<a href="const-eval.html#eval-class" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para estudiar la eficiencia de un método de clasificación supervisada típicamente se obtienen las predicciones para el conjunto de datos de test y se genera una tabla de contingencia, denominada <em>matriz de confusión</em>, comparando las predicciones con los valores reales.</p>
<p>En primer lugar, consideraremos el caso de dos categorías. La matriz de confusión será de la forma:</p>
<table>
<colgroup>
<col width="29%" />
<col width="35%" />
<col width="35%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Observado/Predicción</th>
<th align="center">Positivo</th>
<th align="center">Negativo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Positivo</td>
<td align="center">Verdaderos positivos (TP)</td>
<td align="center">Falsos negativos (FN)</td>
</tr>
<tr class="even">
<td align="center">Negativo</td>
<td align="center">Falsos positivos (FP)</td>
<td align="center">Verdaderos negativos (TN)</td>
</tr>
</tbody>
</table>
<p>A partir de esta tabla se pueden obtener distintas medidas de la precisión de las predicciones (serían medidas globales de la calidad de la predicción de nuevas observaciones). Por ejemplo, dos de las más utilizadas son la tasa de verdaderos positivos y la de verdaderos negativos (tasas de acierto en positivos y negativos), también denominadas <em>sensibilidad</em> y <em>especificidad</em>:</p>
<ul>
<li><p>Sensibilidad (<em>sensitivity</em>, <em>recall</em>, <em>hit rate</em>, <em>true positive rate</em>; TPR): <span class="math display">\[TPR = \frac{TP}{P} = \frac{TP}{TP+FN}\]</span></p></li>
<li><p>Especificidad (<em>specificity</em>, <em>true negative rate</em>; TNR): <span class="math display">\[TNR = \frac{TN}{TN+FP}\]</span></p></li>
</ul>
<p>La precisión global o tasa de aciertos (<em>accuracy</em>; ACC) sería: <span class="math display">\[ACC = \frac{TP + TN}{P + N} = \frac{TP+TN}{TP+TN+FP+FN}\]</span> Sin embargo, hay que tener cuidado con esta medida cuando las clases no están balanceadas. Otras medidas de la precisión global que tratan de evitar este problema son la <em>precisión balanceada</em> (<em>balanced accuracy</em>, BA): <span class="math display">\[BA = \frac{TPR + TNR}{2}\]</span> (media aritmética de TPR y TNR) o la <em>puntuación F1</em> (<em>F1 score</em>; media armónica de TPR y el valor predictivo positivo, PPV, descrito más adelante): <span class="math display">\[F_1 = \frac{2TP}{2TP+FP+FN}\]</span> Otra medida global es el coeficiente kappa de Cohen <span class="citation">(<a href="#ref-cohen1960" role="doc-biblioref">Cohen, 1960</a>)</span>, que compara la tasa de aciertos con la obtenida en una clasificación al azar (empleando la proporción de cada clase): <span class="math display">\[\kappa = \frac{2 (TP \cdot TN - FN \cdot FP)}{(TP + FP) (FP + TN) + (TP + FN) (FN + TN)}\]</span> Un valor de 1 indicaría máxima precisión y 0 que la precisión es igual a la que obtendríamos clasificando al azar.</p>
<p>También hay que ser cauteloso al emplear medidas que utilizan como estimación de la probabilidad de positivo (denominada <em>prevalencia</em>) la tasa de positivos en la muestra de test, como el valor (o índice) predictivo positivo (<em>precision</em>, <em>positive predictive value</em>; PPV): <span class="math display">\[PPV = \frac{TP}{TP+FP}\]</span> (que no debe ser confundido con la precisión global ACC) y el valor predictivo negativo (NPV): <span class="math display">\[NPV = \frac{TN}{TN+FN},\]</span> si la muestra de test no refleja lo que ocurre en la población (por ejemplo si la clase de interés está sobrerrepresentada en la muestra). En estos casos habrá que recalcularlos empleando estimaciones válidas de las probabilidades de la clases (por ejemplo, en estos casos, la función <code>caret::confusionMatrix()</code> permite establecer estimaciones válidas mediante el argumento <code>prevalence</code>).</p>
<p>Como ejemplo emplearemos los datos anteriores de valoraciones de viviendas y estatus de la población, considerando como respuesta una nueva variable <code>fmedv</code> que clasifica las valoraciones en “Bajo” o “Alto” dependiendo de si <code>medv &gt; 25</code>.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="const-eval.html#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># data(Boston, package = &quot;MASS&quot;)</span></span>
<span id="cb32-2"><a href="const-eval.html#cb32-2" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> Boston</span>
<span id="cb32-3"><a href="const-eval.html#cb32-3" aria-hidden="true" tabindex="-1"></a>datos<span class="sc">$</span>fmedv <span class="ot">&lt;-</span> <span class="fu">factor</span>(datos<span class="sc">$</span>medv <span class="sc">&gt;</span> <span class="dv">25</span>, <span class="co"># levels = c(&#39;FALSE&#39;, &#39;TRUE&#39;)</span></span>
<span id="cb32-4"><a href="const-eval.html#cb32-4" aria-hidden="true" tabindex="-1"></a>                      <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Bajo&quot;</span>, <span class="st">&quot;Alto&quot;</span>)) </span></code></pre></div>
<p>En este ejemplo, si realizamos un análisis descriptivo de la respuesta, podemos observar que las clases no están balanceadas:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="const-eval.html#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(datos<span class="sc">$</span>fmedv)</span></code></pre></div>
<pre><code>## 
## Bajo Alto 
##  382  124</code></pre>
<p>En este caso también emplearemos el estatus de los residentes (<code>lstat</code>) como único predictor. Como se puede observar en la Figura <a href="const-eval.html#fig:featureplot">1.12</a>, hay diferencias en su distribución dependiendo de la categoría, por lo que aparentemente es de utilidad para predecir el nivel de valoración de las viviendas.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="const-eval.html#cb35-1" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">featurePlot</span>(datos<span class="sc">$</span>lstat, datos<span class="sc">$</span>fmedv, <span class="at">plot =</span> <span class="st">&quot;density&quot;</span>,</span>
<span id="cb35-2"><a href="const-eval.html#cb35-2" aria-hidden="true" tabindex="-1"></a>                   <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;lstat&quot;</span>, <span class="st">&quot;Densidad&quot;</span>), <span class="at">auto.key =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:featureplot"></span>
<img src="01-introduccion_files/figure-html/featureplot-1.png" alt="Distribución del estatus de la población dependiendo del nivel de valoración de las viviendas." width="75%" />
<p class="caption">
Figura 1.12: Distribución del estatus de la población dependiendo del nivel de valoración de las viviendas.
</p>
</div>
<p>Como método de clasificación emplearemos regresión logística (este tipo de modelos se tratarán en la Sección <a href="reg-glm.html#reg-glm">2.2</a>). El siguiente código realiza la partición de los datos y ajusta este modelo, considerando <code>lstat</code> como única variable explicativa, a la muestra de entrenamiento:</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="const-eval.html#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Particionado de los datos</span></span>
<span id="cb36-2"><a href="const-eval.html#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb36-3"><a href="const-eval.html#cb36-3" aria-hidden="true" tabindex="-1"></a>nobs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(datos)</span>
<span id="cb36-4"><a href="const-eval.html#cb36-4" aria-hidden="true" tabindex="-1"></a>itrain <span class="ot">&lt;-</span> <span class="fu">sample</span>(nobs, <span class="fl">0.8</span> <span class="sc">*</span> nobs)</span>
<span id="cb36-5"><a href="const-eval.html#cb36-5" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> datos[itrain, ]</span>
<span id="cb36-6"><a href="const-eval.html#cb36-6" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> datos[<span class="sc">-</span>itrain, ]</span>
<span id="cb36-7"><a href="const-eval.html#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajuste modelo</span></span>
<span id="cb36-8"><a href="const-eval.html#cb36-8" aria-hidden="true" tabindex="-1"></a>modelo <span class="ot">&lt;-</span> <span class="fu">glm</span>(fmedv <span class="sc">~</span> lstat, <span class="at">family =</span> binomial, <span class="at">data =</span> train)</span>
<span id="cb36-9"><a href="const-eval.html#cb36-9" aria-hidden="true" tabindex="-1"></a>modelo</span></code></pre></div>
<pre><code>## 
## Call:  glm(formula = fmedv ~ lstat, family = binomial, data = train)
## 
## Coefficients:
## (Intercept)        lstat  
##       3.744       -0.542  
## 
## Degrees of Freedom: 403 Total (i.e. Null);  402 Residual
## Null Deviance:       461 
## Residual Deviance: 243   AIC: 247</code></pre>
<p>En este tipo de modelos podemos calcular las estimaciones de la probabilidad de la segunda categoría empleando <code>predict()</code> con <code>type = "response"</code>, a partir de las cuales podemos establecer las predicciones como la categoría más probable:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="const-eval.html#cb38-1" aria-hidden="true" tabindex="-1"></a>obs <span class="ot">&lt;-</span> test<span class="sc">$</span>fmedv</span>
<span id="cb38-2"><a href="const-eval.html#cb38-2" aria-hidden="true" tabindex="-1"></a>p.est <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelo, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>, <span class="at">newdata =</span> test)</span>
<span id="cb38-3"><a href="const-eval.html#cb38-3" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">factor</span>(p.est <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Bajo&quot;</span>, <span class="st">&quot;Alto&quot;</span>))</span></code></pre></div>
<p>Finalmente, podemos obtener la matriz de confusión en distintos formatos:</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="const-eval.html#cb39-1" aria-hidden="true" tabindex="-1"></a>tabla <span class="ot">&lt;-</span> <span class="fu">table</span>(obs, pred)</span>
<span id="cb39-2"><a href="const-eval.html#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="co"># addmargins(tabla, FUN = list(Total = sum))</span></span>
<span id="cb39-3"><a href="const-eval.html#cb39-3" aria-hidden="true" tabindex="-1"></a>tabla</span></code></pre></div>
<pre><code>##       pred
## obs    Bajo Alto
##   Bajo   71   11
##   Alto    8   12</code></pre>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="const-eval.html#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Porcentajes respecto al total</span></span>
<span id="cb41-2"><a href="const-eval.html#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="dv">100</span><span class="sc">*</span><span class="fu">prop.table</span>(tabla), <span class="at">digits =</span> <span class="dv">2</span>) </span></code></pre></div>
<pre><code>##       pred
## obs    Bajo Alto
##   Bajo 69.6 10.8
##   Alto  7.8 11.8</code></pre>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="const-eval.html#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Porcentajes (de aciertos y fallos) por categorías</span></span>
<span id="cb43-2"><a href="const-eval.html#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="dv">100</span><span class="sc">*</span><span class="fu">prop.table</span>(tabla, <span class="dv">1</span>), <span class="at">digits =</span> <span class="dv">3</span>) </span></code></pre></div>
<pre><code>##       pred
## obs    Bajo Alto
##   Bajo 86.6 13.4
##   Alto 40.0 60.0</code></pre>
<p>Alternativamente, podemos emplear la función <a href="https://rdrr.io/pkg/caret/man/confusionMatrix.html"><code>confusionMatrix()</code></a> del paquete <code>caret</code>, que proporciona distintas medidas de precisión:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="const-eval.html#cb45-1" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">confusionMatrix</span>(pred, obs, <span class="at">positive =</span> <span class="st">&quot;Alto&quot;</span>, <span class="at">mode =</span> <span class="st">&quot;everything&quot;</span>)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction Bajo Alto
##       Bajo   71    8
##       Alto   11   12
##                                         
##                Accuracy : 0.814         
##                  95% CI : (0.724, 0.884)
##     No Information Rate : 0.804         
##     P-Value [Acc &gt; NIR] : 0.460         
##                                         
##                   Kappa : 0.441         
##                                         
##  Mcnemar&#39;s Test P-Value : 0.646         
##                                         
##             Sensitivity : 0.600         
##             Specificity : 0.866         
##          Pos Pred Value : 0.522         
##          Neg Pred Value : 0.899         
##               Precision : 0.522         
##                  Recall : 0.600         
##                      F1 : 0.558         
##              Prevalence : 0.196         
##          Detection Rate : 0.118         
##    Detection Prevalence : 0.225         
##       Balanced Accuracy : 0.733         
##                                         
##        &#39;Positive&#39; Class : Alto          
## </code></pre>
<p>Si el método de clasificación proporciona estimaciones de las probabilidades de las categorías, disponemos de más información en la clasificación que también podemos emplear en la evaluación del rendimiento. Por ejemplo, se puede realizar un análisis descriptivo de las probabilidades estimadas y las categorías observadas en la muestra de test (ver Figura <a href="const-eval.html#fig:classprob">1.13</a>):</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="const-eval.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Imitamos la función caret::plotClassProbs()</span></span>
<span id="cb47-2"><a href="const-eval.html#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lattice) </span>
<span id="cb47-3"><a href="const-eval.html#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="fu">histogram</span>(<span class="sc">~</span> p.est <span class="sc">|</span> obs, <span class="at">xlab =</span> <span class="st">&quot;Probabilidad estimada&quot;</span>, </span>
<span id="cb47-4"><a href="const-eval.html#cb47-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">ylab =</span> <span class="st">&quot;Porcentaje (de la categoría)&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:classprob"></span>
<img src="01-introduccion_files/figure-html/classprob-1.png" alt="Distribución de las probabilidades estimadas de valoración alta de la vivienda dependiendo de la categoría observada." width="80%" />
<p class="caption">
Figura 1.13: Distribución de las probabilidades estimadas de valoración alta de la vivienda dependiendo de la categoría observada.
</p>
</div>
<p>Para evaluar las estimaciones de las probabilidades se suele emplear la curva ROC (<em>receiver operating characteristics</em>, característica operativa del receptor; diseñada inicialmente en el campo de la detección de señales). Como ya se comentó, normalmente se emplea <span class="math inline">\(c = 0.5\)</span> como punto de corte para clasificar en la categoría de interés (<em>regla de Bayes</em>), aunque se podrían considerar otros valores (por ejemplo, para mejorar la clasificación en una de las categorías, a costa de empeorar la precisión global). En la curva ROC se representa la sensibilidad (TPR) frente a la tasa de falsos negativos (FNR = 1 <span class="math inline">\(-\)</span> TNR = 1 <span class="math inline">\(-\)</span> especificidad) para distintos valores de corte (ver Figura <a href="const-eval.html#fig:ROC-curve">1.14</a>). Para ello se puede emplear el paquete <code>pROC</code> <span class="citation">(<a href="#ref-R-pROC" role="doc-biblioref">Robin et al., 2011</a>)</span>:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="const-eval.html#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC)</span>
<span id="cb48-2"><a href="const-eval.html#cb48-2" aria-hidden="true" tabindex="-1"></a>roc_glm <span class="ot">&lt;-</span> <span class="fu">roc</span>(<span class="at">response =</span> obs, <span class="at">predictor =</span> p.est)</span>
<span id="cb48-3"><a href="const-eval.html#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(roc_glm, <span class="at">xlab =</span> <span class="st">&quot;Especificidad&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Sensibilidad&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ROC-curve"></span>
<img src="01-introduccion_files/figure-html/ROC-curve-1.png" alt="Curva ROC correspondiente al modelo de regresión logística." width="75%" />
<p class="caption">
Figura 1.14: Curva ROC correspondiente al modelo de regresión logística.
</p>
</div>
<!-- 
View((as.data.frame(roc_glm[2:4])))
plot(roc_glm, legacy.axes = TRUE, print.thres = 0.5)
-->
<p>Lo ideal sería que la curva se aproximase a la esquina superior izquierda (máxima sensibilidad y especificidad). La recta diagonal se correspondería con un clasificador aleatorio. Una medida global del rendimiento del clasificador es el área bajo la curva ROC (AUC; equivalente al estadístico U de Mann-Whitney o al índice de Gini). Un clasificador perfecto tendría un valor de 1, mientras que un clasificador aleatorio tendría un valor de 0.5.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="const-eval.html#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># roc_glm$auc</span></span>
<span id="cb49-2"><a href="const-eval.html#cb49-2" aria-hidden="true" tabindex="-1"></a>roc_glm</span></code></pre></div>
<pre><code>## 
## Call:
## roc.default(response = obs, predictor = p.est)
## 
## Data: p.est in 82 controls (obs Bajo) &lt; 20 cases (obs Alto).
## Area under the curve: 0.843</code></pre>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="const-eval.html#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ci.auc</span>(roc_glm)</span></code></pre></div>
<pre><code>## 95% CI: 0.743-0.943 (DeLong)</code></pre>
<p>Como comentario adicional, aunque se puede modificar el punto de corte para mejorar la clasificación en la categoría de interés (de hecho, algunas herramientas como <code>h2o</code> lo modifican por defecto; en este caso concreto para maximizar <span class="math inline">\(F_1\)</span> en la muestra de entrenamiento), muchos métodos de clasificación (como los basados en árboles descritos en el Capítulo 2) admiten como opción una matriz de pérdidas que se tendrá en cuenta para medir la eficiencia durante el aprendizaje. Si está disponible, esta sería la aproximación recomendada.</p>
<p>En el caso de más de dos categorías podríamos generar una matriz de confusión de forma análoga, aunque en principio solo podríamos calcular medidas globales de la precisión como la tasa de aciertos o el coeficiente kappa de Cohen. Podríamos obtener también medidas por clase, como la sensibilidad y la especificidad, siguiendo la estrategia “uno contra todos” descrita en la Sección <a href="métodos-de-aprendizaje-estadístico.html#notacion">1.2.1</a>. Esta aproximación es la que sigue la función <code>confusionMatrix()</code> del paquete <code>caret</code> (devuelve las medidas comparando cada categoría con las restantes en el componente <code>$byClass</code>).</p>
<p>Como ejemplo ilustrativo, consideraremos el conocido conjunto de datos <code>iris</code> <span class="citation">(<a href="#ref-fisher1936use" role="doc-biblioref">Fisher, 1936</a>)</span>, en el que el objetivo es clasificar flores de lirio en tres especies (<code>Species</code>) a partir del largo y ancho de sépalos y pétalos, aunque en este caso emplearemos un clasificador aleatorio.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="const-eval.html#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb53-2"><a href="const-eval.html#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Partición de los datos</span></span>
<span id="cb53-3"><a href="const-eval.html#cb53-3" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> iris</span>
<span id="cb53-4"><a href="const-eval.html#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb53-5"><a href="const-eval.html#cb53-5" aria-hidden="true" tabindex="-1"></a>nobs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(datos)</span>
<span id="cb53-6"><a href="const-eval.html#cb53-6" aria-hidden="true" tabindex="-1"></a>itrain <span class="ot">&lt;-</span> <span class="fu">sample</span>(nobs, <span class="fl">0.8</span> <span class="sc">*</span> nobs)</span>
<span id="cb53-7"><a href="const-eval.html#cb53-7" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> datos[itrain, ]</span>
<span id="cb53-8"><a href="const-eval.html#cb53-8" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> datos[<span class="sc">-</span>itrain, ]</span>
<span id="cb53-9"><a href="const-eval.html#cb53-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Entrenamiento </span></span>
<span id="cb53-10"><a href="const-eval.html#cb53-10" aria-hidden="true" tabindex="-1"></a>prevalences <span class="ot">&lt;-</span> <span class="fu">table</span>(train<span class="sc">$</span>Species)<span class="sc">/</span><span class="fu">nrow</span>(train)</span>
<span id="cb53-11"><a href="const-eval.html#cb53-11" aria-hidden="true" tabindex="-1"></a>prevalences</span></code></pre></div>
<pre><code>## 
##     setosa versicolor  virginica 
##    0.32500    0.31667    0.35833</code></pre>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="const-eval.html#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculo de las predicciones</span></span>
<span id="cb55-2"><a href="const-eval.html#cb55-2" aria-hidden="true" tabindex="-1"></a>levels <span class="ot">&lt;-</span> <span class="fu">names</span>(prevalences) <span class="co"># levels(train$Species)</span></span>
<span id="cb55-3"><a href="const-eval.html#cb55-3" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">factor</span>(levels, <span class="at">levels =</span> levels) </span>
<span id="cb55-4"><a href="const-eval.html#cb55-4" aria-hidden="true" tabindex="-1"></a>pred.rand <span class="ot">&lt;-</span> <span class="fu">sample</span>(f, <span class="fu">nrow</span>(test), <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> prevalences)</span>
<span id="cb55-5"><a href="const-eval.html#cb55-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluación</span></span>
<span id="cb55-6"><a href="const-eval.html#cb55-6" aria-hidden="true" tabindex="-1"></a>caret<span class="sc">::</span><span class="fu">confusionMatrix</span>(pred.rand, test<span class="sc">$</span>Species)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa          3          3         1
##   versicolor      4          2         5
##   virginica       4          7         1
## 
## Overall Statistics
##                                         
##                Accuracy : 0.2           
##                  95% CI : (0.077, 0.386)
##     No Information Rate : 0.4           
##     P-Value [Acc &gt; NIR] : 0.994         
##                                         
##                   Kappa : -0.186        
##                                         
##  Mcnemar&#39;s Test P-Value : 0.517         
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                  0.273            0.1667           0.1429
## Specificity                  0.789            0.5000           0.5217
## Pos Pred Value               0.429            0.1818           0.0833
## Neg Pred Value               0.652            0.4737           0.6667
## Prevalence                   0.367            0.4000           0.2333
## Detection Rate               0.100            0.0667           0.0333
## Detection Prevalence         0.233            0.3667           0.4000
## Balanced Accuracy            0.531            0.3333           0.3323</code></pre>
<!--
Ejercicio palmer penguins
Otro conjunto de datos alternativos es el conocido PalmerPenguins
-->
<!-- Sección <a href="dimen-curse.html#dimen-curse">1.4</a> -->
</div>
</div>
<h3>Bibliografía<a href="bibliografía.html#bibliografía" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-breiman1984classification" class="csl-entry">
Breiman, L., Friedman, J., Stone, C. J., y Olshen, R. A. (1984). <em>Classification and Regression Trees</em>. Taylor; Francis.
</div>
<div id="ref-R-boot" class="csl-entry">
Canty, A., y Ripley, B. D. (2024). <em><span>boot: Bootstrap R (S-Plus) Functions</span></em>.
</div>
<div id="ref-cohen1960" class="csl-entry">
Cohen, J. (1960). A Coefficient of Agreement for Nominal Scales. <em>Educational and Psychological Measurement</em>, <em>20</em>(1), 37-46. <a href="https://doi.org/10.1177/001316446002000104">https://doi.org/10.1177/001316446002000104</a>
</div>
<div id="ref-fisher1936use" class="csl-entry">
Fisher, R. A. (1936). The use of multiple measurements in taxonomic problems. <em>Annals of eugenics</em>, <em>7</em>(2), 179-188. <a href="https://doi.org/10.1111/j.1469-1809.1936.tb02137.x">https://doi.org/10.1111/j.1469-1809.1936.tb02137.x</a>
</div>
<div id="ref-R-cv" class="csl-entry">
Fox, J., y Monette, G. (2024). <em><span>cv: Cross-Validation of Regression Models</span></em>. <a href="https://cran.r-project.org/package=cv">https://cran.r-project.org/package=cv</a>
</div>
<div id="ref-hyndman2021forecasting" class="csl-entry">
Hyndman, R. J., y Athanasopoulos, G. (2021). <em>Forecasting: principles and practice</em> (3a. ed.). OTexts. <a href="https://otexts.com/fpp3" class="uri">https://otexts.com/fpp3</a>. <a href="https://otexts.com/fpp3">https://otexts.com/fpp3</a>
</div>
<div id="ref-kvaalseth1985cautionary" class="csl-entry">
Kvålseth, T. O. (1985). Cautionary note about <span>R2</span>. <em>The American Statistician</em>, <em>39</em>(4), 279-285. <a href="https://doi.org/10.1080/00031305.1985.10479448">https://doi.org/10.1080/00031305.1985.10479448</a>
</div>
<div id="ref-R-MASS" class="csl-entry">
Ripley, B. (2023). <em><span>MASS: Support Functions and Datasets for Venables and Ripley’s MASS</span></em>. <a href="https://cran.r-project.org/package=MASS">https://cran.r-project.org/package=MASS</a>
</div>
<div id="ref-R-pROC" class="csl-entry">
Robin, X., Turck, N., Hainard, A., Tiberti, N., Lisacek, F., Sanchez, J.-C., y Müller, M. (2011). <span>pROC: an open-source package for R and S+ to analyze and compare ROC curves</span>. <em>BMC Bioinformatics</em>, <em>12</em>, 77. <a href="https://cran.r-project.org/web/packages/pROC/">https://cran.r-project.org/web/packages/pROC/</a>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="10">
<li id="fn10"><p>Se podrían considerar otras funciones de pérdida, por ejemplo con la distancia <span class="math inline">\(L_1\)</span> sería la mediana condicional, pero las consideraciones serían análogas.<a href="const-eval.html#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>La partición en <em>k-fold</em> CV se suele realizar al azar. Hay que tener en cuenta la aleatoriedad al emplear <em>k-fold</em> CV, algo que no ocurre con LOOCV.<a href="const-eval.html#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>Pueden ser de interés el paquete <a href="https://CRAN.R-project.org/package=cv"><code>cv</code></a> <span class="citation">(<a href="#ref-R-cv" role="doc-biblioref">Fox y Monette, 2024</a>)</span> y también la función <code>cv.glm()</code> del paquete <a href="https://CRAN.R-project.org/package=boot"><code>boot</code></a> <span class="citation">(<a href="#ref-R-boot" role="doc-biblioref">Canty y Ripley, 2024</a>)</span>.<a href="const-eval.html#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p>Suponiendo que los modelos se pueden ordenar del más simple al más complejo.<a href="const-eval.html#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>Otras implementaciones, como la función <code>caret::plotObsVsPred()</code>, intercambian los ejes, generando un gráfico de dispersión de predicciones sobre observaciones.<a href="const-eval.html#fnref14" class="footnote-back">↩︎</a></p></li>
<li id="fn15"><p>Por ejemplo obtendríamos el mismo valor si desplazamos las predicciones sumando una constante (<em>i. e.</em> no tiene en cuenta el sesgo). Lo que interesaría sería medir la proximidad de los puntos a la recta <span class="math inline">\(y=x\)</span>.<a href="const-eval.html#fnref15" class="footnote-back">↩︎</a></p></li>
<li id="fn16"><p>Versión “simplificada” (y más eficiente) de una de las propuestas en el post <a href="https://stackoverflow.com/questions/36068963/r-how-to-split-a-data-frame-into-training-validation-and-test-sets">https://stackoverflow.com/questions/36068963</a>. En el caso de que la longitud del factor <code>f</code> no coincida con el número de filas (por redondeo), se generaría un <em>warning</em> (suprimido) y se reciclaría.<a href="const-eval.html#fnref16" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="métodos-de-aprendizaje-estadístico.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="dimen-curse.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rubenfcasal/book_mpae/edit/master/01-introduccion.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["book_mpae.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
